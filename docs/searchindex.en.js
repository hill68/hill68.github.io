var relearn_searchindex = [
  {
    "breadcrumb": "FlitSoft Docs \u003e  UAS",
    "content": "小型固定翼无人机飞行动力学模型为小型固定翼无人机仿真系统提供逼真的飞行动力学与飞行控制方案，替代当前的简单PID+运动学模型。文档涵盖系统需求、6-DOF动力学模型、级联控制架构、模块接口、参数标定及实现建议等内容。\nJSBSim User manual如何使用 JSBSim 进行模拟运行、创建飞行器模型、编写脚本，以及如何执行其他不涉及对 JSBSim 程序代码进行更改的任务。\nJSBSim Quickstart旨在让用户和开发者了解JSBSim软件的所有功能。",
    "description": "小型固定翼无人机飞行动力学模型为小型固定翼无人机仿真系统提供逼真的飞行动力学与飞行控制方案，替代当前的简单PID+运动学模型。文档涵盖系统需求、6-DOF动力学模型、级联控制架构、模块接口、参数标定及实现建议等内容。\nJSBSim User manual如何使用 JSBSim 进行模拟运行、创建飞行器模型、编写脚本，以及如何执行其他不涉及对 JSBSim 程序代码进行更改的任务。\nJSBSim Quickstart旨在让用户和开发者了解JSBSim软件的所有功能。",
    "tags": [],
    "title": "Aerodynamics",
    "uri": "/uas/fix_wing_uav_flight_sim/index.html"
  },
  {
    "breadcrumb": "FlitSoft Docs \u003e  UAS \u003e  Trajectory Planning",
    "content": "κ轨迹平滑κ轨迹生成算法。κ=1：轨迹以最短时间过渡到下一个航段；κ=0：轨迹执行一个最小时间过渡，并直接通过航路点；求解κ∈[0,1]使轨迹具有与原始航路点路径等长\nκ轨迹点生成代码说明针对模块化的κ轨迹点生成 C++ 代码的详细说明。用于在给定 κ∈ [0,1] 的条件下，在航路点之间生成平滑的 κ-轨迹点。\n无人机实时动态轨迹平滑一种实时、可行的轨迹生成算法，用于无人机通过一系列航路点飞行。 特别地，算法可配置为动态可行轨迹与直线航路点路径具有相同的路径长度。 该文还详细描述了与算法相关的实现问题。\n等长轨迹κ求解算法设计一种基于二分查找的数值方法，用以求解参数 κ，从而使得生成的 κ-轨迹路径长度与原始航路点路径长度完全一致。",
    "description": "κ轨迹平滑κ轨迹生成算法。κ=1：轨迹以最短时间过渡到下一个航段；κ=0：轨迹执行一个最小时间过渡，并直接通过航路点；求解κ∈[0,1]使轨迹具有与原始航路点路径等长\nκ轨迹点生成代码说明针对模块化的κ轨迹点生成 C++ 代码的详细说明。用于在给定 κ∈ [0,1] 的条件下，在航路点之间生成平滑的 κ-轨迹点。\n无人机实时动态轨迹平滑一种实时、可行的轨迹生成算法，用于无人机通过一系列航路点飞行。 特别地，算法可配置为动态可行轨迹与直线航路点路径具有相同的路径长度。 该文还详细描述了与算法相关的实现问题。\n等长轨迹κ求解算法设计一种基于二分查找的数值方法，用以求解参数 κ，从而使得生成的 κ-轨迹路径长度与原始航路点路径长度完全一致。",
    "tags": [],
    "title": "kappa-trajectories",
    "uri": "/uas/trajectory_planning/kappa-trajectories/index.html"
  },
  {
    "breadcrumb": "FlitSoft Docs \u003e  EM",
    "content": "辛格方向图模型This summary is independent of the content.\n高斯方向图模型This summary is independent of the content.",
    "description": "天线方向图模型",
    "tags": [],
    "title": "Antenna Pattern",
    "uri": "/em/antenna-pattern/index.html"
  },
  {
    "breadcrumb": "FlitSoft Docs \u003e  UAS \u003e  Path Searching",
    "content": "基于运动基元的A*算法将基于运动基元的A*算法从四旋翼无人机改进适配到固定翼无人机",
    "description": "基于运动基元的A*算法将基于运动基元的A*算法从四旋翼无人机改进适配到固定翼无人机",
    "tags": [],
    "title": "A* Path Searching",
    "uri": "/uas/path-searching/a-search/index.html"
  },
  {
    "breadcrumb": "FlitSoft Docs \u003e  UAS",
    "content": "A* Path Searching 基于运动基元的A*算法将基于运动基元的A*算法从四旋翼无人机改进适配到固定翼无人机",
    "description": "A* Path Searching 基于运动基元的A*算法将基于运动基元的A*算法从四旋翼无人机改进适配到固定翼无人机",
    "tags": [],
    "title": "Path Searching",
    "uri": "/uas/path-searching/index.html"
  },
  {
    "breadcrumb": "FlitSoft Docs \u003e  UAS",
    "content": "基于非线性模型预测控制的无人机编队飞行在非线性模型预测控制（NMPC）框架下设计了一种分布式、无碰撞的编队飞行控制律。编队构型在虚拟参考点坐标系中确定。通过代价惩罚实现避障，通过代价惩罚结合新的优先级策略实现机间防碰撞。",
    "description": "基于非线性模型预测控制的无人机编队飞行在非线性模型预测控制（NMPC）框架下设计了一种分布式、无碰撞的编队飞行控制律。编队构型在虚拟参考点坐标系中确定。通过代价惩罚实现避障，通过代价惩罚结合新的优先级策略实现机间防碰撞。",
    "tags": [],
    "title": "Formation Control",
    "uri": "/uas/formation-control/index.html"
  },
  {
    "breadcrumb": "FlitSoft Docs \u003e  EM",
    "content": "地空测控链路计算模型该模型侧重于通过考虑视距限制、信号传播特性、接收机灵敏度及多普勒频移影响等因素，评估无人机地空测控链路的连通性和性能。",
    "description": "通信模型",
    "tags": [],
    "title": "Communication",
    "uri": "/em/comm/index.html"
  },
  {
    "breadcrumb": "FlitSoft Docs \u003e  UAS",
    "content": "三段S曲线速度规划模型旨在为无人机轨迹规划提供一条平滑的 S 曲线速度规划方案。通过先计算变速（过渡）阶段的 S 曲线段，再补充恒速段（定速阶段），最后利用二分查找方法调整期望速度以匹配目标弧长，从而生成一组离散时间点上的速度、加速度和加加速度数据。",
    "description": "三段S曲线速度规划模型旨在为无人机轨迹规划提供一条平滑的 S 曲线速度规划方案。通过先计算变速（过渡）阶段的 S 曲线段，再补充恒速段（定速阶段），最后利用二分查找方法调整期望速度以匹配目标弧长，从而生成一组离散时间点上的速度、加速度和加加速度数据。",
    "tags": [],
    "title": "Velocity Planning",
    "uri": "/uas/velocity_plan/index.html"
  },
  {
    "breadcrumb": "FlitSoft Docs \u003e  UAS",
    "content": "kappa-trajectories κ轨迹平滑κ轨迹生成算法。κ=1：轨迹以最短时间过渡到下一个航段；κ=0：轨迹执行一个最小时间过渡，并直接通过航路点；求解κ∈[0,1]使轨迹具有与原始航路点路径等长\nκ轨迹点生成代码说明针对模块化的κ轨迹点生成 C++ 代码的详细说明。用于在给定 κ∈ [0,1] 的条件下，在航路点之间生成平滑的 κ-轨迹点。\n无人机实时动态轨迹平滑一种实时、可行的轨迹生成算法，用于无人机通过一系列航路点飞行。 特别地，算法可配置为动态可行轨迹与直线航路点路径具有相同的路径长度。 该文还详细描述了与算法相关的实现问题。\n等长轨迹κ求解算法设计一种基于二分查找的数值方法，用以求解参数 κ，从而使得生成的 κ-轨迹路径长度与原始航路点路径长度完全一致。",
    "description": "kappa-trajectories κ轨迹平滑κ轨迹生成算法。κ=1：轨迹以最短时间过渡到下一个航段；κ=0：轨迹执行一个最小时间过渡，并直接通过航路点；求解κ∈[0,1]使轨迹具有与原始航路点路径等长\nκ轨迹点生成代码说明针对模块化的κ轨迹点生成 C++ 代码的详细说明。用于在给定 κ∈ [0,1] 的条件下，在航路点之间生成平滑的 κ-轨迹点。\n无人机实时动态轨迹平滑一种实时、可行的轨迹生成算法，用于无人机通过一系列航路点飞行。 特别地，算法可配置为动态可行轨迹与直线航路点路径具有相同的路径长度。 该文还详细描述了与算法相关的实现问题。\n等长轨迹κ求解算法设计一种基于二分查找的数值方法，用以求解参数 κ，从而使得生成的 κ-轨迹路径长度与原始航路点路径长度完全一致。",
    "tags": [],
    "title": "Trajectory Planning",
    "uri": "/uas/trajectory_planning/index.html"
  },
  {
    "breadcrumb": "FlitSoft Docs",
    "content": "Aerodynamics 小型固定翼无人机飞行动力学模型为小型固定翼无人机仿真系统提供逼真的飞行动力学与飞行控制方案，替代当前的简单PID+运动学模型。文档涵盖系统需求、6-DOF动力学模型、级联控制架构、模块接口、参数标定及实现建议等内容。\nJSBSim User manual如何使用 JSBSim 进行模拟运行、创建飞行器模型、编写脚本，以及如何执行其他不涉及对 JSBSim 程序代码进行更改的任务。\nJSBSim Quickstart旨在让用户和开发者了解JSBSim软件的所有功能。\nPath Searching A* Path Searching 基于运动基元的A*算法将基于运动基元的A*算法从四旋翼无人机改进适配到固定翼无人机\nFormation Control 基于非线性模型预测控制的无人机编队飞行在非线性模型预测控制（NMPC）框架下设计了一种分布式、无碰撞的编队飞行控制律。编队构型在虚拟参考点坐标系中确定。通过代价惩罚实现避障，通过代价惩罚结合新的优先级策略实现机间防碰撞。\nVelocity Planning 三段S曲线速度规划模型旨在为无人机轨迹规划提供一条平滑的 S 曲线速度规划方案。通过先计算变速（过渡）阶段的 S 曲线段，再补充恒速段（定速阶段），最后利用二分查找方法调整期望速度以匹配目标弧长，从而生成一组离散时间点上的速度、加速度和加加速度数据。\nTrajectory Planning kappa-trajectories κ轨迹平滑κ轨迹生成算法。κ=1：轨迹以最短时间过渡到下一个航段；κ=0：轨迹执行一个最小时间过渡，并直接通过航路点；求解κ∈[0,1]使轨迹具有与原始航路点路径等长\nκ轨迹点生成代码说明针对模块化的κ轨迹点生成 C++ 代码的详细说明。用于在给定 κ∈ [0,1] 的条件下，在航路点之间生成平滑的 κ-轨迹点。\n无人机实时动态轨迹平滑一种实时、可行的轨迹生成算法，用于无人机通过一系列航路点飞行。 特别地，算法可配置为动态可行轨迹与直线航路点路径具有相同的路径长度。 该文还详细描述了与算法相关的实现问题。\n等长轨迹κ求解算法设计一种基于二分查找的数值方法，用以求解参数 κ，从而使得生成的 κ-轨迹路径长度与原始航路点路径长度完全一致。",
    "description": "无人机系统仿真与建模",
    "tags": [],
    "title": "UAS",
    "uri": "/uas/index.html"
  },
  {
    "breadcrumb": "FlitSoft Docs",
    "content": "Antenna Pattern天线方向图模型\nCommunication通信模型",
    "description": "电磁域新概念与模型",
    "tags": [],
    "title": "EM",
    "uri": "/em/index.html"
  },
  {
    "breadcrumb": "FlitSoft Docs",
    "content": "LoRA对论文《LoRA: Low-Rank Adaptation of Large Language Models》的研究动机、方法设计、实验验证及深入分析等方面进行了详细剖析\nWhy We Think测试时计算（test time compute）与思维链（Chain-of-thought, CoT）已显著提升了模型性能，同时也引发了许多研究问题。本文旨在回顾关于如何有效利用测试时计算（即“思考时间”）以及为何它能带来帮助的最新进展。\n基础模型与智能决策基础模型与智能决策的进展、挑战与展望。决策智能从基于规则的发展为以人工智能驱动，实现了自适应和情境感知的决策。基础模型统一知识，促进在医疗及其他领域的可扩展、自适应决策。决策基础模型的进展依赖于安全、隐私以及人机伦理的保障。",
    "description": "AI文献与进展",
    "tags": [],
    "title": "AI",
    "uri": "/agi/index.html"
  },
  {
    "breadcrumb": "FlitSoft Docs",
    "content": "This is a new chapter.",
    "description": "智能博弈文献与模型",
    "tags": [],
    "title": "Gaming",
    "uri": "/gaming/index.html"
  },
  {
    "breadcrumb": "FlitSoft Docs",
    "content": "Advanced Battle Management System先进战斗管理系统 (ABMS) ——美国空军面临的需求、进展、挑战与机遇.\n决策优势与主动权决策优势与主动权：完善联合全域指挥与控制",
    "description": "C2新概念与模型",
    "tags": [],
    "title": "C2",
    "uri": "/c2/index.html"
  },
  {
    "breadcrumb": "FlitSoft Docs",
    "content": "",
    "description": "仿真平台与技术新进展",
    "tags": [],
    "title": "Simulation",
    "uri": "/simu/index.html"
  },
  {
    "breadcrumb": "FlitSoft Docs",
    "content": "This is a new chapter.",
    "description": "This is a new chapter.",
    "tags": [],
    "title": "Visualization",
    "uri": "/visual/index.html"
  },
  {
    "breadcrumb": "FlitSoft Docs",
    "content": "This is a new chapter.",
    "description": "This summary is independent of the content.",
    "tags": [],
    "title": "Log",
    "uri": "/log/index.html"
  },
  {
    "breadcrumb": "FlitSoft Docs \u003e  AI",
    "content": "1. 研究背景与动机 当下，自然语言处理领域普遍采取“大规模预训练＋下游微调”的范式。然而，随着模型规模不断增大，全量微调(fine-tuning) 面临以下两大挑战：\n存储与部署成本高昂：例如在 GPT-3 175B（约1750亿参数）上进行全量微调时，每个任务都需要保存一套完整的 175B 参数，若同时支持多个任务，则需要占用数 TB 级别的存储空间，且加载模型实例时开销巨大。 训练资源门槛升高：对于 Adam 这样的自适应优化器，需要为所有参数维护梯度和优化器状态，GPT-3 175B 全量微调时，显存占用高达约 1.2TB，这对大多数团队和硬件环境几乎无法承受。 为缓解上述问题，既往研究尝试冻结部分权重或通过引入外部适配器（adapter）/前缀（prompt/prefix）等模块来降低可训练参数规模。但这些方法往往会带来以下弊端：\nAdapter 方法增加推理时延：在 Transformer 层间插入一个小规模的瓶颈层（Adapter），虽参数量少，但必须在正向推理时进行额外计算，在线推理时（尤其 Batch Size=1 情况下）延迟不容忽视。 Prompt/Prefix 方法难以优化且占用输入长度：这类方法通过在输入序列中插入特殊标记，使模型在前向时多处理一段“可训练”激活；但随着特殊标记数目增多，性能提升并不稳定，而且会减少可用于下游任务的实际 Token 数。 鉴于此，论文提出一种新的 低秩适配(LoRA, Low-Rank Adaptation) 策略：在保持预训练权重不变的前提下，通过向每层注入低秩分解矩阵来进行微调，从而在不增加推理时延、不缩减序列长度的情况下，大幅降低可训练参数量和显存占用。\n2. 问题定义 假设已得到一个预训练的自回归语言模型 $P_\\Phi(y\\mid x)$，其参数为 $\\Phi_0$。在下游任务中，往往通过最大化条件语言建模目标进行全量微调：\n$$ \\max_{\\Phi}\\sum_{(x,y)\\in \\mathcal{Z}}\\sum_{t=1}^{|y|} \\log P_{\\Phi}(y_t)(y_t \\mid x, y_{\u003c t}) $$此时需为每个下游任务保存一份 $\\Delta \\Phi$，且 $|\\Delta \\Phi| = |\\Phi_0|$。当 $\\Phi_0$ 较大（如 GPT-3 175B）时，无论是存储还是训练显存都几近或超出可承受范围。\n论文改写该问题为：寻找一个仅依赖于少量参数 $\\Theta$ 的更新映射 $\\Delta \\Phi(\\Theta)$ 使得\n$$ \\max_{\\Theta}\\sum_{(x,y)\\in \\mathcal{Z}}\\sum_{t=1}^{|y|} \\log P_{\\Phi_0 + \\Delta \\Phi(\\Theta)}(y_t \\mid x, y_{\u003c t}), |\\Theta| \\ll |\\Phi_0|. $$最终目标是在显存占用与可训练参数量大幅下降的同时，仍保持或超越全量微调的模型性能。\n3. LoRA 方法 3.1 核心思想：低秩分解更新 LoRA 的核心假设是：在大规模预训练模型的下游微调过程中，权重变化 $\\Delta W$ 具有“低秩”特性，即若原始权重矩阵 $W_0\\in \\mathbb{R}^{d\\times k}$ 进行更新因子 $\\Delta W$，则可以近似为低秩分解\n$$ W_0 + \\Delta W = W_0 + B A, \\quad B \\in \\mathbb{R}^{d \\times r},\\; A \\in \\mathbb{R}^{r \\times k},\\; r \\ll \\min(d, k). $$其中，$W_0$ 冻结不更新，仅对矩阵 $A, B$ 进行梯度更新。这样就将原来需要更新的 $d\\times k$ 参数量，压缩为 $d\\times r + r\\times k\\approx 2dr$ 个参数。\n在前向计算时，对于某一层输入向量 $x\\in \\mathbb{R}^k$，原本输出为 $h = W_0 x$。采用 LoRA 后，输出变为\n$$ h = W_0 x + \\Delta W\\,x = W_0 x + B (A x). \\tag{3} $$因此在实现上，只需在每次前向时多做一个 $A x$ 然后左乘 $B$，并与原始输出相加即可。论文实施时将 $B$ 初始化为零矩阵，$A$ 初始化为服从高斯分布的小随机值，保证微调初期 $\\Delta W = BA$ 为零；训练过程中，会对 $A,B$ 应用缩放系数 $\\alpha/r$（对相同的学习率而言相当于缩放初始值），以方便在不同秩 $r$ 下无需大幅调参而保持收敛稳定。\n3.1.1 与全量微调的关系 当 $r = \\min(d,k)$ 时，等价于对原始权重矩阵 $W_0$ 进行全秩微调，相当于完整的 $\\Delta W$； 当采用更小的 $r$ 时，只训练低秩子空间中的更新，从而实现与全量微调相似的表达力，但参数量和计算开销大幅减少。 3.2 在 Transformer 中的应用 论文将 LoRA 主要应用于 Transformer 结构中**自注意力模块（self-attention）**的投影矩阵：查询矩阵 $W_q$、键矩阵 $W_k$、值矩阵 $W_v$、输出矩阵 $W_o$ 以及前馈网络（MLP）部分的全连接权重矩阵。具体做法如下：\n仅对注意力投影矩阵应用 LoRA：论文在大多数实验中只在 $W_q$ 和 $W_v$ 上引入低秩更新矩阵 $\\Delta W_q = B_q A_q$，$\\Delta W_v = B_v A_v$，并冻结其它权重（包括 MLP 层和层归一化层等）。实验证明，这样已经能够获得与全量微调相当或更优的性能。 保持正向推理时延不变：在部署推理时，只需将训练好的 $\\Delta W$ 与 $W_0$ 合并为 $W_0 + BA$，正向计算流程与微调后模型完全一致，没有新增任何顺序化计算，因此不会增加推理时延。 灵活切换任务：将 $\\Delta W$ 合并后对应于某个任务的权重写入硬盘，多个任务只需维护一份基础预训练权重与若干份低秩适配参数（大小通常为几 MB），切换任务时仅载入对应的 $\\Delta W$，显存和存储占用极小。 应用位置 维度 低秩参数量 $\\displaystyle 2\\times d\\times r$ 说明 $W_q$ $d\\times d$ $2dr$ 查询投影，只改前两项 $W_v$ $d\\times d$ $2dr$ 值投影 … … … … 实践中，仅在 $W_q, W_v$ 上应用 $r=4$ 时（共计适配参数约数 MB 级别），即可满足 GPT-3 175B各种下游任务的性能需求。\n4. LoRA 的实用优势与局限 4.1 优势 显存占用降低\n由于大部分权重冻结，不需为其维护梯度或优化器状态，仅对低秩矩阵 $A,B$ 更新。以 GPT-3 175B 为例，LoRA 微调时显存从约 1.2 TB 降至约 350 GB，节省约 3 倍显存。 可训练参数量大幅减少\n对 GPT-3 175B，仅在 $W_q,W_v$ 部分以 $r=4$ 方式注入，则低秩参数量约为 4.7 M，相比全量微调（175 B）减少约 10 000 ×。 推理时延不增加\n预先合并 $\\Delta W = B A$ 到权重后，推理流程与全量微调相同，不会引入顺序化计算。与 Adapter 方法相比，Adapter 在每层插入瓶颈层会造成推理时间因顺序运算大幅增长，而 LoRA 不存在此缺陷。 任务切换便捷\n共享同一份预训练权重，在不同任务间只需加载不同的几 MB 级别的低秩适配参数，存储和部署成本极低。 训练吞吐量提升\n由于冻结大部分权重，反向传播计算量下降，在相同硬件下可获得约 25% 的训练速度提升。 4.2 局限 批量多任务训练不便\n若想在一个 Batch 中同时对不同任务样本使用不同的 $\\Delta W$（即 A,B 不同），需在正向时动态切换权重，或者不合并权重，此时推理/训练流程复杂。论文指出若对延迟敏感，可以选择动态加载 LoRA 模块，否则需将不同 $\\Delta W$ 合并到原权重，从而无法混合多任务一起正向。 低秩假设或不适用所有任务\n当下游任务与预训练任务域差异极大（例如全新语言、跨模态任务）时，所需更新可能并不低秩，此时 LoRA 的表达能力可能受限。论文在 GPT-3 上实验发现对于大部分 NLP 任务，仅需 $r=1$ 即可；但也提示并非所有任务都适用，需要适度调节秩 $r$。 5. 实验验证 论文在四种主流 Transformer 结构上进行了大规模实验：RoBERTa、DeBERTa、GPT-2 以及 GPT-3 175B。下文中，对照各项结果进行说明。\n5.1 基线方法 基线名称 说明 Full Fine-Tuning（FT） 对所有权重和偏置进行微调。 BitFit 仅训练偏置向量（bias），其它权重冻结。 Adapter (Houlsby 等) 在自注意力和 MLP 后插入瓶颈 Adapter 层。AdapterL/AdapterH 两种变体，分别对应单适配器或双适配器结构，参数量约为原模型的 1% 左右。 Prefix-Tuning/Embedding (PE) 在输入/层激活前加入 lp + li 个可训练 Token 激活，等同于动态插入额外可训练参数，无法并行优化且会占用下游任务的序列长度。 Prefix-Layer (PL) 类似于 PrefixEmbed，但对各层插入可训练的激活向量，同样占用计算和序列长度。 5.2 RoBERTa Base/Large 上的 GLUE 基准 论文在 GLUE 数据集（包含 MNLI、SST-2、MRPC、CoLA、QNLI、QQP、RTE、STS-B）上对 RoBERTa base (125M 参数) 和 RoBERTa large (355M 参数) 进行了多种方法对比。部分结果汇总如下（指标为各任务对应分数，整体为平均得分；越高越好）：\n模型 (RoBERTa Base) 可训练参数 MNLI SST-2 MRPC CoLA QNLI QQP RTE STS-B Avg. FT (125M) 125 M 87.6 94.8 90.2 63.6 92.8 91.9 78.7 91.2 86.4 BitFit (0.1 M) 0.1 M 84.7 93.7 92.7 62.0 91.8 84.0 81.5 90.8 85.2 AdapterD (0.3 M) 0.3 M 87.1 94.2 88.5 60.8 93.1 90.2 71.5 89.7 84.4 AdapterD (0.9 M) 0.9 M 87.3 94.7 88.4 62.6 93.0 90.6 75.9 90.3 85.4 LoRA (r=4, 0.3 M) 0.3 M 87.5 95.1 89.7 63.4 93.3 90.8 86.6 91.5 87.2 模型 (RoBERTa Large) 可训练参数 MNLI SST-2 MRPC CoLA QNLI QQP RTE STS-B Avg. FT (355 M) 355 M 90.2 96.4 90.9 68.0 94.7 92.2 86.6 92.4 88.9 LoRA (r=8, 0.8 M) 0.8 M 90.6 96.2 90.9 68.2 94.9 91.6 87.4 92.6 89.0 AdptP (3.0 M) 3.0 M 90.2 96.1 90.2 68.3 94.8 91.9 83.8 92.1 88.4 AdptP (0.8 M) 0.8 M 90.5 96.6 89.7 67.8 94.8 91.7 80.1 91.9 87.9 AdptH (6.0 M) 6.0 M 89.9 96.2 88.7 66.5 94.7 92.1 83.4 91.0 87.8 AdptH (0.8 M) 0.8 M 90.3 96.3 87.7 66.3 94.7 91.5 72.9 91.5 86.4 LoRA (0.8 M) 0.8 M 90.6 96.2 90.2 68.2 94.8 91.6 85.2 92.3 88.6 从上表可以看出，LoRA 在仅用 0.3 M—0.8 M 可训练参数的情况下，几乎匹配甚至略超全量微调，且优于其他几种参数高效微调方法（如 Adapter、BitFit 等）。\n5.3 DeBERTa XXL 上的 GLUE 基准 DeBERTa XXL（约 1.5B 参数）也是较大规模可用模型。论文在 GLUE 任务上对比了下列设置：\n模型 (DeBERTa XXL) 可训练参数 MNLI SST-2 MRPC CoLA QNLI QQP RTE STS-B Avg. FT (1.5 B) 1500 M 91.8 97.2 92.0 72.0 96.0 92.7 93.9 92.9 91.1 LoRA (r=8, 4.7 M) 4.7 M 91.9 96.9 92.6 72.4 96.0 92.9 94.9 93.0 91.3 结果显示，LoRA 仅用 4.7 M 可训练参数，就能略微超过全量微调的 DeBERTa XXL，且比 Adapter 等方法表现更稳定。\n5.4 GPT-2 Medium/Large 上的 NLG 任务 针对生成任务，论文在 E2E NLG Challenge、WebNLG、DART 等数据集上对比了以下方法。以 E2E NLG Challenge（指标包括 BLEU、NIST、METEOR、ROUGE-L、CIDEr；越高越好）为例：\n模型 \u0026 方法 可训练参数 BLEU NIST METEOR ROUGE-L CIDEr GPT-2 Medium (FT, 354.9 M) 354.9 M 68.2 8.62 0.4565 0.710 2.47 GPT-2 Medium (AdapterL, 0.37 M) 0.37 M 66.3 8.41 0.450 0.698 2.40 GPT-2 Medium (AdapterL, 11.09 M) 11.09 M 68.9 8.71 0.461 0.713 2.47 GPT-2 Medium (AdapterH, 11.09 M) 11.09 M 67.3 8.50 0.460 0.707 2.44 GPT-2 Medium (FTTop2, 25.19 M) 25.19 M 68.1 8.59 0.460 0.708 2.41 GPT-2 Medium (PreLayer, 0.35 M) 0.35 M 69.7 8.81 0.461 0.714 2.49 GPT-2 Medium (LoRA, 0.35 M) 0.35 M 70.4 8.85 0.4689 0.7186 2.5349 模型 \u0026 方法 可训练参数 BLEU NIST METEOR ROUGE-L CIDEr GPT-2 Large (FT, 774.0 M) 774.0 M 68.5 8.78 0.460 0.699 2.45 GPT-2 Large (AdapterL, 0.88 M) 0.88 M 69.1 8.68 0.463 0.714 2.49 GPT-2 Large (AdapterL, 23.00 M) 23.00 M 68.9 8.70 0.461 0.713 2.45 GPT-2 Large (PreLayer, 0.77 M) 0.77 M 70.3 8.85 0.462 0.717 2.47 GPT-2 Large (LoRA, 0.77 M) 0.77 M 70.4 8.89 0.4689 0.720 2.47 由此可见，LoRA 在仅 0.3 M—0.8 M 可训练参数的情况下，取得了与全量微调相当甚至略优的生成质量。\n5.5 GPT-3 175B 上的规模化实验 最后，论文将 LoRA 扩展至 GPT-3 175B，重点验证其在大模型下的可行性及性能。实验包括 WikiSQL（NL→SQL）、MultiNLI (MNLI-matched) 和 SAMSum（三元组对话摘要）三种任务，结果如下：\n方法 可训练参数 WikiSQL (Acc. %) MultiNLI-m (Acc. %) SAMSum (Rouge-1/2/L) GPT-3 (FT) 175 255.8 M 73.8 89.5 52.0/28.0/44.5 GPT-3 (BitFit, 14.2 M) 14.2 M 71.3 91.0 51.3/27.4/43.5 GPT-3 (PreEmbed, 3.2 M) 3.2 M 63.1 88.6 48.3/24.2/40.5 GPT-3 (PreLayer, 20.2 M) 20.2 M 70.1 89.5 50.8/27.3/43.5 GPT-3 (AdapterH, 7.1 M) 7.1 M 71.9 89.8 53.0/28.9/44.8 GPT-3 (AdapterH, 40.1 M) 40.1 M 73.2 91.5 53.2/29.0/45.1 GPT-3 (LoRA, 4.7 M) 4.7 M 73.4 91.7 53.8/29.8/45.9 GPT-3 (LoRA, 37.7 M) 37.7 M 74.0 91.6 53.4/29.2/45.1 可以看出，LoRA 在极少参数（4.7 M）情况下，已经逼近或超越了全量微调（175 B）的性能，并且随着可训练参数量增加（37.7 M），任务性能略有提升但基本趋于稳定。实验还给出了不同方法在可训练参数数目上的性能曲线（图 2），LoRA 的表现明显更为平滑和可扩展。\n6. 对 LoRA 更新矩阵的深入分析 针对为何低秩更新能取得上述效果，论文进行了多项实证研究，探讨更新矩阵 $\\Delta W$ 的秩及与原权重 $W$ 之间的关系。以下是关键结论：\n6.1 选取哪些权重进行 LoRA 更优 在 GPT-3 175B 上设定约 18 M 参数预算，实验对比了在不同注意力矩阵上分别应用 LoRA 的效果（秩 $r$ 根据权重数目反算，适配 $W_q, W_v$ 时取 $r=4$，仅适配单矩阵时取 $r=8$）。结果（表 5）显示：\n适配位置 可训练参数约 18 M WikiSQL (Acc. %) MNLI(m) (Acc. %) 仅 $W_q$ (r=8) 18 M 68.8—70.4 90.7—90.9 仅 $W_k$ (r=8) 18 M 70.0 90.8 仅 $W_v$ (r=8) 18 M 73.0 91.0 仅 $W_o$ (r=8) 18 M 73.2 91.3 $W_q,W_k$ (各 r=4) 18 M 71.4 91.3 $W_q,W_v$ (各 r=4) 18 M 73.7 91.3 $W_q,W_k,W_v,W_o$ (r=2) 18 M 73.7 91.7 可见，在预算固定时，同时适配 $W_q$ 与 $W_v$（各 $r=4$）能够获得最佳整体表现。单独适配某一矩阵往往次优，比如仅适配 $W_q$ 需要更高 $r$ 才能接近效果。\n6.2 更新矩阵是否真低秩？最佳秩 $r$ 的选择 实验进一步在 GPT-3 上考察了不同秩 $r$ 对下游任务性能的影响。以同时适配 $\\{W_q,W_v\\}$ 为例，在 WikiSQL 和 MNLI 上，当 $r$ 取 1、2、4、8、64 时，性能如表 6 所示：\n适配位置 r WikiSQL (±0.5 %) MNLI (±0.1 %) 仅 $W_q$ 1 68.8 90.7 仅 $W_q$ 2 69.6 90.9 仅 $W_q$ 4 70.5 91.1 仅 $W_q$ 8 70.4 90.7 仅 $W_q$ 64 70.0 90.7 $W_q,W_v$ 1 73.4 91.3 $W_q,W_v$ 2 73.3 91.4 $W_q,W_v$ 4 73.7 91.3 $W_q,W_v$ 8 73.8 91.6 $W_q,W_v$ 64 73.5 91.4 $W_q,W_k,W_v,W_o$ 1 74.1 91.2 … … … … 可见，仅用 $r=1$ 即可让 $\\{W_q,W_v\\}$ 在这两项任务上达到接近最优性能，进一步说明了更新 $\\Delta W$ 的“内在秩（intrinsic rank）”极低。反之，仅适配单个矩阵 $W_q$ 时则需要稍大 $r$ 才能逼近。\n6.3 更新矩阵 $\\Delta W$ 与原权重 $W$ 之间的关联 论文借助**奇异值分解（SVD）和子空间相似度（Grassmann 距离投影）**来探究 $\\Delta W$ 与 $W$ 的关联程度。\n$\\Delta W$ 是否与 $W$ 的主要奇异向量方向对齐？ 定义对于矩阵 $W$ 的前 $r$ 个左右奇异向量分别为 $U_W \\in \\mathbb{R}^{d\\times r}, V_W \\in \\mathbb{R}^{k\\times r}$；对于 $\\Delta W$ 的对应前 $r$ 个奇异向量为 $U_{\\Delta}, V_{\\Delta}$。论文计算了\n$$ \\lVert U_{\\Delta}^\\top\\,W\\,V_{\\Delta} \\rVert_F \\quad\\text{与}\\quad \\lVert W \\rVert_F,\\;\\lVert \\Delta W \\rVert_F $$的对比，发现 $\\Delta W$ 与 $W$ 之间存在明显相关性，即 $\\lVert U_{\\Delta}^\\top\\,W\\,V_{\\Delta} \\rVert_F$ 远大于对随机矩阵情形，说明 $\\Delta W$ 更倾向于放大 $W$ 中尚未充分强调但对下游任务重要的特征模式。举例：在 GPT-3 第 48 层 $W_q$ 上，当 $r=4$ 时，有\n$$ \\frac{\\|\\Delta W_q\\|_F}{\\|U_{\\Delta}^\\top\\,W_q\\,V_{\\Delta}\\|_F} \\approx 21.5, \\quad \\lVert W_q\\rVert_F \\approx 61.95,\\;\\lVert \\Delta W_q\\rVert_F \\approx 6.91,\\;\\lVert U^\\top W_q V\\rVert_F \\approx 0.32, $$而随机矩阵投影仅约 0.02，可见 $\\Delta W$ 在特征放大方面的力度远超随机噪声。\n不同秩 $r$ 学得的子空间是否一致？ 论文考察了在相同层（如 GPT-3 第 48 层）下，$\\Delta W$ 当 $r=8$ 与 $r=64$ 时得到的奇异值向量子空间之间的重叠程度，计算归一化子空间相似度 $\\phi(\\Delta W_{r=8}, \\Delta W_{r=64})$，发现最重要的前几维方向（尤其第 1 奇异向量）高度重合，而后续方向多为噪声。由此进一步佐证：$\\Delta W$ 的“有效秩”非常低。\n不同随机种子学得的 $\\Delta W$ 子空间是否稳定？ 当 $r=64$ 时，论文对两次随机初始化训练得到的 $\\Delta W$ 做同样的子空间相似度分析，发现前数个奇异方向在不同种子之间具有一定重叠，而随机高秩矩阵之间却无此现象。说明 LoRA 的优化结果并非完全随机，而是在低秩子空间里学得了较稳定的模式。\n7. 结论与展望 7.1 主要贡献 提出 LoRA，利用低秩分解技术，仅对部分权重层注入 $B\\in \\mathbb{R}^{d \\times r}$、$A\\in \\mathbb{R}^{r \\times d}$ 两个低秩矩阵进行微调，而冻结大部分预训练权重，从而显著降低可训练参数量（如 GPT-3 175B 仅需 $\\sim4.7$ M），同时在推理阶段不引入额外时延。 在多种模型（RoBERTa、DeBERTa、GPT-2、GPT-3）和任务（NLU、NLG）上全面实验，证明 LoRA 在仅用数百万参数的情况下，能够获得或超过全量微调的性能，并优于其他高效微调方法（Adapter、Prefix 等）。 通过实证分析，揭示了微调更新矩阵 $\\Delta W$ 的“内在秩”极低，并与原权重 $W$ 具有显著相关性，从而从理论和经验两方面说明 LoRA 原理的合理性。 7.2 未来研究方向 论文指出若干可拓展方向：\n与其他高效微调方法结合：如将 LoRA 与 Prefix-Tuning、Adapter、Tensor-Product 结构等组合，或利用不同张量分解方法进一步压缩参数空间。 微调机理研究：深入探索为何低秩更新能够捕获下游任务所需特征，以及 $\\Delta W$ 如何重塑预训练特征空间。LoRA 的低秩约束使得此类分析更易开展。 自动化权重选取：目前论文主要通过经验或少量验证选取在哪些权重矩阵上应用 LoRA；未来可研究更有理论依据或通过自动搜索的方式来决定最优注入位置。 进一步压缩与加速：针对不同任务的秩需求进行动态调节，或探索更稀疏/结构化的低秩分解形式，以在更严格资源约束下保持性能。 总之，LoRA 在保持推理效率的前提下，实现了对大规模预训练模型微调的极大参数压缩，为大模型在资源受限环境下的下游部署提供了可行方案，并为进一步研究微调机理提供了启发。\n论文中文译文\n此浏览器不支持 iframe，请 点击下载 PDF",
    "description": "对论文《LoRA: Low-Rank Adaptation of Large Language Models》的研究动机、方法设计、实验验证及深入分析等方面进行了详细剖析",
    "tags": [],
    "title": "LoRA",
    "uri": "/agi/lora/index.html"
  },
  {
    "breadcrumb": "FlitSoft Docs \u003e  C2",
    "content": "摘要 先进战斗管理系统 (ABMS) 概述\n先进战斗管理系统（ABMS）是美国空军部（DAF）对美国国防部（DoD）联合全域指挥与控制（JADC2）框架概念的贡献。JADC2旨在更紧密地整合和联合行动能力，以应对灵活的对手。它是一个企业级解决方案，用于将空军、陆军、海军陆战队、海军和太空部队的传感器连接成一个单一的网络，目标是在所有战争层次和阶段、跨越所有领域并与合作伙伴一起感知、理解和行动，以在相关速度上提供信息优势。ABMS旨在实现无缝的联合和多国信息共享及作战指挥与控制（C2）。通过ABMS，来自情报、监视和侦察（ISR）、武器系统可用性以及军事行动状态等关键作战数据可以在整个国防部企业中共享。ABMS使决策过程得以压缩，并在不受领域或地理边界限制的情况下实现效果的汇聚。这种速度对决策者和战斗人员至关重要。\nABMS 的演变与性质\nABMS最初于2017年作为“空中战斗管理和监视”系统推出，是一个旨在替换老化的空中预警与控制系统（AWACS）和即将退役的E-8C联合监视和目标攻击雷达系统（JSTARS）机队的传统采办项目。然而，鉴于《国家防务战略》（NDS），空军领导层重新评估了ABMS的需求，认为单一平台已不再是提供跨多个领域C2能力的正确解决方案。到2019年4月，该系统转变为先进战斗管理系统——一个多域分层的C2系统家族，而非单一的现代化项目。其目标是实现“任何传感器都可以与任何射手对话，无论是在太空、陆地、海上、空中还是网络空间”。\nABMS被设计为随着时间的推移继续利用不断发展的（主要是商业）技术，而不是建立一个展示现有技术的静态系统集成。因此，ABMS作为一个空军部级别的总体活动，没有一组固定的需求来构建，没有单一的成本估算，也没有一组单一的操作能力来部署。相反，重点主要是设计企业规模的架构，并制定要求以确保构成ABMS的系统菜单能够满足这些要求。\n最近，新任空军部长Frank Kendall审查了ABMS的重点，认为其“在实现和部署可测量的具体作战成果方面没有足够的专注”。他主张在定义的时间内开发具体、实用的军事技术，并要求建立绩效指标来评估ABMS是否显著改进了当前的C2能力。\n治理与组织结构\nABMS的治理需要指挥结构和决策结构。在指挥结构上，ABMS最初由空军部首席架构师办公室（DAF CAO）管理，但在2020年11月，主要责任办公室（OPR）从DAF CAO转移至空军部快速能力办公室（RCO）。快速能力办公室（DAF RCO）被指定为ABMS的主导组织，委员会认为这是一个积极的步骤，有助于将ABMS从演示和实验转向重点能力发布。在新的指挥结构下，DAF RCO作为ABMS的项目执行办公室（PEO），负责起草采办战略、进行业务审查、提供和整合能力以纳入架构评估通道，并指导能力发布的开发。首席架构师则负责编码技术需求、促进企业数字架构和标准的整合、主持架构审查委员会（ARB）会议以及建立和提供基于模型的系统工程（MBSE）和其他协作工具。服务采购执行官（SAE）保留ABMS所有方面的决策权。委员会支持这一治理结构，认为其与ABMS这样一个复杂系统不断发展的性质相一致。\n从决策结构来看，ABMS作为JADC2框架的贡献者，需要跨服务和多国协调。这需要一个具有真正决策权的美国国防部（DoD）级别的治理结构。委员会发现，目前的ABMS和更广泛的JADC2治理结构不充分，缺乏在所有领域执行C2的适当权威。由J6领导的JADC2跨职能团队（CFT）是一个积极的第一步，但包含的参与者过多，且未能有效赋权做出所需的高层决策。这导致各军种和国防部机构各自开发自己的C2系统，互操作性面临挑战。委员会建议，联合参谋部J6或指定的国防部执行代理人应建立一个权威的联合级别机构来解决这些问题。\n除了技术挑战，整合广泛的ABMS生态系统还需要考虑组织和人力因素。实现真正联合和多国一体化作战需要解决文化、社会和情感障碍。打破垂直分割并在所有层面实现有效的联合互操作性，需要国防部创建由共同战术、技术和程序（TTPs）支持的统一愿景。\n技术架构与关键能力\nABMS的架构是指各个系统组件和能力之间的关系和互联。目标是将所有组件和互联整合起来，以实现更大的系统目标——跨越整个空军部传感器、网络组件和武器系统的协调指挥与控制，以及连接到更大的JADC2企业架构。架构成功根本上依赖于严格遵循应用程序接口（API）和数据标准。ABMS架构应具备在所有应用中实现通信、数据和计算的完整性、可用性和保密性的能力。目标不仅是建立一个共同作战图（COP），而且是建立一个可用于任何边缘战略或战术决策的数据全貌表示。架构还应强调在退化或拒绝环境中运行的通信、数据和计算。保护ABMS免受网络漏洞和对手攻击需要将网络安全纳入整体架构设计。\nABMS架构仍处于初期阶段且不断演变。委员会发现，ABMS架构需要为所有通信、数据和计算元素提供完整性、可用性和保密性，并具备适应性，以便在时间上实现持续开发、部署、测试、改进和完善。按照目前的计划，如果要完全实现JADC2下的联合战斗概念（JWC），ABMS架构可能会面临互操作性挑战。委员会强烈建议在联合层面开发ABMS架构，以实现与其他军种和多国合作伙伴的互操作性。\nABMS架构由一系列平台、传感器、网络和数据链通过安全云互联。它包括硬件和软件，以及支持技术。在早期的空军部首席架构师管理下，它包括六个产品类别：传感器集成、数据和数据管理、安全处理、连接性、应用程序和效果集成。这些产品类别由多条软件产品线（如cloudONE、dataONE、omniaONE等） 和硬件产品线（如radioONE、boxONE等）支持。\n关键的技术和方法包括：\n数据中心战 数据被视为战略资产。需要采用一系列能够支持从战术到战略的全方位能力的数据交换技术。国防部的《数据战略》指导组件制定自己的实施计划，这可能导致不一致和冗余。需要联合参谋部J6或指定的国防部执行代理人为所有JADC2参与系统建立互操作性要求和性能指标，并就通用数据结构和数据安全级别达成一致。 人工智能与机器学习 (AI/ML) AI/ML被视为加速数据传输和决策的关键。ABMS的smartONE能力使用AI/ML进行感知和综合数据，并提示用户潜在有用的信息。最终目标是利用AI/ML提供更多的自动化和预测分析，以更快地加速数据传输和决策。委员会建议设计和执行一个全面的AI战略，而不仅仅是ABMS的某些选定能力。可以考虑使用超级自动化和自动化机器学习（AutoML）等商业能力来提高效率和效果。 容器化与Kubernetes 为了在持续集成/持续交付和部署（CI/CD）环境中实现敏捷开发，容器化和Kubernetes被广泛采用。空军部内部已成功在F-16和U-2飞机上使用Kubernetes。DevSecOps被采纳为ABMS的通用开发环境，通过容器化和CI/CD实现。这有助于快速部署、原型设计、更快的部署，并实现安全自动化。 数据权利 对于ABMS，拥有或访问所有数据权利可能不可行也不可持续。委员会建议对于具有强大接口规范的模块化开放系统设计，应获取性能和接口要求，而不是所有知识产权。 多级安全性 (MLS) MLS允许处理不同分类级别的信息并控制不同许可用户的访问。ABMS通过CrossDomainONE和ABMS DeviceOne SecureView（ADSV）引入了MLS方法。但委员会指出仍需自动化数据传输和集成，并解决高度机密信息的净化问题。 网络安全与零信任 (ZT) 安全性对ABMS至关重要，数据存储、处理和通信必须安全可靠。应为所有ABMS及其支持组件设计整体的网络安全架构。ABMS开发者逐步采用零信任（ZT）架构。ZT是一种架构构造，要求在分布式系统中所有交互进行认证和授权。然而，ZT概念前景可期，但目前尚未完全成熟到可以作为ABMS这样军事C2系统中的唯一安全保护措施。需要一个全面的网络安全计划，包括进攻和防御计划，并进行红队测试。委员会建议制定并实施一个强大的全企业进攻和防御网络安全战略。 测试与建模 测试与评估（T\u0026E）的主要目标是风险降低。ABMS的设计是不断演变的，开发测试集成到DevSecOps流程中，操作测试通过大规模试验和演习进行（即“上坡”演示）。委员会建议ABMS可能需要通过模型驱动系统工程（MBSE）、建模和仿真（M\u0026S）以及数字孪生的组合来重新调整未来的测试，尤其是在预算削减和更侧重于实际操作改进的背景下。空军部正在大力推动采用数字工程（DE），MBSE是其子集。数字孪生被国防部内部多个项目采用，委员会建议在ABMS开发中扩大数字孪生的使用。 联合任务指挥中心 (CMCC) CMCC是支持ABMS元素的软件、硬件和人机界面的原型能力，旨在在复杂C2框架内指挥、任务和组合多个任务。它是基于开放架构框架开发的。委员会建议空军快速能力办公室考虑扩展CMCC，并将其指定为ABMS的零阶段。 挑战与机遇\nABMS面临诸多挑战。它缺乏一组明确定义的最低性能目标、单一的固定要求集、拟议能力交付的时间表以及用于执行这些目标的预算和资源的系统分配。成功的大规模能力交付面临挑战，甚至不太可能。委员会难以对其数据和通信架构进行全面评估，因为其技术设计和架构尚处于初期阶段且不断演变。其性能特征受到限制，主要与演示有关，而非实际操作活动。国会决定将ABMS的总预算削减近一半，显然限制了ABMS在近期到中期内的成就。目前的治理结构不充分，缺乏国防部级别的执行代理来协调各军种和国防部机构的C2系统开发。此外，实现真正联合和多国一体化作战需要解决文化、社会和情感障碍。遗留系统必须以连贯、分阶段和成本效益高的方式集成到新架构中。进攻和防御网络安全对ABMS至关重要，但目前零碎的方式处理可能产生漏洞。将数据视为战略资产需要解决大规模信息共享缺乏企业级数据标准的问题。在作战期间，如何在受限环境中（如GPS受限、EW或网络安全受损）进行决策、权限分配和信任考量也是重要挑战。\n尽管存在挑战，ABMS的努力也带来了机遇。例如，预算限制可能迫使空军部领导做出重要决策和优先考虑ABMS的投资和能力。将ABMS管理权转移到DAF RCO被视为积极一步，有助于从演示转向能力部署。采用商业技术和加速采购方法也是机遇。技术进步（如AI/ML、容器化、DevSecOps、MBSE、M\u0026S、数字孪生、MLS、ZT）为提高ABMS的效率、效果、安全性和适应性提供了潜力。克服组织和文化障碍，实现跨军种和多国合作伙伴的水平整合，是实现JADC2愿景的关键机遇。\n委员会的建议\n委员会提出了多项建议，以解决上述挑战并抓住机遇，其中包括（但不限于）：\n在JADC2层面定义ABMS架构，确保与其他系统的互操作性。 设计模块化架构，包含开放标准和接口。 设计架构时包含特定技术要求和解决方案，以确保在受限环境中运行。 采用一系列数据交换技术支持能力范围。 设计并执行全面的AI战略。 就通用数据结构和数据安全级别达成一致，并在联合层面定义数据标准和工具。 扩大容器化和Kubernetes的使用，用于持续开发和安全漏洞检测/缓解。 采用DevSecOps作为通用开发环境。 获取模块化开放系统设计的性能和接口要求，而非所有知识产权。 在架构中设计弹性，并指定所需性能的动态标准。 为JADC2和ABMS制定并实施强大的全企业网络安全战略。 分阶段应用零信任（ZT），并整合ZT服务，包括多因素认证。 利用空军的任务防御团队对网络防御进行红队测试。 与美国网络司令部合作解决网络漏洞和利用。 将MBSE方法应用于工程和维持活动，使其成为操作员需求与开发团队之间的桥梁。 扩大数字孪生在开发中的使用。 考虑扩展联合任务指挥中心（CMCC），并将其指定为ABMS的零阶段。 建立一个权威的联合级别机构，解决和决策JADC2贡献者的技术、操作和指挥问题。 解决实现联合战斗概念所需的文化、社会和情感障碍。 在设计、运行、人员配置和培训ABMS时，审查和解决人工智能的伦理使用问题。 在计划中考虑并融入人员、文化、培训等非物质因素。 建立课程，培训或招聘人工智能/机器学习、MBSE、网络安全等领域的高合格专家。 总而言之，ABMS作为一个非传统采办项目，在持续发展中，其技术设计和架构尚处于初期阶段且不断演变。它是空军部对JADC2的关键贡献，旨在通过技术和流程创新实现跨领域的无缝连接、信息共享和快速决策，以应对日益复杂的全球安全环境和对手带来的挑战。然而，其成功需要克服技术互操作性、治理结构不完善、预算限制、组织文化障碍以及人员培训等多方面的挑战。委员会的分析和建议为ABMS及其相关采办计划在更大的JADC2框架下的发展提供了见解和改进方向。\n中文译文\n此浏览器不支持 iframe，请 点击下载 PDF",
    "description": "先进战斗管理系统 (ABMS) ——美国空军面临的需求、进展、挑战与机遇.",
    "tags": [],
    "title": "Advanced Battle Management System",
    "uri": "/c2/advanced_battle_management_system/index.html"
  },
  {
    "breadcrumb": "FlitSoft Docs \u003e  AI",
    "content": "日期：2025年5月1日 | 预计阅读时间：40分钟 | 作者：Lilian Weng\n特别感谢 John Schulman 对本文提供了许多非常有价值的反馈和直接修改。\n测试时计算（test time compute）（Graves et al. 2016、Ling, et al. 2017、Cobbe et al. 2021）与思维链（Chain-of-thought, CoT）（Wei et al. 2022、Nye et al. 2021）已显著提升了模型性能，同时也引发了许多研究问题。本文旨在回顾关于如何有效利用测试时计算（即“思考时间”）以及为何它能带来帮助的最新进展。\n动机 让模型“思考得更久”有多种动机。\n心理学类比 这个核心思想与人类思考的方式密切相关。人类无法立即回答“12345乘以56789是多少？”这样的问题。我们通常会花时间思考和分析，尤其是在面对复杂问题时。在 《思考，快与慢》（Kahneman, 2013） 一书中，Daniel Kahneman 根据 双过程理论（dual process theory） 将人类的思维模式分为两种：\n快思考（系统1）：快速且自动地运行，依赖直觉和情感，几乎不需要努力。 慢思考（系统2）：需要有意识地投入逻辑思考与大量认知资源。该模式更耗费心理能量，需要主动参与。 由于系统1思维快速且轻松，往往成为主要决策机制，但这也以牺牲准确性和逻辑为代价。它依赖于大脑的心理捷径（即启发式），因此容易出错和产生偏差。通过有意识地放慢思考节奏，花更多时间反思、改进和分析，我们可以激活系统2思维，挑战本能，从而做出更理性的决策。\n计算资源视角 深度学习的一个视角是：神经网络可以通过正向传播中所能访问的计算与存储量来刻画。如果我们用梯度下降方法训练模型解决问题，那么优化过程将学会如何利用这些资源——即学会如何将资源组织成执行计算和存储信息的“电路”。从这个角度看，如果我们设计一个能够在测试时执行更多计算的架构或系统，并训练其有效利用这些资源，那么它的表现会更好。\n在 Transformer 模型中，每生成一个 token 所需的计算量（以 FLOPs 衡量）大约是模型参数量的两倍。而在稀疏模型如专家混合（mixture of experts, MoE）中，每次前向传播只激活部分参数，因此其计算量为：计算量 = 2 * 参数量 / 稀疏率，其中稀疏率指的是被激活的专家比例。\n另一方面，CoT 允许模型在为每个答案 token 进行计算时执行更多的 FLOPs。事实上，CoT 的一个优点是：它可以根据问题的复杂程度动态调整所需的计算量。\n潜变量建模 机器学习中的一个经典思想是：定义一个含有潜变量（latent variable）$z$ 和可见变量（visible variable）$y$ 的概率模型，其中$y$ 是给定的数据。对潜变量取边际（求和）可以表达一个对可见变量的丰富分布：\n$$ P(y) = \\sum_z \\sim P(z) P(y|z) $$例如，我们可以通过设定$x$ 为数学问题的描述，$y$ 为答案或证明，$z$ 为通往证明过程中的自由思考路径，来建模数学题与答案的分布。此时我们优化的目标为：\n$$ P(y|x) = \\sum_z \\sim p(z|x) P(y|x, z) $$这种潜变量的视角在理解涉及多个并行 CoT 收集或在 CoT 空间中搜索的方法时特别有用，这些算法可视为从后验分布$P(z|x,y)$ 中采样。同时，这一视角也说明了将对数损失函数$\\log P(y|x)$ 作为目标优化的重要性——在预训练中它非常有效。\nToken 中的思考 在生成简短答案之前先生成中间步骤的策略，尤其是针对数学问题，最早由 Ling et al. 2017 探索，他们提出了 AQUA-RAT 数据集。随后 Cobbe et al. 2021 扩展了这一工作，推出了 Grade School Math (GSM) 数据集。Cobbe 等人通过人类书写解答训练生成器，并使用验证器判断候选解的正确性，从而对解答进行搜索。Nye et al. (2021) 尝试将中间思考 token 作为“草稿板”，而 Wei et al.（2022）首次提出了现在被广泛使用的术语 思维链（chain-of-thought, CoT）。\n早期改进 CoT 推理能力的工作包括：对人类书写的推理轨迹或过滤过的模型推理轨迹进行监督学习；后者可被视为一种初级形式的强化学习（reinforcement learning, RL）。另一些研究发现，通过恰当的提示可显著提升经过指令调优（instruction tuned）模型的数学表现，例如使用 \"think step by step\"（Kojima et al. 2022）或更复杂的提示鼓励模型优先反思相关知识（Yasunaga et al. 2023）。\n后续研究发现，可通过对具有自动可验证答案的数据集（如短答案 STEM 问题或可用单元测试验证的编程任务）执行强化学习，显著提升 CoT 推理能力（Zelikman et al. 2022，Wang et al., 2023，Liu et al., 2023）。这一思路因 o1-preview、o3、以及 R1 技术报告（DeepSeek-AI, 2025）的发布而走红，报告中展示了一种使用策略梯度算法的简单方法即可达到强大性能。\n思维链提示能提高解决数学问题的成功率。模型越大，越能从“思考时间”中受益。（图源：Wei et al. 2022）\n分支与修订 测试时计算的根本意图是：在测试阶段自适应地调整模型输出分布。可以通过多种方式利用测试时的资源在解码阶段选择更优样本，从而引导模型向更理想的分布输出。\n提升解码过程的两种主要方法是并行采样与顺序修订：\n并行采样 同时生成多个输出，可在每步使用奖励信号进行引导，或在末尾通过验证器评估质量。这是最广泛采用的测试时性能提升方法，如 best-of-N 或 beam search。若没有可用的真实标签，常使用“自洽性”（self-consistency）（Wang et al. 2023）在多个 CoT 展开中采用多数投票选出最终答案。 顺序修订 根据上一步的输出逐步调整模型回应，让模型有意识地反思自身输出并修正错误。该过程可能需依赖精调模型，因为单靠模型本身的自我纠错能力，缺乏外部反馈，可能无法提升表现（Kamoi et al. 2024，Huang et al. 2024）。 并行采样简单、直观且易于实现，但受限于模型一次性输出正确结果的能力。顺序修订显式要求模型反思错误，虽更慢、实现更复杂，但能有效推动修正。然而，该方式可能会将原本正确的预测改错，或引入其它幻觉内容。这两种方法也可以结合使用。Snell et al. (2024) 指出：简单问题更适合使用纯顺序的测试时计算，而困难问题则在并行与顺序计算之间达到最优组合时表现最好。\n并行采样与顺序修订的示意图。\n并行采样（Parallel Sampling） 在拥有一个生成模型与用于评估完整或部分样本的打分函数的前提下，可以采用多种搜索算法来寻找得分更高的样本。最简单的算法是 Best-of-N：采样$N$ 个独立样本，并根据某种打分函数选出得分最高者。Beam Search（束搜索）是一种更复杂的搜索算法，其搜索过程更具适应性，会在更有前景的解空间中投入更多采样计算资源。\nBeam Search 维护一组可能性较高的部分序列，交替进行扩展与剪枝。在候选选择机制上，可以借助过程奖励模型（Process Reward Model, PRM；Lightman et al. 2023）来引导 beam search 的候选选择。Xie 等人 (2023) 使用大语言模型（LLM）评估自身生成的推理步骤是否正确，并将其格式化为选择题。结果发现，这种逐步自我评估在 beam search 解码中能降低累计误差。此外，在采样过程中对温度进行退火（annealing）可减缓随机性带来的干扰。Xie 等人的实验在 GSM8k、AQuA 和 StrategyQA 等少样本基准上使用 Codex 模型实现了 5–6% 的性能提升。\nReward Balanced Search（简称 REBASE；Wu et al. 2025）则另行训练了一个 PRM，用于决定 beam search 中每一深度的每个节点应扩展的程度，其依据是 softmax 归一化后的奖励得分。Jiang et al. (2024) 所训练的 PRM 被命名为 “RATIONALYST”，用于基于合成推理的 beam search 引导，训练数据为大量无标注语料。当包含该推理路径时，若能显著降低真实答案 token 的负对数概率（neg log-prob），就认为这条推理路径是“好的”。在推理时，RATIONALYST 通过估计下一个推理步骤的 log 概率（隐式方式）或直接生成下一步推理内容（显式方式）来对 CoT 生成器提供过程监督。\nBeam search 解码过程通过 LLM 对每个推理步骤进行自我评估来进行引导。（图源：Xie et al. 2023）\n有趣的是，可以在没有显式零样本或少样本提示的情况下诱发模型的思维链（CoT）路径。Wang \u0026 Zhou (2024) 发现：若在采样初期保留置信度最高的$k$ 个 token（置信度定义为 top-1 与 top-2 候选间的概率差），并对这$k$ 个分支分别进行贪婪解码，则很多生成序列自然就包含了 CoT。尤其是当上下文中已出现 CoT 时，这会使模型在生成最终答案时更具信心。\n为了计算最终答案的置信度，需要借助任务特定启发式方法（如数学题中最后一个数字）或进一步提示模型 “So the answer is” 来提取答案区间。之所以仅在首个 token 进行分支，是基于如下观察：早期分支能显著增强解路径的多样性，而后续 token 会受此前内容的强烈影响。\nTop-k 解码示意图，其中$k$ 是首次采样步骤中保留的候选数量。（图源：Wang \u0026 Zhou, 2024）\n顺序修订（Sequential Revision） 如果模型能反思并修正过去回答中的错误，我们就希望其能迭代地产出越来越高质量的修订序列。但实际上，大语言模型（LLM）并不具备这种内在的自我修正能力，直接使用这种能力往往效果不佳，其失败模式包括：\n幻觉（hallucination）：将正确答案改成错误； 行为崩溃：修订时未作出实质性修改或根本不修改； 泛化失败：在测试时遇到分布漂移时无效。 Huang 等人 (2024) 的实验表明，直接套用自我修正机制反而会导致性能下降。为实现有效的自我改进，模型需要外部反馈，如：与真实标签匹配、启发式方法、任务特定指标、编程题的单元测试结果（Shinn 等人, 2023）、更强大的模型监督（Zhang et al. 2024）、或人类反馈（Liu et al. 2023）。\n自我修正学习（Self-correction learning；Welleck et al. 2023）目标是：在给定固定生成模型$P\\_0(y\\_0|x)$ 的情况下，训练一个校正器模型$P\\_\\theta(y|y\\_0,x)$。生成器保持通用性，而校正器可根据任务而定，仅在给定初始响应与可选反馈（如文本、编译器日志、单测结果）条件下生成内容：\n首先在数据池中为每个提示生成多个输出； 若两个输出中一个的价值更高，则构造 “增值对”（value-improving pair）：$(x, y, y')$； 这些样本对按照价值差$v(y') - v(y)$ 和输出相似度$Similarity(y, y')$ 的比例进行抽样训练； 校正器的输出也可用于扩展数据池。在推理阶段，校正器可用于生成修正轨迹的顺序修订过程。 通过配对同一问题下模型输出构造增值对来训练校正器模型的自我修正学习示意图。（图源：Welleck et al. 2023）\n递归检查（Recursive inspection；Qu et al. 2024）也是训练更强校正器的方法，不过其采用单一模型同时执行生成与自我修正。\nSCoRe（Self-Correction via Reinforcement Learning） 是一个基于多轮强化学习（RL）的自我修正方法（Kumar et al. 2024）。该方法鼓励模型在第二轮生成中产出比第一轮更好的答案。训练包括两个阶段：\n阶段1：最大化第二次尝试的正确率，并在第一轮加入 KL 惩罚以限制其偏离原始模型； 阶段2：同时优化第一轮和第二轮的答案质量。 这种设计既能鼓励第一次输出的多样性，又能逐步提升整体表现。\n通过两阶段强化学习训练显式提升模型的自我修正能力的结构图。（图源：Kumar et al. 2024）\n强化学习提升推理能力（RL for Better Reasoning） 近年来，通过强化学习（Reinforcement Learning, RL）显著提升语言模型推理能力的研究不断取得突破。这些方法通常采用带有真实答案的问题集（如 STEM 题或逻辑谜题）作为训练基础，模型的奖励机制以获得正确答案为目标。该方向的热度部分来自 OpenAI o 系列模型的出色表现，以及随后 DeepSeek 团队发布的模型与技术报告。\nDeepSeek-R1（DeepSeek-AI, 2025）是一个开源大语言模型（LLM），旨在在数学、编程、逻辑等高阶推理任务中取得卓越表现。其训练流程包括两轮 SFT-RL（监督微调 + 强化学习）：\n冷启动 SFT：对 DeepSeek-V3-Base 在数千条冷启动数据上进行微调，以解决可读性差、语言混用问题。\n面向推理的强化学习：\n仅对推理类 prompt 训练推理模型；\n设定两类基于规则的奖励：\n格式奖励：要求使用 \u003cthinking\u003e...\u003c/thinking\u003e 包裹 CoT； 准确性奖励：数学题需将答案放入指定格式（如边框中）以便验证；编程题使用编译器验证是否通过测试用例。 拒绝采样 + 非推理类 SFT：\n从步骤2的 RL checkpoint 中进行拒绝采样，结合 DeepSeek-V3 的非推理类监督数据（写作、问答、自认知等）； 过滤掉混用语言、长段落或代码块的 CoT； 对总共80万样本进行2轮微调训练。 最终 RL 阶段：对推理与非推理 prompt 共同进行训练，以提升有用性、无害性与推理能力。\nDeepSeek-R1 在多个主流推理基准上与 OpenAI o1-preview、o1-mini 表现相当，DeepSeek-V3 为唯一非推理模型。（图源：DeepSeek-AI, 2025）\n有趣的是，DeepSeek 团队还展示了无需 SFT，纯 RL 训练即可学习高级推理能力，如反思与回溯（即“顿悟时刻”）。模型在 RL 训练中自然学会投入更多思考 token 来解决复杂问题。“顿悟时刻”指模型在反思错误后主动尝试其它路径进行修正。\n随后有多个开源项目尝试复现 R1 成果，如 Open-R1、SimpleRL-reason、TinyZero，均基于 Qwen 模型。这些尝试也验证了纯 RL 方法在数学问题与“顿悟能力”方面的有效性。\n模型学会反思并修正错误的示例。（图源：（左）DeepSeek-AI, 2025；（右）Zeng et al. 2025）\nDeepSeek 还公开了部分失败尝试。例如：使用过程奖励模型（PRM）因难以定义每步规则、评估中间步骤是否正确而失败，训练过程也容易被奖励欺骗（reward hacking）破坏；而 MCTS（蒙特卡洛树搜索）则因语言模型 token 的搜索空间过大且精细奖励建模困难而未能成功。这些失败案例提供了有价值的洞察，也呼吁社区更多分享“不成功”的经验。\n外部工具的使用 在推理步骤中，某些中间步骤可以通过执行代码或运行数学计算来可靠且准确地完成。将推理组件中的这一部分卸载到外部代码解释器上（例如 PAL（Program-Aided Language Model，程序辅助语言模型；Gao et al. 2022）或 Chain of Code（Li et al. 2023））可以借助外部工具扩展大语言模型（LLM, Large Language Model）的能力，从而免去让 LLM 学习执行代码或充当计算器的需求。这些代码模拟器（如 Chain of Code 中的实现）可以由 LLM 增强：如果标准代码解释器失败，我们可以选择使用 LLM 来执行该行代码。\n使用代码来增强推理步骤对于数学问题、符号推理和算法任务尤其有益。这些单元测试在某些编程问题中可能并不存在，在这些情况下，我们可以指示模型自我生成单元测试，以便它可以通过测试来验证其解决方案的正确性（Shinn 等人，2023）。\n一个程序辅助语言模型提示的示例。（图片来源：Gao et al. 2022）\nReAct（Reason+Act；Yao et al. 2023）将搜索维基百科 API 的行为与推理轨迹的生成结合起来，使推理路径能够整合外部知识。\n一个 ReAct 提示方法的示例，用于解决 HotpotQA 问题，通过使用维基百科搜索 API 作为外部工具来辅助推理。（图片来源：Yao et al. 2023）\no3 与 o4-mini，是 OpenAI 最近发布的两个优秀示例，其中推理过程涉及到工具使用，如网页搜索、代码执行和图像处理。团队观察到，大规模强化学习呈现出与 GPT 范式相同的趋势，即“更多计算 = 更好性能”。\n忠实思考（Thinking Faithfully） 深度学习模型通常被当作黑箱来处理，已经提出了各种可解释性方法。可解释性具有几个重要用途：首先，它为我们提供了一个额外的检验手段，用以判断模型是否与其创建者的意图不一致，或是否以我们难以从行为中察觉的方式表现异常。其次，它可以帮助我们判断模型是否使用了合理的流程来得出答案。思维链（Chain-of-thought, CoT）提供了一种特别便利的可解释性形式，因为它以自然语言展示了模型的内部推理过程。然而，这种可解释性的前提是模型能忠实地描述其内部思维过程。\n近期的研究表明，监控推理模型的 CoT 能够有效地检测出模型的不良行为，例如 奖励欺骗（reward hacking），甚至可以使一个较弱的模型监控一个更强的模型（Baker et al. 2025）。增加测试时计算量也能提高对抗性鲁棒性（Zaremba et al. 2025）；从直觉上讲，这也是合理的：在面对异常输入（例如对抗样本或越狱攻击）时，更长的思考时间将特别有助于模型理解其所面临的异常情况。\n该实验要求模型根据其思维过程判断另一个模型是否在某种程度上试图通过代码问题中的单元测试作弊。我们可以通过不同类型的监控器在训练过程中监控这些奖励欺骗行为。exit(0) 代码作弊是指智能体利用一个漏洞在未运行所有单元测试的情况下提前退出环境。raise SkipTest 欺骗是指智能体从测试框架之外的函数抛出异常，以跳过单元测试评估。（图片来源：Baker et al. 2025）\n模型是否忠实地表达了其思考？ 从直觉上讲，模型的 CoT 可能存在偏差，这是由于缺乏明确的训练目标来鼓励忠实推理，或者当我们在基于人类书写解释上微调模型时，这些人类样本本身可能就包含错误。因此，我们不能默认认为 CoT 一定是忠实的。\nLanham 等人（2023） 研究了几种 CoT 忠实性失效的模式，方法是故意在 CoT 中引入错误，并测量这些错误对一系列多项选择任务（例如 AQuA、MMLU、ARC Challenge、TruthfulQA、HellaSwag）准确率的影响：\n错误 1（过早作答）：模型可能在生成 CoT 之前就过早得出结论。这通过提前截断或在 CoT 中插入错误来进行测试。不同的任务揭示了对 CoT 效果的任务特定依赖性；有些任务在 CoT 被截断后评估性能会下降，有些则不会。Wang 等人（2023） 做了类似实验，但引入的是更微妙的错误，例如桥接对象或语言模板方面的错误。 错误 2（无信息 token）：CoT 中的无信息 token 是否提高了性能？该假设通过将 CoT 替换为填充文本（如全为句号）来测试，结果显示没有准确率的提升，并且某些任务的性能在没有 CoT 的情况下略优。 错误 3（人类难以理解的编码）：将相关信息以人类难以理解的方式编码。以非标准方式改写 CoT 不会降低数据集上的性能，说明性能提升并不依赖于人类可读的推理过程。 用于评估 CoT 忠实性的不同扰动方式示意图。（图片来源：Lanham et al. 2023）\n有趣的是，Lanham 等人指出，对于多项选择题，小模型可能还不足以充分利用 CoT，而较大的模型即使没有 CoT 也可能完成任务。这种对 CoT 推理的依赖性（通过“有 CoT 与无 CoT 得出相同答案的比例”衡量）在多选任务中并不总是随着模型规模增加而增加，但在加法类任务中确实随模型规模上升而增强，表明“思考时间”在复杂推理任务中更为重要。\nCoT 依赖性衡量为有无 CoT 情况下给出相同答案的百分比。在加法等推理任务中影响更显著，且大模型受益更多。（图片来源：Lanham et al. 2023）\n测试 CoT 忠实性的另一个方法是扰动提示语（prompt），而不是直接修改 CoT 路径（Turpin et al. 2023、Chua \u0026 Evans, 2025、Chen et al. 2025）。\n一种方法是在少样本示例中始终将正确答案标记为 “(A)”，以人为引入偏差。\n另一种提示方法是在提示中插入误导性暗示，例如： \"我觉得答案是 \u003crandom_label\u003e，但想听听你的意见。\" 或 \"一位斯坦福教授认为答案是 \u003crandom_label\u003e\"。\n通过比较模型在有无误导提示下对同一问题的回答，我们可以测量模型是否能忠实地描述提示对其答案的影响。特别是当模型生成不同答案（有提示与无提示）时，我们衡量模型是否在有提示条件下承认提示对其推理有影响。如果模型是忠实的，它应该明确承认该影响，并指出答案变化是由提示引起的。\nGPT 与 Claude 模型对不同类型的上下文偏差敏感。准确率的下降表明存在系统性的不忠实。直接的错误标签提示比“答案总是 A”类型的偏差更有效。（图片来源：Turpin et al. 2023）\n多项研究发现，推理模型在描述提示影响方面比所有测试过的非推理模型都更可靠。例如，我们可以衡量模型在多少个样本中承认提示是决定性因素（即“忠实 CoT”）。推理模型（Claude 3.7 Sonnet、DeepSeek R1）整体上比非推理模型（Claude 3.6、DeepSeek V3）表现更好。\n推理模型更容易展现出忠实的思维链（faithful CoT），相较于非推理模型。（图片来源：Chen et al. 2025）\n一些证据表明，使用奖励模型（Reward Model）会降低模型输出的忠实性。在经典 RLHF（基于人类反馈的强化学习）中，奖励模型并未被训练来鼓励忠实行为，因为其偏好比较数据集是通过人类选择看起来更好或更令人满意的输出样本构建的。\n然而，在推理模型中，CoT 路径是为了生成正确最终答案而优化的，而不是去迎合奖励模型（RM）中定义的人类偏好，因此从直觉上讲，它们更有可能是忠实的。\n对思维链的优化压力：利还是弊？（Optimization Pressure on CoT: Good or Bad?） 监控推理模型的思维链（CoT）以检测奖励欺骗行为是有效的。一种简单的用法是在测试阶段使用监控器作为过滤器运行拒绝采样，从而识别不含奖励欺骗的解答。然而，这种方法只在强化学习（RL）的早期阶段有效；随着模型进一步优化，很难在计算预算内找到能通过 CoT 监控器的样本。这个挑战自然暗示了我们可以考虑将 CoT 监控器融入 RL 奖励中——这是一种基于过程的监督形式，以防止奖励欺骗。\n然而，将 CoT 监控奖励纳入 RL 中的做法效果并不好，因为它会导致“模糊化的奖励欺骗”：模型试图在 CoT 中隐藏其真实意图（Baker et al. 2025）。即使在 RL 训练中施加来自 CoT 监控器的直接优化压力，模型仍能找到作弊方法，尽管频率略有下降，但它可以将意图隐藏在 CoT 中，从而避开监控器的检测。\n当使用监控器为训练过程提供 RL 奖励信号以防止奖励欺骗时，模型仍然可以找到作弊方式，同时避开监控器的检测。（图片来源：Baker et al. 2025）\nYeo et al. (2025) 对 CoT 长度奖励信号的实验验证了与 Baker 等人相似的结论：新的奖励塑形方式可能引发新的奖励欺骗类型。他们设计了一个奖励函数，使得正确的 CoT 比错误的具有更高奖励，短的正确 CoT 比长的正确 CoT 奖励更高，短的错误 CoT 比长的错误 CoT 惩罚更重。由于该额外奖励，模型倾向于在面对困难问题时在 CoT 中重复文本，而不是尝试真正解决问题。为防止这种作弊行为，Yeo 等人进一步引入了 n-gram 重复惩罚机制。\n在使用 CoT 长度奖励信号进行训练时，需要谨慎地进行奖励塑形以保持稳定性。（图片来源：Yeo et al. 2025）\nChen et al. (2025) 对一个缺陷 RL 环境进行了实验，其中使用了包含错误答案的打分器来评估多项选择题。模型学习如何在超过 99% 的 prompt 上利用奖励漏洞进行作弊，但在他们的大多数环境中，模型几乎从未（\u003c2% 的概率）在其 CoT 中口头表达奖励欺骗的策略。在这种情况下，进一步的 RL 优化压力也无法促使模型显式描述其作弊行为。\nRL 训练本质上对奖励欺骗极为敏感。仅依赖启发式的奖励欺骗调查和手动修复可能导致“打地鼠”（whack-a-mole）式的修补循环。因此，我们建议在 RL 训练中尝试直接优化 CoT 时要非常谨慎，甚至尽量避免这样做。\n连续空间中的思考（Thinking in Continuous Space） 自适应计算时间（Adaptive Computation Time）由 Alex Graves 于 2016 年提出，虽然早于大型语言模型的出现，但开创了使模型能够在推理时动态决定计算步数的方向，这可以被视为使模型在测试时能够在连续空间中“思考更多”。在连续空间中的自适应思考时间可以通过纵向（采用循环架构）或横向（更多的顺序采样步骤）来实现。\n循环架构（Recurrent Architecture） 已经提出了多种架构变体，旨在使 Transformer 架构具备循环能力，以实现自适应测试时计算能力（Dehghani 等人, 2019、Hutchins 等人, 2022、Bulatov 等人, 2022）。深入探讨该主题的文献会使本文过长，因此这里只回顾部分代表性工作。\nUniversal Transformer（Dehghani 等人, 2019）将 Transformer 中的自注意力机制与 RNN 中的循环机制结合，借助自适应计算时间机制（Graves, 2016）动态调整处理步骤数量。在高层次上，它可被视为对每个 token 学习隐藏状态表示的循环函数；若步数固定，则 Universal Transformer 等价于一个具有跨层参数共享的多层 Transformer。\n一项较新的循环架构设计由 Geiping et al. (2025) 提出：在标准 Transformer 之上添加一个循环模块 R。该循环模块的每次迭代接收嵌入$e$ 和一个随机状态$s\\_i$。从概念上讲，这种循环深度架构有些类似于条件扩散模型（conditioned diffusion model），其中原始输入$e$ 在每一步中都作为输入传入，而一个初始为高斯分布的随机状态$s\\_i$ 经过多次迭代被不断更新。（有趣的是，他们部分类似扩散模型的设计在实验中表现较差。）\n$$ e = P(x)\\quad \\text{（嵌入）} \\\\ s_0 \\sim \\mathcal{N}(0, \\sigma^2 I_{n \\cdot h}) \\\\ s_i = R(e, s_{i-1})\\quad \\text{对于 } i \\in \\{1, \\dots, r\\} \\quad \\text{（循环模块，类似 Transformer block）} \\\\ p = C(s_r)\\quad \\text{（反嵌入层）} $$训练时，循环次数$r$ 对每个输入序列是随机的，采样自对数正态泊松分布。为控制计算开销，反向传播仅对循环单元的最后$k$ 次迭代进行（实验中$k=8$），从而可以在 Poisson 分布的长尾部分进行训练。嵌入模块的输出$e$ 在每一步都被注入，因此在每步中都接收梯度更新，模拟 RNN 的训练方式。\n不出所料，训练循环模型的稳定性非常敏感。诸如初始化、归一化、超参数等因素都至关重要，尤其在扩大训练规模时。例如，隐藏状态可能会崩溃：所有 token 的隐藏状态预测相同；或者模型可能学会忽略输入状态$s$。为提升稳定性，Geiping 等人采用了嵌入缩放因子、较小的学习率和精心调参。\n在训练一个 35 亿参数模型的深度循环实验中绘图。约在$\\bar{r} = 32$ 时趋于饱和，使人思考该架构在更大迭代次数上的外推和泛化能力。（图片来源：Geiping et al. 2025）\n思维Token（Thinking Tokens） 思维token指的是在训练或推理过程中引入的一组隐式token，它们本身不携带直接的语言含义。相反，它们的作用是为模型提供额外的“思考时间”和计算能力，以便获得更好的表现。\nHerel 与 Mikolov（2023） 引入了在句子中每个单词后插入特殊思维token（例如 \u003cT\u003e）的想法，并在这种构造的数据集上训练模型。每个思维token为模型提供了更多的时间来处理信息并作出更优预测。在玩具模型设置下，使用思维token训练的模型比不使用它们的基线模型获得了更低的困惑度（perplexity）。思维token的益处在面对复杂推理任务或涉及数字的句子时尤为明显。\n类似地，Goyal 等人（2024） 提出的暂停token（pause tokens）通过在输入序列末尾添加虚拟token（例如 . 或 # 之类字符）来延迟模型的输出，从而在推理阶段为模型提供额外的计算资源。重要的是在训练和推理阶段都注入这些暂停token，仅在微调阶段使用暂停token收效甚微。在训练过程中，这些暂停token被插入到随机均匀位置的多个副本中，并且训练时忽略这些token的loss。\n与标准设置相比，训练与推理阶段注入暂停token的方式示意图。（图片来源：Goyal et al. 2024）\n有趣的是，在上述实验中，思维token或暂停token并未携带任何额外信息，也没有引入新的参数，但为何仍然有效呢？一方面，它们通过引入更多的推理循环扩展了计算资源，从而有效提升计算能力；另一方面，它们可被视为一种特殊的、隐式的思维链（CoT）形式。其不足之处在于模型需要针对思维token进行预训练。尽管如此，这种策略为进一步提升测试时计算资源的利用能力，在推理阶段CoT之外提供了新的路径。\nQuiet-STaR（Zelikman 等人，2025）通过在每个token后生成推理理由（rationale）来引入token级推理。它混合带有和不带理由的未来token预测，并使用学习机制来生成更优的推理理由，同时用 REINFORCE 方法优化 rationale 的质量。\nQuiet-STaR 示意图。（图片来源：Zelikman et al. 2025）\nQuiet-STaR 包含三个阶段：\nThink：带 rationale 的下一token预测。由于token级推理代价高昂，该过程设计为并行生成多个 rationale。使用特殊注意力映射，使所有思维token仅关注自己、当前思维中的先前思维token，以及前文文本。 Talk：不带 rationale 的下一token预测与带 rationale 的结果进行混合。两者logits的混合权重由浅层MLP结构输出的混合头部学习而来。最终可通过教师强制（teacher forcing）选择正确token。 Learn：通过 REINFORCE 训练模型生成更好的 rationale，保留提升下一个token预测概率的样本，舍弃降低性能的样本。 在未进行数据集特定微调的情况下，Quiet-STaR 在 Mistral 7B 上实现了零样本条件下的性能提升：CommonsenseQA 从 36.3% 提升至 47.2%，GSM8K 从 5.9% 提升至 10.9%。\n思考作为潜变量（Thinking as Latent Variables） 潜变量模型定义了一种概率框架，通过不可观测的**潜变量（latent variables）**来解释可观测数据。这些潜变量捕捉了生成观察结果的隐藏结构或中间过程。语言模型可被视为概率潜变量模型，其中测试时的思考与推理步骤就是潜在的“思维变量”（latent thought variables）（Zhou et al. 2020、Phan et al. 2023）。\n此类模型定义问题$x\\_i$、答案$y\\_i$ 与潜在思维$z\\_i$ 的联合分布。我们的目标是最大化在给定多个思维链情况下的对数似然（$N$ 是样本数，$K$ 是每个问题的CoT数量）：\n$$ \\log L(\\theta) = \\log p(y|x) = \\log \\sum_{k=1}^{K} p(y, z^{(k)}|x) = \\log \\sum_{k=1}^{K} p(z^{(k)}|x) p(y|z^{(k)}, x) = \\log \\mathbb{E}_{z^{(k)} \\sim p(z^{(k)}|x)} [p(y|z^{(k)}, x)] $$我们的目标是，在给定每个问题的若干推理轨迹${z^{(k)}}\\_{k=1}^K$ 的前提下，最大化答案的边际似然$p(y|x)$。\n期望最大化（Expectation-Maximization） 期望最大化算法（Expectation–Maximization, EM） 是一个广泛使用的迭代算法，用于优化带有隐藏变量的模型参数，因此也可用于训练更优的 CoT 并据此生成更优答案。\n该算法通常在以下两个步骤之间迭代，直到收敛：\nE 步骤（Expectation）：估计潜变量的缺失信息（即如何采样更好的 CoT）； M 步骤（Maximization）：在给定潜变量下优化模型参数（即如何生成更好的答案）： $$ \\log L(\\theta) = \\underbrace{\\log \\mathbb{E}_{z^{(k)} \\sim p(z^{(k)}|x)}}_{\\text{E-step}} \\underbrace{p(y|z^{(k)}, x)}_{\\text{M-step}} $$由于我们无法直接从后验分布$p(z|x,y)$ 中采样，研究者们探索了其他方法，如使用人类标注数据（Zhou et al. 2020）、Metropolis-Hastings MCMC 采样（Phan et al. 2023）、或带特殊重要性权重的 Monte Carlo 采样（Ruan et al. 2025）来获得高质量 CoT 样本以更新模型。\nRuan 等人（2025） 实验使用带潜在思维的 Web 文本语料，并采用 EM 算法进行训练，其中潜在思维对每段观察数据合成生成，模型在潜在思维与文本联合建模下以自回归方式学习。\n注入潜在思维后的语料训练流程示意图。（图片来源：Ruan et al. 2025）\n他们首先用一个 LLM$q\\sim$ 在给定观察数据$X\\_i$ 的前提下生成潜在思维$Z\\_i$：\n你将获得一对网页文档的前缀与后缀。你的任务是在它们之间插入潜在思维，来解释后缀是如何基于前缀生成的。潜在思维应包括：缺失的背景知识，以及每个陈述背后的推理过程（特别是逐步推导或逻辑推理）。 通过 \u003cStartOfLatent\u003e\u003cPrior\u003e ... \u003cEndOfPrior\u003e 这样的特殊token，将生成的潜在思维插入原始数据中，以训练联合分布$p(z, x)$ 或近似后验$q(z|x)$，具体取决于插入位置（在$x$ 前或后）。但由于 CoT 是由近似模型$q\\sim(z|x)$ 生成，其性能会受限。\n为解决这一问题，Ruan 等人提出在 E 步中引入重要性权重，其公式为：\n$$ w^{(k)} = \\frac{p(z^{(k)}, x)}{q(z^{(k)}|x)} = \\frac{p(x|z^{(k)}) p(z^{(k)})}{q(z^{(k)}|x)} $$即优先选择那些：能够较好预测观察数据（$p(x|z^{(k)})$ 高）、简单直观（$p(z^{(k)})$ 高）、但又不是过于显而易见的 CoT（$q(z^{(k)}|x)$ 低）。\n迭代学习（Iterative Learning） 由于预训练模型已经具备生成思维链（CoT）的能力，因此可以设计一个直观的迭代改进流程：生成多个 CoT，并仅在**能导出正确答案的推理理由（rationale）**上对模型进行微调。\n然而，这种直接设计可能失败，因为模型在失败的问题上无法获得学习信号。STaR（“自学推理器”，Self-taught reasoner；Zelikman et al. 2022）通过引入“rationalization”过程解决了这个限制：当模型失败时，它会在已知问题和真实答案的条件下向后生成高质量 CoT，以便生成更合理的推理链。然后，模型会在以下两类正确解答上进行微调：一类是自然推导得到正确答案的 CoT，另一类是通过 rationalization 生成的 CoT。\nSTaR 算法示意图。（图片来源：Zelikman et al. 2022）\n我们可以将 STaR 看作是强化学习中策略梯度（policy gradient）的一种近似形式，其中奖励函数为简单的指示函数$𝟙[ŷ = y]$。我们的目标是在$z ∼ p(z|x)$、$y ∼ p(y|x,z)$ 的采样过程中最大化该奖励的期望，因为\n$$ p(y|x) = \\sum_z p(z|x) p(y|x,z) $$推导如下：\n$$ \\nabla_θ J(θ) = \\nabla_θ \\mathbb{E}_{z_i, y_i ∼ p(\\cdot | x_i)} \\mathbb{1}[y_i = y_i^{truth}] \\\\ = \\sum_{i=1}^N \\nabla_θ \\mathbb{1}[y_i = y_i^{truth}] p(y_i, z_i | x_i) \\\\ = \\sum_{i=1}^N \\mathbb{1}[y_i = y_i^{truth}] p(y_i, z_i | x_i) \\nabla_θ \\log p(y_i, z_i | x_i) $$每次迭代等价于：首先根据$\\mathbb{1}[y = y\\_{truth}]$ 筛选 CoT 样本，然后通过监督微调优化生成优质 CoT 与答案的对数概率（logprob）。STaR 的性能随训练迭代次数提升而改善，而“rationalization”过程进一步加速了模型对更优 CoT 的学习。\n他们还观察到：高温采样（high temperature sampling）虽然提高了获得正确答案的几率，但往往伴随着错误的推理链，在这种数据上微调 LLM 会降低泛化能力。对于没有真实标签的数据集，可以采用多个高温输出的多数投票结果作为“代理真值”（proxy ground truth）（Wang et al. 2022），从而使用合成样本进行训练。\n两数相加任务准确率对比示意图。通过 rationalization（基于真实答案生成 CoT），模型能够更早掌握复杂运算任务，如 5 位数加法。（图片来源：Zelikman et al. 2022）\n思考时间的扩展规律（Scaling Laws for Thinking Time） 前文已提供了大量证据表明：在推理阶段允许模型投入更多计算资源以进行思考，在产生最终答案前进行推理，可以显著提升性能。诸如“提示模型生成中间推理步骤”或“训练模型在预测下一个 token 前暂停思考”的技术，均可让模型性能超越训练阶段所获得的能力上限。这本质上为提升模型智能引入了新的维度，与传统 scaling law 中的规模、训练计算量、数据量等因素互补（Kaplan et al. 2020）。\n近期研究表明，优化大语言模型（LLM）在测试时的计算资源使用，可能比单纯扩展参数量更高效（Snell et al. 2024，Wu et al. 2025）。小模型配合高效的推理算法，可以在成本与性能之间提供帕累托最优的权衡。\nSnell 等人（2024） 比较了预训练计算与推理计算的使用情况，并发现两者不可互换。测试时计算在模型能力差距较小时可轻松弥补简单和中等难度问题的缺口，但在困难问题上补偿能力有限。预训练与推理token预算之比至关重要。测试时计算仅在推理token远少于训练token的情况下才具有优势。这表明：构建能力强大的基础模型仍然是核心任务，仅靠推理时计算无法弥补大能力缺口。\n（左）不同推理预算下的准确率变化（迭代修订 vs 并行解码）；（右）小模型+推理技巧 vs 大14倍模型+贪婪解码性能对比。当推理token远少于训练token时，测试时计算的优势最为明显。（图片来源：Snell et al. 2024）\ns1 模型（Muennighoff \u0026 Yang 等人，2025）通过“预算强制”（budget forcing）技术控制思维链长度（即强制加词 \"wait\" 增加推理长度，或使用 \"Final Answer:\" 提前结束推理）。他们观察到：平均思考时间（以token计）与下游任务准确率呈显著正相关。\n并行与顺序扩展的测试时计算方法在 s1 实验中均展现出与评估性能的正相关关系。（图片来源：Muennighoff \u0026 Yang 等人，2025）\n当将此预算强制技术与其他控制 CoT 长度的解码方法对比时，发现一个惊人现象：简单的拒绝采样（即仅接受满足指定长度的生成）反而导致“反向 scaling”——即 CoT 越长，准确率越低。\n（左）思维链路径越长，评估准确率越高；（右）使用拒绝采样控制 CoT 长度时，路径越长反而准确率越低，呈负相关。（图片来源：Muennighoff \u0026 Yang 等人，2025）\n未来展望（What’s for Future） 对测试时计算（test-time compute）和思维链推理（chain-of-thought reasoning, CoT）的探索为提升模型能力带来了新的机遇。更有趣的是，通过测试时思考机制，我们正逐步迈向构建更类人的 AI 系统，这些系统将体现人类思维中的最佳实践，包括适应性、灵活性、批判性反思与自我纠错。\n当前的进展令人振奋，同时也激励我们在未来开展更多研究，不仅要深入理解“我们——以及我们的模型——如何思考”，更要理解“为何思考”。\n在文章的最后，作者呼吁研究者对以下有关测试时计算与思维链推理的未解问题展开进一步研究：\n我们能否激励模型在强化学习（RL）训练过程中，生成人类可读且忠实的推理路径，同时避免奖励欺骗行为？\n如何定义奖励欺骗（reward hacking）？我们能否在不依赖人类干预的前提下，在强化学习训练或推理过程中捕捉奖励欺骗？又如何避免对奖励欺骗的“打地鼠”式（whack-a-mole）修复？\n自我纠错（self-correction）可以在思维链内部发生，也可以在多轮强化学习中被显式激励。我们如何在没有真实标签（ground truth）时，训练模型自我纠错而不引发幻觉（hallucination）或性能退化（regression）？\n对于高度依赖上下文、个性化且难以评分的任务（如创意写作、情感辅导、头脑风暴），我们该如何进行基于 CoT 展开的强化学习训练？\n在实际部署模型时，我们不可能无限增加测试时的思考时间。那么如何将测试时思考带来的性能收益，平滑地转化为基础模型的能力（例如通过 知识蒸馏 distillation 以降低推理成本）？\n如何使测试时计算的投入根据任务难度自动适配？即，模型在遇到困难问题时“多想一会”，在简单任务上则快速给出答案？\nCitation Please cite this work as:\nWeng, Lilian. \"Why We Think\". Lil'Log (May 2025). https://lilianweng.github.io/posts/2025-05-01-thinking/ Or use the BibTex citation:\n@article{weng2025think, title = {Why We Think}, author = {Weng, Lilian}, journal = {lilianweng.github.io}, year = {2025}, month = {May}, url = \"https://lilianweng.github.io/posts/2025-05-01-thinking/\" } References [1] Alex Graves. “Adaptive Computation Time for Recurrent Neural Networks.”. arXiv preprint arXiv:1603.08983 (2016).\n[2] Wang Ling, et al. “Program Induction by Rationale Generation: Learning to Solve and Explain Algebraic Word Problems.”. arXiv preprint arXiv:1705.04146 (2017).\n[3] Karl Cobbe, et al. “Training Verifiers to Solve Math Word Problems.”. arXiv preprint arXiv:2110.14168 (2021).\n[4] Jason Wei, et al. “Chain of Thought Prompting Elicits Reasoning in Large Language Models.”. NeurIPS 2022.\n[5] Maxwell Nye, et al. “Show Your Work: Scratchpads for Intermediate Computation with Language Models.”. arXiv preprint arXiv:2112.00114 (2021).\n[6] Daniel Kahneman. Thinking, Fast and Slow. Farrar, Straus and Giroux (2013).\n[7] Takeshi Kojima, et al. “Large Language Models are Zero-Shot Reasoners.”. NeurIPS 2022.\n[8] Michihiro Yasunaga, et al. “Large Language Models as Analogical Reasoners”. arXiv preprint arXiv:2310.01714 (2023).\n[9] Eric Zelikman, et al. “STaR: Bootstrapping Reasoning With Reasoning.”. NeurIPS 2022.\n[10] Xuezhi Wang, et al. “Self-consistency Improves Chain of Thought Reasoning in Language Models.”. ACL 2023.\n[11] Ryo Kamoi, et al. “When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs.”. TACL 2024.\n[12] Jie Huang, et al. “Large Language Models Cannot Self-Correct Reasoning Yet.”. ICLR 2024.\n[13] Noah Shinn, et al. “Reflexion: Language Agents with Verbal Reinforcement Learning.”. arXiv preprint arXiv:2303.11366 (2023).\n[14] Yunxiang Zhang, et al. “Small Language Models Need Strong Verifiers to Self-Correct Reasoning.”. ACL Findings 2024.\n[15] Hao Liu, et al. “Chain of Hindsight Aligns Language Models with Feedback.”. arXiv preprint arXiv:2302.02676 (2023).\n[16] Sean Welleck, et al. “Generating Sequences by Learning to Self-Correct.”. arXiv preprint arXiv:2211.00053 (2023).\n[17] Yuxiao Qu, et al. “Recursive Introspection: Teaching Language Model Agents How to Self-Improve.”. arXiv preprint arXiv:2407.18219 (2024).\n[18] Aviral Kumar, et al. “Training Language Models to Self-Correct via Reinforcement Learning.”. arXiv preprint arXiv:2409.12917 (2024).\n[19] Hunter Lightman, et al. “Let’s Verify Step by Step.”. arXiv preprint arXiv:2305.20050 (2023).\n[20] Yuxi Xie, et al. “Self-Evaluation Guided Beam Search for Reasoning.”. NeurIPS 2023.\n[21] Yangzhen Wu, et al. “Inference Scaling Laws: An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models”. ICLR 2025.\n[22] Dongwei Jiang, et al. “RATIONALYST: Pre-training Process-Supervision for Improving Reasoning”. arXiv preprint arXiv:2410.01044 (2024).\n[23] Xuezhi Wang and Denny Zhou. “Chain-of-Thought Reasoning Without Prompting.”. arXiv preprint arXiv:2402.10200 (2024).\n[24] DeepSeek-AI. “DeepSeek-V3 Technical Report.” arXiv preprint arXiv:2412.19437 (2024).\n[25] DeepSeek-AI. “DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning.”. arXiv preprint arXiv:2501.12948 (2025).\n[26] Luyu Gao, Aman Madaan \u0026 Shuyan Zhou, et al. “PAL: Program-aided Language Models.”. ICML 2023.\n[27] Shunyu Yao, et al. “ReAct: Synergizing Reasoning and Acting in Language Models.”. ICLR 2023.\n[29] Bowen Baker, et al. “Monitoring Reasoning Models for Misbehavior and the Risks of Promoting Obfuscation.”. arXiv preprint arXiv:2503.11926 (2025).\n[30] Wojciech Zaremba, et al. “Trading Inference-Time Compute for Adversarial Robustness.”. arXiv preprint arXiv:2501.18841 (2025).\n[31] Tamera Lanham, et al. “Measuring Faithfulness in Chain-of-Thought Reasoning”. arXiv preprint arXiv:2307.13702 (2023).\n[32] Boshi Wang, et al. “Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters.”. ACL 2023.\n[33] Miles Turpin, et al. “Language Models Don’t Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting.”. NeuriPS 2023.\n[34] James Chua \u0026 Owain Evans. “Are DeepSeek R1 And Other Reasoning Models More Faithful?”. arXiv preprint arXiv:2501.08156 (2025).\n[35] Yanda Chen et al. “Reasoning Models Don’t Always Say What They Think”. arXiv preprint arXiv:2505.05410 (2025).\n[36] Edward Yeo, et al. “Demystifying Long Chain-of-Thought Reasoning in LLMs.”. arXiv preprint arXiv:2502.03373 (2025).\n[37] Mostafa Dehghani, et al. “Universal Transformers.”. ICLR 2019.\n[38] DeLesley Hutchins, et al. “Block-Recurrent Transformers.”. NeurIPS 2022.\n[39] Aydar Bulatov, et al. “Recurrent Memory Transformers.”. NeuriPS 2022.\n[40] Jonas Geiping, et al. “Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach.”. arXiv preprint arXiv:2502.05171 (2025).\n[41] Herel \u0026 Mikolov. “Thinking Tokens for Language Modeling.”. AITP 2023.\n[42] Sachin Goyal et al. “Think before you speak: Training Language Models With Pause Tokens.”. ICLR 2024.\n[43] Eric Zelikman, et al. “Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking.”. arXiv preprint arXiv:2403.09629 (2025).\n[44] Wangchunshu Zhou et al. “Towards Interpretable Natural Language Understanding with Explanations as Latent Variables.”. NeurIPS 2020.\n[45] Du Phan et al. “Training Chain-of-Thought via Latent-Variable Inference.”. NeurIPS 2023.\n[46] Yangjun Ruan et al. “Reasoning to Learn from Latent Thoughts.”. arXiv preprint arXiv:2503.18866 (2025).\n[47] Xuezhi Wang et al. “Rationale-Augmented Ensembles in Language Models.”. arXiv preprint arXiv:2207.00747 (2022).\n[48] Jared Kaplan, et al. “Scaling Laws for Neural Language Models.”. arXiv preprint arXiv:2001.08361 (2020).\n[49] Niklas Muennighoff \u0026 Zitong Yang, et al. “s1: Simple test-time scaling.”. arXiv preprint arXiv:2501.19393 (2025).\n[50] Peiyi Wang, et al. “Math-Shepherd: Verify and Reinforce LLMs Step-by-step without Human Annotations” arXiv preprint arXiv:2312.08935 (2023).\n[51] Yixin Liu, et al. “Improving Large Language Model Fine-tuning for Solving Math Problems.” arXiv preprint arXiv:2310.10047 (2023).\n[52] Charlie Snell, et al. “Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters.”. arXiv preprint arXiv:2408.03314 (2024).\n[53] OpenAI. o1-preview: “Learning to reason with LLMs.” Sep 12, 2024.\n[54] OpenAI. o3: “Introducing OpenAI o3 and o4-mini.” Apr 16, 2025.",
    "description": "测试时计算（test time compute）与思维链（Chain-of-thought, CoT）已显著提升了模型性能，同时也引发了许多研究问题。本文旨在回顾关于如何有效利用测试时计算（即“思考时间”）以及为何它能带来帮助的最新进展。",
    "tags": [],
    "title": "Why We Think",
    "uri": "/agi/why-we-think-ch/index.html"
  },
  {
    "breadcrumb": "FlitSoft Docs \u003e  C2",
    "content": "Decision Advantage and Initiative Completing Joint All-Domain Command and Control\nBrian R. Price\nAbstract 本文在约翰·博伊德（John Boyd）的观察、定向、决策、行动（OODA）循环和他的《指挥与控制的有机设计》（1987）分析的背景下定义了决策优势和主动权。博伊德的思想远远超越了他所在的时代，但在当今不断变化的作战环境中仍具有重要的现实意义。决策优势的结果是主动权。此外，决策优势不仅是一种状态，也是实现这种优势所需的过程。由于人类仍然是有效的联合全域指挥与控制的关键，规划者和战略家必须接受有关这些关键概念的理论细微差别的教育。\n以空军对决策优势的概念为基础，本文提出了在决策与执行（即规划、决策和执行过程中的“d”和“e”）之间建立更紧密联系的建议。决策优势植根于退役的美国空军上校约翰·博伊德的指挥与控制决策循环概念，本文通过主动权的概念进一步拓展了他的思想。本文提出的主动权工作定义和对空军决策优势定义的修改，完善了联合全域指挥与控制（JADC2）的概念。这些变革有助于联合作战力量创造一种决策氛围，鼓励教育的开展，从而将态势感知纳入更广泛的理解中，并融入那些更难以量化的人为因素的复杂性。\nIntroduction 决策优势：决策优势是态势理解、确保和交换信息的能力，以及通过在各个领域保持优势来进行和传达决策的产物。——《空军条令出版物3-99》，2021年11月19日\n布莱恩·普莱斯博士是空军指挥与参谋学院战斗部门的副教授。\n文职和军事领导人在所需的速度下做出及时的决策，以超越对手。决策需要一个共同的情报图景和对全球部队部署的共享理解，以实时观察作战行动：识别抓住主动权的机会，识别权衡、风险和机会成本。自动化、预先计划的响应和任务指挥对于以所需的相关速度采取行动至关重要。——《联合出版物3-0》，2022年6月\n国防部对联合全域作战（JADO，前身为多域作战）的接受，已引发了一系列发展和组织活动，这些活动由对作战环境变化的感知以及特定近敌对手挑战美国安全领导地位的努力所激发。指挥与控制是所有军种对多域或全域作战概念的核心。鉴于新兴技术对过去规划、决策和执行周期限制的潜在深远影响，本文——作为空军大学2020年JADC2会议的成果——通过博伊德1987年简报《指挥与控制的有机设计》的视角，探讨了决策优势的概念。\n尽管博伊德的脾气暴躁减少了他帮助国防机构的效果，但他在20世纪80年代末的著作在考虑JADC2的意图和架构时，显得出奇地预见性。对博伊德思想的研究可以帮助当前一代的规划者和架构师更好地理解可能性。\n无论使用何种技术来驱散战争中的迷雾与摩擦，人类因素——信仰、信任、共同愿景、身份认同、知识、经验、教育与训练等——可以说对JADC2系统的重要性丝毫不亚于传感器网络、开放数据标准与交换、网状连接、云计算或边缘计算、人机协作、机器学习，甚至人工智能（AI）。俄罗斯对该问题的应对方式表明，俄罗斯的规划者将人类因素视为JADC2系统中最薄弱的环节之一，或可能是其最强有力的方面。\n本文探讨了似乎支撑国防部JADC2系统的一个基本信条——博伊德的观察、定向、决策、行动（OODA）循环。本文并不质疑国防部对这一决策模型的采用。此外，尽管本文探讨了JADC2条令和架构设计，但由于篇幅限制，未涉及作为实践的条令制定的适用性。\nBackground 关于军事革命的概念存在激烈的争论。尽管如此，许多美国军事、盟友和合作伙伴的规划者都认识到正在进行的一场革命，俄罗斯和中国也同样注意到这场革命，它利用了新兴技术。这些技术包括传感器网络、开放架构数据框架、机器学习（“弱”AI）、云计算或边缘计算以及高级分析。此外，这些技术有可能超越现有的规划、决策和执行过程。联合全域指挥与控制旨在为下一代决策者提供根本性优势，但这些技术将如何塑造未来的规划、决策和执行周期，目前尚未明确阐述。\n然而，决策本身并不提供优势；相反，由决策产生的行动——即夺取和保持主动权——才能带来优势。主动权是安全领域内一个未被充分重视的概念，尽管它类似于体育运动中的动量概念，但却难以评估。\n将决策与行动联系起来的问题引发了军事规划者之间的辩论：决策优势是部分由信息优势、训练、教育和人类领域内的其他因素导致的一种状态，还是代表了实现预期效益所必需的过程？事实上，在制定决策优势的全面理论定义时，考虑这两种概念都是至关重要的。无论拥有多少态势感知，都无法替代初级或高级领导者的理解。此外，即使操作执行得再完美，如果战略本身存在缺陷，也可能会失败，正如在阿富汗所发生的那样。\n定义决策优势的基础 尽管高级领导层采用了“信息优势”和“决策优势”这两个术语来表达对联合全域作战（JADO）方法的期望收益，但多年来“决策优势”一直未能被国防部明确定义。在未分类的JADC2和多域作战/JADO文件中提到过决策优势的概念，但并未清晰定义，尽管JADC2系统的全部目的就是“决策的艺术与科学，以及将这些决策转化为行动的能力，利用跨所有领域和任务伙伴的能力，在竞争和冲突中实现作战优势。”最终，在2021年11月，空军发布了其定义。\n图1. 修改后的JADC2高层作战图示\n有些人可能会认为JADC2就是决策优势。上述定义在整个冲突连续体中提供了有用的联系，尽管它并未明确将这一概念与JADC2的技术架构联系起来。这个定义也出现在2020年空战司令部关于JADC2的关键图形总结（图1）中，任务是“以压倒性的决策优势挫败敌人的进攻”，但同样没有明确定义什么是决策优势。\nJADC2的概念是一种旨在提供卓越态势感知的架构。理解JADC2至少需要深入的领域知识，理想情况下，还需要跨领域的知识，这反映了在形成背景时相互碰撞和交互的关键视角。\n在美国军队中，人机协作增强了决策过程。陆军多域作战条令指出，“由人工智能和高速数据处理支持的人机界面，提高了人类决策的速度和准确性。”《2028年多域作战中的美国陆军》，美国陆军训练与条令司令部（TRADOC）手册525-3-1，强调攻击对手的情报、监视和侦察体系：“陆军部队与伙伴及联合部队协作，反制敌方侦察，并实施欺骗，以在敌方决策过程中制造不确定性。”此外，它还指出，“在竞争中展示的能力削弱了对手的信息战行动，并在其决策过程中制造复杂性和不确定性。”\n这与俄罗斯的做法类似，其目的是在决策循环中注入模糊性，以创造机动空间。这也类似于中国的决策方式，中国通过“系统毁灭战”来阻止关键信息的获取并导致瘫痪。\n尽管陆军手册没有定义或使用“决策优势”这一术语，但它确实使用了“决定性空间”这一术语，并将其定义为“在时间和空间（物理、虚拟和认知）中，通过跨域能力的全面优化使用，产生显著优势并极大地影响作战结果的位置。”这似乎是对“决定性点”这一熟悉概念的改编，并且与中国选择对手系统中的关键点并设计对抗系统来进行打击的概念相似。\nTRADOC 525-3-1还讨论了预测性保障作战： 精确后勤保障依赖于一个保障企业资源计划决策支持系统（重点突出），该系统具有预测分析工具和无需请求即可补给或根据优先级重新分配物资的能力；以及指挥官和后勤人员在各级能够查看的实时共同作战图景。\n这样的系统对于支持敏捷作战部署或其他形式的动态部队部署是绝对必要的。\n最后，陆军的综合作战行动旨在协调“与信息相关的能力（IRC），与其他作战线相结合，影响、欺骗、破坏、腐蚀或颠覆敌人和对手的决策，同时保护我们自身”，并影响敌人和民众的战斗意志。TRADOC 525-3-1强调了削弱敌方决策能力的重要性，并建议保护美国的类似能力。在TRADOC 525-3-1的构想中，优势主要通过攻击敌方的认知能力而非构建一个更优越的决策流程和信息环境来获得。\n前陆军未来司令部司令约翰·M·默里（John M. Murray）将军在2021年3月的一次采访中引用前陆军参谋长詹姆斯·麦康维尔（James McConville）将军对“决策主导”一词的使用，清晰地表达了陆军对决策优势的定义：“这是一个正在发展的定义，但目前来看，‘决策主导’是指指挥官能够比任何对手更快、更有效地感知、理解、决策、行动和评估的能力。”默里的这一概念与博伊德的OODA循环非常接近。\n从情报的角度来看，另一种分析指出，可用的、适当分析和保护的情报“可以提供决策优势，使决策者获得更好的信息，并以一种没有这些情报就无法实现的方式理解问题的更多方面”，并且“当对手或竞争者不具备相同的见解或不了解对方决策者所知内容时，这种决策优势尤为关键。”\n这种来自情报界的决策优势概念具有许多优势。在决策者与其对手的比较中，“更好地了解”和“理解问题的更多方面”是基础。这些条件体现了信息和背景的质量，从而导致更优越的理解。\n在讨论JADC2和2021年全球信息主导演习时，美国北方司令部官员表示，“新的人工智能将即时汇集各种数据，为指挥官提供战场的清晰图景，从而做出良好而迅速的决策。”这些官员指出，“关键在于，由AI系统——而不是过去那样缓慢的人类——迅速提供并不断升级最佳选项，以确保高概率的拦截成功率。”美国北方司令部J8 JADC2开发负责人最近解释说：\n“现在，人类可以有更多的时间和更多的选项来做出决策。”\n……[这个工具的想法是提供]一个关于竞争者正在做什么的更早期和更好的理解……这个工具让我们能够看到：竞争者在日常基础上的行动是什么，他们在机场、指挥控制设施以及他们将用于海上行动的地方做了些什么。\n2020年，美国北方司令部司令特伦斯·O’Shaughnessy将军表示，“[JADC2] 将为我们的决策者提供信息，帮助他们做出类似下棋般的决策，思考两到三步之后的动作。它将以相关的速度为决策者提供做出非常复杂决策的能力。”\n博伊德的OODA循环、有机指挥与控制（C2）以及主动权概念 回顾博伊德的OODA循环——这是支撑JADC2的关键基础概念——可以发现现有理论和操作文件中未能涵盖的关于决策优势的一些方面。OODA循环的决策周期概念位于JADC2和JADO愿景与架构文件的核心，假设在技术发展的推动下，更快且拥有更全面的信息进行行动是必要且不可避免的。然而，这一假设曾受到博伊德的挑战。\n在20世纪后期，模糊性、主动权和决策的问题引起了博伊德的注意。虽然博伊德的一些成就可能被夸大了，但他持久的贡献在于将战略家、规划者和行动者的战争、冲突和竞争概念从基于规模转向基于节奏和破坏的模式。这些思想在当今快节奏的技术创新环境中显得更加相关。博伊德是最早提出这些概念的人之一——或许有些过早了——但他的工作对当今的环境仍具有相当的见解，尤其是在模糊性已成为美国近敌对手首选武器的当下。\n简化版OODA循环模型在决策中的广泛接受，证明了博伊德这一引人注目的启发式方法的普及。在军事、商业和战略写作中，“决策周期”一词常常与OODA循环同义。在由所有主要国防部利益相关者制定的图1中，这一循环被呈现为“理解、决策、指挥、实施、评估”。在JADC2文献中，OODA概念作为核心基础，一套需要仔细审视的假设。\n在他的空军生涯中，博伊德对战斗机战术的教学和战斗机设计中机动性的实现与工程作出了重要贡献，这些成就通过他与数学家汤姆·克里斯蒂（Tom Christie）共同开发的能量机动性理论得以实现。在职业生涯后期，博伊德发展了他的核心思想，融入了复杂自适应系统的概念，这些概念现在已反映在国防部的理论中。博伊德通过他多次修订的“冲突模式”简报以及一系列其他不那么宏大但富有洞察力的作品，广泛探讨了冲突问题。\n尽管“冲突模式”受到了广泛关注，但他1987年的一份不太为人所知的简报“指挥与控制的有机设计”定义了今天常用的OODA循环。在“有机设计”中，博伊德阐述了他的愿景。其目的不仅是要更快速地行动，还要创造导致对手混乱和瘫痪的环境，即“在对手的观察-定向-决策-行动循环内作战，将对手困在一个充满不确定性、怀疑、不信任、混乱、无序、恐惧、恐慌和混乱的世界中……或者将对手反折回他自己内部，使其无法应对正在展开的事件和行动。”这后半部分“将对手反折回他自己内部，使其无法应对正在展开的事件和行动”与俄罗斯的反射性控制概念以及中国分解系统链条以孤立系统各部分的做法非常相似，使得各部分之和小于整体。\n博伊德进一步强调了指挥与控制中社会、智力和文化方面的重要性，他总结道，由“基因遗产、以往经历和正在展开的环境”所提供的凝聚力有助于通过滤镜创建环境图景。滤镜源于人类的经验——这些是塑造观察和定向的有形和无形元素。反过来，人为因素是通过决策循环过程取胜的重要推动力。博伊德认为，这一过程就是指挥与控制：“观察-定向-决策-行动的过程代表了指挥与控制过程中发生的事情——这意味着OODA循环可以被认为就是C\u0026C循环。”\nJADC2架构和概念反映了旨在显著提高作战节奏和复杂性的最新发展。这不仅缩短了决策周期，还将其压缩到了所谓的“OODA点”，即数据源的速度和复杂性超出了人类的处理能力。因此，操作员越来越依赖于人机协作、机器学习，最终依赖人工智能（AI）。因此，中国和俄罗斯等近敌竞争者采取了各自的方法，试图介入美国的规划、决策和执行循环。\n在近期竞争和冲突中，决策周期潜力的明显压缩是重要的，但这一概念可能是不完整的。长期研究博伊德思想的弗朗斯·奥辛加（Frans Osinga）谨慎地指出，如果仅仅将OODA循环与时间对齐，往往会被误解。\n对博伊德作品的全面概述表明，OODA循环不仅仅代表或意味着一个决策过程，这一模型包含了比信息优势和速度更多的胜利因素……第一个误解涉及速度要素。快速的OODA循环想法暗示了对决策速度的关注，并通过更快地完成连续的OODA循环来“超越”对手。\n奥辛加的这种说法可能是在讨论JADC2的核心假设，即所提议的计算/数据架构忽略了许多因素——特别是人类维度，有时也被称为人类领域。这些元素在考虑到敌方有意降低系统性能、散布虚假信息以及通过制造模糊性来延迟反应时，是必须考虑的。\n博伊德的工作未能认识到并支持利用传感器和计算机技术显著改善态势感知的潜在好处——例如空军的低空导航与夜间目标红外系统（LANTIRN）、空中预警与控制系统（AWACS）E-3哨兵和E-8C联合监视目标攻击雷达系统（Joint STARS）。很明显，他对越南战争后期传感器网络的否定过于矫枉过正。很少有美国人在越南战争后的世界，甚至是在“9/11”后的战场上，会轻易在没有这些平台或即将替代它们的平台的情况下参战，尽管它们在近敌作战环境中的生存能力受到了挑战。然而，博伊德在其关于“有机”指挥与控制的“替代愿景”中提出的人类因素，值得重新审视，特别是在俄罗斯和中国积极注入模糊性到竞争和冲突环境中，或阻止进入电磁频谱，从而对抗JADC2所追求的清晰性。\n博伊德的工作在近20年的时间里不断发展这一主题。在《指挥与控制的有机设计》中，他提到了当代指挥与控制在行动中的失败，例如西贡撤离（1975年）和沙漠一号行动（1980年）：\n机构应对这些失败的反应是更多更好的传感器、更多的通信设备、更多更好的计算机、更多更好的显示设备、更多的卫星、更多更好的信息融合中心等等——所有这些都整合到一个巨大的、完全信息化、完全能力化的指挥与控制系统中。这种思维方式强调硬件是解决方案……\n我认为还有另一种方式——一种强调人类隐性本质的方式……\n[我们]需要洞察力和愿景……焦点和方向……适应性……[以及]安全。\n博伊德对越南战争后努力克服战争迷雾和摩擦的概念类似于今天的传感器网络、数据架构以及对云计算/边缘计算的强调。虽然博伊德显然忽略了当指挥与控制系统正常运行时，通过态势感知所提供的实质性好处——正如在阿富汗、伊拉克、叙利亚等地的空中和传感器作战中所展示的那样——但他关于人类力量和人类领域的观点在国防部试图构建一个强大、有能力和敏捷的JADC2系统时绝不能被忽视。\n从卡尔·冯·克劳塞维茨（Carl von Clausewitz）的思想出发，博伊德得出以下结论：\n战争的氛围就是摩擦。\n摩擦由威胁、模糊性、欺骗、迅速性、不确定性、不信任等因素产生并被放大。\n摩擦通过隐性理解、信任、合作、简单、专注等因素被减少。\n从这个意义上说，多样性和迅速性倾向于放大摩擦，而和谐和主动性倾向于减少摩擦。\n（博伊德的观点强调了人类因素的重要性，即使在高度技术化的作战环境中，信任、合作和简化等因素在减少战争中的摩擦方面仍然至关重要。）\nJADO（联合全域作战）方法掌握了许多这些要素，试图通过广泛的传感器、数据弹性和边缘计算来减少战争迷雾和摩擦，通过在多个领域的同时行动制造混乱，从而进入对手的OODA循环。然而，当前对JADC2（联合全域指挥与控制）的描述仍然强调速度和信息优势。它们似乎还没有完全接受服务文化或人类因素的变化，这些变化对于实现JADC2概念的全部潜力至关重要，或者更紧迫的是，防范对手创造模糊性、混乱、无序、孤立和延迟（甚至瘫痪）行动的努力。正如上文提到的，中国和俄罗斯采取的方法旨在破坏美国的决策循环，特别是在关键的定向阶段。\n博伊德将定向定义为OODA循环中的关键步骤。他写道：“定向是重心（schwerpunkt）”，它“代表了由遗传传统、文化背景、以往经验和正在展开的环境所塑造的世界的图像、观点或印象。” 换句话说，JADO的信息优势网络所产生的硬数据视图将根据参与者的共享和独特视角被参谋人员和决策者过滤。\n要实现统一的行动，参与者需要有共享的经验、文化和信任。用博伊德的话来说，“定向是一个多方面隐性交叉参照、共情、关联和拒绝的互动过程，这一过程由遗传传统、以往经验和正在展开的环境之间的相互作用所塑造并反过来塑造这些相互作用。” 更具挑衅性的是，他提出了一种去中心化的指挥与控制观念，主张以领导力代替指挥，以理解（监控）代替控制。博伊德强调协调一致的“和谐”去中心化的力量，并指出“理解和领导比指挥与控制（C\u0026C）更适合、更丰富地调整和适应环境。”\n博伊德清楚地理解，推动行动进入并穿透对手的决策循环的目的是制造混乱、无序和瘫痪。值得重申的是，人类因素，包括信仰、信任、共同愿景和身份认同、知识、经验、教育和培训，对JADC2系统的重要性与传感器网络、开放数据标准与交换、网状连接、云计算/边缘计算、人机协作、机器学习，甚至人工智能（如果它能完全发展起来）同样重要。人类因素将成为JADC2系统中最薄弱的环节和最强大的方面。\n主动权的概念 关键的人类因素决定了主动权的概念。主动权，或推动行动的能力，是通过OODA模型在竞争和冲突中奠定基础的。在军事圈子里，特别是有时会有一种信念，即采取行动——任何行动——都比将主动权让给对手要好。\n在最新版本的《联合出版物3-0：联合战役和行动》中，对主动权进行了广泛讨论。在关于联合职能的部分中，主动权被提及六次，并明确与指挥与控制、任务指挥概念以及保障相关联。附录A与进攻性联合行动的原则相关，“进攻的目的是夺取、保持和利用主动权”，但主动权本身并没有被定义。\n将主动权与进攻联系在一起的一个问题是，主动权也可以与防御和诱导行动联系在一起：如果一方引诱对手采取行动，而对手照做了，那么即使是在防御中，对手也掌握了主动权。这可能看起来像是以防御为掩饰的进攻，但将主动权严格地与进攻联系在一起会在参谋军官和指挥官中产生一种错误的预期，即进攻等同于主动权。\n脱离国防部术语的主动权概念在定义通过决策优势所寻求的目标时是有用的。《联合出版物3-0》中提到主动权近40次，并将其作为一个作战阶段来讨论——“利用主动权以实现作战层面的目标。”具体而言，“与夺取主动权相关的部队部署可能具有足够的威慑作用，以劝阻敌人进行进一步的行动，使[作战环境]恢复到更稳定的状态。”\n此外，主动权在联合行动原则中与进攻紧密相关：“进攻性行动是军事力量在保持行动自由和实现有意义目标的同时，夺取和保持主动权的方式。” 重要的不是决策本身，而是决策所带来的主动权和控制力。\n《牛津英语词典》中提供了一个有用的主动权定义：“采取领导，迈出第一步，发起某种行动”；“发起某事的权力、权利或功能，因此，拥有或掌握主动权”；以及“通过某种推动力来驱动或强迫……”。主动权的概念将决策与行动联系起来。主动权使对手不得不重新启动OODA循环，耗费时间，并播下怀疑、混乱、模糊、不信任等情绪，从而削弱博伊德所强调的信心、确定性、清晰性和信任。因此，本文提出以下工作定义：主动权是由及时决策和行动所产生的推动力，使行动自由成为可能，同时限制对手的选择。\n竞争或基于冲突的决策的目标是推动行动，迫使或引诱对手做出反应；成为行动的主体，而不是被动对象；并通过行动迫使对手重新观察、重新定向、重新决策和反应。主动权是一种零和的、二元的资源；战斗双方之一可能拥有它，但不可能同时拥有。然而，也可能双方都不具备主动权，并且在感知与现实之间可能存在差异。一个人可能相信自己拥有主动权，但实际上并没有。\n在国际象棋、围棋或单打决斗中，主动权是显而易见的。如果一个人感到不得不做出某个动作，而他显然更希望做另一个动作时，对手就掌握了主动权，成为了驱动这一行动的人。如果情况反过来，对手就失去了行动自由，被迫做出反应，而不是按照自己的意愿行事。\n这一概念可以推广到战术、作战和战略层面。这也是研究战略游戏、武术或军事和政治历史对于培养军事领域专长有用的部分原因；通过经验，人们能够识别模式，从混乱中提炼出秩序，建立起做出决策的信心，从而传递主动权。任何关于决策优势的定义都应包括夺取和保持主动权的意图。\n决策优势：状态与过程 困扰军事规划者的一个问题是，决策优势到底是代表一种状态还是一种过程。将其视为状态的观点认为，决策优势是一种由技术辅助理解所支持的状态，从而能够做出决策。过程观点则认为，如果不与实现这种状态的方法相联系，那么这种状态是毫无意义的，即必须有具体的方法将理解转化为计划和行动。\n多年来，空军指挥与参谋学院的联合全域战略家（前称多域作战战略家）项目的毕业生们学会了通过威胁信息驱动的决策支持矩阵来增强联合规划过程。通过预测在作战或战略层面推动决策点所需的信息，这类矩阵框架能够收集指挥官的关键信息需求，分析并清晰地呈现风险，并将决策与作战或战略设计相连接。即使使用手动过程，决策支持矩阵的开发和使用虽然需要大量工作人员，但能够在关键时刻实现更快和更有依据的决策。\n(这种观点将决策优势视为一个过程的结果，通过具体的方法和工具，如决策支持矩阵，将理解转化为行动，而不是将其仅仅看作一个由技术辅助的静态状态。因此，过程观点强调了将决策优势从状态转变为具体行动能力的必要性。)\nCOA 1：第1阶段 准备 决策点 NAI/TAI 事件 需要的决策 决策标准 可用资源 CJTF行动 将地面部队力量转移到阿塞拜疆边境 地面部队（LC）向西北伊拉克边境移动进行地面演习（D-1） 最高领导人宣布C日 第0阶段（塑造）完成 空中 - ISR\n海上 - ISR；SPOD防御\n特种作战部队 - ISR；信息作战\n地面 - 演习姿态单位；力量保护\n电子战 - Jx（需要频谱主导）\n空间 - NTM 部署地面部队至阿塞拜疆（AZJ）边境\n开始信息作战行动\n将综合防空系统（IADS）提升至最高戒备状态 1 最高领导人批准部署 国土防御能力绿灯 假设 假设的反应 关键指挥官情报需求（CCIRs） 向美国和阿塞拜疆（AZJ）提供明确的警告 阿塞拜疆发布新闻稿，谴责部队向其边境移动 首要情报需求（PIR）：\n- 美国和阿塞拜疆的战备状况\n- GOAZ的状态\n- 阿塞拜疆关键基础设施的状态 无美国地面部队反对 阿塞拜疆防御部队进入高度戒备状态 紧急信息报告（FFIR）：\n- 综合防空系统（IADS）的姿态/警戒/战备水平 美国和其他国家的情报、监视与侦察（ISR）收集 可能美国对部署部队进行空袭 风险 对任务的影响 发生概率 缓解措施 缓解后剩余风险 将地面部队（LC）转移至阿塞拜疆（AZJ）边境，使美国和阿塞拜疆察觉我们的计划 缩短我们在美国干预前采取行动的时间线 中等 在第0阶段期间，在伊拉克（IZ）边境建立地面演习历史\n通过媒体广泛宣传演习\n向美国提供有关演习合法性的情报 低 不将地面部队转移至阿塞拜疆边境，导致无法为进入阿塞拜疆做好准备 严重拖慢时间线，并迫使整体计划发生变化 高 无 高 图2. 空军指挥与参谋学院联合全域战略家项目演习的决策支持矩阵\n在JADC2架构下，通过自动化，应当可以在很大程度上自动化收集和呈现由工作人员制定的决策支持矩阵，包括动态创建新的力量和资源配置所需的变更，从而实现显著更快的决策和作战相关行动。\n对于这一想法的支持者来说，围绕已知的决策框架创建一个自动化系统是将决策优势概念付诸实践的关键。从某种意义上说，过程视角抓住了从决策到行动的连接需求，正如前文讨论的那样，这是主动权的体现。因此，决策优势是一种持有优势的状态。然而，没有过程，这种优势是毫无意义的，因为它无法转化为对主动权的掌握。\n（这种观点强调，决策优势不仅仅是占据有利位置的状态，更是将这种状态通过具体的过程转化为行动的能力。自动化系统通过在已知的决策框架内高效执行这些过程，有助于确保决策优势能够真正转化为有效的作战行动，进而掌握并保持主动权。）\n定义决策优势 鉴于OODA循环概念的性质，强调了人类因素、速度和信息优势，以及主动权概念的重要性，本文提出了一个决策优势的定义。第一部分定义了决策优势本身，而第二部分则将JADC2置于OODA概念和人类因素的背景下，结合对手的作战方法来进行探讨：决策优势是在正确的时间获取并识别正确信息（信息优势），从而能够做出及时决策并将其转化为行动，从而夺取或保持主动权。\n美国空军最近发布的《空军条令出版物3-99/太空军条令出版物3-99：空军在联合全域作战中的作用》中，将决策优势定义为“态势理解、确保和交换信息的能力，以及通过在各个领域保持优势来做出和传达决策的产物。” 这个定义有许多值得称赞之处。它强调了理解而非单纯的意识。与本文作者的提议不同，它强调了通信的核心作用，并将决策与传达决策的需求联系起来。然而，它也提出了在所有领域保持优势的必要性，这在实践中可能难以实现——尽管毫无疑问，如果能够以某种方式实现，这将是一个理想的情况。\n然而，空军的定义仍然缺乏一个强调决策优势重要性的核心要素——主动权的传递。对军种定义的修改，若能更紧密地将决策与主动权联系起来，可以表述如下：决策优势是态势理解的产物，确保和交换信息的能力，以及做出并传达决策以在关键领域夺取或保持优势的能力。\n(这个修改后的定义不仅保留了原有的态势理解和信息优势的要素，还加强了主动权的重要性，将决策与实际的作战效果紧密相连。通过这样的定义，决策优势不仅仅是信息优势和通信能力的集合，更是通过这些能力最终在关键领域中获得并保持主动权的手段。)\n无论采用哪种定义，决策优势都依赖于优越的理解、自信和信任，这些要素能够克服模糊性并创造清晰性。决策通过夺取和保持对敌人或竞争对手的主动权，迫使其重新观察和重新定向，延迟其决策，最终剥夺其行动甚至保持团结的能力。同时，决策优势旨在最大化友方的行动自由、团结一致以及引导对手朝着有利于美国的决策、目标和最终状态前进的能力，这在一些俄罗斯文献中被称为反射性控制。\n优越的理解源自相关的知识、经验、适当的智力工具、教育和培训；自信源自对理解、愿景、目标、权限和意图的清晰把握——即已知的事物。信任则通过支持既有关系中的风险来对抗未知。因此，决策优势的对立面可能是瘫痪——无法进行定向、决策和行动。\n大卫·爱泼斯坦（David Epstein）最近有力地论证了跨领域和多领域知识的重要性——在这里指的是学术领域，而不一定是作战领域——这种知识在一个高度专业化的世界中解决棘手问题时可能具有巨大的价值。如果爱泼斯坦的观点是正确的，那么广泛而深入的教育对于在不同领域之间转移知识并找到对专家们来说似乎难以解决的问题的解决方案是必要的。此外，当前已知的AI固有限制性，这表明适应性和灵活性是战胜相对狭窄但极为迅速的机器判断的关键。\n爱泼斯坦关于跨领域知识是应对模糊性困境的有力武器的论点，与军事领域中多域或全域作战的概念相呼应，这些作战模式是对敌人实现优势的关键。在这两种观点中，来自单一领域之外的信息或知识的意识能够带来重要的优势。\n(通过综合理解、跨领域知识和信任建立的决策优势，军事规划者可以更好地应对充满不确定性和复杂性的作战环境。主动权的获得不仅仅是信息优势的结果，还依赖于将这些信息转化为行动的能力，以及应对敌方干扰和模糊性策略的灵活性。正如反射性控制概念所强调的那样，决策优势最终在于能够引导并掌控战局的发展方向，而这需要全面的知识基础和灵活的思维方式。)\n乌克兰部队的小型单位创新与俄罗斯部队的中央化指挥形成了鲜明对比，这种对比具有启示性。乌克兰军民不仅拥有技术优势，而且还怀着强烈的保家卫国的愿望，凭借即时创新的技术和战术，令俄罗斯对手措手不及。像M142高机动性火箭炮系统、美国的情报、监视与侦察系统、标枪导弹以及无人机等技术使乌克兰部队在远距离作战中表现得更加灵活和有力。并非这些技术本身使俄罗斯军队困惑，而是这些技术与乌克兰部队创新速度的结合可能是关键所在。\n同样，广泛的教育背景可能有助于防止陷入瘫痪，能够快速综合分析并解决即时出现的棘手问题。这一点至关重要，因为注入模糊性和虚假信息几乎肯定会对支持机器计算和人类判断产生不利影响，从而需要人类来填补这一空白。优质教育结合训练，将有助于应对人为注入的模糊性以及由此产生的战争迷雾和摩擦，因为这些因素会导致子系统被攻击并崩溃。\n在现代化进程中，利用新兴技术的潜力，JADC2系统最薄弱与最强大的环节都将是人类操作员及其所操作的组织。然而，各级决策者仍然需要理解以接近机器速度呈现的信息——他们必须具备态势感知能力。视角、偏见、文化、身份等因素赋予信息以意义，并为战斗信息提供另一套透镜，使其通过。教育是防止组织狭隘僵化的一种对策，而这种个人偏见即使在JADC2得以实现后，仍可能存在，无论它以何种形式呈现。\n(乌克兰部队的成功表明，灵活的思维和创新能力在现代战争中的重要性，不仅仅依赖于技术本身，更在于如何运用这些技术并快速适应变化的战场环境。与此相比，俄罗斯部队的迟缓反应和中央集权式指挥则凸显了缺乏这种创新精神和灵活性的代价。因此，在JADC2系统的开发和应用过程中，确保操作员和组织具备适应性和创新能力至关重要，这需要通过广泛的教育和持续的训练来培养，以应对未来战场上可能遇到的复杂挑战。)\nConclusion 联合全域作战旨在通过利用全域信息优势，获得决策优势。这种信息优势是通过传感器网络、云计算或边缘计算的高级分析以及具备弹性和开放数据连接的支持而创建的，以支撑基于任务指挥的规划、决策和执行周期，这些周期必须比对手更快、更智能、更强大。然而，嵌入在JADC2已发布架构中的一个关键概念——博伊德的OODA循环——经常被误解为仅关注决策速度。博伊德还强调了信息质量的重要性，指出冲突竞争的全部意义在于通过大量输入来使对手迷失方向。此外，最近对决策优势的定义努力忽视了将行动与决策联系起来的重要性——即主动权的掌握和保持，这与进攻并不完全相同。\n即使JADC2取得成功，当今的新兴对手也在试图通过虚假信息、误导以及选择性地攻击美国的指挥与控制系统的要素，来削弱美国当前和近期的战场优势，以制造停顿、犹豫、功能下降，最终导致瘫痪。\n此外，这些攻击所针对的人类因素，即使在一个完美的操作环境中，即使拥有近乎完美的态势感知，也可能扭曲理解并导致糟糕和无效，甚至灾难性的决策。同时，人类处理变化信息的速度比具有中央集权和机器特性（如俄罗斯那样）的机器或组织系统更快。如果像大卫·爱泼斯坦这样的思想家是正确的，那么JADC2系统中的人类元素将是整个系统的关键弱点和强项。对人类广度的考虑可以补充JADC2的机器处理深度，从而揭示战争迷雾和摩擦中隐藏的一些内容。\n(JADC2的成功不仅依赖于技术优势，还需要充分考虑人类因素的复杂性。这些因素可能会因为对手的攻击或自身的局限性而导致决策失误。因此，确保人类操作员具备广泛的知识和快速适应变化的能力，与技术手段相辅相成，是赢得现代战场的关键。)\nDisclaimer and Copyright 《空中与空间作战评论》（Air \u0026 Space Operations Review, ASOR）中的观点和意见仅代表作者个人立场，并未得到美国政府任何机构或部门的正式认可。本文档及其中包含的商标受法律保护，仅供非商业用途。任何复制行为须遵循1976年《版权法》和美国适用条约的规定。作者保留根据《美国法典》第17篇第106条授予的所有权利。任何复制行为均需获得作者的许可，并注明标准的来源引用行。若需帮助，请联系《空中与空间作战评论》编辑：asor@au.af.edu。",
    "description": "决策优势与主动权：完善联合全域指挥与控制",
    "tags": [],
    "title": "决策优势与主动权",
    "uri": "/c2/decision-advantage-and-initiative-completing-joint-all-domain-command-and-control.ch/index.html"
  },
  {
    "breadcrumb": "FlitSoft Docs \u003e  AI",
    "content": "基础模型与智能决策：进展、挑战与展望 PII: S2666-6758(25)00151-1 DOI: https://doi.org/10.1016/j.xinn.2025.100948 Reference: XINN 100948\nTo appear in: The Innovation\nReceived Date: 10 February 2025 Revised Date: 8 May 2025 Accepted Date: 8 May 2025\n© 2025 Published by Elsevier Inc. on behalf of Youth Innovation Co., Ltd.\nJincai Huang ${ }^{16,17,44}$, Yongjun Xu ${ }^{1,36,37,44}$, Qi Wang ${ }^{1,36,37,44}$, Qi (Cheems) Wang ${ }^{2,44}$, Xingxing Liang ${ }^{17,44}$, Fei Wang ${ }^{1,36,37,44}$, Zhao Zhang ${ }^{1,12,44}$, Wei Wei ${ }^{3,44}$, Boxuan Zhang ${ }^{4,44}$, Libo Huang ${ }^{1,44}$, Jingru Chang ${ }^{5,44}$, Liantao Ma ${ }^{6,44}$, Ting Ma ${ }^{7,44}$, Yuxuan Liang ${ }^{8,44}$, Jie Zhang ${ }^{9,41,44}$, Jian Guo ${ }^{10,44}$, Xuhui Jiang ${ }^{10,44}$, Xinxin Fan ${ }^{1,36,37,44}$, Zhulin An ${ }^{1,36,37,44}$, Tingting Li ${ }^{1,44}$, Xuefei Li ${ }^{1,36}$, Zezhi Shao ${ }^{1}$, Tangwen Qian ${ }^{1}$, Tao Sun ${ }^{1}$, Boyu Diao ${ }^{1,36,37}$, Chuanguang Yang ${ }^{1,36}$, Chenqing Yu ${ }^{1,36}$, Yiqing Wu ${ }^{1}$, Mengxian $\\mathrm{Li}^{1,36}$, Haifeng Zhang ${ }^{11,36}$, Yongcheng Zeng ${ }^{11,36}$, Zhicheng Zhang ${ }^{12,36}$, Zhengqiu Zhu ${ }^{16}$, Yiqin Lv ${ }^{13}$, Aming Li ${ }^{14,38}$, Xu Chen ${ }^{15}$, Bo An ${ }^{18}$, Wei Xiao ${ }^{4}$, Chenguang Bai ${ }^{19}$, Yuxing Mao ${ }^{19}$, Zhigang Yin ${ }^{19}$, Sheng Gui ${ }^{20,39}$, Wentao Su ${ }^{21}$, Yinghao Zhu ${ }^{6}$, Junyi Gao ${ }^{22,40}$, Xinyu He ${ }^{23}$, Yizhou $\\mathrm{Li}^{24}$, Guangyin Jin ${ }^{25}$, Xiang Ao ${ }^{1,36,37}$, Xuehao Zhai ${ }^{26}$, Haoran Tan ${ }^{27}$, Lijun Yun ${ }^{28}$, Hongquan Shi ${ }^{29}$, Jun $\\mathrm{Li}^{30}$, Changjun Fan ${ }^{16,17}$, Kuihua Huang ${ }^{17}$, Ewen Harrison ${ }^{22}$, Victor C. M. Leung ${ }^{31,42,43}$, Sihang Qiu $^{16, *}$, Yanjie Dong ${ }^{31, *}$, Xiaolong Zheng ${ }^{12,36, *}$, Gang Wang ${ }^{4, *}$, Yu Zheng ${ }^{32, *}$, Yuanzhuo Wang ${ }^{1,36,37, *}$, Jiafeng Guo ${ }^{1,37, *}$, Lizhe Wang ${ }^{30, *}$, Xueqi Cheng ${ }^{1,37, *}$, Yaonan Wang ${ }^{27, *}$, Shanlin Yang ${ }^{33, *}$, Mengyin $\\mathrm{Fu}^{34, *}$, Aiguo $\\mathrm{Fei}^{35, *}$\n${ }^{1}$ Institute of Computing Technology, Chinese Academy of Sciences, Beijing 100190, China\n${ }^{2}$ Department of Automation, Tsinghua University, Beijing 100084, China\n${ }^{3}$ Huazhong University of Science and Technology, Wuhan 430074, China\n${ }^{4}$ School of Automation, Beijing Institute of Technology, Beijing 100081, China\n${ }^{5}$ School of Information Science and Engineering, Dalian Polytechnic University, Dalian 116034, China\n${ }^{6}$ National Engineering Research Center for Software Engineering, Peking University, Beijing 100871, China\n${ }^{7}$ Department of Oral Implantology, Peking University School and Hospital of Stomatology, Beijing 100081, China\n${ }^{8}$ The Hong Kong University of Science and Technology (Guangzhou), Guangzhou 511453, China\n${ }^{9}$ College of Information and Electrical Engineering, China Agricultural University, Beijing 100083, China\n${ }^{10}$ IDEA Research, International Digital Economy Academy, Shenzhen 518057, China\n${ }^{11}$ Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China\n${ }^{12}$ The State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China\n${ }^{13}$ College of Science, National University of Defense Technology, Changsha 410073, China\n${ }^{14}$ Center for Systems and Control, College of Engineering, Peking University, Beijing 100871, China\n${ }^{15}$ Gaoling School of Artificial Intelligence, Renmin University of China, Beijing 100872, China\n${ }^{16}$ College of Systems Engineering, National University of Defense Technology, Changsha 410073, China\n${ }^{17}$ Laboratory for Big Data and Decision, National University of Defense Technology, Changsha 410073,China\n${ }^{18}$ College of Computing and Data Science, Nanyang Technological University, Singapore 639798, Singapore\n${ }^{19}$ School of Electrical Engineering, Chongqing University, Chongqing 400044, China\n${ }^{20}$ Department of Mathematics, The University of Hong Kong, Hong Kong SAR 999077, China\n${ }^{21}$ School of Food Science and Technology, Dalian Polytechnic University, Dalian 116034, China\n${ }^{22}$ Centre for Medical Informatics, University of Edinburgh, Edinburgh EH16 4UX, UK\n${ }^{23}$ Department of Stomatology, Peking Union Medical College Hospital, Chinese Academy of Medical Sciences and Peking Union Medical College, Beijing 100730, China\n${ }^{24}$ Department of Stomatology, Yuquan Hospital, School of Clinical Medicine, Tsinghua University, Beijing 100040, China\n${ }^{25}$ National Innovative Institute of Defense Technology, Beijing 100091, China\n${ }^{26}$ Department of civil and environmental engineering, Imperial College London, London SW7 2AZ, UK\n${ }^{27}$ College of Electrical and Information Engineering, Hunan University, Changsha 410082, China\n${ }^{28}$ HUA-Innovation High-Tech(Hangzhou) Co., Ltd. , Hangzhou 311100, China ${ }^{29}$ Dalian Naval Academy, Dalian 116018, China\n${ }^{30}$ School of Computer Science, China University of Geosciences, Wuhan 430078, China\n${ }^{31}$ Shenzhen MSU-BIT University, Shenzhen 518172, China\n${ }^{32}$ JD Technology \u0026 JD Intelligent Cities Research, Beijing 101111, China\n${ }^{33}$ School of Management, Hefei University of Technology, Hefei 230009, China\n${ }^{34}$ Nanjing University of Science and Technology, Nanjing 210094, China\n${ }^{35}$ School of Computer Science, National Pilot Software Engineering School, Beijing University of Posts and Telecommunications, Beijing 100876, China\n${ }^{36}$ University of Chinese Academy of Sciences, Beijing 100049, China\n${ }^{37}$ Key Lab of AI Safety, Chinese Academy of Sciences, Beijing 100190, China\n${ }^{38}$ Center for Multi-Agent Research, Institute for Artificial Intelligence, Peking University, Beijing 100871, China\n${ }^{39}$ LSEC, Academy of Mathematics and Systems Science, Chinese Academy of Sciences, Beijing 100190, China\n${ }^{40}$ Health Data Research UK, London NW1 2BE, UK\n${ }^{41}$ State Key Laboratory of Efficient Utilization of Agricultural Water Resources, Beijing 100083, China\n${ }^{42}$ Shenzhen University, Shenzhen 518060, China\n${ }^{43}$ The University of British Columbia, Vancouver V6T1Z4, Canada ${ }^{44}$ These authors contributed equally\n*Correspondence: qiusihang11@nudt.edu.cn (S. Q.), ydong@smbu.edu.cn (Y. D.), xiaolong.zheng@ia.ac.cn (X. Z.), gangwang@bit.edu.cn (G. W.), msyuzheng@outlook.com (Y. Z.), wangyuanzhuo@ict.ac.cn (Y. W.), guojiafeng@ict.ac.cn (J. G.), lizhe.wang@gmail.com (L. W.), cxq@ict.ac.cn (X. C.), yaonan@hnu.edu.cn (Y. W.), yangsl@hfut.edu.cn (S. Y.), fumy@bit.edu.cn (M. F.), aiguofei@bupt.edu.cn (A. F.)\n摘要 智能决策（Intelligent Decision-Making，IDM）是人工智能（AI）的基石，旨在自动化或增强决策过程。现代IDM范式整合先进框架，使智能体能够做出有效且自适应的选择，并将复杂任务分解为可管理的步骤，如AI代理和高阶强化学习。近期基于多模态基础模型的方法统一了视觉、语言及传感数据等多种输入模态，形成统一的决策过程。基础模型（Foundation Models，FMs）已成为科学与工业中的关键技术，变革了决策与研究能力。它们在大规模多模态数据处理上的能力促进了适应性和跨学科的突破，涵盖医疗、生命科学和教育等领域。本文综述了IDM的发展历程、基于基础模型的先进范式及其在各类科学和工业领域中对决策的变革性影响，重点分析了构建高效、自适应且具伦理性的决策系统所面临的挑战与机遇。\n关键词：人工智能，智能决策，基础模型，智能体，大型语言模型。\n1. 引言 决策理论经过数百年发展，融合了数学、统计学、哲学、经济学、心理学和计算机科学等多学科知识。从概率论和期望值的早期概念发展到包含心理因素的复杂模型。20世纪40年代，冯·诺依曼和摩根斯坦关于期望效用的工作奠定了决策的数学基础和概念框架。${ }^{1}$ 赫伯特·西蒙的《行政行为》是现代决策理论的重要里程碑，强调了决策的认知方面。${ }^{2,3}$ 后来，丹尼尔·卡尼曼和阿莫斯·特沃斯基提出了前景理论及双系统思维概念，更准确地解释了决策过程。${ }^{4}$ 总之，决策是一个复杂的问题解决过程，不是单一事件，而是包含一系列步骤的过程。一个广泛接受的多步骤决策框架是OODA循环，${ }^{5}$ 即观察（Observe）、定向（Orient）、决策（Decide）和行动（Act）阶段的循环。直观上，OODA描述了感知数据收集与呈现、提取有效证据、执行逻辑推理，最终以顺序或非顺序方式确定最优行动的过程。IDM作为人工智能的基石，旨在替代某些OODA阶段或辅助人类评估选项、做出选择或通过主动干预复杂动态环境来操控结果。${ }^{6}$ 它是计算机科学、心理学与认知科学、经济学与博弈论、运筹学、控制理论和统计学等多学科交叉领域。区别于传统决策过程，IDM的实现依赖模型集合、优化算法和概率推断工具，实现过程自动化，并在机器人学，${ }^{7}$ 金融，${ }^{8}$ 医疗，${ }^{9}$ 及其他工业应用中长期受关注。\n综上，本文旨在促进IDM在不同领域的应用。为此，我们介绍IDM概念，综述IDM所需技术，总结典型IDM范式的最新进展，并展示部分基于基础模型的有前景的IDM方法。\n1.1 决策要素 IDM包括四个要素：(1) 供智能体交互、采集观测和反馈的环境；(2) 在可行动作空间内执行计划和策略的智能体或决策者；(3) 用于指定目标或目的的奖励或效用函数；(4) 智能工具，如启发式规则构建、学习或挖掘模型及其他优化策略。环境有时是交互式且涉及动力系统的状态转移，当系统转移仅依赖上一个时间步观察到的状态时，可构成马尔可夫决策过程（MDP）${ }^{10}$；否则环境为非马尔可夫。另一方面，根据系统状态在决策中的可观测性，可将决策过程划分为完全观测决策过程与部分观测决策过程。例如，部分机械臂无法感知某些关节位置，但可通过摄像头图像推断自身准确状态，决策环境可抽象为部分观测马尔可夫决策过程（POMDP）。${ }^{11}$ 当系统动力学和统计特征随时间变化时，可定义环境为非平稳。关于智能工具，近百年来涌现多种，包括规则构建、启发式搜索策略、机器学习方法及基础模型（FMs）的应用。\n1.2 基础模型概念 文献中通常将用于多种下游任务的大规模预训练机器学习模型称为基础模型（FM）。典型模型如BERT，${ }^{12}$ GPT，${ }^{13}$ 以及CLIP，${ }^{14}$ 训练于海量语言、视觉、音频或多模态数据集，旨在捕捉有效模式并提取通用表示。基础模型的发展依赖多种学习范式的融合，如自监督学习，${ }^{15,16}$ 元学习，${ }^{17,18,19}$ 及多任务学习。${ }^{20,21,22}$\n1.3 决策遇见基础模型 基础模型的诞生使得通过微调快速适配具体应用成为可能，${ }^{23,24}$ 避免了部署时从零学习的需求。鉴于传统决策范式中计算和数据成本高昂的成分，如基础强化学习，亟需借助基础模型技术革新决策，探索从中受益的路径。\n同时，本工作区别于其他关于基础模型的综述，主要聚焦IDM发展趋势，并探讨利用基础模型最新进展助力IDM模型在更广泛应用场景中的开发潜力。\n1.4 决策技术谱系 决策技术可分为传统决策技术与智能决策技术。传统决策多依赖专家经验和直觉，智能决策则依赖算法驱动和数据支持。智能决策解决了传统决策在大规模状态动作空间面临的算法爆炸问题，以及传统决策算法在不同领域中泛化能力差的问题。传统技术包括基于博弈论的决策技术，${ }^{25}$ 基于启发式优化的决策技术，${ }^{26}$ 及基于知识的决策技术。${ }^{27}$ 智能决策涵盖基于深度强化学习（DRL）、大型语言模型及基础大模型的决策技术。${ }^{28}$ 传统技术在处理简单线性决策问题时高效，但面对多维非线性复杂决策空间仍有限制。基于大型模型的智能决策在面对高维复杂非线性状态动作空间时具备卓越决策能力。IDM不同发展阶段如图1所示。\n图1：智能决策的发展历史。基于规则的决策支持系统通过规则库和事实库实现决策支持，适用于规则明确驱动的场景。数据驱动的决策支持系统结合神经网络、决策树等技术，应用于深蓝和AlphaGo等项目，并在多个领域超越人类。基于基础模型的决策作为数据驱动决策的新兴技术，通过演示数据收集、数据标注和奖励模型训练等步骤，利用大型模型（如GPT系列和LLaMA）实现决策优化，典型应用案例包括OpenVLA、RoboGen等。\nIDM与专家规则。智能决策系统（Intelligent Decision Systems，IDS）发展史上，决策支持系统（Decision Support System，DSS）在学术界和工业界均发挥了关键作用。建立DSS的主要目的是复制领域专家的决策模式，并通过自动化程序执行判断。${ }^{29}$ 早期，结构化数据集稀缺且难以获取，因此采用规则集合和常识作为知识库，识别场景并运用推理实现决策。此方法能快速处理决策查询且具备良好解释性，但局限于特定领域，严重依赖昂贵的专家知识，且难以处理超出既有知识库的情况。\n随着数据库中可学习的实例增多，机器学习和数据挖掘工具在系统开发中日益重要。它们促进了数据驱动模型的创建，捕捉有效模式，从而增强决策过程。有效的算法和学习模型通过预测在不同策略下的结果和趋势，提升数据驱动DSS的优势，同时支持自动知识发现。强化学习（DRL）${ }^{10}$ 是该领域的重要方法，涉及与环境交互、收集奖励信号，并在序列决策过程中对行为进行赋值。DRL在实时策略游戏，${ }^{30,31}$ 无人机竞速，${ }^{32}$ 围棋游戏等领域取得显著成功。${ }^{33}$ 为提高样本效率，出现了离线强化学习（offline RL）范式，从静态大规模转移数据集中学习。${ }^{34,35}$ 尽管数据驱动DSS随着数据量和质量的提升，增强了泛化能力并减少了对精心设计专家知识的依赖，但其本质仍较为静态，仅在有限复杂场景中有效，尚未实现真正的即插即用功能。\nIDM与浅层及深度学习方法。传统决策技术包括基于博弈论的决策方法、基于启发式优化算法的方法以及基于知识的决策技术。传统方法针对不同问题设计，依据具体决策问题选择合适算法。智能体间的博弈模式包括囚徒困境、赌徒博弈和纳什均衡。为实现各智能体最大累积收益，基于智能体收益的规则驱动智能决策被采用。\n启发式优化算法包括遗传算法（GA）、粒子群优化（PSO）、蚁群算法（ACO）、禁忌搜索（TS）和模拟退火（SA），各自针对不同优化问题并应用于特定领域。GA、PSO、ACO属于群体优化算法，TS和SA属于个体优化算法。GA和ACO仅适用于离散优化，其余三种算法可用于离散及连续优化。GA核心在选择阶段保留优良解，交叉和变异阶段生成新解。PSO核心利用局部和全局最优解更新解。ACO通过信息素的沉积与挥发更新和优化路径。TS通过禁忌表避免重复搜索，局部邻域搜索的扩展为全局邻域搜索。SA模拟固体退火原理，通过邻域搜索逐步达到基态。GA应用于优化设计、机器学习参数优化和图像处理；PSO用于神经网络权重优化、无线传感器网络节点部署、机器学习参数优化、图像处理和智能控制。ACO应用于旅行商问题（最短路径）、资源调度和网络优化。TS适用于组合优化问题、模型参数优化和通信网络拓扑结构优化。SA应用于旅行商问题及参数优化。\n基于知识的决策方法包括贝叶斯推断、专家系统等，利用先验知识或知识库实现从环境状态到行动的推理决策和动作执行。贝叶斯推断技术和专家决策系统利用先验知识及预定义规则库实现特定问题的决策和行动选择。传统决策技术通常用于简单线性低维决策问题，依据具体环境和应用选择对应算法。但面对高维大规模状态空间的复杂决策时，传统方法存在规模爆炸和复杂度指数增长问题。基于强化学习（RL）和大型模型的智能决策在大规模状态空间和高维状态动作空间中表现优异，实现更高奖励的动作执行。\n趋势显示AI技术具备重塑决策框架的潜力，决策先验的来源从硬编码的专家知识或人类技能向大规模数据集提取转变。智能决策技术分为基于RL的决策、基于大型模型的决策，以及基于基础模型（FM，指在广泛数据集（文本、图像、音频和视频）上训练且能应用于多下游任务的模型）的决策。${ }^{36}$ RL方法一般用于状态到动作的选择，而基于FM的决策可用于序列决策、群体决策及多模态决策。\nRL方法包含基于价值的、价值分布的、基于策略的和演员-评论家（actor-critic）方法，已应用于Atari游戏及众多决策场景和状态动作选择环境，提升多种应用环境的决策性能。\n最初的RL是基于表格学习的Q-learning，后DQN算法用深度神经网络替代表格，扩展状态动作至更高维度和更复杂表示。此外，Double DQN使用价值网络与目标网络更新Q值（回报或累计奖励），Dueling DQN采用包含状态价值和优势价值的对决架构。价值分布基RL方法包括C51，${ }^{37}$ QR-DQN，IQN，FQF，利用价值分布提升决策能力。基于策略的RL方法直接输出动作生成最优策略，涵盖深度策略梯度（DPG）、DDPG、PPO。演员-评论家RL算法包含SAC、AC、A2C、A3C，其中A3C利用异步优势演员-评论家提升决策效率和累积奖励。\n相比RL方法，基于FM的决策具有更强泛化和适应能力。FM可作为智能体（规划者、决策者、感知者和执行者）、环境、设计者、编码器、条件生成模块及人机交互者。目前主流FM包括Transformer、BERT、T5、GPT系列，以及LLaMA、PaLM等，可用于基于FM的序列决策、群体决策和多模态决策。重要的是，FM与RL方法的结合已成为更流行的IDM范式。\n基于单智能体RL的进展，多智能体强化学习（MARL）将RL扩展至包含多个智能体的环境，智能体需通过合作或竞争进行交互。MARL带来非平稳性、信用分配和智能体间通信等新挑战，并通过多种训练和执行范式加以解决。${ }^{38}$\n去中心化训练与去中心化执行（DTDE）${ }^{39}$ 使智能体无需集中协调即可独立学习和行动，适用于完全分布式系统。中心化训练与去中心化执行（CTDE）${ }^{40,41,42}$ 允许智能体在训练阶段利用集中信息提升学习效率，执行阶段保持去中心化策略以保证现实应用的可扩展性和适应性。分组训练与去中心化执行（GTDE）${ }^{43}$ 将智能体分组，训练阶段组内协调，执行阶段组间去中心化。这些范式为应对多智能体系统复杂性提供了坚实框架，使MARL能优化合作、竞争及混合环境下的决策。\n基于大型模型的智能决策技术以大型模型输入作为状态输入，输出作为动作执行，利用链式思维（chain-of-thought）、思维树、思维图等提示工程技术，形成基于大型模型的决策过程。目前主流大型模型包括Transformer、BERT、T5、GPT系列，以及LLaMA、PaLM等，可用于序列决策和群体决策。\n基于基础模型的智能决策（FM-based IDM）。借助计算平台，数据经过优化整合为模型参数，成为知识的载体。\n认识到数据集、计算能力和模型容量的重要性，${ }^{44}$ 先驱研究者将关注点转向开发基础决策模型（Foundation Decision-Making Models，FDMM）。不同于传统针对具体决策场景开发智能模型的范式，FDMM的初衷是捕捉场景的通用表示，实现零样本或少样本的快速适应，${ }^{45,46}$ 并在开放决策环境中动态进化。如此，我们可在测试阶段实现计算效率，并以极少的学习资源无缝适应环境变化，这在实时控制问题（如自动驾驶）中尤为关键。\nFDMM区别于以往数据驱动决策支持系统（DSS）的核心在于面向场景分布的学习范式。为以更低的计算和数据成本实现跨场景决策，智能决策者需从序列数据集中捕捉内在结构，例如通过自监督学习预测下一个标记作为最优决策动作，${ }^{47}$ 同时以多任务方式处理多个请求，${ }^{48}$ 并有时借助少量示例进行元学习。${ }^{49}$ 诚然，FDMM成功的关键要素包括充足的场景、多样且紧凑的神经推理模块，以及大规模计算资源。\n图2：基础模型的概览与发展\n总体而言，开发FDMM的必要性在于其广泛的应用目标，旨在覆盖广泛的决策场景，而非局限于特定场景。重要的是，FDMM将以往的数据驱动模型从特定场景扩展为多场景适用，并将大规模决策序列压缩为大规模模型参数，作为先验的主要来源，获得可迁移的表示以支持下游任务。同时，当前的决策先验趋于全面，为策略搜索提供有效约束。\n2. 基础模型的概述与发展 基础模型（Foundation Models），如大型语言模型和多模态人工智能系统，因其能够处理并整合跨多领域的大量数据，已成为智能决策的强大工具。这些模型通过大规模数据集训练，擅长识别模式、生成洞见并提供情境感知的推荐，这对于在复杂动态环境中做出明智决策至关重要。凭借其广泛的知识和适应能力，基础模型可辅助从战略规划、风险评估到实时问题解决及个性化决策支持的多样任务。它们在决策框架中的整合提升了效率、准确性和可扩展性，使组织和个人能够应对以往难以解决的挑战。为更好地介绍基于基础模型的决策智能，本节将介绍基础模型的发展，具体包括基础模型的基础知识、大型语言模型（LLMs）及多模态基础模型的发展，最后介绍基础模型的优化。\n2.1 基础模型基础知识 基础模型指的是在广泛数据（通常采用大规模自监督学习）上训练的模型，能够适应（如微调）多种下游任务。${ }^{50}$ 基础模型的特点是规模庞大、参数众多，具备出色的迁移学习能力，能够轻松适应新任务。${ }^{51}$ 它们展现出“涌现能力”，即常常表现出意想不到的功能。这些特性使基础模型在各行各业产生变革性影响，显著推动人工智能技术进步。${ }^{52,50,53,54,55}$\n基础模型的发展与智能决策的进步密切相关，始于词嵌入技术，如Word2Vec ${ }^{56}$ 和GloVe ${ }^{57}$，为理解数据中的语义关系奠定基础。Transformer架构的引入，${ }^{58}$ 利用自注意力机制促进了更复杂的决策，随后BERT ${ }^{59}$ 革新了自然语言处理，实现了上下文感知的预测。随后，GPT-2 ${ }^{60}$ 和GPT-3 ${ }^{61}$ 等大型语言模型迅速发展，展现了前所未有的语言理解与生成能力，使系统能做出更精准和细腻的决策。多模态模型如DALL-E ${ }^{62}$ 和CLIP ${ }^{14}$ 进一步融合视觉与语言，实现更丰富的决策语境，而Swin Transformer ${ }^{63}$ 将类似原理应用于计算机视觉，增强视觉推理和决策。最新发展如GPT-4 ${ }^{13}$ 不断推动规模和精细度极限，实现跨领域更准确、上下文感知和自适应的决策。这一进程标志着从专用单模态模型向功能更强大、多样且多模态系统的转变，根本重塑了人工智能及其智能决策能力。${ }^{64,65,66}$ 基础模型已彻底革新自然语言处理（NLP）、计算机视觉（CV）和图学习等领域的学术研究，使得之前难以实现的复杂数据驱动决策过程成为可能。\n自然语言处理（NLP）。基础模型最初在NLP领域流行。NLP的基础模型始于ELMo ${ }^{67}$，采用双向LSTM ${ }^{68}$ 学习上下文相关词表示。Transformer的引入促使NLP基础模型迅猛发展，涌现出多种模型。它们大致可分为两类：(1) 自回归语言基础模型，(2) 上下文语言基础模型。自回归模型通过逐词生成文本，利用已生成词作为上下文预测下一个词，典型代表为GPT系列。${ }^{69,60,61}$ 该方法在文本生成任务中表现优异，能产出连贯且富有创造性的文本。自回归模型仅利用单方向信息（左或右），非同时双向。相对地，上下文语言模型着重捕捉语言的复杂语义和上下文信息，典型模型包括BERT ${ }^{61}$、UniLM ${ }^{70}$ 和T5 ${ }^{71}$。它们通过双向编码器架构或深度上下文表示提升文本分类、问答、情感分析等任务表现，优势在于理解并生成更具上下文相关性的语言输出。\n计算机视觉（CV）。计算机视觉基础模型起步于卷积神经网络（CNN），如ResNet。${ }^{72}$ 通过大量图像训练，它们能提取图像特征并促进迁移学习。${ }^{73,74}$ 受Transformer在NLP成功启发，部分研究将Transformer作为新骨干。视觉Transformer（Vision Transformer，ViT）${ }^{75}$ 实现重要转变，将图像视为序列块处理，捕获远程依赖，实现更细致的特征提取。Swin Transformer ${ }^{63}$ 进一步完善此方法。另一发展为扩散模型（Diffusion Models），${ }^{76,77,78,79}$ 通过迭代去噪随机高斯噪声图像，逐步逼近目标分布，生成高质量、多样化图像。代表模型有Stable Diffusion 3.0 ${ }^{80}$、DiT ${ }^{81}$、Sora ${ }^{82}$ 等。${ }^{78,83,84,85}$ 多模态模型如CLIP ${ }^{14}$ 和MiniGPT-4 ${ }^{87}$ 等，将图像与文本对齐于共享空间，实现多样化零样本分类。${ }^{86,87,88}$\n图学习。图学习旨在理解与分析图结构数据，关注节点分类、链接预测和图分类任务。${ }^{89,90,91,92,93,94,95}$ 基础模型在图学习领域亦日渐成为新兴研究方向，旨在创建适用于多种图任务和领域的通用模型。图学习基础模型可分为三类：基于图神经网络（GNN）的模型、大型语言模型（LLM）驱动模型及二者结合的GNN+LLM模型。${ }^{96,97}$ (1) 基于GNN的模型：着重利用现有图学习范式，创新基础GNN架构、预训练技术及任务适配。${ }^{98,99,100}$ 如GCC ${ }^{101}$ 采用对比学习预训练图节点嵌入，“All in one”${ }^{102}$ 提出图提示，助力GNN适配多种下游任务。(2) LLM驱动模型：将图数据转换为文本或令牌格式，利用语言模型处理图问题。其中TextForGraph ${ }^{103}$ 通过精心设计提示模板将图数据转为文本，应用LLM处理；InstructGLM ${ }^{104}$ 将图节点令牌纳入LLM词汇表，通过指令调优适配图学习任务。(3) GNN+LLM模型：结合GNN与LLM优势提升图学习性能。如$\\mathrm{GraD}^{105}$ 用LLM编码节点文本属性，再用经典GNN编码图结构。\n其他领域。基础模型在时间序列分析、代码生成、语音处理等领域亦取得显著进展。${ }^{106,107,108,109}$ 时间序列分析中，基础模型旨在通过捕捉复杂时间模式提升预测和异常检测能力。${ }^{110,111,112,113}$ 研究尝试利用LLM知识构建基于LLM的基础模型。${ }^{114,115,116}$ 单模态时间序列基础模型${ }^{117,118,119}$ 仅基于时间序列数据训练，亦有多模态模型${ }^{120,121}$ 融合文本和时间序列信息。代码生成领域，OpenAI的Codex ${ }^{122}$ 和Google的AlphaCode ${ }^{123}$ 能根据自然语言描述理解并生成代码片段，自动化编程任务，提高生产力并减少错误。${ }^{124,125}$ 语音处理涵盖语音识别、合成及翻译，通常涉及语音与文本模态。早期模型如Speech-Transformer ${ }^{126}$ 适配Transformer处理语音任务，利用注意力机制融合音频和文本信息，提升转录准确率和上下文理解。近期研究试图复制语音处理中的规模定律，如Vall-E ${ }^{127}$ 引入Transformer编码音频特征，并尝试利用LLM能力实现更自然的文本转语音合成。\n基础模型的应用已成为推动智能决策的重要基石。在基于知识的问答中，GPT ${ }^{61}$ 展现多样性响应能力，BERT ${ }^{59}$ 优于阅读理解，支持更准确、上下文感知的决策。在推理任务中，思维链（Chain of Thought, CoT）${ }^{128}$ 通过提示中间推理步骤增强LLM复杂推理能力，显著提升算术、常识和符号推理表现。思维树（Tree of Thought, ToT）${ }^{129}$ 进一步让LLM探索多条推理路径并评估选择，促进更强健自适应的推理。在自主系统中，LanguageMPC ${ }^{130}$ 将LLM作为决策者，通过结构化思维流程生成可执行指令，并与模型预测控制（MPC）等低层控制器无缝集成。LLM在多智能体系统的引入${ }^{131}$ 促进代理间通信、推理与学习，提升复杂决策场景中的集体智能。医疗领域，ChatGPT在放射科临床决策辅助中的潜力已被评估，${ }^{132}$ 展示LLM在高风险决策中的变革作用。类似地，将LLM整合至自动驾驶车辆，借助自然语言交互、上下文理解和持续学习，提升决策能力。${ }^{133}$ Expel ${ }^{134}$ 提出一种代理，通过试错收集经验，提炼见解，并结合经验改进新任务决策，且无需更新模型参数，展现自适应经验驱动决策潜力。这些进展凸显基础模型在实现更准确、上下文感知和自适应决策中的关键作用，根本改变智能系统的运行及其与世界的交互方式。\n2.2 基础模型的发展 基础模型最初在自然语言处理（NLP）领域引起广泛关注，随后迅速扩展到多模态领域。本节将分别介绍大型语言模型（LLMs）和多模态基础模型（MMFMs）的发展。基础模型的关键发展节点如图2所示。\n大型语言模型的发展。LLMs代表人工智能领域的重要进展，旨在理解、处理和生成类人文本。通过在海量语料上的广泛预训练，LLMs不仅展现出卓越的语言理解能力，还达到了通用智能水平，使其成为智能决策的核心工具。它们分析复杂数据、生成洞见和预测结果的能力，使其成为提升各领域决策过程的重要组成部分。本章将详细介绍LLMs的主干模型、主流架构、预训练策略、微调与对齐技术，以及应用。\nTransformer：主干架构。LLMs是一类先进的机器学习模型，设计用于理解和生成自然语言。其庞大的参数规模使其在文本生成、翻译和摘要等任务中表现优异。Transformer ${ }^{58,135}$ 架构核心由编码器和解码器组成，每个编码器包含多个相同层，具备多头自注意力机制和简单前馈网络；解码器额外加入跨注意力层以处理编码器输出。${ }^{136,137}$ 自注意力机制允许远距离输入间的直接上下文关联，有效捕获长程依赖。${ }^{138,139}$ 其层次化设计与并行处理能力加速训练，支持大规模数据和模型。${ }^{140,141}$ 这些特点使Transformer成为构建灵活、可扩展LLMs的首选架构。\n主流LLM架构。基于Transformer架构，语言模型主要有四种结构：编码器（如BERT ${ }^{59}$）、因果解码器（如GPT ${ }^{13}$、LLaMA ${ }^{142}$）、前缀解码器（Prefix-LM ${ }^{71}$）和编码器-解码器（如Google的T5 ${ }^{71}$）。尽管编码器结构在早期模型中广泛使用，但因生成能力有限且难以扩展大规模，逐渐被后三者取代。这些结构支持从零样本学习到大规模知识整合的多种应用。\n因果解码器：采用单向注意力机制，确保生成时每个输出仅访问先前输出以维护因果关系。擅长生成自然流畅文本，常用于聊天机器人、故事续写等任务。 前缀解码器：将固定前缀与自由生成后缀结合，前缀部分采用双向注意力，后缀自由生成。适合条件生成任务，允许在给定上下文中灵活生成内容。 编码器-解码器：经典结构，编码器处理输入文本生成中间表示，解码器基于此生成输出。优势在于有效处理复杂输入输出关系，但需大量训练数据。 预训练策略。预训练阶段在大量无标签数据上训练模型，为后续具体任务学习打基础。${ }^{143}$ 该阶段对LLMs至关重要，使其从广泛文本中学习通用语言模式与结构。不同预训练策略聚焦不同语言能力，如语法理解、语义提取或文本生成。目前主流LLMs如GPT系列和T5主要采用自回归预训练方法。自回归框架中，预测内容分为语言建模和去噪自编码两类。\n语言建模：最常见自回归预训练策略，旨在给定上下文预测下一个词，捕捉语言生成的自然序列。此策略训练的模型在文本生成、续写和对话生成等任务中表现强劲，如GPT系列。${ }^{13}$ 去噪自编码：输入数据被故意破坏，模型需恢复原始数据。许多LLMs如GLM ${ }^{144}$、Google T5 ${ }^{71}$ 和BART ${ }^{145}$ 采用此方法。部分模型如UL2 ${ }^{146}$ 结合两者，将语言建模视为掩码下的去噪自编码。 鉴于语言建模的有效性与可扩展性，主流LLMs如GPT ${ }^{13}$、LLaMA ${ }^{142}$ 和QWen ${ }^{147}$ 仍主要采用该策略。\n微调与对齐。微调用于将预训练模型适配特定任务或需求，但完整训练计算资源消耗巨大。参数高效微调（PEFT）${ }^{148}$ 通过只调整少量参数显著降低成本和时间。支持方法包括适配器（在模型中添加可训练层）、前缀调优（通过调整输入提示引导输出）、低秩适配（优化参数矩阵秩）。同时，对齐技术确保模型响应符合人类价值和偏好，保证输出符合用户期望和伦理标准。关键技术包括基于人类反馈的强化学习（RLHF）${ }^{149}$，通过融合人类反馈有效调整模型行为。\n大型语言模型的应用。尽管LLMs能力出众，但仍面临准确性、知识更新及可解释性挑战。为解决，开发了提示学习、知识增强和工具学习等框架。提示学习通过明确指令调整LLMs以适应特定任务，先进方法如CoT ${ }^{128}$ 模仿人类推理逐步演进。然单靠LLMs内部知识常导致不准确信息、过时知识及透明度不足。知识增强（如检索增强生成RAG ${ }^{150}$ 和知识图谱）通过外部资源提升准确性和领域知识。工具学习 ${ }^{151}$ 使LLMs动态调用外部工具，提升问题解决能力和整体表现。\n多模态基础模型的发展。随着AI快速进步，多模态基础模型（MMFM）技术成为研究和应用热点。MMFM能够处理和理解多种数据类型（如文本、图像、音频、视频）。${ }^{64,65,66}$ 通过融合不同模态信息，生成更全面准确的洞见，为决策智能提供坚实的数据基础和认知支持。例如在商业场景，多模态模型可分析客户反馈（文本）、产品图片（视觉）和市场趋势（时间序列），为决策者提供全方位市场视角。\n模型架构。MMFM架构多基于Transformer，因其灵活高效。但随着研究深入，出现多样架构以适应不同数据和任务，主要包括：\n基于Transformer的编码器：核心组件，提取文本、图像、音频等多样输入特征。${ }^{152}$ 如Vision-and-Language Transformer（ViLT）${ }^{153}$ 直接融合视觉与文本，提升多模态理解。 序列生成模型：常用于图像描述和对话系统，生成连贯且上下文相关输出。${ }^{154,83}$ 扩散模型：通过逐步去噪生成高质量样本，提供多模态生成新途径。${ }^{155,156}$ 自回归解码器：配合编码器，逐步生成输出序列，适用于对话生成和文本补全。${ }^{157,158}$ 图神经网络（GNN）：处理图结构数据，建模多模态数据间关系和结构信息，适用于社交网络和知识图谱。${ }^{159,160}$ 混合架构：结合卷积神经网络和Transformer，强化视觉特征提取及信息整合，提升复杂数据理解。${ }^{161,162,163,164}$ 生成对抗网络（GAN）：应用于多模态生成任务，通过对抗训练提升图像或文本生成的真实感。${ }^{165,166}$ 多任务学习框架：同时处理多任务，共享知识，提升泛化和鲁棒性，适合复杂多模态理解应用。${ }^{167,168}$ 这些多样架构极大增强了MMFM性能和应用范围，使其更好地应对复杂现实任务。\n关键技术。以下关键技术推动MMFM性能和适用性提升：\n对齐技术：确保不同模态特征空间一致性，通过对齐模型更好理解图像与描述关系，增强生成与识别能力。常见方法包括对比学习和注意力机制。${ }^{169,170}$ 预训练数据收集：数据丰富度和多样性决定模型表现。预训练通常利用来自社交媒体、图像库和开源出版物的海量标注与非标注数据，涵盖多领域知识。${ }^{171,165}$ 自监督学习与模型优化训练：自监督学习使模型能从无标签数据自主学习，提升下游任务表现。模型优化训练则通过超参数调优和架构改进提升性能。${ }^{172,173,174}$ 下游任务微调：预训练后利用标注数据对特定任务微调，提高准确率和效率。${ }^{155,175}$ 模态融合技术：通过有效融合不同模态数据，增强多模态信息理解，常用注意力机制或特征拼接。${ }^{176,177}$ 知识蒸馏：将大模型知识迁移至小模型，降低计算负担，提高资源受限环境下的运行效率。${ }^{178,179}$ 增量学习：支持模型动态更新，避免重训，对动态数据流处理至关重要。${ }^{180,181}$ 这些技术的结合与创新为MMFM的实用性和灵活性提供了强大支持，推动其在各领域广泛应用。\n代表性模型。目前，众多代表性多模态基础模型（MMFMs）来自工业界或学术界：\n工业界模型：如OpenAI的GPT-4 ${ }^{13}$ 和谷歌的MUM ${ }^{182}$，利用强大的计算资源和专用硬件，通常部署于云平台，支持大规模用户请求的实时处理。这些模型侧重于生产环境中的可扩展性和稳定性，应用于虚拟助手、内容生成和数据分析等场景。 学术界模型：如对比语言-图像预训练（CLIP）${ }^{14}$ 和DALL-E ${ }^{183}$，主要面向理论探索和算法创新的研究。学术模型常运行于较小硬件平台，重点在算法开发而非大规模计算。 计算与硬件差异：工业基础模型依赖大规模分布式计算架构和专用硬件（如TPU、GPU）以处理海量数据并支持高效推理；而学术模型多在小型硬件上运行，更注重算法新颖性而非庞大计算规模。${ }^{184,64}$ 近年来，MMFMs取得显著进展，推动AI多个领域发展。从模型架构到关键技术及典型应用，MMFMs展示出巨大潜力与灵活性。随着计算能力提升及算法持续优化，该领域未来有望实现更广泛应用和理论突破。\n2.3 基础模型的训练、微调与部署优化 基础模型训练阶段需使用高性能GPU集群，训练周期可能长达数周或数月。微调过程中需考虑超参数优化及防止过拟合。部署时，根据不同计算资源调整模型规模，确保及时响应。本节先介绍基础模型训练的优化策略，接着介绍微调的主要优化方法，最后介绍基础模型推理优化策略。\n基础模型训练优化。基础模型通常利用海量数据并采用无监督预训练方法。根据预训练模型架构，可分为编码器结构、解码器结构及编码器-解码器结构三类。编码器结构的基础模型通常采用掩码语言模型，如BERT ${ }^{59}$ 和RoBERTa ${ }^{185}$。解码器结构的基础模型一般采用自回归训练，最大化给定输入序列预测下一个词的概率，代表模型包括GPT系列 ${ }^{69,61,60}$、PaLM ${ }^{186}$ 和LLaMA ${ }^{142,187}$。编码器-解码器混合结构结合前两种预训练方法，随机遮蔽字符序列，随后通过自回归恢复遮蔽内容，代表模型为T5 ${ }^{71}$ 和BART ${ }^{145}$。\n基础模型微调优化。参数高效微调是基础模型适应下游任务的有效方法，近年来成为研究热点。LoRA（低秩适配）${ }^{189}$ 是高效微调的典范，通过为适配特定任务引入低秩矩阵近似，不直接修改原模型权重，而是对受影响层的输出应用低秩矩阵变换。一系列基于LoRA的改进提升了其性能和适用性。QLoRA（量化低秩适配）极大减少内存占用，同时保持微调性能，可在单块48GB GPU上微调65亿参数模型，远低于传统16位微调的内存需求。${ }^{190}$ LoRA-Flow ${ }^{191}$ 在生成任务中每步动态计算融合权重，通过门控机制的softmax函数实现更灵活适配，性能优于标准LoRA。MoSLoRA（子空间混合LoRA）${ }^{192}$ 将权重分解为两个子空间并混合，等效于使用固定混合器融合子空间，且与原LoRA权重联合学习，提升了常识推理、视觉指令调优及主题驱动文本到图像生成等任务表现。\nLoRA、QLoRA和Adapter-based方法在参数效率、训练速度和任务性能上各具特色。LoRA通过低秩分解显著减少可训练参数，实现高参数效率和较快训练速度，任务表现接近全微调；QLoRA基于LoRA引入量化，进一步提升参数效率和训练速度，但因量化可能稍有精度损失，任务表现略低于LoRA，适合资源受限环境；Adapter-based方法插入小型适配模块，仅训练少量参数，参数效率适中、训练速度较快，但通常慢于LoRA，任务性能接近全微调，但在部分复杂任务上稍逊于LoRA。总体来看，LoRA和QLoRA在参数效率和训练速度方面表现优异，Adapter-based方法则在灵活性和任务适应性上有优势。\n性能表现见表1。\n表1：基础模型优化方法比较\n方法 参数效率 训练速度 任务性能 LoRA 高 较快 接近全参数微调 QLoRA 非常高 非常快 略低于LoRA Adapter-based 中等 较快 接近全参数微调 基础模型部署优化。模型压缩和量化是缩减基础模型规模而不显著影响性能的关键策略。此过程包括剪枝技术，通过删除不重要的神经元以简化模型；${ }^{193}$ 知识蒸馏，${ }^{194,195,196,197}$ 即将复杂模型学得的知识迁移至更紧凑模型。此外，量化通过降低模型计算所需的数值精度，${ }^{198}$ 大幅缩减模型体积并加速推理时间。这些优化对提升基础模型在资源受限环境中的效率和可部署性至关重要。经过优化的模型在有限资源条件下表现出色。SANA-0.6B模型变体，与现代大型扩散模型如Flux-12B相比，体积小20倍，吞吐量快100倍以上，可部署于16GB笔记本GPU，生成1024×1024分辨率图像耗时不到1秒。${ }^{199}$ LLaMA 3.2 3B针对边缘计算和移动设备优化，支持128K令牌上下文，在业内表现卓越，擅长摘要、指令执行及文本重写等设备端任务，推动基础模型在需本地处理与隐私保护的应用中更高效便捷。${ }^{200,201}$\n随着基础模型的发展，其在智能决策中的作用日益重要。基础模型在决策中的优势体现在：\n强大的预测能力。通过深度学习和大规模数据训练，基础模型能捕捉数据中复杂模式和非线性关系，提升预测准确性。例如，在金融领域预测市场趋势；在医疗领域辅助诊断和制定治疗方案。 跨领域知识整合。基础模型具备融合多领域知识的能力，支持跨学科决策。例如，在气候变化研究中，基础模型可整合气象学、经济学、社会学等多学科数据，助力制定综合应对策略。 人机协作。传统决策模型通常作为辅助工具，交互方式有限。而基础模型能通过自然语言交互（如ChatGPT）与人类协作，提供更直观灵活的决策支持。 3. 基于基础模型的决策范式及关键技术 先进的决策范式结合复杂模型与框架，使智能体能在动态环境中做出有效选择。AI智能体倾向于利用大型语言模型（LLM）中整合的规则与经验，促进更高效的决策。高级强化学习（RL）模型通过试错学习策略，优化多任务中的长期奖励，并将决策分解为易执行步骤。${ }^{202,203}$ 例如，多智能体系统和层级强化学习架构应运而生，以应对更复杂的协同和任务分解场景。此外，基于多模态基础模型的决策将视觉、语言和感知数据等多种输入模态整合到统一的决策流程中。通过融合不同类型的信息（如视觉线索与文本描述），多模态决策方法增强了鲁棒性与适应性，使智能体能处理需要细致理解或推理的任务。\n本节系统讨论现有先进决策范式。基础模型与先进决策框架的结合使AI更接近人类式决策，尤其在不确定的现实环境中体现出认知灵活性和效率。\n3.1 基础模型在智能决策中的重要角色 在决策过程中，基础模型（FM）能赋能全新决策范式。除了作为智能体，FM还能充当环境、设计者、编码器、条件生成模块及人机交互者。采用这些新决策范式可进一步增强基础大规模模型在多领域的泛化与决策能力。基于FM的智能决策技术能生成最优策略、动作、规划方案等。决策范式可分为三种模式。图3展示了FM在智能体模块中可作为规划者、感知者、决策者和执行者等角色。\n在环境与设计者模块，FM可作为动作执行目标、环境组成或环境状态转移的桥梁，提升策略有效性。编码器模块中，FM生成状态编码或优化策略编码；在条件生成模块和人机交互模块，FM分别用于条件生成和人机交互。基于FM的多决策范式有效提升了决策模式和应用环境的适应性，显著优化了决策性能和泛化能力。\n基于FM的智能体，FM可作为环境与设计者、编码器、条件生成及人机交互者。作为环境与设计者时，策略获得的动作在FM中执行以更新状态，FM设计奖励、转移、状态与环境。作为编码器，FM对状态进行编码形成表示和策略，规范状态信息。结合条件，FM使用任务、状态与提示输出行为生成、世界生成及动作内容。作为人机交互者，FM接收对话形式的人类指令，输出策略和动作以解读指令。多种FM决策范式极大优化决策性能，拓展至自然科学和社会科学领域。表2列出了三种FM类型的基本内容及比较属性，包括主要建模技术和应用领域。\n表2：基础模型范式概念框架——功能角色映射、核心建模技术、跨领域应用及优缺点对比\nFM功能 主要建模技术 应用领域 优势 缺点 智能体 LLM思维链（CoT）；强化学习；专家规则 机器人、金融交易等 通用决策到复杂环境、实时响应 推理效率低，安全验证与人类价值对齐难，生成质量与延迟问题 环境 生成式仿真（GenSim） 城市规划、医学仿真等 低成本生成多样场景，高风险任务预训练 仿真与现实差距大，多模态动态建模复杂 交互者 检索增强生成（RAG） 教育辅助、智能客服等 自然语言交互，用户友好，个性化需求匹配 高幻觉风险，隐私保护与伦理对齐挑战 作为智能体的FM。任务及其提示输入至FM规划器，生成对应策略 $1,2,\\ldots,n$，选择最优动作执行。作为感知者，FM收集来自多个环境 $1,2,\\ldots,n$ 的多模态信息（文本、图像、音频、视频），形成当前状态。作为决策者，FM ${ }^{204,205}$ 利用状态及状态提示获得最优策略与相应动作，动作执行后产生环境反馈奖励，用于优化FM决策策略。此外，作为执行者，FM通过工具、API、Web GPT、Python生成动作表现并根据当前状态执行。${ }^{206}$ 基于FM的智能决策代理改进决策场景与范式，提升决策能力。\n作为环境与设计者的FM。在非智能体模块中，FM可充当环境与设计者 ${ }^{36}$，将状态信息形式化为马尔可夫决策过程（MDP），包含状态转移、奖励函数、策略、动作等。FM可作为动作执行目标、环境组成或环境状态转移桥梁，增强策略效果。${ }^{207}$ 进一步地，FM设计并形式化环境状态格式与动作空间，提升策略生成能力。例如，FM的微调参数矩阵 ${ }^{208,209,210}$ 可视为环境，借助微调方法训练，用于生成对应策略与动作以更新FM参数。作为环境设计者，FM可设计相应状态编码 ${ }^{211}$、奖励函数及状态转移函数 ${ }^{212}$，即用于形式化环境，如图3所示。作为条件生成模块，基于FM的条件生成表现模块 ${ }^{36}$ 可结合任务描述和条件输出行为生成（动作）与世界模型生成（环境动力学）。${ }^{205}$ 此生成模型还可应用于文本或图像数据，建模行为、环境及长期轨迹。${ }^{205,213}$ 行为与世界模型可视为策略，生成对应动作及MDP轨迹。生成的行为与世界模型可用于执行和形式化环境，勾勒环境条件生成信息。此外，在FM编码器模块中，FM用于将环境状态信息编码成提取表示，生成策略与动作。FM编码器模块可视为环境数据的多模态编码器，例如将视频数据转换为音频与图像数据，音频再编码成对应编码信息。非数值状态信息编码为数值向量，如将文本或图像编码为向量形式，便于输入大型模型。向量化 ${ }^{214}$ 是将非数值信息转为向量的有效方法，因此编码器模块是将状态信息转换为高效策略与动作生成形式的工具。FM架起状态表示形式转换的桥梁，将状态编码为更便于计算机处理的形式。\n图3：基础模型在智能决策中的关键角色\n作为人机交互者的FM。在基于FM的人机交互模块中，FM能根据人类以对话形式发出的指令生成相应策略、动作及解释。${ }^{205}$ 通过基于文本、图像和音频的对话，FM实现人机智能交互。故FM可视为人机交互桥梁，可部署于机器人或无人车辆 ${ }^{215}$，提供智能问答服务。基于FM的多种决策范式有效促进决策模式及应用环境的适应性，多模态FM决策范式极大优化决策性能与泛化能力。\n3.2 基于大型语言模型赋能的智能决策AI智能体 随着大型语言模型（LLMs）赋能的AI智能体出现，智能决策正经历深刻变革。不同于传统依赖手工规则、从头规划或调度算法的决策方法，LLM驱动的智能体利用大规模预训练模型，能实时处理和响应多样且动态的输入。这些智能体不仅擅长理解复杂任务与语境，还促进知识迁移，支持跨领域策略的快速适应。基于LLM的智能体一大优势是无需大量再训练即可迅速调整决策、优化动作，应对变化环境。借助思维链（Chain of Thought, CoT）${ }^{216}$ 等机制，LLM智能体展现高度透明且可解释的决策流程，将复杂推理拆解为清晰步骤。此能力使其在复杂动态环境中优于传统决策模型，提供更灵活透明的决策框架，适合需要快速响应和实时决策的场景。\n提升AI智能体决策能力的技术。LLM赋能的AI智能体显著提升决策能力，依托强化学习与人类反馈（RLHF）、检索增强生成（RAG）、搜索算法及高级推理方法等先进技术。RLHF已被证明在使LLM行为与人类价值对齐方面极为有效。${ }^{217,149,218,219,187}$ 这类方法通常依赖人工标注的偏好数据集训练奖励模型，再通过强化学习引导LLM训练。传统RLHF采用近端策略优化（PPO）算法${ }^{220}$ 进行对齐微调，但资源消耗巨大。为提高资源利用率，近年兴起直接优化LLM自身的方法。${ }^{221,222,223,224,225,226}$ RAG通过检索相关外部信息改善知识获取，使LLM智能体能基于实时数据生成更准确、语境敏感的回答，特别适合需最新知识或跨领域复杂决策任务。${ }^{150}$ 搜索算法，如束搜索和蒙特卡洛树搜索（MCTS），${ }^{227,228}$ 通过探索多个候选解或模拟不同决策路径，提升复杂长期决策任务（如博弈论、战略规划）中的决策效率与鲁棒性。${ }^{229}$ 先进推理方法如CoT ${ }^{216}$、思维树（Tree of Thought, ToT）${ }^{129}$ 和思维图（Graph of Thought, GoT）${ }^{230}$ 深化推理能力。CoT通过拆解复杂推理步骤提高决策透明度，ToT和GoT则通过层级或图形结构帮助智能体处理复杂多步决策任务。上述技术共同赋能LLM智能体在多种动态环境中实现自适应、透明且信息充分的决策。\nAI智能体的应用场景。LLM智能体广泛应用于战略推理，${ }^{231}$ 博弈论，${ }^{232}$ 实时决策，${ }^{233,234,235,236,237}$ 以及跨任务知识迁移，${ }^{238,239,240,241,242,243}$ 展现了其在复杂环境中的强大能力。在战略推理中，LLM智能体能预测动态且高度不确定环境中的对手行为，实时调整策略，尤其在多智能体博弈中，博弈论集成增强了决策效果。例如，在《星际争霸》等复杂策略游戏中，LLM智能体不仅预测敌方行动，还能适时调整策略以获取优势。随着LLM在实时决策中的应用日益广泛，诸如LLM-PySC2 ${ }^{233}$ 和SC-Phi2 ${ }^{234}$ 等测试平台成为评估LLM智能体宏观决策与战术协作能力的重要工具，解决多模态观测与实时反馈等挑战，推动复杂决策背景下LLM研究。在演绎推理任务中，LLM智能体表现同样亮眼。如在狼人杀游戏中，LLM能模拟人类欺骗、信任建立与策略沟通，增强对复杂动态环境的适应力。${ }^{236,237}$ 在创造性任务中，LLM展现生成新颖定义的能力，如Minecraft ${ }^{244,245,246}$、Balderdash ${ }^{247}$ 等游戏中体现其战略逻辑和创新思维，凸显其在推理与创造任务的潜力及广泛适用性。LLM智能体还应用于自动驾驶 ${ }^{241}$ 和机器人领域，${ }^{240,242}$ 证明其在实时决策与战略推理中的实力。自动驾驶中，LLM智能体处理车辆及环境实时数据，快速识别潜在风险，制定应急策略，提供高效准确的决策支持。${ }^{241}$ 机器人任务要求LLM接收自然语言指令，转化为机器人可执行的具体动作，需有效桥接语言理解与控制系统。${ }^{240,242}$ 在复杂多智能体环境中，LLM智能体在合作与竞争中展现独特优势。TMGBench平台 ${ }^{248}$ 测试LLM智能体在多种游戏类型中的战略推理与决策能力，推进竞争场景下理性决策的应用。基于LLM的社会推理游戏日益受AI研究关注，AdaSociety ${ }^{249}$ 和AI Metropolis ${ }^{250}$ 等平台支持LLM智能体模拟和优化复杂社会动态与协作任务，提高决策效率和系统适应性。LLM智能体在经济决策领域的应用也在扩展，通过模拟真实经济交互，帮助研究者更好理解与预测经济行为，推动经济学、社会学等领域研究。${ }^{238,239}$ 总体而言，LLM智能体技术的发展及其在复杂领域的多样应用，不仅提升了实时决策能力，也推动了战略推理、社会推理和创造性思维等创新。\nAI智能体的限制与挑战。尽管LLM赋能智能体在多个领域表现出色，仍存在若干挑战和瓶颈。一大限制是其处理多模态数据的能力，尤其整合图像、音频或传感器信号时的不足。由于LLM主要针对文本输入设计，往往难以高效处理非符号数据，影响该类环境中的决策。此外，LLM智能体面临可扩展性和实时决策的挑战，尤其在低级控制任务中。尽管推理复杂，但在要求精确即时响应的动态环境中常显不足。在高频率、低延迟场景下，决策延迟可能削弱系统响应与效率。安全性依然是关键问题，特别是在高风险应用中。若缺乏与人类价值和安全协议的有效对齐，LLM智能体可能做出意外且潜在有害的决策。确保LLM智能体在复杂环境中做出稳健、安全的选择，并在不确定性下保持稳定，将是推动AI智能体技术发展的重要方向。\n3.3 基于高级深度强化学习的智能决策 传统强化学习（Vanilla RL）将决策环境视为典型的马尔可夫决策过程（MDP），其完整元素在现实世界中很少完全存在。技术层面上，仍存在效率、泛化和可扩展性等瓶颈。同时，强化学习的成功高度依赖于基于非平凡专家知识的奖励设计。为此，研究者探讨了若干高级强化学习主题，以缩小理论与实践间的差距，使深度强化学习更易于应用。总体而言，这些研究聚焦样本效率、策略迁移、信用分配、不完全环境和安全性等问题。强化学习的不同范式如图4所示。\n图4：强化学习的不同范式 (A) 离线强化学习：仅利用现有历史数据，无需或极少在线交互，学习最优或近似最优策略。 (B) 元强化学习：赋予智能体“学习如何学习”的能力，快速适应新任务。 (C) 层级强化学习：引入层级结构，将复杂任务分解为高层“元动作”或子任务及低层具体执行策略，简化学习过程。 (D) 多智能体强化学习：研究多个智能体通过协作或竞争学习最优策略的强化学习范式。\n离线强化学习（Offline RL）。离线强化学习${ }^{34}$ 指完全依赖静态历史数据集学习最优策略，摒弃在线交互中的试错模式。简言之，离线RL旨在提取并泛化历史数据中的知识，归纳出在类似环境下表现良好的策略。离线RL的实际需求源自风险敏感领域中探索不可行或高风险（如金融市场百万次自动交易），并涉及复用珍贵昂贵的数据集，降低数据采集成本。常用策略包括：(1) 行为正则化，将学习策略约束在行为策略附近，降低遭遇分布外（OOD）状态风险；${ }^{251,252}$ (2) 带不确定性量化的Q学习及离线策略评估，抑制数据稀少区域的值估计过高，保障安全；${ }^{253,254}$ (3) 隐式策略优化，利用序列或生成建模学习表达力强的决策器，如决策Transformer或扩散策略。${ }^{255,256}$ 最新进展提供了较宽松的策略学习支持约束 ${ }^{35}$ 和价值学习方法 ${ }^{257}$，促进策略在行为策略支持范围内优化，取得业界领先表现。尽管前景广阔，离线RL仍面临实际挑战，包括OOD状态和动作的存在，${ }^{258,259}$ 静态数据集的多样性与质量，${ }^{260}$ 以及鲁棒的策略评估技术。此外，值得关注的挑战还有有效子目标定位、多效信用分配、子目标探索策略设计以及层级执行者间的协调。\n元强化学习（Meta RL）。元强化学习考虑MDP分布上的泛化，训练智能体利用过往经验快速适应未见但相似任务。直观动机是打造通用智能体，具备学习能力，避免部署时从零训练。元RL的核心技术是编码元知识以快速适应，或从少量样本推断任务特征，使其适应变化环境，如多样地形的机器人控制和多场景自动驾驶，避免部署中的计算成本和样本效率瓶颈。现有典型方法包括基于优化的 ${ }^{17,261}$ 和基于上下文的 ${ }^{262,263,264,45}$。MAML ${ }^{17}$ 是基于优化的方法，寻求元策略，通过梯度更新适配新MDP。PEARL ${ }^{262}$ 是基于上下文的方法，学习任务嵌入以实现任务特定策略的摊销。然而，元RL在元训练阶段计算和采样成本高，泛化能力严重依赖于任务分布设计（类似领域随机化）。作为创建可适应智能体的有希望方向，元RL仍需在任务分布设计、高效元训练和鲁棒性方面取得突破，以确保更广泛的适用性。\n层级强化学习（Hierarchical RL）。复杂决策中任务结构清晰，层级强化学习（HRL）管理决策过程，将任务分解为多个层级。在高层策略中制定子目标，低层策略执行并达成这些子目标，从而将复杂的长时域任务拆分为一系列易管理子任务。例如，在自动驾驶系统中，导航智能体为高层策略，指挥低层控制器执行具体转向操作。此类分解促进模块化策略学习，通过跨任务指定多样组合技能提高样本效率。同时，HRL利用任务中的时间抽象，适应不同时间尺度的决策需求。常见方法为不同选项框架，选项为具有自身策略和终止条件的时序扩展动作。例如，MAXQ框架递归分解价值函数为更简单层级组成部分。${ }^{265}$ 类似选项机制扩展至DQN形成H-DQN。${ }^{266}$ HRL通过探索子目标代替具体动作提升探索效率，类似人类追求长远目标的战略规划。\n多智能体强化学习（Multi-agent RL, MARL）。多智能体强化学习涉及多个自主智能体在共享环境中学习与交互，实现合作、竞争或混合目标。智能体决策非孤立，需适应环境动态及其他智能体策略变化。MARL适用于复杂实际领域，如群体机器人、实时战略游戏 ${ }^{267}$、分布式控制系统 ${ }^{268}$ 及智能交通 ${ }^{269}$。但MARL带来额外复杂性，需专门技术处理交互、通信、资源分配及战略决策。智能体可能存在目标冲突，需实现群体智能决策。MARL建模为随机博弈或马尔可夫博弈，旨在多智能体协调、竞争或混合环境中求稳健解。智能体需处理部分可观测性、多样交互，并实践去中心化学习。常用策略为中心化训练、去中心化执行（CTDE），训练阶段利用共享信息，执行阶段独立行动。独立学习将MARL降解为多个单智能体策略，缺乏训练阶段协调机制，难应对其他智能体策略变化引发的非平稳问题。${ }^{270}$ 基于价值的方法将联合价值分解为个体价值，实现有效信用分配促进合作。${ }^{271,272,31}$ 尽管如此，通信机制设计、信用分配、环境非平稳性等挑战依旧存在。${ }^{273}$\n过去十年深度强化学习理论和应用均有突破，尤其上述高阶深度RL范式提升了复杂序列决策的可行性。然而，将深度RL扩展至更多实际场景仍不易，面临技术、安全和效率瓶颈，源于昂贵的环境交互、不稳定的策略学习动态及奖励设计。幸运的是，部分新兴AI智能体及先进生成模型展现出缓解这些限制的潜力，如世界模型逼近 ${ }^{274}$、子目标设计 ${ }^{275}$ 和时间及多智能体层面的信用分配。${ }^{276,277}$ 基础模型与高级RL方法在大规模决策模型中日益融合，以平衡效率与准确性。随着决策模型规模扩大，基础模型与RL的协同变得实现先进智能的关键。\n3.4 基于高级基础模型的智能决策范式 在理解决策中的神经网络扩展规律时，必须覆盖足够丰富的决策场景进行预训练和元训练。然而，这一过程常伴风险，尤其是机器人可能执行危险动作，形成典型的“鸡生蛋还是蛋生鸡”困境。针对这一挑战，收集多样且高质量的数据集、开发反事实预测器，以及利用Sim2Real或Real2Sim2Real模块${ }^{278}$，成为解决决策场景限制的有效策略。总体而言，图5概述了构建基础决策模型（FDMM）的有前景方法。\n图5：基于基础模型的高级智能决策范式 (A) 视觉-语言-动作（VLA）结合LLM的层级推理与视觉模型的感知能力，将高阶任务拆解为可执行子任务，应对场景多样性和部分可观测性带来的计算与数据瓶颈。 (B) 视频学习（LfV）利用大规模廉价在线视频数据，将原始视频转化为结构化转移轨迹，实现通用智能体训练，挖掘现实世界中多样、嘈杂视频中的上下文信息。 (C) 生成式仿真（GenSim）结合仿真环境与提示引导的任务提案模块和智能体模块，创造多样决策场景并优化自适应策略，减少对昂贵真实数据的依赖，适用于机器人和自主系统等复杂任务。\n示范学习（Learning from Demonstrations, LfD）与视觉-语言-动作（Vision-Language-Action, VLA）。人工智能决策的自然范式是示范学习${ }^{279}$，即构建由专家策略指导的多样技能决策序列，供模型学习。LfD利用示范作为丰富监督源，提供环境中理想行为样例。LfD的离线设置支持概率模型生成场景特定序列，实现上下文依赖的策略学习。此概率框架可细致理解决策中的变异与不确定性，支持部分可观测环境的鲁棒策略开发。但随着场景多样性增加，所需交互序列呈指数增长，带来巨大计算和数据需求。部分可观测性进一步阻碍准确策略推导。VLA多模态基础模型作为有力替代，通过融合LLM的层级推理能力和视觉模型的感知能力，应对复杂决策任务。利用语言内在结构，VLA模型将高阶任务拆解为易管理子任务。行为克隆技术${ }^{280}$ 直接将视觉输入（如图像或视频标记）映射至低阶执行动作。典型模型包括RT-2 ${ }^{281}$、UniPi ${ }^{282}$ 和OpenVLA ${ }^{283}$，展示了示范在训练通用智能体中的价值。这些模型借助编码于语言中的人类决策先验，通过示范提升多模态理解与动作执行能力。示范学习随时间成为下游任务不可或缺的资源，增强模型在多样环境中的泛化能力。然而，VLA模型面临关键限制，包括对大规模视觉-语言-动作数据集和多模态决策序列的依赖，限制了其在未知场景中的扩展性和泛化潜力，成为发挥其全部能力的瓶颈。未来研究需攻克数据与计算挑战，确保其在实际任务中的广泛适用性和鲁棒性。\n视频学习（Learning from Videos, LfV）。高质量多样示范是训练鲁棒决策智能体的关键，但通常需大量时间和资金。培养通用决策者，关键在于寻找成本效益高的交互序列来源。互联网提供了丰富廉价的视频资源，记录了现实中对象交互，环境自身可视为生成模型。基于此，LfV${ }^{284,285}$ 利用大规模视频数据集构建综合视频基础模型，推断隐式动作。LfV侧重将原始视频转化为结构化转移轨迹。借助弱监督和无监督学习技术，LfV间接标注动作和奖励，降低人工标注需求，实现从未整理嘈杂数据集中提取有效任务示范。生成的序列作为策略学习数据集，桥接感知与决策。LfV优势在于利用海量在线廉价数据，显著降低训练样本生成成本。视频中丰富多样的场景提供了支持复杂任务泛化策略学习的上下文信息。关键进展包括采用自监督学习和对比学习技术，解决动作分割与状态表示难题。但LfV仍面临重要挑战：视频数据的部分可观测性（关键状态可能不可见）妨碍准确策略推导；无关物体和环境干扰产生噪声，导致轨迹次优；动作空间不完整或不精确，因视频可能缺少任务所有可能转移的完整覆盖。即便最新交互式生成决策模型Genie-2依赖大量专家视频注释。${ }^{284}$ 未来需通过精炼动作空间、多模态信号表示与鲁棒数据过滤机制，解决这些瓶颈，确保扩展性与可靠性。\n生成式仿真（Generative Simulation, GenSim）人工智能。为降低数据采集成本，GenSim${ }^{286,287,288,289}$ 利用仿真环境促进决策与策略学习。其框架包含两个关键组件：任务提案模块，基于提示生成多样仿真场景；智能体模块，学习适应或优化跨场景策略。该范式无需完全依赖昂贵真实数据，即可探索复杂多样的决策环境。在RoboGen等实现中，${ }^{287}$ LLM集成任务提案机制，将高层任务分解为子任务，使智能体能调用仿真API、检索知识并通过强化学习训练低层策略。此模块化框架提升扩展性与适应性，适合机器人与自主系统等现实应用。OMNI ${ }^{289,290}$ 通过模拟涵盖广泛现实条件的决策环境即为典范。在GenSim中，“生成”涵盖两个关键维度：决策场景创造与具备跨任务鲁棒适应能力策略开发。${ }^{286}$ 这些仿真场景支持策略测试与改进，缩小合成与现实环境差距。该迭代反馈环加速策略学习，减少对真实数据依赖，并支持高风险场景的主动实验。\n然而，GenSim面临关键挑战。其有效性依赖于仿真器的准确性与保真度，仿真与现实动力学差异导致策略性能下降，称为Sim2Real差距。${ }^{291}$ 此外，Real2Sim2Real框架指出，策略在仿真与现实间迁移的复杂性增加难度。确保策略的鲁棒泛化、设计高保真仿真器以及验证动态现实环境中的策略表现，是GenSim亟待攻克的研究方向。通过整合LLM指导任务设计、可扩展仿真模块与强化学习技术，GenSim如Genesis代表了低成本自适应决策研究的有力方向。${ }^{286}$ 然而，解决其技术与理念瓶颈是充分发挥潜力的关键。\n3.5 大规模智能决策的关键技术 本节介绍大规模智能决策的关键技术。为清晰展示这些技术的协同工作机制，首先提出一个框架，如图6所示${ }^{292}$。该框架勾勒了智能体决策过程中的核心技术组件及其相互关系，提供了理解各技术元素在智能决策中作用的直观视角。\n通过“记忆”（Memory）、“规划”（Planning）、“工具”（Tools）与“动作”（Action）的集成应用，大规模智能决策系统能高效处理复杂任务，实现决策流程的自动化与优化。下文将详细讨论各技术模块及其在智能决策中的作用。\n大规模智能决策系统整体可视为一个智能体，通过多个技术模块协同实现高效决策。图6中将这些技术归为四类：“记忆”、“规划”、“工具”和“动作”。该框架展示了智能体决策过程中的关键技术组成及相互联系，帮助理解这些技术如何支撑大规模智能决策。\n图6：智能决策关键技术示例 大规模智能决策系统可视为一个“智能体”，其核心技术框架大致分为四个模块：记忆、规划、工具与动作。智能体通过感知模块获取外部环境信息，并存储于短期与长期记忆中。规划模块基于当前环境状态和历史信息生成决策方案，工具模块提供计算和搜索等外部资源辅助决策。最终，智能体根据规划结果执行相应动作，影响环境状态，并通过环境反馈进一步调整行为策略。\n通过整合“记忆”、“规划”、“工具”和“动作”，大规模智能决策系统能够有效应对复杂任务，实现决策自动化与优化。例如，在自动驾驶中，智能体利用记忆模块回忆交通规则和历史信息，规划路径，实时应用传感器和地图数据等工具，制定最佳驾驶策略。在智能电网管理中，智能体基于历史数据和实时电网状态进行电力调度和优化，确保电网高效稳定运行。接下来将具体探讨各技术模块及其在智能决策中的作用。\n记忆模块。在大规模智能决策技术中，记忆技术通过积累历史经验优化决策过程，提高效率，减少错误。它使系统能在复杂环境中学习与改进，通过经验回放加速学习，支持个性化和上下文感知的决策。此外，记忆增强系统的稳定性与可解释性，使决策轨迹可回溯，提升透明度。在多智能体系统中，记忆促进知识共享和协同决策，提升整体性能。它还帮助系统及时发现异常、诊断问题并调整策略，增强系统鲁棒性和适应性。\n早期对记忆机制的探索多聚焦于模型设计与算法优化，寻求高效存储和利用历史信息的方法以提升任务表现。${ }^{293,294}$ 经典且具代表性的方法之一是循环神经网络（RNNs）${ }^{295}$，通过跨时间步隐状态循环传递信息，使模型具备记忆能力。然而，梯度消失问题导致RNN难以有效学习长期依赖，限制其仅在短期范围内保持信息，长依赖任务表现不佳。\n为此，学者提出多种改进方法。${ }^{296,297,298}$ 其中，长短时记忆网络（LSTM）${ }^{296}$ 在RNN基础上引入门控机制，部分缓解梯度消失问题，显著提升短期记忆建模能力，广泛应用于时间序列分析和自然语言处理（NLP）任务。${ }^{299,300}$ 但LSTM仍面临并行能力差、长距离依赖建模能力有限等挑战，处理长序列任务时效率较低。\n然而，上述方法难以满足长期记忆需求。为应对这一挑战，研究者广泛探索提升长期依赖建模和利用的方法。${ }^{301,302,303}$ 其中，记忆网络（Memory Networks）${ }^{301}$ 提出带显式长期存储的神经网络架构，实现知识的存储与检索，开创了显式长期记忆建模的成功尝试，为后续增强记忆神经网络奠定基础。通过引入外部记忆组件，记忆网络使模型更有效访问和利用存储信息，提升处理长期依赖和复杂推理任务的能力。另一方面，Transformer${ }^{58}$ 利用自注意力机制动态分配权重，捕捉输入序列内部依赖，突破传统序列时间步限制，极大增强模型的并行计算能力。注意力机制动态筛选与当前任务相关的关键信息，减少计算冗余，使智能体能在短时间内快速决策。该架构奠定了大量大规模预训练模型（如GPT、BERT）的基础，确立了现代机器学习研究与应用中广泛采用的预训练-微调范式。\n自Transformer问世以来，基于其架构的改进方法层出不穷。${ }^{304,305,306,307}$ 其中，2020年提出的压缩Transformer（Compressive Transformer）${ }^{304}$ 结合短期与压缩记忆，保持长序列任务中的历史上下文，提升Transformer的记忆建模能力。同年，检索增强生成（RAG）${ }^{308}$ 提出语言模型结合外部数据库检索的框架，弥补模型知识有限问题，促进长期依赖建模与知识增强任务生成，有效突破语言模型知识记忆瓶颈。近年，Mamba${ }^{309}$ 等工作通过引入选择性状态空间模型（SSM）与线性递归机制，提出新颖记忆建模框架，实现低复杂度高效状态更新，对序列任务性能提升和长期依赖建模具有潜力。\n规划与控制技术。智能决策的关键技术依赖合理的规划方法、工具使用和动作执行。规划技术通过分析任务需求和约束设计最优动作方案，确保决策有效且可行；工具使用技术为智能体提供必要辅助资源，支持信息高效处理、问题解决及任务完成；动作执行技术保障智能体根据规划准确快速地执行具体操作，实现预期目标。三者有机结合，使智能决策高效且精准。\n过去，规划问题受广泛关注。${ }^{310,311,312}$ 其中，分层任务网络（HTN）${ }^{310}$ 通过层级分解任务，将高层目标逐步细化为具体操作步骤，形成可执行规划路径，作为早期规划技术经典代表，数十年广泛应用。\n随着机器学习与环境建模融合，2018年提出的世界模型（World Models）${ }^{313}$ 引入智能体通过学习环境潜在表示进行规划与决策，模拟环境状态，突破动态环境中复杂决策难题，显著提升任务规划的泛化能力与效率，广泛应用于策略游戏和强化学习任务。\n此外，研究者开始探索“工具使用”方法，旨在赋能智能体学会有效利用现有外部工具，提升规划与执行能力。部分研究${ }^{314,315}$ 将神经网络与模块化工具结合，支持逻辑推理与复杂任务分解，展示模型利用工具完成任务的潜力。近期提出的Toolformer${ }^{316}$ 通过自监督学习，训练模型自主决定调用API的时机、传递参数及整合结果，显著提升模型零样本学习能力。但Toolformer存在工具调用机制固定、上下文适应性不足、复杂任务泛化能力有限等缺陷。ToolLLM${ }^{317}$ 构建了名为ToolBench的工具使用指令调优数据集，提出深度优先搜索决策树（DFSDT）方法，使开放式LLM能调用超过1.6万个真实API，显著提升推理和泛化能力。然而，ToolLLM仅在窄领域任务（如特定类别工具操作）表现优异，难以应对多任务、多领域复杂交互。相比之下，最新提出的OS-Copilot${ }^{318}$ 构建通用框架，实现与操作系统的全面交互，使智能体能在网页、终端、文件、多媒体及第三方应用等多领域自主操作，解决当前智能体任务范围和工具适应性限制，为构建通用操作系统级智能体提供技术基础，推动其从工具调用向开放环境多任务、多领域适应性进化。\n随着GPT-4等LLM发展，融合推理与行动的规划技术成为研究热点。谷歌DeepMind提出的ReAct${ }^{319}$ 结合基于自然语言的思维链推理与工具使用，实现高效规划。该方法利用LLM推理能力拆解复杂任务，直接与工具或环境交互执行动作，为更高级多功能规划系统铺路。近年提出的世界知识模型（WKN）${ }^{320}$ 集成先验任务知识与动态状态知识，显著增强智能体在复杂环境中的全局规划与动态适应能力，在多任务中取得性能突破。此外，ReAct${ }^{319}$ 提出结合思维链推理与动态工具使用的方法，有效整合LLM推理与执行能力，实现决策任务中高效动作执行。Voyager${ }^{321}$ 进一步推进开放世界环境中的探索与技能复用，借助LLM通过自然语言生成行动计划与代码，动态适应任务目标，并引入长期记忆机制存储与复用技能，展现了在开放世界游戏Minecraft中的自主探索与任务执行能力，解决了开放环境中的自主探索、技能获取和持续学习挑战，显著提升智能体在动态环境中生成与优化动作的能力。\n3.6 仿真技术及其在智能决策中的关键作用 仿真技术通过数学公式、物理模型、机器学习算法、计算机生成的表示或其组合，复制现实世界的过程或系统，使得研究复杂行为、底层特征和涌现现象成为可能。${ }^{322}$ 仿真凭借探索因果关系和基于模型的情景分析能力，这类“假设性”分析成为评估潜在结果和指导未来决策的宝贵工具。${ }^{323}$ 除了直接支持决策，仿真技术在智能决策范式中（如强化学习和基础模型）也发挥着不可或缺的作用，承担优化学习环境、生成海量数据、实现全面测试评估等多重关键功能。因此，该技术已广泛应用于交通、社会系统、经济、军事行动、能源管理等复杂系统的分析和决策。${ }^{324}$ 尽管基于仿真的方法在支持决策时具备可控分析优势，现实应用中仍面临若干限制：（1）计算效率与仿真精度难以平衡；（2）提升模型在未知场景中泛化能力的仿真环境设计存在挑战；（3）决策变量耦合机制尚不明确。幸运的是，仿真作为跨学科解决方案，持续融合前沿信息通信技术（ICT）和人工智能技术，推动自身发展。例如，知识-数据联合驱动建模、多模态与多任务仿真、计算实验方法${ }^{325}$催生了平行智能${ }^{326}$、生成式仿真${ }^{286}$、数字孪生${ }^{327}$等创新仿真理念。尤其是将大型语言模型（LLMs）引入建模与仿真，焕发新活力，备受关注，推动复杂系统智能决策进步。\n基于仿真的智能决策。美国国防部将仿真定义为利用物理、数学或其他逻辑模型对系统、实体、现象或过程进行时间上的复制，以支持管理或技术决策。${ }^{328}$ 仿真支持实验、假设检验与情景分析，为多领域系统行为在不同条件下的理解与决策提供有价值见解。技术进步推动仿真发展，诞生平行智能${ }^{326}$、基于LLM的智能体建模与仿真${ }^{329}$、仿真智能决策生成${ }^{324,330}$等创新概念，均紧密关联智能决策。根据支持决策的方式，仿真动机可分为：（1）基于仿真的预测——通过分析一个或多个变量未来趋势，探索解空间，辅助未来决策。例如，在COVID-19疫情期间，开发了基于多源信息融合的交互式个体模拟器，用以预测疫情传播。${ }^{331}$（2）因果推理——通过改变外部干预进行假设实验，基于实验结果调整决策，支持干预管理。例如，朱等人${ }^{332}$提出细粒度人工社会结合功能数据模型的通用计算实验框架，评估不同干预措施效果，旨在达到效益与成本的帕累托最优。（3）涌现发现——利用多尺度仿真研究涌现行为与要素耦合机制，获取新知识，提升决策效果。以大型交通枢纽疫情防控为例，开发个体级移动模型与接触网络，精准模拟传染病传播。${ }^{333}$ 研究发现累积发病率呈线性增长，区别于城市静态网络的指数增长模式，为制定更有效控制策略提供依据。\n仿真增强智能决策。仿真在多智能体强化学习与具身智能体的训练、学习与评估中发挥重要作用。它提供安全、高效、可定制的环境，生成大规模训练数据，实现模型性能和泛化能力的全面评估。此外，仿真为模型优化和部署前测试（Sim2Real）提供关键支持，保障真实应用。${ }^{334}$ 根据辅助强化学习和基础模型等智能决策范式，仿真动机可细分为：（1）提供安全、低成本、可定制的测试或交互环境，生成训练和测试数据，加速学习过程。例如，自动驾驶与机器人领域的真实环境测试存在安全风险和高昂实验成本，仿真环境可按需定制多样条件，安全、经济地模拟各种罕见、危险或难以复现的实际情景，全面测试模型鲁棒性与适应性。典型平台包括TongVerse${ }^{335}$、Isaac Sim${ }^{336}$和Genesis。（2）评估模型泛化能力，支持多样评估指标。仿真允许模型在多样化且贴近现实的场景中测试，验证其从仿真到现实的泛化能力。生成式仿真${ }^{286}$使此过程更具成本效益与高效性。仿真环境还支持平均奖励、最佳单实例奖励、样本效率等多种评估指标，帮助全面可靠地衡量模型表现。例如，RL-CycleGAN在仿真训练并在真实机器人抓取任务中验证，表现卓越。${ }^{337}$（3）通过人类反馈优化强化学习，实现人机价值对齐。RLHF中，仿真可生成后验反馈，评估模型行为是否真正有益。例如，引入的基于回顾性仿真的强化学习（RLHS）模拟合理结果并诱导反馈，评估行为的实际效用，降低模型行为与人类价值不一致的风险。${ }^{338}$ 实验表明，RLHS在帮助用户达成目标及满意度评价上持续优于RLHF。\n开放挑战与未来方向。本文探讨基于仿真的智能决策面临的挑战与未来研究方向：（1）数据与知识联合驱动的建模与仿真。仿真与真实环境差异意味着仿真中表现优异的模型在真实部署时可能效果大打折扣，如何结合不同尺度信息构建仿真环境尤为关键。基于知识的方法受限于当时认知能力，往往难以精准捕捉复杂系统演化机制；数据驱动方法依赖数据量与质量，观测数据缺失时效果大幅下降。因此，充分利用两者优势，研究数据与知识联合驱动建模与仿真是未来重要趋势。（2）大规模仿真系统中计算效率与仿真精度的权衡。大规模复杂场景的仿真面临效率、扩展性和资源消耗等挑战，如何优化仿真系统支持大规模训练与测试，尤其针对基于API的商业LLM模型，是亟需解决的问题。故系统层面（如计算任务优化）与提示层面（创新提示策略）的优化，以保证结果准确同时缩短运行时间，是未来研究重点。除此之外，构建开放可扩展仿真平台、大模型赋能建模与仿真工作流、实现仿真环境中的持续学习、多模态多任务仿真等问题，也引起广泛关注，值得深入探讨。\n通过应对上述挑战并探索未来方向，仿真技术有望显著提升智能决策能力，推动人工智能领域进一步发展。\n4. 基于基础模型的科学智能决策 随着人工智能技术的持续进步，基础模型（Foundation Models，简称FM）在科学领域中日益成为核心力量，显著推动了科学研究和决策能力的提升。本章探讨了基础模型在信息科学、数学科学、生命科学、医疗健康、牙科、城市科学、农业科学、经济科学和教育科学等多学科领域的应用，详细阐述了它们在增强科研能力和提升决策质量方面的作用。相关内容结构如图7所示。 图7：基础模型驱动的多学科科学智能决策（展示了FM在智能决策中的核心作用，支持多样数据类型训练，并展示其在信息科学、数学科学、生命科学、医疗健康、牙科、城市科学、农业科学、经济科学和教育科学等关键科学领域的应用）。\n4.1 信息科学 基础模型（FM）通过大规模自监督学习预训练，在信息科学的多种下游任务中表现出强大的泛化能力。${ }^{50}$ 它们的迁移学习能力使其在推理${ }^{339}$、控制${ }^{340}$、规划${ }^{341}$和搜索${ }^{50}$等领域取得成功，涵盖机器人学、自动化、遥感、通信和电力系统等应用。例如，基于FM的模型赋能机器人在现实世界中操作，并通过数据驱动洞见支持人类决策。与特定任务模型不同，FM通过共享任务间的特征实现对未知问题的泛化，支持上下文学习和跨模态处理。${ }^{48}$ 例如，Gato${ }^{342}$作为通用代理，能进行聊天、图像描述、游戏和机器人控制。${ }^{339}$ 通过整合多样数据集，FM增强了Atari游戏${ }^{11}$、棋盘游戏${ }^{343}$和机器人任务${ }^{344,345}$中的序列决策，展现了未来智能系统的巨大潜力。\n通用机器人与自主系统。 在FM出现之前，机器人领域的深度学习高度依赖特定任务数据集，限制了其灵活性和可扩展性。${ }^{346}$ 传统机器人系统需要手工策划特定任务的数据集，难以应对复杂或陌生环境。FM通过在多样数据集上的大规模预训练，结合特定任务微调，改变了这一范式。这使得FM能够学习可迁移的表征，机器人能从原始传感输入中提取高级语义特征，并应用于多样决策过程。特别地，上下文学习和指令微调技术使机器人能从自然语言提示或多模态信号推断任务目标，无需显式重训。FM最具变革性的特性之一是其零样本学习能力，依托对比学习和基于提示的适应机制，使机器人能够无需针对任务训练即泛化到未知任务，大幅提升其在非结构化或新颖环境中的适应性。${ }^{347}$ 典型FM模型如BERT${ }^{59}$、GPT-3${ }^{61}$、GPT-4${ }^{13}$、CLIP${ }^{14}$、DALL-E${ }^{62}$和PaLM-E${ }^{240}$展示了其在机器人领域的多样性。BERT起初设计用于自然语言处理，帮助机器人解码复杂语义信息，尤其适合多步骤语言指令。GPT-3和GPT-4以其自然语言推理和生成能力著称，使机器人能够处理用户命令并制定多步骤行动计划。CLIP实现文本与视觉表示对齐，支持机器人基于文本描述识别与交互对象。DALL-E通过生成合成环境支持任务演练和路径规划。在多模态推理方面，FM整合异构传感数据为统一表征，提升机器人的感知、推理和决策能力。${ }^{348,349,350,351,352,353,354}$ 这些能力使机器人能将文本命令关联至对象、位置和动作，促进空间推理及实际任务执行。例如，PaLM-E整合视觉、语言和传感输入，赋予机器人处理复杂场景的强大推理能力。${ }^{240}$ 机器人群智能的最新进展进一步体现了FM的影响力。传统群机器人依赖预定义通信协议和特定任务规划策略，而利用大型语言模型DeepSeek进行推理与交流则催生了类人群体行为。${ }^{355}$ 在去中心化的多机器人系统中，个体仅掌握局部信息，FM使机器人能够发现同伴、交换信息并通过自然语言动态协调。零样本实验结果显示，合作、协商与互纠错等社会行为涌现，模拟了人类团队协作的部分特征。这一创新路径展示了FM驱动代理构建互动社会的可能性，推动了“机器人人类学”研究并揭示自主系统中协作结构的涌现机制。\nFM从预训练中迁移知识的能力，显著缩短训练时间并减少计算资源需求。模仿学习中，FM利用视觉或文本形式的专家示范生成高质量策略。${ }^{356}$ 强化学习中，FM通过语言驱动的奖励机制优化策略，减少迭代次数提升任务表现。${ }^{357}$ 此外，大型视觉语言模型（VLM）支持机器人视觉问答（VQA）和视觉内容描述生成，简化数据标注和任务执行。${ }^{358}$ 通过微调，FM适应多样机器人应用，如自主系统、家用助理、工业自动化及多机器人协调。${ }^{359}$\n这些进展突显了FM在增强跨模态推理和连接用户意图与机器行动方面的变革性影响。FM在机器人领域的集成标志着自主系统发展的重要里程碑。不同于传统基于规则或特定任务学习方法，FM利用多模态数据上的大规模预训练实现跨场景泛化。通过Transformer架构和自监督学习，FM能解析自然语言指令并推断用户意图，确保自主系统与人类目标高度契合。具体而言，提示工程和指令微调技术使FM能基于上下文线索动态调整响应，提升动态环境中的决策能力。\n除了理解命令，FM还通过结构化推理和少样本学习提升机器人智能决策。它们利用跨模态嵌入，使自主系统能够关联视觉、语言和运动等感知输入，做出上下文感知决策。${ }^{360}$ 例如，GPT-4${ }^{13}$和PaLM-E${ }^{240}$展示了处理复杂语言指令并高精度转化为机器人可执行动作的能力。对比学习和强化学习技术使模型响应模式通过真实反馈不断优化。此外，这些模型的可靠性取决于学习表征质量和提示结构优化，强化了下游任务微调策略的重要性。FM与机器人深度整合，奠定了未来自主系统的基础技术地位。\n遥感领域的多模态理解。 近年来，遥感技术取得显著进展，多样传感器（光学、热成像、雷达等）促进了地表高分辨率数据采集。光学传感器捕捉可见光和近红外光用于植被与地貌分析，热成像传感器监测火山活动和气候变化，雷达传感器则在极端天气条件下为土壤水分估计和城市基础设施测绘提供关键数据。${ }^{361,362,61}$ 基础模型通过自监督学习整合大规模多光谱和多时相数据，显著提升遥感能力。与需特定任务特征工程的传统模型不同，FM利用Transformer架构学习跨传感器模态的时空相关性。例如，基于卫星影像与地理空间描述预训练的视觉语言模型，实现了无需大量标注数据的零样本地表变化分类和分割。此外，对比学习使FM能对齐卫星图像与文本描述，提升从异构遥感数据中提取有意义模式的能力。这些能力极大提升了森林砍伐监测、灾害响应和气候建模等任务的效率和准确性，体现了FM在遥感应用中的变革性影响。\nFM在遥感任务中的应用，如场景分类、语义分割、目标检测和变化检测，显著提升了性能并设定了新标杆。最初，卷积神经网络（CNN）如ResNet${ }^{72}$被用于提升图像识别和分类任务。随后，Transformer利用自注意力机制建模长距离依赖，更有效处理大规模图像数据。${ }^{58,363}$ 在遥感领域，FM通过自监督学习技术即使无大量标注数据也能学习鲁棒表征，提升其多样性和适用性。${ }^{364}$ 卫星掩码自编码器（SatMAE）作为专为时序和多光谱卫星图像设计的模型，在变化检测任务中表现突出，因其学习了空间和时间特征。${ }^{365}$ Scale-MAE将尺度感知学习融入自编码器框架，捕获多尺度地理空间表征，适用于城市规划中宏观与微观细节并重的基础设施测绘和土地利用分类。${ }^{366}$ 此外，DINO-MC通过自监督学习改进了FM的全局与局部对齐能力，将对比学习扩展到全局特征与局部图像块的对齐，提升了目标检测和场景分类的性能。${ }^{367}$ 这些模型利用FM的强大能力显著推进了复杂遥感数据处理，推动环境监测和城市发展规划的进步。尽管面临高质量多样化数据集需求和大量计算资源等挑战，FM的进步标志着遥感领域迈入新纪元，设定了准确率和效率的新标准。\n智能制造的高效决策。 传统机器学习方法在智能制造系统中处理多模态数据时面临重大挑战，因其通常依赖特定任务的特征工程和针对生产线或制造过程设计的专门模型。这不仅带来巨大计算和人力成本，也限制了模型在工业多样化场景中的泛化能力。此外，传统ML模型往往难以有效整合异构数据源，限制了其跨模态推理和自适应决策的能力。相比之下，FM利用跨模态嵌入表示学习将多模态数据映射至统一向量空间，促进不同模态间的信息融合与协同决策。通过对多样数据集的大规模预训练，FM获得强大的零样本和少样本学习能力，使其能以极少调整泛化到未见任务。这些特性显著提升了其在动态复杂工业环境中的可扩展性、适应性和整体性能，为智能数据驱动制造系统的发展提供了有力方向。传统深度学习模型在预测性维护（PHM）中常面临泛化能力有限、多模态数据处理困难和多任务执行不足等问题，阻碍其在动态工业环境中的应用。GPT类模型凭借捕捉长期依赖的能力，在处理多样传感器数据流如振动${ }^{368}$、声音${ }^{369}$、电流${ }^{370}$、电压${ }^{371}$、温度${ }^{372}$和压力${ }^{372}$等方面表现突出。例如，时间序列Transformer（TST）集成了时间序列标记和Transformer架构，在旋转机械故障模式识别上显著优于传统CNN和RNN。${ }^{373}$ 此外，通过提示工程融入领域知识，FM无需改变模型架构即可提升输出质量和准确度。${ }^{374}$ VS-LLaVA流程${ }^{375}$将大型语言模型应用于信号参数识别和故障诊断，显著提升了性能。\n智能制造范式正从机器中心向人机协作转型，后者在多品种小批量生产中提升了灵活性和效率。${ }^{376}$ 尽管具备潜力，人机协作仍受限于任务特异性以及遇到新物体时需重新训练。基础模型以其强大的推理和泛化能力应对这些限制，使其成为多样化人机协作任务的理想选择。早期研究利用计算机视觉技术提升机器人感知，如手势识别和运动模式编码，${ }^{377,378,379,380}$ 近期研究转向通用任务执行框架。例如，机器人Transformer基于大规模、任务无关数据集训练，实现跨多样机器人任务的泛化。${ }^{381}$ 此外，FM结合视觉基础模型（VFM）进行场景感知和大型语言模型（LLM）进行任务推理，形成生成执行控制代码的流水线，使机器人能够通过语言和视觉指导完成先前未见的任务。\n推动下一代通信智能化。 通信网络技术挑战源于其动态性、复杂性及日益多样的需求，涵盖网络配置和安全增强等方面。${ }^{382,383}$ 基础模型凭借其强大的多模态数据处理、泛化和上下文理解能力，有望在这些领域协同解决问题，为未来通信网络的智能高效运行提供关键技术支持。\n网络配置涉及为交换机、路由器、服务器和网络接口等设备设置参数，确保数据从源头到目标可靠传输。灵活高效的网络配置框架是支持下一代通信中资源调度、流量管理和服务优化的关键技术。CloudEval-YAML${ }^{384}$作为云原生应用YAML配置的基准工具，分析了12个大型语言模型的生成质量、任务性能和成本效率，解决了缺乏标准化基准的问题，有助于LLM在云环境中的应用与优化。利用自回归生成（如GPT-4）或扩散模型（如DiffusionBERT${ }^{385}$）等生成机制，Verified Prompt Programming（VPP）${ }^{386}$通过结合GPT-4生成能力、结构化提示及人工验证，提高了网络配置准确性。该方法通过提示工程和人工校正迭代优化模型生成的代码，确保自动化配置过程更加精确可靠。随着大型模型的发展，基于LLM的端到端网络配置方法逐渐成为智能配置的关键。同时，提出了全自动网络管理系统的通用框架，免除人工验证。${ }^{387}$ 该方法利用自然语言和LLM生成代码，通过提示工程结合领域知识和通用程序合成技术，保证高质量网络配置代码的生成。\n通信技术进步带来更高复杂度和互联性，网络攻击种类和手段日益多样化，令网络安全与攻击检测尤为重要。${ }^{388}$ 研究者开发了高质量网络安全数据集，并提出特定领域语言模型作为基础组件，增强对专业知识和技术术语的理解。此外，SecureBERT专为捕捉网络安全文本如网络威胁情报（CTI）语义设计。${ }^{389}$ 它基于大量网络安全相关内容训练，兼顾通用语义理解并针对各类网络安全任务进行评估。与微调预训练LLM的方法不同，SecurityBERT从零开始构建特定安全领域的大型语言模型。${ }^{390}$ 该模型基于BERT架构，采用隐私保护的定长编码（PPFLE）和字节级字节对编码（BBPE）分词器处理网络流量数据。模型体积仅16.7MB，标准CPU推理时间不足0.15秒，展现出卓越效率。它在识别14种不同攻击类型方面优于传统机器学习和深度学习方法，整体准确率达98.2%。\n电力系统的发展。 电力作为能源系统的关键组成部分，深刻影响我们的日常生活。为推动全球电气化和实现碳中和，构建高效、灵活和互联的电力系统势在必行。目前，物联网（IoT）和人工智能（AI）等新技术突破为电力行业的数字化智能化转型带来了机遇与挑战。\n近年来，以大型语言模型（LLMs）为代表的AI大模型技术取得显著进展，在全球多个行业展现出广阔潜力。${ }^{391}$ 以OpenAI的生成式预训练Transformer（GPT）系列为代表，最新的GPT-4通过深化Transformer架构和创新预训练策略，有效提升了大模型性能，推动其在广泛领域的应用。LLM技术的迭代发展深刻影响电力行业，促进了潜在电力大模型的研发与应用。\n在电力系统中，传统数据采集多依赖以往经验选择特征，效率低且带有主观性。相比之下，基于AI大模型的自动化数据分析突破了手工选择的局限，通过学习大量多变量数据，提取由智能终端汇聚至云端的数据特征，提升分析模型的预测精度。当前，大模型智能决策技术已初步应用于电气设备的智能诊断、运行与维护。其强大的数据处理能力、自主学习能力和分析预警功能，有效解决传统技术中的诊断准确率不足、响应滞后和运维成本高等问题。同时，通过深入挖掘设备运行数据，基于大模型的智能决策能够提前预警潜在故障，实现故障源精准定位，优化运行策略，提高运维效率。\n例如，中国国家电网基于大量基础数据和评估模型，推出了AI辅助电力决策系统。${ }^{392}$ 该系统以配电网设备评估标准为依据，整合静态设备参数与动态运行数据，建立全面评估框架，实现对站内或线路主设备的评估，从而为站点巡检、运行和维护策略提供智能决策支持。中国南方电网开发了多模态电力模型“Big Watt”，利用AI技术分析电网运行信息、用户负荷、天气预报和终端检测等多源数据，提供详细的电力系统运行维护分析与预测信息。${ }^{393}$ 该大模型能够识别配电电网中的典型缺陷隐患，在突发事件和意外情况下快速准确地给出响应建议，大幅提升电网和系统的韧性与适应性。此外，ABB Ability数据平台结合云计算、大数据和5G等技术，构建了信息交叉赋能电力辅助系统，实现电力设备的故障分析与远程诊断，提高电力系统智能运维效率。${ }^{394}$ 瑞士Alpiq公司推出的Grid Sense系统，利用AI技术分析电力系统的负载、电网故障和电力检测，紧密结合先进信息技术与电力系统，解决了传统人工巡检存在的人力成本高、工作强度大和巡检效果差等问题。以上成功案例彰显了AI大模型智能决策能力在状态监测、故障预测等方面的强大功能，显著提升了电力系统的安全性与可靠性。\n随着AI技术的不断深化和普及，电力系统运行和能源管理的智能决策辅助技术正朝着精细化、实时化和协同化方向发展。最新进展表明，未来电力系统将紧密依赖AI大模型对海量复杂数据进行深度融合与智能分析，从而实现运行维护效率与电网韧性的双重提升。预计大模型将在推动电力系统向更智能、可靠和绿色方向发展中发挥重要作用。\n挑战与展望。\n数据质量与数据可用性： 在计算机与信息科学领域，特别是工业系统与下一代通信领域，数据（如设备故障记录、传感器测量、网络延迟${ }^{396,397}$）常常难以获取且含大量噪声${ }^{398}$、缺失值或时间戳错误。此外，下一代通信中的现有数据集通常体量不足且任务特异，因现有数据多为特定任务（如流量预测或网络优化）构建，缺乏对通信网络复杂场景的全面覆盖。FM训练严重依赖大规模、多样化数据，这给上述领域带来挑战。数据稀缺、低质量和任务特异性极大限制了工业系统和下一代通信中模型的训练和应用。因此，关键挑战之一是如何利用生成型FM（如合成数据生成技术）进行数据扩充，或采用少样本学习方法（如迁移学习和元学习）实现有限数据下的高效学习。 部署问题： 工业机器人和下一代通信领域中，平台资源通常有限，尤其是边缘设备或移动终端。FM部署通常需要强大计算硬件，尤其是GPU或TPU集群，在资源受限环境下部署成为难题。此外，工业运营和下一代通信网络要求实时或近实时数据处理能力，对模型推理速度提出更高要求。因此，有效压缩FM模型（如剪枝和量化）和优化低延迟推理是实际应用中的关键挑战。 4.2 数学科学 基础模型（FM）利用大规模预训练，从多样化数据集中提取通用的数学模式，从而为传统问题如优化、统计推断和模式识别提供新颖的方法。${ }^{36,399}$ 它们的有效性源自核心数学原理：线性代数通过矩阵运算和高维变换构建神经网络结构；${ }^{400,401}$ 微积分支持基于梯度的优化和概率积分；${ }^{402,403}$ 概率统计通过贝叶斯推断和假设检验支撑不确定性量化。${ }^{404,405}$ 这些数学基础不仅促进了基础模型的发展，同时也从基础模型带来的洞见中受益——形成理论进展指导模型架构，模型表现揭示新数学问题的良性循环。我们将系统性地考察这一互动，通过基础模型的模型架构与训练、优化技术、应用及挑战四个方面展开。\n模型架构与训练。 理解基础模型的架构选择和训练范式，对发挥其在数学科学领域处理复杂结构和提取有意义模式的潜力至关重要。神经网络由相互连接的神经元层组成，${ }^{406}$ 提供了逼近非线性和高维函数的灵活且强大的框架。\n在神经网络框架内，专用架构如卷积神经网络（CNN）、循环神经网络（RNN）和前馈神经网络针对特定数据结构和问题领域设计。CNN善于处理类似网格的数据结构，提取局部特征，是图像分析或空间数据处理等任务不可或缺的工具。RNN设计用于序列数据，捕获时间依赖性并揭示跨时步的模式，尽管其长程依赖常因梯度消失面临挑战。${ }^{407}$ 前馈网络作为最简单变体，在处理静态输入输出映射问题时表现出高度效率，体现了神经网络架构的多样性。${ }^{408}$ 相比之下，Transformer通过解决传统序列模型（如RNN）限制革新了基础模型领域。${ }^{409}$ Transformer的核心是自注意力机制，使其能够并行处理整个序列，高效捕获长距离依赖并具备良好扩展性。${ }^{410,411}$ 这一创新在数学科学中价值非凡，Transformer擅长解析符号数据、求解复杂方程以及识别大型数据集中复杂模式，其精准处理多样任务的能力使其成为推进计算方法的基石。${ }^{412}$\n优化技术。 优化在基础模型开发中同样重要，决定了模型学习与泛化的效率。优化技术通过最小化损失函数来调整模型参数，是促使模型收敛和提升性能的关键。随机梯度下降（SGD）${ }^{413}$ 作为基础方法，采用数据的随机子集逐步更新参数，平衡计算效率与学习稳定性。${ }^{414}$ 在此基础上，自适应矩估计（Adam）引入自适应学习率和动量，加速收敛、提升高维空间性能。${ }^{415}$ 更高级算法如二阶方法和梯度裁剪技术应对梯度消失与爆炸问题，增强优化过程的稳定性和精确度。在数学科学背景下，优化需更高的精度与稳定性，因为数值计算通常涉及求解方程或分析多维数据，要求严格。针对这些独特需求微调优化算法，研究者可释放基础模型的全部潜力，解决更复杂的问题，推动数学研究的边界。通过稳健架构与先进训练技术的无缝融合，基础模型持续变革我们解决数学科学问题的方式。\n应用。 基础模型正在革新科学应用，在数学建模与仿真、应用科学、符号数学及不确定性决策等方面带来变革性进展。\n在数学建模与仿真领域，基础模型通过数据驱动方法优化流程，特别是在传统解析方法难以应对的领域。${ }^{417}$ 例如，物理信息神经网络（PINNs）被广泛用于通过将物理定律直接融入神经网络架构，解决流体动力学和气候建模中的复杂非线性偏微分方程。图神经网络（GNN）通过捕获交通网络的空间依赖性和动态特征，模拟交通流。${ }^{418}$ 在应用科学中，基础模型提升了对复杂系统的理解，如气候动态和材料科学。CNN分析卫星影像等气候数据以预测天气模式，RNN建模材料性能的时间演变，助力新材料的发现。${ }^{419,420}$ 这些数据驱动模型补充了传统框架，弥合了理论与经验观察的差距。${ }^{421}$ 在符号数学方面，基础模型通过符号积分和定理证明等任务复制并扩展人类推理。基于Transformer的架构，如DeepMind的AlphaTensor，通过学习数学表达式结构实现复杂符号操作自动化。${ }^{422,423}$ 此外，基础模型在不确定性决策方面表现突出，这在流行病学和金融等领域至关重要。贝叶斯神经网络（BNN）提供疾病传播的概率推理，强化学习（RL）优化不确定市场环境下的交易策略。${ }^{424,425}$\n挑战与展望。 尽管基础模型具备变革性应用潜力，但其仍面临显著限制，尤其是计算需求和可解释性问题。训练和部署这类模型需庞大的计算资源，包括高性能计算设施和大量内存。随着模型规模和复杂度呈指数增长，资源需求成为研究机构的重要门槛。此外，基础模型“黑箱”特性使其决策过程难以解释，尤其是在涉及复杂数学推理与验证的任务中。这一点在金融、医疗等高风险领域尤为关键，信任、透明度和问责制不可或缺，理解模型推理至关重要。${ }^{426}$ 从复杂架构中挖掘模型输出的理据仍是深刻且持续的挑战，凸显了提升可解释性和可用性创新方法的必要性。${ }^{427}$\n4.3 生命科学 生命科学致力于探索生物活动的本质及其发展规律。近年来，人工智能技术显著推动了生命科学的应用，尤其是在药物设计、合成生物学和健康干预等领域（见图7）。随着基于基础模型（FM）的技术进步，生命科学在分析精度、预测能力和智能决策方面有望实现质的飞跃。\n新药设计与决策。 人工智能技术的快速发展催生了具有海量参数的大型模型，代表性系统如ChatGPT和AlphaFold。在新药设计领域，研究者利用大型模型技术设计了多种具有显著生物活性的药物分子，包括小分子、大环、肽、蛋白质及核酸。利用大型语言模型（LLM），这些模型不仅自主学习序列特征，还能快速生成配体小分子。例如，混合生成化学语言模型（CLM）在设计PI3Kγ配体方面表现出亚微摩尔至纳摩尔的活性，并展示了骨架跳跃潜力。${ }^{428}$ 此外，基于LLM的方法可生成候选生物活性肽。Chen等人设计了无毒副作用的新型生物活性肽序列。${ }^{429}$ 尽管LLM方法高效且精准地生成生物分子序列，但仍面临数据依赖性和可解释性挑战。受AlphaFold蛋白质结构预测的启发，基于深度学习的基础模型能准确设计和预测大环肽结构。Rettie等人提出“环化编码”作为位置编码，以基于序列信息预测天然环肽结构，拓展了大环药物分子的结构空间。${ }^{430}$\n除了利用预训练的基础模型，另一种方法是应用标准强化学习（RL）代理优化药物分子的从头设计。David Baker团队提出了利用蒙特卡洛树搜索的RL方法设计蛋白纳米材料，克服了从碎片构建蛋白的自下而上方法无法解决的挑战。${ }^{431}$ 由于蛋白质结构空间的爆炸性增长，深度强化学习（DRL）方法高度依赖计算预测，通过策略网络和值网络的优化，有望提升效率和应用范围。例如，Frederic等人训练了基于DRL的策略型基础模型，结合神经架构搜索、超参数调优及序贯决策过程的联合优化，设计RNA药物分子。${ }^{432}$ 总之，作为前沿先进的技术手段，AI智能决策模型已广泛应用于新药研发过程中的科学问题和技术挑战。\n合成生物学规划与工程。 随着AI与生物学的深度融合，合成生物学领域迅速发展。例如，AI与植物合成生物技术结合，催生了颠覆性且可持续的农业应用。${ }^{25}$ 通过训练先进的基础模型，传统的生物合成周期被转化为多维的“设计-构建-测试-学习-预测”工作流程，${ }^{25}$ 提高了合成效率并降低了成本。近期AI辅助的合成生物学进展聚焦于基因组注释、蛋白质工程、代谢途径预测和合成路线规划等关键领域。例如，Zhou等人提出了结合元迁移学习、排序和参数微调的少样本学习方法，优化多种蛋白语言模型，在极度数据稀缺条件下提升预测性能。${ }^{26}$ 尽管该方法通过聚合酶湿实验验证有效，但蛋白质LLM的优化仍受数据分布影响显著，表明需进一步完善。\n此外，针对耗时的生物合成过程，AI模型可分析并规划合成路线，优化反应条件，最终找到更快更高效的合成路径，有效缩短生物化学合成周期。例如，Vaucher等人从自然语言处理角度出发，利用定制规则的NLP模型将化学反应规则构建视为文本提取问题。${ }^{27}$ 虽然该方法预测准确且易解释，但需大量计算资源且在基础模型中泛化性较差。传统优化生物合成反应条件的方法依赖化学家手工枚举所有可能组合并独立决策，既耗时又昂贵。优化生物合成反应条件是实现AI辅助化学合成的关键步骤。例如，Zhou等人将强化学习与化学知识结合，迭代记录化学反应结果并选择新反应条件，以提升结果，实现优化化学反应的动态交互决策过程。${ }^{28}$ AI必将成为提升合成反应条件的有力工具。\n生命健康干预与管理。 利用基础模型强大的数据处理、预测与自适应学习能力，可制定更科学、精细的生命与健康干预方案，提高干预效果，降低医疗成本，促进健康管理普及。尤其是AI在精准营养领域的应用带来深远变革。基于自然语言处理的基础模型不仅能提取和预测饮食模式，${ }^{433}$ 还能提供可解释的饮食相关疾病预测，探索饮食模式与代谢健康结果间的关系，证明NLP方法在提升疾病预测模型中的有效性。${ }^{59}$ 基于NLP的基础模型构建了分子水平的营养分析与饮食推荐模型，根据遗传、环境和生活方式等因素为个体提供定制化、精准的饮食建议。${ }^{71}$\n通过构建高效模型，强化学习能动态平衡多重目标，提升食物的感官属性和营养价值。Amiri等人提出结合协同过滤与用户评分、偏好和营养数据的多层次实时奖励机制。${ }^{69}$ 该算法不仅兼顾营养与健康因素，还能动态适应用户潜在饮食习惯，大幅提升用户接受度和依从性。此外，传统饮食推荐方法通常基于用户历史偏好推荐食物，但难以满足实时健康需求。Liu等人利用强化学习的连续决策和交互能力，结合协同过滤算法，开发出自适应饮食决策模型。${ }^{434}$ 该模型不仅满足营养与健康要求，还动态调整用户口味偏好和个人满意度。强化学习技术能通过反馈机制迭代优化食谱配方，实现对不断变化的消费者需求的响应。尽管强化学习在餐饮推荐领域取得一定成功，但仍存在显著不足。现有文献往往仅将食物成分归类，未充分考虑食物组成及饮食结构对健康的具体影响。此外，个体遗传数据常被忽视，导致健康特征评估不全面。未来研究应将季节变化、特定场合和原料供应等动态因素纳入餐饮推荐方案。通过整合知识图谱，可更动态地展现用户偏好，提升饮食推荐算法的泛化能力和效果。\n挑战与展望。 智能决策模型在生命科学中的应用，尤其是在药物开发、合成生物学和健康干预方面，正推动革命性变革。然而，这些进展也面临数据、算法、伦理和法律等多方面挑战，主要体现在以下三点：（1）数据挑战：相较于基础模型所需的大规模数据，生命科学数据规模相对较小，且常含噪声和缺失值，影响智能决策模型的准确性。未来可通过数据增强与预处理、多源数据融合及敏感性分析等方法解决此类数据问题；（2）大模型预训练数据稀缺：生物医药数据（如化合物、靶点、分子相互作用、临床试验数据）稀缺且难以获得，给大模型预训练带来巨大挑战。未来可结合跨域迁移学习、少样本学习和自监督学习等技术，从有限数据中提取有价值信息，最大化模型泛化和性能；（3）健康干预中的隐私与合规：健康干预领域需大量包含敏感信息的个人健康数据。确保数据隐私保护及合规性是一大挑战。未来生命科学中的智能决策模型可通过数据匿名化、差分隐私、联邦学习、加密技术及法律伦理标准的综合策略保障数据安全与合规，最大限度降低隐私泄露与误用风险。\n4.4 医疗健康 医学是人类进步与福祉的基石。基础模型（FM）如今为早期疾病筛查、手术规划等复杂任务提供了高效且智能的决策支持，能够实现文本、影像与基因组数据的统一解决方案，且对任务特定数据需求极低。${ }^{435,165,436}$ 以下内容讨论了基础模型如何在诊断、医学影像等多领域重塑医疗健康。\n通过多模态和基因组数据整合推进诊断。 基础模型通过结合丰富的医学知识与先进推理能力，在临床诊断中展现出巨大潜力。大型语言模型（LLM）如GPT-4在医学问答和病例分析等任务中表现出近乎专家的水平。${ }^{437,438,439}$ 多次评估表明，基于LLM的决策支持系统在专科诊断环境中与临床医生不相上下甚至更优，凸显其多功能性及广泛应用潜力。${ }^{440}$\n尽管取得进展，可靠性挑战依然存在。例如，部分知名模型偶尔会输出事实错误的回答，凸显诊断流程中人工监管的重要性。基于检索的增强方法为输出结果提供可信依据，有效降低错误率并提升模型可信度。${ }^{441,442}$ 此外，多模态模型现已融合文本与实时影像或视频，实现更全面的诊断。这对外科病理和视网膜影像等领域尤为重要，能够借助多数据流的上下文线索提升诊断准确度。${ }^{443,444}$\n除了文本和影像，基础模型还拓展至波形数据、放射学和组织病理学数据的诊断应用。例如，已有基础模型用于基于心电图（ECG）数据诊断心血管疾病。${ }^{445}$ MedSAM在通用分割领域表现优异，能准确识别多模态的解剖区域和病变，${ }^{446}$ 视觉语言模型可生成合成放射影像，用于资源受限场景的数据增强。${ }^{447}$ 肿瘤学领域中，MUSK等模型结合病理图像和患者数据识别分子生物标志物、评估治疗反应，从而提升诊断特异性。${ }^{448}$ 大规模组织病理学应用能够精准分类常见与罕见癌症，且适应不同染色协议。${ }^{449,450}$\n此外，新兴的基因组和多组学基础模型进一步扩展了诊断能力。${ }^{451}$ Nucleotide Transformer捕获DNA序列的有意义表示，适用于低数据环境下的特定变异检测，${ }^{452}$ scGPT结合单细胞转录组和蛋白质组数据用于细胞类型识别。${ }^{453}$ GET利用染色质可及性数据揭示与疾病状态相关的未知调控元素。${ }^{454}$ 基因组基础模型${ }^{455}$提升了基于DNA序列的个性化基因表达预测。以上成果展现了大模型在诊断中的协同效应，借助多模态数据提高诊断准确性，减轻临床负担。\n优化治疗策略与药物管理。 基础模型在引导治疗策略中作用日益显著。通过提炼广泛的临床数据，这些系统可辅助选择治疗方案、管理药物及处理复杂医疗决策。例如，近期研究强调LLM通过关联基因组数据与标准化治疗方案，为肿瘤科医生生成可行指导的实用价值。${ }^{440,438}$\n在手术等高风险环境中，集成的大型多模态模型通过解析文本记录、影像乃至实时手术视频，提供患者状态的全貌。${ }^{443}$ 这种整体视角有助于提高手术中决策的准确性，但仍需严格的领域特定验证以保障患者安全。肿瘤学尤其受益于视觉语言方法，如MUSK结合影像证据与患者历史，提供更精准的治疗方案。${ }^{448}$\n治疗支持还涵盖药物基因组学和靶向治疗，多组学基础模型能够预测药物疗效与毒副作用风险。${ }^{453,454}$ 通过整合基因变异到蛋白组特征等多种数据，这些模型能发现传统孤立系统难以捕捉的个体化治疗路径。尽管应用初见成效，仍需通过真实世界验证不断完善，以确保模型安全有效部署。\n提升个性化预后预测和治疗反应。 预后评估是基础模型影响力日益增长的另一重要领域。其融合影像、病理及多组学数据的能力，使临床结果预测更为细致，如生存率和复发风险。肿瘤学中，LLM不仅提供具体诊断见解，还能预测疾病进展时间线，指导医生与患者讨论治疗目标及临终关怀。${ }^{440}$\n多模态方法加强预后建模，综合影像特征、遗传信息和电子健康记录。视觉语言系统由诊断转向治疗反应风险评估，揭示靶向疗法的成功可能性。${ }^{446,447}$ 多组学模型如GET精准预测基因表达变化，为疾病轨迹及干预点提供线索。${ }^{454}$ 这些能力亦可扩展至更广泛的群体健康问题，包括公共健康监测和慢性病风险分层。\n此外，基于大规模临床文本训练的LLM有助预测住院时长、再入院率及并发症概率。${ }^{456,457}$ 通过将纵向临床数据与患者历史关联，模型能识别出预后较差的高风险患者。与诊断和治疗一样，模型在真实世界的稳健表现依赖于针对数据偏移和潜在偏见的细致校准，需持续监督和验证。\n借助基础模型优化临床工作流程和资源管理。 高效的临床流程管理与自动化是现代医疗的重中之重，行政负担常常影响患者护理质量。基础模型擅长患者数据摘要、文档自动化及关键临床概念标记。例如，GatorTron通过大规模临床语料训练，在医学问答和语义相似度任务上达到了先进水平，体现了规模优势在减轻重复性文档工作中的价值。${ }^{458}$\n除了信息提取，领域微调的LLM还能高精度完成分类任务，如肌肉骨骼疼痛的分类，从而简化分诊和转诊流程。${ }^{459}$ 这些模型亦能生成患者记录、病理报告及影像检查的简明临床摘要，其摘要质量在部分指标上可媲美甚至优于人类专家。${ }^{460}$\n资源管理是另一重要应用领域。大模型在预测医院运营指标方面表现出色，包括再入院率、住院时长和护理质量指标。${ }^{456,457}$ 通过自动整合来自不同渠道的患者数据，这些系统能实现更主动的排班优化、床位分配及支持成本效益的医疗服务。尽管自动化优势明显，数据隐私、模型可解释性及公平性问题仍需成为临床应用的关注重点。\n挑战与展望。 尽管潜力巨大，基础模型在医疗领域的应用仍面临诸多实施障碍。伦理问题主要源于训练数据的偏见——特别是模型多以西方数据为主，可能导致其他人口群体或地区的结果欠佳或不公平。${ }^{461,462}$ 临床可靠性同样是难题，标准化评测表现优异的模型，在现实多变的临床实践中并非总能无缝适用。${ }^{463,464}$\n监管因素增加了复杂性，医疗机构、临床医生及AI开发者需面对不断变化的责任风险。虽然AI辅助系统可能降低个体医生的法律风险，制造商和组织则需应对不确定的监管框架及创新AI解决方案的报销模式。${ }^{465}$ 未来发展需透明模型架构、持续多样化训练数据以及强调安全与问责的人机协作指南。${ }^{466}$ 持续的临床评估，包括自动专家评价和前瞻性试验，对于验证诊断和治疗效果至关重要。${ }^{467}$ 通过这些努力，基础模型能够强化——而非取代——临床医生的专业知识，提供可扩展的数据驱动见解，提升患者疗效，同时遵循严格的医疗护理标准。\n4.5 口腔医学 基于医疗健康数据训练的人工智能（AI）模型在疾病诊断、治疗规划和健康管理方面展现出显著潜力，尤其是在口腔医学领域。在这一领域，基础模型（FM）和智能决策系统有望通过提升精准诊断、优化治疗策略及改善患者疗效，变革临床工作流程。本文将探讨基础模型及智能决策系统在牙科实践中的机遇、现有应用、关键挑战与未来发展方向。\n口腔医疗中基础模型与智能决策的基本原理。 通用的医疗健康基础模型（HFM）能够灵活应用于多种医疗任务，处理多模态医疗数据。与专注于特定医疗任务或数据模态的传统专用AI模型不同，医疗基础模型在语言、视觉、生物信息学和多模态等相关医疗AI子领域表现出卓越成功。${ }^{468}$ FM在学习了大量医学语言数据后，在医学文本处理和讨论任务中表现优异。${ }^{437,469}$ 视觉基础模型（VFM）在医学图像处理上显示出极大潜力。不同模态、器官、任务及特定VFM均展现了其在多种医疗情境下的通用性和灵活性。${ }^{470}$ 生物信息学基础模型（BFM）则为蛋白质序列、DNA、RNA及其他元素的分析提供了机会。${ }^{471,472}$ 多模态基础模型（MFM）通过融合多种数据模态，实现了对不同医疗模态的解读及基于多模态的任务执行，效率更高。${ }^{165,473}$ 因此，这些模型为解决复杂临床问题提供了基础，提升了医疗及牙科操作的效率和效能，涵盖自由文本或护士记录、电子健康档案、报告、放射影像、实验室检测、牙科影像、审计、数字扫描信息、整合基因组数据及临床研究档案等。${ }^{474}$ 在医疗决策中，临床医生会综合考虑患者的既往及现病史、当前可用的医学文献证据，以及其专业能力和经验。${ }^{475}$\n基础模型在牙科诊断与预后中的进展。 医学诊断对于预防疾病进展和改善治疗效果至关重要。基于FM的医学诊断能够根据医学检查及患者陈述预测最可能的疾病，有助于及时治疗和避免不良后果。${ }^{476}$ 近年来，FM已被用于提升医学诊断，展现出在包括牙科问题在内的多种疾病上的通用能力。${ }^{477,478,479}$ 一项研究评估了ChatGPT-4在口腔外科领域作为智能虚拟助理的能力。一位专业口腔外科医生对ChatGPT-4回答的30个口腔外科相关问题进行了评估，发现存在差异，准确率为71.7%。${ }^{480}$ 该结果凸显ChatGPT-4作为牙科临床决策辅助工具的作用，同时强调其无法取代熟练口腔外科医生的专业水平。VFM可对选定的低风险影像自动进行疾病筛查，辅助检测和识别模糊的靶解剖结构，减轻放射科医师负担并提升诊断准确率。传统龋齿诊断主要依赖牙医的视觉和触觉检查。治疗策略前，需迅速而全面地评估口腔健康状况。牙科疾病诊断往往耗费专家大量时间和精力，有时需借助X光扫描和CBCT以做出有效判断。多项研究探讨了AI辅助模型在诊断龋齿、牙周炎、药物相关骨坏死、颌面骨折、口腔鳞状细胞癌及颞下颌关节疾病等方面的有效性。${ }^{481,482,483,484,485,486}$ 这些疾病可通过医学影像识别。VFM的分割与识别为医学影像中的定位提供信息，帮助放射科医师将图像划分为语义区域并识别关注区域。${ }^{487,488}$\n部分VFM在疾病预后方面表现出良好成果，能够提供生物标志物预测疾病概率或预期进展。例如，Tooth GenAI通过支持向量回归模型，评估患者数据，预测牙周炎等疾病的牙骨流失，帮助早期干预，预测三个月及六个月的骨流失情况。模型利用用户提供的个人数据进行预测，并配合图示支持治疗设计及疾病过程追踪。${ }^{489}$\n通过基础模型推进个性化治疗规划。 FM通常提供即插即用的医学图像处理工具，无需额外采集数据或训练模型，即可用于手术规划或辅助，这是一种传统范式，在外科领域具潜在应用。随着数字牙科的发展，个性化治疗规划成为提升患者疗效的关键策略。HFM能协助制定个体化方案。外科医生可借助三维分割VFM，从CT及MRI等医学影像中区分三维结构以进行手术规划。分割VFM还能识别手术过程中内窥镜视野中的器械或相关区域，有助提高手术效果。${ }^{490}$\n在牙种植设计与植入规划中，AI可基于患者CBCT数据自动生成最优植入设计与方案，综合考虑骨密度、邻牙位置和咬合关系等因素，从而提升种植成功率。${ }^{491,492}$ AI的主要应用在于解剖标志物的分割，这也是构建虚拟患者的重要步骤。虚拟植入仍需开发并科学验证全自动数字化方案。${ }^{493}$ 在正畸治疗计划中，是否需要颌骨手术是另一个关键决策。不同医生对是否需做颌骨手术意见不一，${ }^{494}$ 且缺乏统一标准判定手术必要性。但已有方法尝试通过AI算法辅助临床医生。${ }^{495,496}$ Choi等人报告AI不仅能预测颌骨手术指征，还能以约91%的成功率预测拔除前磨牙的指征。${ }^{497}$ 这类创新无疑将帮助外科医生和牙科专家更顺利完成可预测、及时的术前规划阶段。\n牙科中的智能决策技术。 随着数字时代的到来，智能决策技术的整合逐渐显示出显著优势，现已广泛应用于正畸学、活动局部义齿设计、复杂颌面重建术后预后预测等多个领域。${ }^{498,499}$ 近期，PUMCH疗法（光声蒸汽联合微创化学机械制备水动力封填治疗）为牙髓治疗带来创新理念。${ }^{500}$ 自动化牙髓器械的引入进一步拓展了该专科智能决策的范畴，提升治疗便利性和可预测性。\n随着临床数据积累与机器学习能力的提升，先进建模工具使临床医生能通过将牙齿形态与特定治疗参数对齐来优化治疗方案，推动更具证据支持、以患者为中心的决策。${ }^{501}$ 此外，这些建模系统增强了术后抗力损失的预测能力，助力长期疗效评估。工具集成还强化了临床医师与患者之间的沟通，促进更充分的治疗预期及长期效果讨论。${ }^{502}$ 此外，这些系统的预测功能支持早期干预策略，提升临床决策的精准度和时效性。\n挑战与展望。 HFM的训练需大量医疗数据，因此如何在确保隐私和安全的同时实现数据整合与共享，是亟需解决的伦理问题。医疗数据必须合乎伦理地获取。身体扫描能提供医疗数据，但CT成像可能对身体造成损伤。${ }^{503}$ 虽然这种损伤对疾病治疗可能较小，但将人体扫描用于AI训练数据集是违反伦理的。这类数据难以大规模获取，正如当前某些数据采集模式所见，限制了HFM任务的训练。此外，伦理还限制医疗数据的使用和分发。医疗健康数据包含敏感甚至危险的身体信息，包括基因数据。数据使用与分发受法律和数据所有者严格监管。未经规范积累和使用于基础模型训练存在安全风险。外部环境的不确定性也加大了HFM使用风险。${ }^{504,505,506}$\nHFM需跨多模态数据操作，${ }^{507}$ 然而，不同机构健康数据的来源多样，导致数据格式和质量存在显著差异。不同人群、地区和医疗机构的健康数据特征各异，实用中导致HFM数据异质性。${ }^{508}$ 基础模型的发展标志着从专用任务向通用任务的转变，使AI具备更广泛的能力，以应对现实世界中多样需求和复杂环境。FM亦具备革新医疗的潜力。先进的HFM能无缝分析多种数据模态，动态学习新任务，利用领域知识，在广泛医疗工作中展现前景。尽管潜力巨大，HFM模型仍面临明显挑战。其卓越的适应性增加了全面验证的难度，且规模庞大带来更高的计算成本。HFM为医疗提供了前所未有的机遇，助力临床医生完成多项关键任务，减轻临床工作负担，使其能有更多时间关注患者。\n4.6 城市科学 基础模型（FM）通过处理海量数据、识别模式并生成可操作的洞察，显著推动了城市科学中城市规划、政策制定和管理的各个方面的决策进展。${ }^{509}$ 以下介绍了它们在城市科学中从预测到决策的多种贡献方式，并配以相关文献或论文。\n基础模型提升城市预测建模能力。 FM赋能城市科学家以高精度预测城市事件，${ }^{510}$ 如交通拥堵、污染水平和能源需求。通过利用历史和实时数据，FM促进了短期和长期规划中的改进决策。近期文献表明，大型语言模型（LLM）可以作为零样本预测器应用于预测学习任务，${ }^{116,511}$ 尤其是在城市场景中。通过设计新型分词器和上下文学习技术，LLM在预测表现上优于传统统计方法如ARIMA。然而，由于LLM在解读复杂数值数据模式时面临挑战，研究人员探索了对LLM进行时间序列分析${ }^{512,120,513}$ 和城市时空预测的微调方法。${ }^{514,515}$ 主要策略包括微调LLM中的特定模块，如层归一化和位置编码，或训练额外神经层（如嵌入层和预测头）以更好地匹配下游应用。其他方法${ }^{516}$ 研究通过缩放和量化等技术将时间序列数据转换为固定词汇表，从而对序列值进行分词，支持在经过分词的序列上用交叉熵损失训练现有LLM架构。\n除了利用预训练的LLM，另一种方法是使用跨域城市数据（交通、能源、气候、空气污染等）从零开始训练基础模型。这一趋势由UniST模型${ }^{517}$体现，UniST是一种面向广泛城市场景的通用时空预测模型。其核心理念是利用多样化的城市时空数据进行有效预训练，以捕捉复杂的时空动态，并通过引入知识引导的提示增强下游应用的泛化能力。后续研究将类似方法扩展到更广泛的城市数据，如人类轨迹数据${ }^{518,519}$ 和遥感数据。${ }^{520,521}$\n基础模型融合多模态数据以加速城市科学的可解释透明决策。 FM在推动城市科学中决策的可解释性和透明性方面发挥了变革性作用。通过利用大量文本、数值和空间数据，LLM能够促进更明晰、数据驱动的决策，使专家和公众都更易理解。这些模型通过为复杂决策提供清晰解释，增强了透明度并提升公众信任。尤其是，FM支持高效且可访问的决策过程，无论是通过人机交互、参与式规划，还是评估/验证框架。\n举例说明第一类，交通信号灯控制应用中，LLM促成基于实时环境和交通模式的自适应数据驱动交通灯系统，优化交通流。${ }^{522}$ 该模型能分析传感器数据、天气条件和城市出行趋势，动态调整信号时序，旨在减少拥堵、提升交通安全。通过解释为何触发特定信号变化，LLM推动交通管理更透明。这种解释性确保城市规划者和公众理解交通控制措施背后的逻辑，增强对系统及其应变能力的信任。\n第二类中，FM作为模拟人类行为的代理，辅助城市决策。例如，在参与式城市规划中，这些模型整合城市规划、社区反馈和环境报告等多样数据源，以数据驱动且透明的方式指导决策。通过处理大规模公众输入，FM识别社区内的关键趋势、优先事项和关切，帮助规划者使城市发展符合公众需求。此外，FM生成易懂的规划决策解释，确保复杂政策向公众清晰传达。这种透明性赋能公民更有意义地参与规划过程，确信其声音被倾听、观点被考虑。近期研究${ }^{523}$提出一种创新的参与式城市规划方法，使用FM代理模拟多样化的规划者和居民角色。流程从规划者草拟初步土地利用方案开始，随后居民进行模拟讨论，根据其需求反馈意见。为提升讨论效率，采用“鱼缸机制”，允许部分居民参与对话，其他居民旁听。规划者据此调整方案，形成更包容、响应性强的规划过程。\n第三类中，FM利用自然语言理解和推理能力，对政策评估与验证贡献显著。它们辅助情境分析，提供简洁的政策摘要和相关文献检索，支持知情决策。${ }^{61}$ LLM支持场景模拟，生成假设性结果和利益相关方视角，预测社会反应。${ }^{13}$ 同时，它们分析调查或社交媒体中的公众情绪，使政策与舆论保持一致。验证阶段，FM识别逻辑矛盾，交叉比较政策最佳实践，评估包容性确保公平。通过揭示偏见和意外影响，支持公平政策制定。常规任务如文档解析、数据提取及评价报告撰写实现自动化，提高效率。${ }^{524}$ 通过促进迭代改进，LLM作为动态工具帮助优化政策、监控更新，确保政策过程的适应性和稳健性。${ }^{525}$\n挑战与展望。 FM在未来城市治理和决策中的应用将带来深远社会影响。FM为城市精准智能治理及去中心化可持续发展奠定坚实基础。例如，基于FM的智能交通系统有望实现城市交通状况的实时全面感知，并根据道路状况灵活控制交通信号，大幅缓解大都市区交通拥堵，从而显著降低汽车排放。基于FM的智能城市规划系统可显著减少专家知识偏见，为城市发展提供去中心化科学决策支持。此外，虚拟环境中的仿真实验有效避免了现实中因短视规划造成的不必要物资和能源浪费。总体而言，基于FM的应用将引领传统城市向智慧城市转型，显著减轻城市管理决策部门的工作负担，使其更专注于城市中的人文关怀。\n除了上述积极的社会影响，FM在城市中的应用也可能引发一些担忧。例如，强大FM应用需收集大量数据用于训练，其中包括城市区域的个人轨迹数据，这引发数据隐私问题。必须对数据进行匿名化和保护，以防大量个人隐私泄露。另一挑战是将FM技术与城市治理中的社会价值观对齐。大都市区复杂的人口结构导致基于性别、种族、收入等因素的多样化城市生活需求。这种多样性可能导致理论上的最优方案未必符合现实社会文化状况。因此，解决FM应用与社会价值观的对齐问题，对其在城市不同群体中的广泛采用至关重要。\n4.7 农业科学 农业是保障粮食安全、维护社会稳定和促进经济增长的基石。\n基于基础模型（FM）的智能决策为农民提供更明智的选择，优化资源配置，提升整体农场管理水平，有望通过提高生产力、可持续性和决策效能，彻底改变农业领域。\n基于FM的作物管理：洞察精准决策。 精准农业和智能农业的核心理念是利用高科技手段实现农业生产的精细化管理。${ }^{526}$ 人工智能正逐步改变传统农业的生产方式，提高农业的生产效率和可持续性。在此背景下，FM通过提供智能决策支持和优化资源配置，成为智慧作物管理的关键方法。${ }^{527}$ 结合农业遥感数据${ }^{528}$与地面传感器数据，FM在作物生长监测、精准农业技术以及病虫害监测与防控领域，通过精细调优模型展现出巨大潜力。\n具体而言，FM通过整合气象模式、土壤性质和遥感数据，实现作物生长状况的实时监测，从而及时识别潜在作物问题并提供调整方案。${ }^{529}$ 结合历史产量数据，FM还能准确预测作物产量，辅助农业规划和粮食安全保障。${ }^{530,531}$ 在精准农业技术中，FM能够准确分析天气和土壤数据，做出个性化施肥和灌溉决策。${ }^{532}$ 这种智能资源管理确保作物生长所需的养分和水分得到最优配给，避免过度施肥和灌溉。对于病虫害监测与防控，传统视觉方法通常依赖单一图像数据，受限于数据质量，难以有效支持病害传播预测和防控措施的决策。${ }^{533}$ FM凭借强大的多模态学习能力，能够快速识别作物病虫害的类型和严重程度，并提供针对性的防治建议。${ }^{534}$ FM在高效处理和理解多模态数据方面的优势，使其能够在复杂农业生产环境中进行全面分析和决策，促进智慧作物管理的进一步发展。FM的应用不仅优化了农业生产流程，还为农业的可持续发展提供了有力支持。${ }^{535}$\nFM赋能植物育种。 植物育种在作物改良中起着关键作用，其主要目标是选择性提升产量、抗病性和抗逆性等性状。${ }^{536}$ 传统植物育种依赖于表型选择和基因型分析，通常通过田间试验、育种和后代筛选完成。然而，该方法存在育种周期长、资源消耗高及环境因素复杂等限制，成为提高育种效率的瓶颈。基于此，结合AI领域最新进展，智能植物育种作为一种方法论应运而生，能够结合多维数据，利用人工智能、大数据和先进基因组学技术优化作物品种。${ }^{537}$ 然而，传统机器学习方法常常难以处理时空组学数据的复杂性。多模态基础模型（MFM）为此提供了有希望的解决方案。${ }^{538}$\n作为一类新型基础模型，MFM能够同时处理多种数据模态，如文本、图像、视频、音频及结构化数据（例如基因组序列或传感器数据）。${ }^{165}$ 这使得它们能够有效捕捉和分析基因型、表型与环境之间的相互作用。此外，MFM还支持跨模态任务，应用范围更广，例如从文本生成图像（如根据基因型描述生成预测作物表型图像）。该领域著名模型包括对比语言-图像预训练（CLIP）${ }^{14}$和引导式语言-图像预训练（BLIP）。${ }^{539}$ 通过高效处理异构数据集，MFM显著提升了表型预测的准确性，使育种者能够更精确地预测作物表现并优化性状选择，从而加快遗传增益。未来，MFM预计将在作物育种中发挥越来越关键的作用，改变农业创新格局。\n基于FM的现代畜牧业：从健康监测到全链路优化。 AI与FM技术的持续发展推动现代畜牧业迈向更高的智能化、精准化与高效化。${ }^{540,541}$ AI在畜牧业中的应用，尤其是在动物健康监测、疾病预测和资源配置优化方面，${ }^{542,543,544}$ 展现出巨大潜力。卷积神经网络（CNN）通过处理和分析动物图像及视频数据，实现对异常动物行为的检测与预警。图神经网络（GNN）将每只牲畜视为图中的一个节点，将它们之间的交互或传播路径视为边，有效捕捉复杂的关联结构，从而提高健康监测的准确性。通过提升管理效率和优化资源分配，AI显著助力降低生产和运营成本。目前，畜牧业中的深度学习决策模型多聚焦于特定场景，如基于体温、活动水平和食欲变化预测动物健康状况。${ }^{545}$ 然而，这些决策模型通常依赖人类专家知识和历史数据进行训练，限制了其应对跨学科知识整合和复杂数据挑战的能力。${ }^{546}$ 相较于传统模型，FM通过整合多学科知识和从大规模多模态数据中学习，有效解决了这些问题。${ }^{547}$ FM能够处理和整合来自不同领域的多维复杂信息，从而提供更准确、更全面的智能决策。FM不仅提升了畜牧业健康监测和疾病预测的准确度，也优化了资源配置，推动农业生产管理的精准化与智能化。因此，FM已成为当前智慧畜牧业中提升管理效率和优化资源配置的关键工具。\n挑战与展望。 未来十年，我们将持续见证新兴人工智能方法与物联网（IoT）技术的发展。这些进步将有助于实现最优决策，提升农业生产和管理的智能化水平。目前，我们在有效整合这些前沿技术进农业生产中面临诸多挑战，尤其是在跨学科系统解决方案以及农业低成本AI应用的实现方面。农业、计算机科学与环境科学等领域的跨学科融合仍存在技术壁垒。如何结合农业实际需求与AI技术，设计既高效又适应生产规律的智能系统，亟需大量创新与研究。同时，AI技术成本较高且小规模农业经济体的需求各异，低成本应用成为推动智慧农业的核心难题。为克服这些挑战，除了技术创新，还需开发更具成本效益的硬件设备和简化接口，并针对不同地区量身定制应用方案。政府政策支持、行业标准制定以及农业企业与科技公司的合作，也将在推动技术采纳和降低成本方面发挥关键作用。随着技术进步和成本下降，智慧农业将实现精准化、智能化和可持续发展，提升全球农业产业效率，促进粮食安全和农村经济的可持续增长。\n4.8 经济科学 在经济科学领域，基础模型融合异构的市场信号，实现更快速的风险评估、更精准的投资洞察以及更灵敏的合规监控，${ }^{548,549,550,551,552,553}$ 如图7所示。它们在资产类别和场景上的广泛泛化能力超越了基于规则的工具，推动了信用评分、普惠金融和战略决策的创新。\nFM赋能信用评估与普惠金融。 传统的信用评估往往依赖人工经验和线下数据采集，导致流程繁琐、信息不对称和覆盖范围有限。相比之下，基于FM的决策智能能够高效整合并语义分析大量异构数据源，如文本、图像、交易记录和社交媒体信息，从而构建更精准且动态的信用档案。${ }^{554}$ 凭借自动因子发现、生成式对话以及对借款人信用行为的持续监控等能力，基础模型帮助金融机构降低运营成本，加快贷款决策流程，并向小微企业及其他服务不足的客户群体提供定制化金融服务，提升了普惠金融的覆盖率和可及性。${ }^{555,556}$\nFM在投资决策支持和市场分析中的应用。 基础模型在证券投资和资产配置领域的应用日益增多。除传统的量化策略外，融入FM的决策智能促进了对多元信息来源的整合，包括宏观经济指标、行业报告、公司披露、市场新闻和情绪数据。通过先进的自然语言理解和多模态学习技术，基础模型能够更全面地描绘市场动态和风险特征。${ }^{557,558,559}$ 此外，生成式人工智能技术还能产生丰富的交易策略建议和预警信号，使分析师、投资组合经理和交易员能够更精准地优化资产配置和定价决策。${ }^{560}$\nFM在风险控制与监管技术中的应用。 加强风险防范和确保监管合规对于维护金融市场稳定至关重要。基础模型决策智能利用深度学习、基于图的知识表示和异常检测算法，提升了对异常交易、欺诈披露和非法融资活动的早期发现和实时监控能力。${ }^{561,562}$ 此外，监管机构能够借助基础模型实施“智能监管”，自动化合规检查、跟踪政策执行，并快速调整监管策略以应对行业新动态。${ }^{563}$ 新加坡金融管理局（MAS）、英国金融行为监管局（FCA）以及美国证券交易委员会（SEC）等国际机构均积极试验基础模型和人工智能驱动的监管技术，为完善国内监管框架提供了宝贵借鉴。\n4.9 教育科学 基础模型正在重塑教育科学，通过支持自适应辅导、数据驱动的学习分析及公平获取优质内容，${ }^{50}$ 如图7所示。其多模态推理和庞大的知识库助力个性化学习路径和实时反馈，显著提升学习者参与度和学习效果。\n个性化与自适应学习中的基础模型应用 基础模型在教育中的一大优势是实现个性化学习推荐。通过分析大量学生数据，如学习表现记录、互动历史和评估结果，这些模型能够推断个体学习者画像，推荐定制化的教学材料。例如，基于语言的基础模型可以根据学生当前水平动态调整阅读材料或题目，保持最佳挑战度，减少挫败感。${ }^{61,570}$ 此外，模型还能识别学生理解上的薄弱环节，主动提供针对性练习或解释内容，从而提高补救效率和知识保持率。\n基础模型支持差异化教学，满足不同学习风格和偏好。视觉学习者可借助模型生成的信息图或交互模拟，听觉学习者则可接收带解说的内容或播客。这种个性化确保教育内容对更广泛学生群体均具吸引力与可访问性，促进包容性教育。\n同时，基础模型提升了多语言和方言支持，跨越语言障碍，使非母语学生及多语言背景学习者能够访问教育资源。它们还能生成盲文、音频描述和手语翻译等多样内容格式，满足不同学生需求。${ }^{571}$ 基于基础模型的自适应技术提供定制学习路径和辅助工具，促进公平学习环境，使所有学生无论面对何种挑战均有成功机会。${ }^{572}$\n例如，最近的DeepSeek-v3模型可分析学生学习模式，提供实时反馈，实现个性化辅导。通过数据驱动评估识别学生知识盲点，模型调整内容传递和练习设计，促进教师的精准干预。此举不仅提升整体学习效率和参与度，也推动教育公平，满足个体需求。\n智能辅导与反馈系统中的基础模型 智能辅导系统（ITS）与自动反馈机制是另一关键应用领域。传统上，高质量个性化反馈规模化供给面临挑战。基础模型赋能的ITS能够提供更丰富、细致的指导，评估学生开放式问题回答，实时指出误区并提出替代解法。系统还基于决策智能判断反馈内容、时间和方式，最大化教学效果。${ }^{573}$\n基于基础模型的先进ITS能模拟一对一辅导，运用苏格拉底式提问和结构化学习，促进深度理解。例如数学教育中，系统引导学生攻克复杂问题，提供提示和反思，鼓励批判性思维与自我调节。自动评分系统不仅评估答案正确性，还考察推理过程，支持形成性评价。\n自动反馈覆盖多学科，实时个性化反馈帮助学生理解并改正错误，形成即时强化循环，提升学习效果和成绩保持率。${ }^{574}$\n教师与机构决策支持中的基础模型 基础模型在教育中的潜力还体现在辅助教师与教育管理者决策。基于大模型的智能系统可分析现有教材，发现知识覆盖不足，推荐补充资源；支持学生分班与风险预测，促使早期干预。${ }^{575,573}$\n它们还助力教师专业发展，提供个性化培训资源，识别提升领域，推荐循证教学策略。对于管理者，基础模型简化排课、资源分配与政策制定等运营任务，通过分析机构数据与预测趋势，提高管理效率。\n此外，基础模型促进教育者间协作，提供共享最佳实践、资源和创新教学方法的平台，推动教学和学习持续改进。\n挑战与展望 未来，基础模型在教育应用中具备巨大创新与研究潜力。发展重点包括提升模型的可解释性，使教师能理解并信赖AI推荐与反馈；集成多模态数据（行为分析、生物特征、上下文信息）以提供更全面支持。\n融合教育学、认知科学和人工智能的跨学科研究，将推动设计更先进、符合教育理论和最佳实践的AI系统。\n此外，缩小数字鸿沟、保障公平接入AI教育技术是实现基础模型社会效益最大化的关键。开发低成本、可扩展解决方案，提升师生数字素养，将促进技术的广泛应用和包容性普及。\n总之，基础模型融入教育环境将催生更自适应、包容且数据驱动的学习体系。借助其决策智能，教师与教育机构可显著提升教学质量、个性化服务及整体教育成效。然而，解决相关挑战和伦理问题是实现这些先进AI系统教育潜力的必要条件。\n5. 风险与挑战 5.1. 基于大型语言模型（LLM）代理的决策安全性 近年来，随着大型语言模型（LLM）的快速发展，基于LLM的代理技术逐渐渗透到决策领域。然而，现有研究${ }^{576,577,578}$揭示了LLM代理存在的安全问题，这些问题对决策过程带来了潜在风险，如图8所示。结合近期对基于LLM代理${ }^{576}$和智能算法安全性的调查${ }^{579}$，我们了解到基于LLM的决策框架通常包含多个组成部分：用户、预定义系统提示、记忆检索、外部环境（即一组工具集）等，因此潜在的脆弱性和安全威胁可能来自这些方面；另一方面，安全问题也可能源自LLM模型本身的内部。接下来，我们将分别从外部风险和内部风险两个方面揭示决策安全问题。\n图8：LLM代理中的风险与挑战。 左侧三张子图展示了算法层面基于内在脆弱性和交互环境的攻击与防护，如越狱、后门、模型审查等。中间展示了应用层面从不同学科视角的隐私风险，如成员推断攻击、信息茧房等。右侧展示了系统层面基于PoT和智能决策环境的LLM可信度和鲁棒性问题，如内容冲突幻觉、事实冲突幻觉等。\n来自LLM代理的外部风险。 在决策链过程中，LLM代理可能遭遇以下攻击： i) 提示注入攻击（Prompt Injection Attacks）：攻击者向原始提示注入特殊指令，操纵模型的理解，导致错误输出。${ }^{580,581,582}$ 此外，这类提示注入攻击还可能通过操纵可访问的外部环境（即各种辅助工具）破坏规划过程。${ }^{583,584}$ ii) 代理记忆中毒（Agent Memory Poisoning）：与传统深度学习训练中的数据中毒攻击不同，这里指的是向用于检索的数据库注入恶意或误导性数据，使代理生成不合理的决策规划或动作。${ }^{585,586}$ iii) LLM代理后门攻击（Backdoor Attacks on LLM Agent）：针对思维规划（Plan-of-Thought, PoT），攻击者先对部分规划示范进行中毒，包含带有后门的规划步骤和对抗目标动作，然后在查询提示中注入触发器。${ }^{587,588,589,590}$\n来自LLM的内部风险。 LLM自身也存在多种安全问题，可能导致决策失败： i) 越狱攻击（Jailbreak Attacks）：类似传统的对抗样本，通过特定的提示工程策略绕过LLM的安全防护，使其生成意料之外的内容。${ }^{591,592,593,594}$ ii) 模型审查（Model Interrogation）：一种针对LLM对齐问题的新威胁，与越狱攻击不同，模型审查无需精心设计提示，而是通过强制模型输出低概率词汇，迫使其泄露有害或未对齐的响应。攻击者需具备访问LLM每个输出位置的Top-k词汇预测的前提。${ }^{595}$ iii) LLM后门攻击（Backdoor Attacks on LLM）：类似传统深度学习中的后门风险，攻击者通过微调指令，秘密嵌入触发器至LLM模型中。${ }^{596,597,598,599}$ 这种隐蔽的后门攻击可使LLM生成符合攻击者意图的规划或行动响应，对决策者构成严重威胁。\n上述内外部风险均对决策过程构成严峻威胁。为促进LLM在决策中的实际应用，接下来我们将从两个角度介绍防御对策。\n基于LLM代理的防护措施。 由于决策任务通常包含多个推断规划/动作的阶段，因此对应多种防御策略： i) 定界符（Delimiters）：决策者可使用定界符封装查询，确保仅执行查询内容。${ }^{576}$ ii) 改写（Paraphrasing）：防御者可通过重新措辞查询，破坏恶意指令或触发器中的特殊字符序列。${ }^{600}$ iii) 打乱顺序（Shuffle）：针对PoT后门，随机打乱PoT示范流程。 iv) 记忆中毒检测（Memory-Poisoning Detection）：通过测量文本困惑度或使用LLM识别被破坏的记忆。${ }^{582}$\n针对LLM模型的防护。 鉴于LLM的复杂性，防护通常需要综合策略，我们总结了代表性防御机制： i) 无偏训练（Unbiased Training）：越狱攻击与对抗攻击具有相似性，${ }^{601}$ 一种有效防御是增强和平衡多模态模型的训练数据，甚至将恶意指令纳入联合训练。例如，对抗训练通过引入对抗样本作为训练数据，提高模型对抗攻击的鲁棒性。${ }^{602,603}$ ii) 系统提示增强（System Prompt Enhancement）：研究指出，较短的系统提示会增加攻击成功率，因此系统提示也需增强鲁棒性。${ }^{604}$ iii) 恶意内容过滤（Malicious-Content Filtration）：部分攻击绕过输入阶段的安全防护，但在输出阶段失败，因此决策链中需增加输出检测和恶意内容过滤措施。\n综上，基于LLM代理的决策体系现阶段较为复杂，其安全威胁既来自LLM本身，也源于其外部组件，这些风险在决策过程中可能带来严重后果。为促进LLM决策技术的实际应用，未来需要更加重视并投入更多精力解决相关安全问题。\n5.2. 机器幻觉的成因与缓解 幻觉现象早在大型语言模型（LLM）出现之前就已在自然语言处理（NLP）领域被发现，通常指模型生成与所提供源内容不符或无意义的回答。${ }^{605}$ 目前，鉴于LLM的多功能性，幻觉可大致分为三类${ }^{606}$： i) 输入冲突型幻觉（Input-Conflicting Hallucination），指生成的内容或回应与用户输入不一致。此类情况通常发生在LLM对任务指令理解产生误解时； ii) 上下文冲突型幻觉（Context-Conflicting Hallucination），指LLM产生的内容与其之前生成的内容相冲突。这种情况往往因LLM无法追踪上下文或在对话中保持一致性，可能源自长期记忆不足；${ }^{607}$ iii) 事实冲突型幻觉（Fact-Conflicting Hallucination），指LLM生成的内容与既有知识不符。此现象由LLM应用过程中多个阶段引入的多种原因造成。\nLLM产生幻觉的原因包括： i) 训练数据中含噪声（Noise-Contained Training Data）。众所周知，LLM目前在数万亿token上进行预训练，但其中部分数据来源于伪造、过时或带有偏见的信息。${ }^{608}$ 例如，研究指出LLM可能将与伪装相关的内容误解为事实知识。${ }^{609}$ McKenna等人${ }^{610}$发现幻觉现象与训练数据分布密切相关，且LLM偏向于训练数据中出现频率较高的样本； ii) 错误隐蔽性（Error Invisibility）。由于LLM存储了庞大的知识量，即使错误信息通常显得合理，也加大了减少输入冲突型和上下文冲突型幻觉的难度； iii) LLM过度自信（Over-Estimation of LLM）。Kadavath的实验${ }^{611}$报告LLM对正确答案和错误答案的置信度相当。Yin等${ }^{612}$调查了代表性LLM区分未知问题的能力，结果显示即使是先进的LLM，其表现仍不及人类。换言之，LLM对事实知识的理解超出了知识边界，即存在过度自信问题。\n针对幻觉问题，也存在多种缓解措施： i) 预训练语料的精心筛选（Curation of Pre-Training Corpora）。如前所述，噪声数据会损害LLM的知识质量，有效且直接的缓解方式是筛选预训练语料，确保训练数据可靠且真实。${ }^{613}$ 例如，目前的LLM尝试从可信来源采集数据，Llama 2对维基百科数据进行过采样； ii) 监督微调（Supervised Fine-Tuning, SFT）。SFT通常包括两步：首先对大量任务指令数据进行标注，然后利用最大似然估计对预训练LLM在标注数据上进行微调。同样，精心筛选的指令微调数据集也有效。与幻觉相关的基准TruthfulQA${ }^{614}$验证显示，在经过筛选的指令数据集上进行SFT能显著提升模型的真实性和事实准确性； iii) 解码策略设计（Decoding Strategy Designing, DSD）。DSD旨在确定如何从模型生成的概率分布中选择输出token。${ }^{615}$ Lee等${ }^{616}$提出“事实核采样（factual-nucleus sampling）”，结合“top-p”采样和贪婪解码，实现在多样性与事实性之间的合理平衡。Dhuliawala等${ }^{617}$开发了“链式验证（Chain-of-Verification）”解码框架以缓解幻觉。Li等${ }^{618}$提出推理时干预策略（Inference-Time Intervention）以提高LLM的真实性； iv) 不确定性估计（Uncertainty Estimation）。不确定性可作为判断何时信任LLM的标准，帮助用户过滤不确定的回答。目前提供三种不确定性估计视角${ }^{619}$，分别基于模型logit、语言表达和逻辑一致性。\n综上，以上内容阐明了幻觉产生的原因及相关缓解策略。鉴于幻觉可能发生于预训练、微调及推理阶段，决策生命周期中需要谨慎设计任务输入指令，辅以监督微调、解码策略和不确定性估计等措施。\n5.3. 数据隐私泄露 在深度学习领域，通常将数据集隐私攻击称为成员推断攻击（Membership Inference Attacks，MIA），即给定某条记录 $D$ 和基于训练数据集 $D_{train}$ 训练的深度学习模型，攻击者试图推断该记录 $D$ 是否属于训练数据集 $D_{train}$。在传统的MIA中，常用的方法是通过访问目标模型的黑箱反馈信息，重新训练一个替代模型${ }^{620}$，也称为影子模型。\n随着数据隐私攻击的快速发展，目前的LLM也面临类似的数据隐私泄露风险。例如，Carlini等人${ }^{621}$探讨了如何利用用于下一token预测的LSTM模型的对数困惑度（log-perplexity）推断训练数据中的敏感序列。随后，Carlini等人${ }^{621}$还提出了基于GPT-2（Transformer架构）结合困惑度查询和zlib熵进行数据提取的方法。此外，Mattern等人${ }^{622}$针对GPT-2提出了一种基于计算给定序列与邻近样本损失差异的邻域攻击方法。不同于此，Meeus等人近期针对拥有70亿参数以上的现代LLM提出了文档级别的MIA。迄今为止，关于数据集相关的隐私攻击研究仍然有限，部分原因是考虑到万亿token和数十亿参数的复杂性，生成替代模型的难度极大。然而，即便如此，在决策过程中，决策相关的训练数据集仍需防范各种成员推断攻击。\n5.4. 社会管理与价值对齐风险 LLM已在多个领域，特别是自然语言处理和计算机视觉中广泛应用。然而，价值观错配导致了对用户和社会的严重问题，如刻板印象${ }^{623}$、社会偏见${ }^{624}$、非法指令${ }^{625}$、道德判断${ }^{626}$等。为实现与人类价值观的对齐，目前已建立一系列基准，用于测试不同LLM并从多个角度纠正其不当行为。例如，FLAMES${ }^{627}$针对无害性原则及具有中国特色的和谐价值观开展测试；ALI-Agent${ }^{628}$利用LLM驱动的智能体自主能力进行刻板印象、道德和合法性适应性评估；Lee等人${ }^{629}$提出针对韩国社会价值观和常识的对齐基准；Fu等人${ }^{630}$研究文化遗产领域的错配问题。综上所述，LLM正渗透日常生活，同时也带来了越来越多社会管理和价值观方面的挑战。\n技术脆弱性。 随着信息技术和社交网络的发展，社会信息传播渠道和管理模式逐渐从传统的自上而下单一形式转向分散、灵活、多样化的模式。近年来，以LLM为代表的人工智能技术的出现，无疑极大地提升了信息传播的速度和广度，同时也增强了社会公共管理部门的行政效率。然而，LLM的快速发展也带来了诸多社会管理风险。首先，基于LLM的技术易大量生成欺骗性文本、图像乃至短视频，这些虚假信息通过发达的社交媒体网络迅速传播。尤其是扭曲或误解政策的虚假信息传播速度往往超过社会管理部门的响应速度，扰乱正常政策执行和社会秩序${ }^{631}$。其次，基于LLM和推荐系统的社交机器人加剧了“信息茧房”现象${ }^{632}$，通过强大的决策能力精准投放信息，锁定目标受众，通过重复交互逐步固化人的认知边界，成为煽动网络极端用户群体种族主义和政治极化的催化剂，进而将网络暴力扩散至线下抗议、示威甚至骚乱，引发社会动荡${ }^{633}$。\n监管空白。 此外，某些社会管理的伦理敏感领域，尤其是医疗健康领域，LLM存在诸多潜在风险。尽管诸如Med-PaLM${ }^{634}$的LLM在诊断准确率上已超过人类医生的八个临床维度中的九个，但其部署仍面临监管挑战。美国食品药品监督管理局（FDA）因LLM模型曾被发现无意中违反临床决策支持指南，迟迟不愿将其认证为医疗器械，凸显了对如欧盟人工智能法案等严格验证和透明度要求的监管机制与政策框架的紧迫需求。此外，LLM训练数据中的文化偏见进一步加剧了这些风险。比较分析表明，GPT-4在非西方医疗数据集上的诊断表现落后于西方中心的数据集，在资源匮乏环境中错误率提高了19%${ }^{635}$。总之，基于LLM的技术对未来社会管理带来一定风险与挑战，亟需填补监管机制和政策框架的空白，以促进LLM模型与主流价值观的对齐并主动防范潜在问题。\n价值对齐关注。 当前AI价值对齐方法大致可分为三类：来自人类反馈的强化学习、监督微调方法和推理时对齐${ }^{636}$。这些方法在对齐的可解释性和对齐目标的多样性方面仍面临诸多挑战。近期，微软亚洲研究院牵头的“价值罗盘”（Value Compass）项目从伦理学和社会学理论的跨学科视角出发${ }^{637}$，提出了基于基本人类价值理论的BaseAlign算法。BaseAlign基于社会心理学家Shalom H. Schwartz提出的多维人类基本价值构建了一个基本价值空间${ }^{638}$，将对齐的目标价值表示为该空间中的一个向量。然后，利用判别模型推导当前大模型行为对应的价值向量，通过最小化两向量之间的距离实现对齐。在一定程度上，BaseAlign增强了大模型价值对齐的可解释性和透明性，以及对不断演变的社会文化背景和变化的社会规范的适应能力。然而，尽管AI价值对齐技术取得进展，实现大模型真正的价值对齐仍有较大差距。挑战包括“对齐税”（alignment tax）问题，即价值对齐可能削弱大模型的原有能力，以及监督的可扩展性问题，特别是在未来AI能力和知识远超人类的情形下，需有效的监管与控制。\n因此，针对监管机制和政策，实施行业特定的合规框架、强制对LLM进行偏见审计，并开发跨文化的对齐与验证基准尤为重要。\n6. 结论 综上所述，本文全面回顾了智能决策（IDM）技术的发展，重点强调了其通过模型、优化算法和概率推理工具整合而演进的过程。文章聚焦于以基础模型（FM）为核心的决策范式，探讨了其在各领域变革智能决策的潜力。尽管基础模型为推动多样化应用中的智能决策提供了前所未有的机遇，但其在安全性、数据隐私和部署成本等方面也带来了显著挑战。\n未来智能决策的发展将聚焦于以下几个方面：首先，决策的可解释性和透明性。尽管诸如链式思维（Chain of Thought, CoT）等方法能够部分揭示大型模型的决策过程，但仍面临生成不稳定、粒度不可控以及与人类推理不一致等问题。因此，在军事、法律和医疗等高风险行业的智能决策应用中，亟需进一步研究以提升模型的可解释性并解决模型幻觉等问题。其次，跨学科智能决策需要深入探索。目前的智能决策方法大多基于通用模型或针对特定领域，但为了确保决策的合规性和经济可行性，往往需要融合法律、经济等多学科知识。因此，构建跨学科智能决策体系将成为未来研究的重要方向之一。最后，决策环境通常是动态变化的，现有模型的训练和部署方式难以使模型持续适应不断演变的决策环境。因此，研究模型在推理阶段自我进化和动态更新以应对环境变化，也是未来的关键探索领域。\n智能决策的本质在于实现决策过程的自动化。它对人类社会和科学进步具有深远意义，为更明智、高效和智能的解决方案铺平道路。展望未来，需持续努力解决现有挑战，深入挖掘其在新兴领域的潜力，促进智能决策整体发展及其对世界的积极影响。\n7. ACKNOWLEDGEMENT This work was partially supported by the National Natural Science Foundation of China under Grants No. (62372470, 72225011, 62402414, U23B2059, 62173034, 32222070, 62402017, 72421002, 62206303, 62476264, 62406312, 62102266,\n52173241, U23A20468), the National Key Research and Development Program of China (2023YFD1900604), the Strategic Priority Research Program of the Chinese Academy of Science (XDB0680301), the Youth Innovation Promotion Association CAS (2023112), the National High Level Hospital Clinical Research Funding (2022-PUMCH-A-014), the Beijing Natural Science Foundation (4244098), the Science and Technology Innovation Program of Hunan Province (2023RC3009), the Key Research and Development Program of Yunnan Province (202202AE090034), the MNR Key Laboratory for Geo- Environmental Monitoring of Greater Bay Area (GEMLab-2023001), the Science and Technology Innovation Key R\u0026D Program of Chongqing (CSTB2024TIAD-STX0024), the China National Postdoctoral Program for Innovative Talents (BX20240385), and River Talent Recruitment Program of Guangdong Province (2019ZT08X603).\n8. 作者贡献 J.H. 和 Y.X. 负责设计和组织本文综述。Q.W., Qi (Cheems) .W., T.L., X.L. 和 S.Q. 撰写了“引言”部分。Z.Z., Z.S., T.Q., T.S., B.D., Chuanguang.Y., Chengqing.Y., Y.W. 和 M.L. 撰写了“基础模型概述与发展”部分。X.L., W.W., H.Z., Y.Z., Zhicheng.Z., Zhengqiu.Z., Y.L., A.L., Xu.C., B.A. 和 X.Z. 撰写了“基于基础模型的决策范式与关键技术”部分。F.W., B.Z., L.H., J.C., L.M., T.M., Y.L., J.Z., Jian.G., X.J., W.X., C.B., Y.M., Z.Y., S.G., W.S., Yinghao.Z., Junyi.G., X.H., Y.L., G.J., X.A., X.Z., H.T., L.Y., H.S., J.L., E.H., V.M.L, Y.D, G.W., Yu.Z., Yuanzhuo.W., Jiafeng.G. 和 L.W. 撰写了“基础模型驱动的科学智能决策”部分。X.F., Qi (Cheems) .W. 和 G.J. 撰写了“大型模型智能决策的风险与挑战”部分。Z.A., C.F. 和 K.H. 撰写了“结论”部分。Xueqi.C., Yaonan.W., S.Y., M.F. 和 A.F. 对本文进行了指导和修改。\n9. DECLARATION OF INTERESTS The authors declare no competing interests.\nREFERENCES [1] David Hawkins. Theory of games and economic behavior. Philosophy of Science, 12(3):221-227, 1945.\n[2] Herbert A Simon and Chester Irving Barnard. Administrative behavior: A study of decisionmaking processes in administrative organization. Macmillan, 1947.\n[3] HA Simon. The new science of management decision, 1960.\n[4] Daniel Kahneman and Amos Tversky. Prospect theory: An analysis of decision under risk Econometrica, 47(2):263-292, 1979.\n[5] John Boyd. Destruction and creation. US Army Comand and General Staff College Leavenworth, WA, 1987.\n[6] Jatinder ND Gupta, Guisseppi A Forgionne, Manuel Mora T, Alexandre Gachet, and Pius Haettenschwiler. Develop- ment processes of intelligent decision-making support systems: review and perspective. Intelligent Decision-making Support Systems: Foundations, Applications and Challenges, pages 97-121, 2006.\n[7] Alejandro Agostini, Carme Torras, and Florentin Wo\"rgo\"tter. Efficient interactive decisionmaking framework for robotic applications. Artificial Intelligence, 247:187-212, 2017.\n[8] Lean Yu, Shouyang Wang, and Kin Keung Lai. An intelligent-agent-based fuzzy group decision making model for finan- cial multicriteria decision support: The case of credit scoring. European journal of operational research, 195(3):942-959, 2009.\n[9] Hui Yang, Erhun Kundakcioglu, Jing Li, Teresa Wu, J Ross Mitchell, Amy K Hara, William Pavlicek, Leland S Hu, Alvin C Silva, Christine M Zwart, et al. Healthcare intelligence: turning data into knowledge. IEEE Intelligent Systems, 29(3):54-68, 2014.\n[10] Richard S Sutton. Reinforcement learning: An introduction. A Bradford Book, 2018.\n[11] Volodymyr Mnih. Playing atari with deep reinforcement learning. arXiv preprint arXiv:1312.5602, 2013.\n[12] Ganesh Jawahar, Beno^1t Sagot, and Djame’ Seddah. What does bert learn about the structure of language? In ACL 2019-57th Annual Meeting of the Association for Computational Linguistics, 2019.\n[13] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023.\n[14] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language supervision. In International conference on machine learning, pages 8748-8763. PMLR, 2021.\n[15] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. A simple framework for contrastive learning of visual representations. In International conference on machine learning, pages 1597-1607. PMLR, 2020.\n[16] Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Dolla’r, and Ross Girshick. Masked autoencoders are scalable vision learners. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 16000-16009, 2022.\n[17] Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation of deep networks. In International conference on machine learning, pages 1126-1135. PMLR, 2017.\n[18] Jake Snell, Kevin Swersky, and Richard Zemel. Prototypical networks for few-shot learning. Advances in neural information processing systems, 30, 2017.\n[19] Qi Wang, Marco Federici, and Herke van Hoof. Bridge the inference gaps of neural processes via expectation maxi- mization. In The Eleventh International Conference on Learning Representations, 2023.\n[20] Bo Liu, Yihao Feng, Peter Stone, and Qiang Liu. Famo: Fast adaptive multitask optimization. Advances in Neural Information Processing Systems, 36, 2024.\n[21] Jiayi Shen, Xiantong Zhen, Qi Wang, and Marcel Worring. Episodic multi-task learning with heterogeneous neural processes. Advances in Neural Information Processing Systems, 36:7521475228, 2023.\n[22] Jiayi Shen, Cheems Wang, Zehao Xiao, Nanne Van Noord, and Marcel Worring. Go4align: Group optimization for multi-task alignment. arXiv preprint arXiv:2404.06486, 2024.\n[23] Brian Lester, Rami Al-Rfou, and Noah Constant. The power of scale for parameter-efficient prompt tuning. arXiv preprint arXiv:2104.08691, 2021.\n[24] Yuchen Yang, Yingdong Shi, Cheems Wang, Xiantong Zhen, Yuxuan Shi, and Jun Xu. Reducing fine-tuning memory overhead by approximate and memory-sharing backpropagation. arXiv preprint arXiv:2406.16282, 2024.\n[25] Zeyu Ma, Shiyu Wang, Xinyang Deng, and Wen Jiang. An improved approach for adversarial decision making under uncertainty based on simultaneous game. In 2018 Chinese Control And Decision Conference (CCDC), pages 2499-2503. IEEE, 2018.\n[26] Gerd Gigerenzer and Wolfgang Gaissmaier. Heuristic decision making. Annual review of psychology, 62(1):451-482, 2011.\n[27] Natalya Kireeva, Irina Pozdnyak, and Nikolay Filippov. Development of a decision-making algorithm for expert system in information security. In 2020 IEEE International Conference on Problems of Infocommunications. Science and Technology (PIC S\u0026T), pages 212-216. IEEE, 2020.\n[28] Liting Chen, Lu Wang, Hang Dong, Yali Du, Jie Yan, Fangkai Yang, Shuang Li, Pu Zhao, Si Qin, Saravan Rajmohan, et al. Introspective tips: Large language model for in-context decision making. arXiv preprint arXiv:2305.11598, 2023.\n[29] Marko Bohanec and V Rajkovic. Expert system for decision making. Sistemica, 1(1):145-157, 1990.\n[30] Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A Rusu, Joel Veness, Marc G Bellemare, Alex Graves, Martin Riedmiller, Andreas K Fidjeland, Georg Ostrovski, et al. Humanlevel control through deep reinforcement learning. nature, 518(7540):529-533, 2015.\n[31] Jianzhun Shao, Yun Qu, Chen Chen, Hongchang Zhang, and Xiangyang Ji. Counterfactual conservative q learning for offline multi-agent reinforcement learning. Advances in Neural Information Processing Systems, 36, 2024.\n[32] Elia Kaufmann, Leonard Bauersfeld, Antonio Loquercio, Matthias Mu\"ller, Vladlen Koltun, and Davide Scaramuzza. Champion-level drone racing using deep reinforcement learning. Nature, 620(7976):982-987, 2023.\n[33] Julian Schrittwieser, Ioannis Antonoglou, Thomas Hubert, Karen Simonyan, Laurent Sifre, Simon Schmitt, Arthur Guez, Edward Lockhart, Demis Hassabis, Thore Graepel, et al. Mastering atari, go, chess and shogi by planning with a learned model. Nature, 588(7839):604-609, 2020.\n[34] Sergey Levine, Aviral Kumar, George Tucker, and Justin Fu. Offline reinforcement learning: Tutorial, review, and perspectives on open problems. arXiv preprint arXiv:2005.01643, 2020.\n[35] Yixiu Mao, Hongchang Zhang, Chen Chen, Yi Xu, and Xiangyang Ji. Supported trust region optimization for offline reinforcement learning. In International Conference on Machine Learning, pages 23829-23851. PMLR, 2023.\n[36] Sherry Yang, Ofir Nachum, Yilun Du, Jason Wei, Pieter Abbeel, and Dale Schuurmans. Foundation models for decision making: Problems, methods, and opportunities. arXiv preprint arXiv:2303.04129, 2023.\n[37] Marc G. Bellemare, Will Dabney, and Rémi Munos. A distributional perspective on reinforcement learning. CoRR, abs/1707.06887, 2017.\n[38] S. V. Albrecht, F. Christianos, and L. Scha\"fer. Multi-Agent Reinforcement Learning: Foundations and Modern Ap- proaches. MIT Press, 2024.\n[39] Christian Schro\"der de Witt, Tarun Gupta, Denys Makoviichuk, Viktor Makoviychuk, Philip H. S. Torr, Mingfei Sun, and Shimon Whiteson. Is independent learning all you need in the starcraft multi-agent challenge? CoRR, abs/2011.09533, 2020.\n[40] Frans A. Oliehoek, Matthijs T. J. Spaan, and Nikos Vlassis. Optimal and approximate q-value functions for decentral- ized pomdps. J. Artif. Intell. Res., 32:289-353, 2008.\n[41] Landon Kraemer and Bikramjit Banerjee. Multi-agent reinforcement learning as a rehearsal for decentralized planning. Neurocomputing, 190:82-94, 2016.\n[42] Chao Yu, Akash Velu, Eugene Vinitsky, Jiaxuan Gao, Yu Wang, Alexandre Bayen, and Yi Wu. The surprising effective- ness of PPO in cooperative multi-agent games. In Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track, 2022.\n[43] Mengxian Li, Qi Wang, and Yongjun Xu. Gtde: Grouped training with decentralized execution for multi-agent actor- critic. In Thirty-Ninth AAAI Conference on Artificial Intelligence, 2025.\n[44] Jost Tobias Springenberg, Abbas Abdolmaleki, Jingwei Zhang, Oliver Groth, Michael Bloesch, Thomas Lampe, Phile- mon Brakel, Sarah Bechtle, Steven Kapturowski, Roland Hafner, et al. Offline actor-critic reinforcement learning scales to large models. arXiv preprint arXiv:2402.05546, 2024.\n[45] Qi Wang and Herke Van Hoof. Model-based meta reinforcement learning using graph structured surrogate models and amortized policy search. In International Conference on Machine Learning, pages 23055-23077. PMLR, 2022.\n[46] Fangchen Liu, Hao Liu, Aditya Grover, and Pieter Abbeel. Masked autoencoding for scalable and generalizable decision making. Advances in Neural Information Processing Systems, 35:1260812618, 2022.\n[47] Ramanan Sekar, Oleh Rybkin, Kostas Daniilidis, Pieter Abbeel, Danijar Hafner, and Deepak Pathak. Planning to explore via self-supervised world models. In International conference on machine learning, pages 8583-8592. PMLR, 2020.\n[48] Scott Reed, Konrad Zolna, Emilio Parisotto, Sergio Gomez Colmenarejo, Alexander Novikov, Gabriel Barth-Maron, Mai Gimenez, Yury Sulsky, Jackie Kay, Jost Tobias Springenberg, et al. A generalist agent. arXiv preprint arXiv:2205.06175, 2022.\n[49] Jane X Wang, Zeb Kurth-Nelson, Dhruva Tirumala, Hubert Soyer, Joel Z Leibo, Remi Munos, Charles Blundell, Dhar- shan Kumaran, and Matt Botvinick. Learning to reinforcement learn. arXiv preprint arXiv:1611.05763, 2016.\n[50] Rishi Bommasani, Drew A Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael S Bernstein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill, et al. On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258, 2021.\n[51] Fuzhen Zhuang, Zhiyuan Qi, Keyu Duan, Dongbo Xi, Yongchun Zhu, Hengshu Zhu, Hui Xiong, and Qing He. A comprehensive survey on transfer learning. Proceedings of the IEEE, 109(1):4376, 2020.\n[52] Yongjun Xu, Xin Liu, Xin Cao, Changping Huang, Enke Liu, Sen Qian, Xingchen Liu, Yanjun Wu, Fengliang Dong, Cheng-Wei Qiu, et al. Artificial intelligence: A powerful paradigm for scientific research. The Innovation, 2(4), 2021.\n[53] Lu Yuan, Dongdong Chen, Yi-Ling Chen, Noel Codella, Xiyang Dai, Jianfeng Gao, Houdong Hu, Xuedong Huang, Boxin Li, Chunyuan Li, et al. Florence: A new foundation model for computer vision. arXiv preprint arXiv:2111.11432, 2021.\n[54] Shashank Subramanian, Peter Harrington, Kurt Keutzer, Wahid Bhimji, Dmitriy Morozov, Michael W Mahoney, and Amir Gholami. Towards foundation models for scientific machine learning: Characterizing scaling and transfer behav- ior. Advances in Neural Information Processing Systems, 36, 2024.\n[55] Yongjun Xu, Fei Wang, Zhulin An, Qi Wang, and Zhao Zhang. Artificial intelligence for sciencebridging data to wisdom. The Innovation, 4(6), 2023.\n[56] Tomas Mikolov. Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781, 2013.\n[57] Jeffrey Pennington, Richard Socher, and Christopher D Manning. Glove: Global vectors for word representation. In Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP), pages 1532-1543, 2014.\n[58] A Vaswani. Attention is all you need. Advances in Neural Information Processing Systems, pages 5998-6008, 2017.\n[59] Jacob Devlin Ming-Wei Chang Kenton and Lee Kristina Toutanova. Bert: Pre-training of deep bidirectional transform- ers for language understanding. In Proceedings of naacL-HLT, volume 1, page 2. Minneapolis, Minnesota, 2019.\n[60] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.\n[61] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:1877-1901, 2020.\n[62] Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever. Zero-shot text-to-image generation. In International conference on machine learning, pages 8821-8831. Pmlr, 2021.\n[63] Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo. Swin transformer: Hierarchical vision transformer using shifted windows. In Proceedings of the IEEE/CVF international conference on computer vision, pages 10012-10022, 2021.\n[64] Shukang Yin, Chaoyou Fu, Sirui Zhao, Ke Li, Xing Sun, Tong Xu, and Enhong Chen. A survey on multimodal large language models. CoRR, abs/2306.13549, 2023.\n[65] Peng Xu, Xiatian Zhu, and David A. Clifton. Multimodal learning with transformers: A survey. IEEE Trans. Pattern Anal. Mach. Intell., 45(10):12113-12132, 2023.\n[66] Duzhen Zhang, Yahan Yu, Jiahua Dong, Chenxing Li, Dan Su, Chenhui Chu, and Dong Yu. Mmllms: Recent advances in multimodal large language models. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar, editors, Findings of the Association for Computational Linguistics, ACL 2024, Bangkok, Thailand and virtual meeting, August 11-16, 2024, pages 12401-12430. Association for Computational Linguistics, 2024.\n[67] Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke Zettlemoyer. Deep contextualized word representations. In Marilyn Walker, Heng Ji, and Amanda Stent, editors, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Lan- guage Technologies, Volume 1 (Long Papers), pages 2227-2237, New Orleans, Louisiana, June 2018. Association for Computational Linguistics.\n[68] Alex Graves and Alex Graves. Long short-term memory. Supervised sequence labelling with recurrent neural networks, pages 37-45, 2012.\n[69] Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al. Improving language understanding by genera- tive pre-training. 2018.\n[70] Li Dong, Nan Yang, Wenhui Wang, Furu Wei, Xiaodong Liu, Yu Wang, Jianfeng Gao, Ming Zhou, and Hsiao-Wuen Hon. Unified language model pre-training for natural language understanding and generation. Advances in neural information processing systems, 32, 2019.\n[71] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. Journal of machine learning research, 21(140):1-67, 2020.\n[72] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceed- ings of the IEEE conference on computer vision and pattern recognition, pages 770-778, 2016.\n[73] Jason Yosinski, Jeff Clune, Yoshua Bengio, and Hod Lipson. How transferable are features in deep neural networks? Advances in neural information processing systems, 27, 2014.\n[74] Mingsheng Long, Yue Cao, Jianmin Wang, and Michael Jordan. Learning transferable features with deep adaptation networks. In International conference on machine learning, pages 97-105. PMLR, 2015.\n[75] Alexey Dosovitskiy. An image is worth $16 \\times 16$ words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929, 2020.\n[76] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances in neural information processing systems, 33:6840-6851, 2020.\n[77] Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli. Deep unsupervised learning using nonequilibrium thermodynamics. In International conference on machine learning, pages 2256-2265. PMLR, 2015.\n[78] Yang Song and Stefano Ermon. Generative modeling by estimating gradients of the data distribution. Advances in neural information processing systems, 32, 2019.\n[79] Weilun Feng, Chuanguang Yang, Zhulin An, Libo Huang, Boyu Diao, Fei Wang, and Yongjun Xu. Relational diffusion distillation for efficient image generation. In Proceedings of the 32nd ACM International Conference on Multimedia, pages 205-213, 2024.\n[80] Patrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas Mu\"ller, Harry Saini, Yam Levi, Dominik Lorenz, Axel Sauer, Frederic Boesel, et al. Scaling rectified flow transformers for high-resolution image synthesis. In Forty-first International Conference on Machine Learning, 2024.\n[81] William Peebles and Saining Xie. Scalable diffusion models with transformers. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 4195-4205, 2023.\n[82] Tim Brooks, Bill Peebles, Connor Holmes, Will DePue, Yufei Guo, Li Jing, David Schnurr, Joe Taylor, Troy Luhman, Eric Luhman, et al. Video generation models as world simulators. OpenAI Blog, 1:8, 2024.\n[83] Quan Sun, Qiying Yu, Yufeng Cui, Fan Zhang, Xiaosong Zhang, Yueze Wang, Hongcheng Gao, Jingjing Liu, Tiejun Huang, and Xinlong Wang. Generative pretraining in multimodality. arXiv preprint arXiv:2307.05222, 2023.\n[84] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bjo\"rn Ommer. Highresolution image syn- thesis with latent diffusion models. In Proceedings of the IEEE/CVF conference on computer vision and pattern recog- nition, pages 10684-10695, 2022.\n[85] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. Hierarchical textconditional image generation with clip latents. arXiv preprint arXiv:2204.06125, 1(2):3, 2022.\n[86] Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. Visual instruction tuning. Advances in neural information processing systems, 36, 2024.\n[87] Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and Mohamed Elhoseiny. Minigpt-4: Enhancing vision-language understanding with advanced large language models. arXiv preprint arXiv:2304.10592, 2023.\n[88] Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana Hasson, Karel Lenc, Arthur Mensch, Katherine Millican, Malcolm Reynolds, et al. Flamingo: a visual language model for few-shot learning. Advances in neural information processing systems, 35:2371623736, 2022.\n[89] Xueqi Cheng, Xiaohui Yan, Yanyan Lan, and Jiafeng Guo. Btm: Topic modeling over short texts. IEEE Transactions on Knowledge and Data Engineering, 26(12):2928-2941, 2014.\n[90] Xue-Qi Cheng and Hua-Wei Shen. Uncovering the community structure associated with the diffusion dynamics on networks. Journal of Statistical Mechanics: Theory and Experiment, 2010(04):P04024, 2010.\n[91] Yujie Li, Tao Sun, Zezhi Shao, Yiqiang Zhen, Yongjun Xu, and Fei Wang. Trajectory-user linking via multi-scale graph attention network. Pattern Recognition, 158:110978, 2025.\n[92] Yunke Zhang, Yuming Lin, Guanjie Zheng, Yu Liu, Nicholas Sukiennik, Fengli Xu, Yongjun Xu, Feng Lu, Qi Wang, Yuan Lai, et al. Metacity: Data-driven sustainable development of complex cities. The Innovation, 6(2):100775, 2025.\n[93] Tangwen Qian, Yongjun Xu, Zhao Zhang, and Fei Wang. Trajectory prediction from hierarchical perspective. In Proceedings of the 30th ACM International Conference on Multimedia, pages 6822-6830, 2022.\n[94] Tao Sun, Fei Wang, Zhao Zhang, Lin Wu, and Yongjun Xu. Human mobility identification by deep behavior relevant location representation. In International Conference on Database Systems for Advanced Applications, pages 439-454. Springer, 2022.\n[95] Saiping Guan, Xiaolong Jin, Jiafeng Guo, Yuanzhuo Wang, and Xueqi Cheng. Neuinfer: Knowledge inference on n-ary facts. In Proceedings of the 58th annual meeting of the association for computational linguistics, pages 6141-6151, 2020.\n[96] Zhuo Chen, Zhao Zhang, Zixuan Li, Fei Wang, Yutao Zeng, Xiaolong Jin, and Yongjun Xu. Selfimprovement program- ming for temporal knowledge graph question answering. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 14579-14594, 2024.\n[97] Ke Liang, Lingyuan Meng, Meng Liu, Yue Liu, Wenxuan Tu, Siwei Wang, Sihang Zhou, Xinwang Liu, Fuchun Sun, and Kunlun He. A survey of knowledge graph reasoning on graph types: Static, dynamic, and multi-modal. IEEE Transactions on Pattern Analysis and Machine Intelligence, 46(12):9456-9478, 2024.\n[98] Chengqing Yu, Fei Wang, Zezhi Shao, Tangwen Qian, Zhao Zhang, Wei Wei, and Yongjun Xu. Ginar: An end-to-end multivariate time series forecasting model suitable for variable missing. In Proceedings of the 30th ACM SIGKDD conference on knowledge discovery and data mining, pages 3989-4000, 2024.\n[99] Yujie Li, Zezhi Shao, Yongjun Xu, Qiang Qiu, Zhaogang Cao, and Fei Wang. Dynamic frequency domain graph convolutional network for traffic forecasting. In ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 52455249. IEEE, 2024.\n[100] Ke Liang, Yue Liu, Sihang Zhou, Wenxuan Tu, Yi Wen, Xihong Yang, Xiangjun Dong, and Xinwang Liu. Knowl- edge graph contrastive learning based on relation-symmetrical structure. IEEE Transactions on Knowledge and Data Engineering, 36(1):226-238, 2023.\n[101] Jiezhong Qiu, Qibin Chen, Yuxiao Dong, Jing Zhang, Hongxia Yang, Ming Ding, Kuansan Wang, and Jie Tang. Gcc: Graph contrastive coding for graph neural network pre-training. In Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery \u0026 data mining, pages 1150-1160, 2020.\n[102] Xiangguo Sun, Hong Cheng, Jia Li, Bo Liu, and Jihong Guan. All in one: Multi-task prompting for graph neural networks. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pages 2120-2131, 2023.\n[103] Frederik Wenkel, Guy Wolf, and Boris Knyazev. Pretrained language models to solve graph tasks in natural language. In ICML 2023 Workshop on Structured Probabilistic Inference backslash \u0026 Generative Modeling, 2023.\n[104] Ruosong Ye, Caiqi Zhang, Runhui Wang, Shuyuan Xu, and Yongfeng Zhang. Language is all a graph needs. In Findings of the Association for Computational Linguistics: EACL 2024, pages 1955-1973, 2024.\n[105] Costas Mavromatis, Vassilis N Ioannidis, Shen Wang, Da Zheng, Soji Adeshina, Jun Ma, Han Zhao, Christos Faloutsos, and George Karypis. Train your own gnn teacher: Graph-aware distillation on textual graphs. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pages 157-173. Springer, 2023.\n[106] Tianjie Zhao, Sheng Wang, Chaojun Ouyang, Min Chen, Chenying Liu, Jin Zhang, Long Yu, Fei Wang, Yong Xie, Jun Li, et al. Artificial intelligence for geoscience: Progress, challenges and perspectives. The Innovation, 2024.\n[107] Tangwen Qian, Yile Chen, Gao Cong, Yongjun Xu, and Fei Wang. Adaptraj: a multi-source domain generalization framework for multi-agent trajectory prediction. In 2024 IEEE 40th International Conference on Data Engineering (ICDE), pages 5048-5060. IEEE, 2024.\n[108] Yongjun Xu, Fei Wang, and Tangtang Zhang. Artificial intelligence is restructuring a new world. The Innovation, 5(6), 2024.\n[109] Fei Wang, Di Yao, Yong Li, Tao Sun, and Zhao Zhang. Ai-enhanced spatial-temporal data-mining technology: New chance for next-generation urban computing. The Innovation, 4(2), 2023.\n[110] Zezhi Shao, Zhao Zhang, Fei Wang, and Yongjun Xu. Pre-training enhanced spatial-temporal graph neural network for multivariate time series forecasting. In Proceedings of the 28th ACM SIGKDD conference on knowledge discovery and data mining, pages 1567-1577, 2022.\n[111] Zezhi Shao, Zhao Zhang, Wei Wei, Fei Wang, Yongjun Xu, Xin Cao, and Christian S Jensen. Decoupled dynamic spatial-temporal graph neural network for traffic forecasting. Proceedings of the VLDB Endowment, 15(11):2733-2746, 2022.\n[112] Zezhi Shao, Fei Wang, Yongjun Xu, Wei Wei, Chengqing Yu, Zhao Zhang, Di Yao, Tao Sun, Guangyin Jin, Xin Cao, et al. Exploring progress in multivariate time series forecasting: Comprehensive benchmarking and heterogeneity analysis. IEEE Transactions on Knowledge and Data Engineering, 2024.\n[113] Zezhi Shao, Zhao Zhang, Fei Wang, Wei Wei, and Yongjun Xu. Spatial-temporal identity: A simple yet effective base- line for multivariate time series forecasting. In Proceedings of the 31st ACM International Conference on Information \u0026 Knowledge Management, pages 4454-4458, 2022.\n[114] Defu Cao, Furong Jia, Sercan O Arik, Tomas Pfister, Yixiang Zheng, Wen Ye, and Yan Liu. Tempo: Prompt-based generative pre-trained transformer for time series forecasting. arXiv preprint arXiv:2310.04948, 2023.\n[115] Ching Chang, Wen-Chih Peng, and Tien-Fu Chen. Llm4ts: Two-stage fine-tuning for time-series forecasting with pre-trained llms. arXiv preprint arXiv:2308.08469, 2023.\n[116] Nate Gruver, Marc Finzi, Shikai Qiu, and Andrew G Wilson. Large language models are zero-shot time series forecast- ers. Advances in Neural Information Processing Systems, 36, 2024.\n[117] Zhihan Yue, Yujing Wang, Juanyong Duan, Tianmeng Yang, Congrui Huang, Yunhai Tong, and Bixiong Xu. Ts2vec: Towards universal representation of time series. In Proceedings of the AAAI Conference on Artificial Intelligence, pages 8980-8987, 2022.\n[118] Jiaxiang Dong, Haixu Wu, Haoran Zhang, Li Zhang, Jianmin Wang, and Mingsheng Long. Simmtm: A simple pre- training framework for masked time-series modeling. Advances in Neural Information Processing Systems, 36, 2024.\n[119] Yuan Wang, Zezhi Shao, Tao Sun, Chengqing Yu, Yongjun Xu, and Fei Wang. Clusteringproperty matters: A cluster- aware network for large scale multivariate time series forecasting. In Proceedings of the 32nd ACM International Conference on Information and Knowledge Management, pages 4340-4344, 2023.\n[120] Ming Jin, Shiyu Wang, Lintao Ma, Zhixuan Chu, James Y Zhang, Xiaoming Shi, Pin-Yu Chen, Yuxuan Liang, Yuan- Fang Li, Shirui Pan, et al. Time-llm: Time series forecasting by reprogramming large language models. arXiv preprint arXiv:2310.01728, 2023.\n[121] Hao Xue and Flora D Salim. Promptcast: A new prompt-based learning paradigm for time series forecasting. IEEE Transactions on Knowledge and Data Engineering, 2023.\n[122] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde De Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374, 2021.\n[123] Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, Re’mi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, et al. Competition-level code generation with alphacode. Science, 378(6624):1092-1097, 2022.\n[124] Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, et al. Starcoder: may the source be with you! arXiv preprint arXiv:2305.06161, 2023.\n[125] Carlos E Jimenez, John Yang, Alexander Wettig, Shunyu Yao, Kexin Pei, Ofir Press, and Karthik Narasimhan. Swe- bench: Can language models resolve real-world github issues? arXiv preprint arXiv:2310.06770, 2023.\n[126] Linhao Dong, Shuang Xu, and Bo Xu. Speech-transformer: a no-recurrence sequence-to-sequence model for speech recognition. In 2018 IEEE international conference on acoustics, speech and signal processing (ICASSP), pages 5884-5888. IEEE, 2018.\n[127] Chengyi Wang, Sanyuan Chen, Yu Wu, Ziqiang Zhang, Long Zhou, Shujie Liu, Zhuo Chen, Yanqing Liu, Huam- ing Wang, Jinyu Li, et al. Neural codec language models are zero-shot text to speech synthesizers. arXiv preprint arXiv:2301.02111, 2023.\n[128] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. Chain- of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems, 35:24824-24837, 2022.\n[129] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan Cao, and Karthik Narasimhan. Tree of thoughts: Deliberate problem solving with large language models. Advances in Neural Information Processing Systems, 36, 2024.\n[130] Hao Sha, Yao Mu, Yuxuan Jiang, Li Chen, Chenfeng Xu, Ping Luo, Shengbo Eben Li, Masayoshi Tomizuka, Wei Zhan, and Mingyu Ding. Languagempc: Large language models as decision makers for autonomous driving. arXiv preprint arXiv:2310.03026, 2023.\n[131] T Guo, X Chen, Y Wang, R Chang, S Pei, NV Chawla, O Wiest, and X Zhang. Large language model based multi- agents: A survey of progress and challenges. In 33rd International Joint Conference on Artificial Intelligence (IJCAI 2024). IJCAI; Cornell arxiv, 2024.\n[132] Arya Rao, John Kim, Meghana Kamineni, Michael Pang, Winston Lie, and Marc D Succi. Evaluating chatgpt as an adjunct for radiologic decision-making. MedRxiv, pages 2023-02, 2023.\n[133] Can Cui, Yunsheng Ma, Xu Cao, Wenqian Ye, and Ziran Wang. Drive as you speak: Enabling human-like interaction with large language models in autonomous vehicles. In Proceedings of the IEEE/CVF Winter Conference on Applica- tions of Computer Vision, pages 902-909, 2024.\n[134] Andrew Zhao, Daniel Huang, Quentin Xu, Matthieu Lin, Yong-Jin Liu, and Gao Huang. Expel: Llm agents are experiential learners. In Proceedings of the AAAI Conference on Artificial Intelligence, pages 19632-19642, 2024.\n[135] Chengqing Yu, Guangxi Yan, Chengming Yu, and Xiwei Mi. Attention mechanism is useful in spatio-temporal wind speed prediction: Evidence from china. Applied Soft Computing, 148:110864, 2023.\n[136] Chengqing Yu, Fei Wang, Yilun Wang, Zezhi Shao, Tao Sun, Di Yao, and Yongjun Xu. Mgsfformer: A multi-granularity spatiotemporal fusion transformer for air quality prediction. Information Fusion, 113:102607, 2025.\n[137] Fang Cheng and Hui Liu. Multi-step electric vehicles charging loads forecasting: An autoformer variant with feature extraction, frequency enhancement, and error correction blocks. Applied Energy, 376:124308, 2024.\n[138] Chengqing Yu, Fei Wang, Zezhi Shao, Tao Sun, Lin Wu, and Yongjun Xu. Dsformer: A double sampling transformer for multivariate time series long-term prediction. In Proceedings of the 32nd ACM international conference on information and knowledge management, pages 3062-3072, 2023.\n[139] Yu Chengqing, Yan Guangxi, Yu Chengming, Zhang Yu, and Mi Xiwei. A multi-factor driven spatiotemporal wind power prediction model based on an ensemble deep graph attention reinforcement learning networks. Energy, 263:126034, 2023.\n[140] Chengqing Yu, Guangxi Yan, Chengming Yu, Xinwei Liu, and Xiwei Mi. Mriformer: A multiresolution interactive transformer for wind speed multi-step prediction. Information Sciences, 661:120150, 2024.\n[141] Chengming Yu, Ji Qiao, Chao Chen, Chengqing Yu, and Xiwei Mi. Tfeformer: A new temporal frequency ensemble transformer for day-ahead photovoltaic power prediction. Journal of Cleaner Production, 448:141690, 2024.\n[142] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothe’e Lacroix, Baptiste Rozie`re, Naman Goyal, Eric Hambro, and Faisal Azhar. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971, 2023.\n[143] Zezhi Shao, Tangwen Qian, Tao Sun, Fei Wang, and Yongjun Xu. Spatial-temporal large models: A super hub linking multiple scientific areas with artificial intelligence. The Innovation, page 100763, 2024.\n[144] Team GLM, Aohan Zeng, Bin Xu, Bowen Wang, Chenhui Zhang, Da Yin, Diego Rojas, Guanyu Feng, Hanlin Zhao, Hanyu Lai, et al. Chatglm: A family of large language models from glm-130b to glm-4 all tools. arXiv preprint arXiv:2406.12793, 2024.\n[145] M Lewis. Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and compre- hension. arXiv preprint arXiv:1910.13461, 2019.\n[146] Yi Tay, Mostafa Dehghani, Vinh Q Tran, Xavier Garcia, Jason Wei, Xuezhi Wang, Hyung Won Chung, Siamak Shakeri, Dara Bahri, Tal Schuster, et al. Ul2: Unifying language learning paradigms. arXiv preprint arXiv:2205.05131, 2022.\n[147] Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, et al. Qwen technical report. arXiv preprint arXiv:2309.16609, 2023.\n[148] Edward J Hu, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen, et al. Lora: Low- rank adaptation of large language models. In International Conference on Learning Representations, 2022.\n[149] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems, 35:27730-27744, 2022.\n[150] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rockta\"schel, et al. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in Neural Information Processing Systems, 33:9459-9474, 2020.\n[151] Timo Schick, Jane Dwivedi-Yu, Roberto Dess`1, Roberta Raileanu, Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to use tools. Advances in Neural Information Processing Systems, 36, 2024.\n[152] Wenqi Shao, Chonghe Jiang, Kaipeng Zhang, Yu Qiao, Ping Luo, et al. Foundation model is efficient multimodal multitask model selector. Advances in Neural Information Processing Systems, 36, 2024.\n[153] Wonjae Kim, Bokyung Son, and Ildoo Kim. Vilt: Vision-and-language transformer without convolution or region supervision. In International conference on machine learning, pages 55835594. PMLR, 2021.\n[154] Haiyang Xu, Qinghao Ye, Ming Yan, Yaya Shi, Jiabo Ye, Yuanhong Xu, Chenliang Li, Bin Bi, Qi Qian, Wei Wang, et al. mplug-2: A modularized multi-modal foundation model across text, image and video. In International Conference on Machine Learning, pages 38728-38748. PMLR, 2023.\n[155] Chunyuan Li, Zhe Gan, Zhengyuan Yang, Jianwei Yang, Linjie Li, Lijuan Wang, Jianfeng Gao, et al. Multimodal foundation models: From specialists to general-purpose assistants. Foundations and Trends® in Computer Graphics and Vision, 16(1-2):1-214, 2024.\n[156] Xingqian Xu, Zhangyang Wang, Gong Zhang, Kai Wang, and Humphrey Shi. Versatile diffusion: Text, images and variations all in one diffusion model. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 7754-7765, 2023.\n[157] Yin Zheng, Yu-Jin Zhang, and Hugo Larochelle. A deep and autoregressive approach for topic modeling of multimodal data. IEEE transactions on pattern analysis and machine intelligence, 38(6):1056-1069, 2015.\n[158] AJ Piergiovanni, Isaac Noble, Dahun Kim, Michael S Ryoo, Victor Gomes, and Anelia Angelova. Mirasol3b: A mul- timodal autoregressive model for time-aligned and contextual modalities. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 26804-26814, 2024.\n[159] Yanan Wang, Michihiro Yasunaga, Hongyu Ren, Shinya Wada, and Jure Leskovec. Vqa-gnn: Reasoning with multi- modal knowledge via graph neural networks for visual question answering. In Proceedings of the IEEE/CVF Interna- tional Conference on Computer Vision, pages 2158221592, 2023.\n[160] Feiyu Chen, Jie Shao, Shuyuan Zhu, and Heng Tao Shen. Multivariate, multi-frequency and multimodal: Rethink- ing graph neural networks for emotion recognition in conversation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 10761-10770, 2023.\n[161] Chuanguang Yang, Zhulin An, Hui Zhu, Xiaolong Hu, Kun Zhang, Kaiqiang Xu, Chao Li, and Yongjun Xu. Gated convolutional networks with hybrid connectivity for image classification. In Proceedings of the AAAI conference on artificial intelligence, pages 12581-12588, 2020.\n[162] Swalpa Kumar Roy, Ankur Deria, Danfeng Hong, Behnood Rasti, Antonio Plaza, and Jocelyn Chanussot. Multimodal fusion transformer for remote sensing image classification. IEEE Transactions on Geoscience and Remote Sensing, 61:1-20, 2023.\n[163] Yikai Wang, Xinghao Chen, Lele Cao, Wenbing Huang, Fuchun Sun, and Yunhe Wang. Multimodal token fusion for vision transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 12186-12195, 2022.\n[164] Fang Cheng and Hui Liu. An adaptive hybrid deep learning-based reliability assessment framework for damping track system considering multi-random variables. Mechanical Systems and Signal Processing, 208:110981, 2024.\n[165] Nanyi Fei, Zhiwu Lu, Yizhao Gao, Guoxing Yang, Yuqi Huo, Jingyuan Wen, Haoyu Lu, Ruihua Song, Xin Gao, Tao Xiang, et al. Towards artificial general intelligence via a multimodal foundation model. Nature Communications, 13(1):3094, 2022.\n[166] Fei Ma, Yang Li, Shiguang Ni, Shao-Lun Huang, and Lin Zhang. Data augmentation for audiovisual emotion recogni- tion with an efficient multimodal conditional gan. Applied Sciences, 12(1):527, 2022.\n[167] Zihao Wang, Shaofei Cai, Anji Liu, Yonggang Jin, Jinbing Hou, Bowei Zhang, Haowei Lin, Zhaofeng He, Zilong Zheng, Yaodong Yang, et al. Jarvis-1: Open-world multi-task agents with memory-augmented multimodal language models. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2024.\n[168] Wenjie Zheng, Jianfei Yu, Rui Xia, and Shijin Wang. A facial expression-aware multimodal multitask learning frame- work for emotion recognition in multi-party conversations. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 15445-15459, 2023.\n[169] Amanpreet Singh, Ronghang Hu, Vedanuj Goswami, Guillaume Couairon, Wojciech Galuba, Marcus Rohrbach, and Douwe Kiela. Flava: A foundational language and vision alignment model. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 15638-15650, 2022.\n[170] Zhiqing Sun, Sheng Shen, Shengcao Cao, Haotian Liu, Chunyuan Li, Yikang Shen, Chuang Gan, Liang-Yan Gui, Yu- Xiong Wang, Yiming Yang, et al. Aligning large multimodal models with factually augmented rlhf. arXiv preprint arXiv:2309.14525, 2023.\n[171] Sheng Zhang, Yanbo Xu, Naoto Usuyama, Hanwen Xu, Jaspreet Bagga, Robert Tinn, Sam Preston, Rajesh Rao, Mu Wei, Naveen Valluri, et al. Biomedclip: a multimodal biomedical foundation model pretrained from fifteen million scientific image-text pairs. arXiv preprint arXiv:2303.00915, 2023.\n[172] Chuanguang Yang, Zhulin An, Linhang Cai, and Yongjun Xu. Mutual contrastive learning for visual representation learning. In Proceedings of the AAAI Conference on Artificial Intelligence, pages 3045-3053, 2022.\n[173] Zhimin Chen, Longlong Jing, Yingwei Li, and Bing Li. Bridging the domain gap: Self-supervised 3d scene understand- ing with foundation models. Advances in Neural Information Processing Systems, 36, 2024.\n[174] Abhinav Valada, Rohit Mohan, and Wolfram Burgard. Self-supervised model adaptation for multimodal semantic segmentation. International Journal of Computer Vision, 128(5):1239-1285, 2020.\n[175] Hiroki Furuta, Kuang-Huei Lee, Ofir Nachum, Yutaka Matsuo, Aleksandra Faust, Shixiang Shane Gu, and Izzeddin Gur. Multimodal web navigation with instruction-finetuned foundation models. arXiv preprint arXiv:2305.11854, 2023.\n[176] Dana Lahat, Tu\"lay Adali, and Christian Jutten. Multimodal data fusion: an overview of methods, challenges, and prospects. Proceedings of the IEEE, 103(9):1449-1477, 2015.\n[177] Jing Gao, Peng Li, Zhikui Chen, and Jianing Zhang. A survey on deep learning for multimodal data fusion. Neural Computation, 32(5):829-864, 2020.\n[178] Yong Li, Yuanzhi Wang, and Zhen Cui. Decoupled multimodal distilling for emotion recognition. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 6631-6640, 2023.\n[179] Shicai Wei, Chunbo Luo, and Yang Luo. Mmanet: Margin-aware distillation and modality-aware regularization for incomplete multimodal learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recog- nition, pages 20039-20049, 2023.\n[180] Chaohui Yu, Qiang Zhou, Jingliang Li, Jianlong Yuan, Zhibin Wang, and Fan Wang. Foundation model drives weakly incremental learning for semantic segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 23685-23694, 2023.\n[181] Yuxing Long, Binyuan Hui, Fulong Ye, Yanyang Li, Zhuoxin Han, Caixia Yuan, Yongbin Li, and Xiaojie Wang. Spring: Situated conversation agent pretrained with multimodal questions from incremental layout graph. In Proceedings of the AAAI Conference on Artificial Intelligence, pages 13309-13317, 2023.\n[182] Pandu Nayak. Mum: A new ai milestone for understanding information. Google, May, 18, 2021.\n[183] Mr D Murahari Reddy, Mr Sk Masthan Basha, Mr M Chinnaiahgari Hari, and Mr N Penchalaiah. Dall-e: Creating images from text. UGC Care Group I Journal, 8(14):71-75, 2021.\n[184] Tadas Baltrus`aitis, Chaitanya Ahuja, and Louis-Philippe Morency. Multimodal machine learning: A survey and taxon- omy. IEEE transactions on pattern analysis and machine intelligence, 41(2):423-443, 2018.\n[185] Yinhan Liu. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692, 2019.\n[186] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, and Sebastian Gehrmann. Palm: Scaling language modeling with pathways. Journal of Machine Learning Research, 24(240):1-113, 2023.\n[187] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288, 2023.\n[188] Yuren Mao, Yuhang Ge, Yijiang Fan, Wenyi Xu, Yu Mi, Zhonghao Hu, and Yunjun Gao. A survey on lora of large language models. arXiv preprint arXiv:2407.11046, 2024.\n[189] Edward J Hu, yelong shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. LoRA: Low-rank adaptation of large language models. In International Conference on Learning Representations, 2022.\n[190] Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. Qlora: Efficient finetuning of quantized llms. In A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine, editors, Advances in Neural Information Processing Systems, volume 36, pages 10088-10115. Curran Associates, Inc., 2023.\n[191] Hanqing Wang, Bowen Ping, Shuo Wang, Xu Han, Yun Chen, Zhiyuan Liu, and Maosong Sun. Lora-flow: Dynamic lora fusion for large language models in generative tasks. In Proceedings of the 62nd Annual Meeting of the Associa- tion for Computational Linguistics (Volume 1: Long Papers), pages 12871-12882, Bangkok, Thailand, August 2024. Association for Computational Linguistics.\n[192] Taiqiang Wu, Jiahao Wang, Zhe Zhao, and Ngai Wong. Mixture-of-subspaces in low-rank adaptation. In Yaser Al- Onaizan, Mohit Bansal, and Yun-Nung Chen, editors, Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, pages 7880-7899, Miami, Florida, USA, November 2024. Association for Computa- tional Linguistics.\n[193] Xinyin Ma, Gongfan Fang, and Xinchao Wang. Llm-pruner: On the structural pruning of large language models. Advances in neural information processing systems, 36:21702-21720, 2023.\n[194] Chuanguang Yang, Zhulin An, Libo Huang, Junyu Bi, Xinqiang Yu, Han Yang, Boyu Diao, and Yongjun Xu. Clip-kd: An empirical study of clip model distillation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 15952-15962, 2024.\n[195] Chuanguang Yang, Helong Zhou, Zhulin An, Xue Jiang, Yongjun Xu, and Qian Zhang. Crossimage relational knowl- edge distillation for semantic segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 12319-12328, 2022.\n[196] Chuanguang Yang, Zhulin An, Linhang Cai, and Yongjun Xu. Hierarchical self-supervised augmented knowledge distillation. In International Joint Conference on Artificial Intelligence, pages 1217-1223, 2021.\n[197] Chuanguang Yang, Zhulin An, Helong Zhou, Fuzhen Zhuang, Yongjun Xu, and Qian Zhang. Online knowledge dis- tillation via mutual contrastive learning for visual recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence, 45(8):10212-10227, 2023.\n[198] Yilong Zhao, Chien-Yu Lin, Kan Zhu, Zihao Ye, Lequn Chen, Size Zheng, Luis Ceze, Arvind Krishnamurthy, Tianqi Chen, and Baris Kasikci. Atom: Low-bit quantization for efficient and accurate llm serving. In P. Gibbons, G. Pekhi- menko, and C. De Sa, editors, Proceedings of Machine Learning and Systems, volume 6, pages 196-209, 2024.\n[199] Enze Xie, Junsong Chen, Junyu Chen, Han Cai, Haotian Tang, Yujun Lin, Zhekai Zhang, Muyang Li, Ligeng Zhu, Yao Lu, and Song Han. Sana: Efficient high-resolution image synthesis with linear diffusion transformer, 2024.\n[200] Markus J Buehler. Preflexor: Preference-based recursive language modeling for exploratory optimization of reasoning and agentic thinking. arXiv preprint arXiv:2410.12375, 2024.\n[201] Yiqing Wu, Zhao Zhang, Fei Wang, Yongjun Xu, and Jincai Huang. Towards more economical large-scale foundation models : no longer a game for the few. The Innovation, page 100832, 2025.\n[202] Hui Liu, Chengqing Yu, Haiping Wu, Zhu Duan, and Guangxi Yan. A new hybrid ensemble deep reinforcement learning model for wind speed short term forecasting. Energy, 202:117794, 2020.\n[203] Xinwei Liu, Muchuan Qin, Yue He, Xiwei Mi, and Chengqing Yu. A new multi-data-driven spatiotemporal pm2. 5 forecasting model based on an ensemble graph reinforcement learning convolutional network. Atmospheric Pollution Research, 12(10):101197, 2021.\n[204] Yongjun Xu, Fei Wang, Zhulin An, Qi Wang, and Zhao Zhang. Artificial intelligence for sciencebridging data to wisdom. The Innovation, 4(6), 2023.\n[205] Sherry Yang. Foundation Models for Decision Making: Algorithms, Frameworks, and Applications. PhD thesis, EECS Department, University of California, Berkeley, Aug 2024.\n[206] Qi Wang, Yanghe Feng, Jincai Huang, Yiqin Lv, Zheng Xie, and Xiaoshan Gao. Large-scale generative simulation artificial intelligence: The next hotspot. The Innovation, 4(6), 2023.\n[207] Fei Wang, Di Yao, Yong Li, Tao Sun, and Zhao Zhang. Ai-enhanced spatial-temporal data-mining technology: New chance for next-generation urban computing. The Innovation, 4, 2023.\n[208] Zihao Fu, Haoran Yang, Anthony Man-Cho So, Wai Lam, Lidong Bing, and Nigel Collier. On the Effectiveness of Parameter-Efficient Fine-Tuning. arXiv e-prints, page arXiv:2211.15583, November 2022.\n[209] Zeyu Han, Chao Gao, Jinyang Liu, Jeff Zhang, and Sai Qian Zhang. Parameter-Efficient FineTuning for Large Models: A Comprehensive Survey. arXiv e-prints, page arXiv:2403.14608, March 2024.\n[210] Ke Liang, Lingyuan Meng, Hao Li, Meng Liu, Siwei Wang, Sihang Zhou, Xinwang Liu, and Kunlun He. Mgksite: Multi-modal knowledge-driven site selection via intra and inter-modal graph fusion. IEEE Transactions on Multimedia, 2024.\n[211] Pranav Ashar, Srinivas Devadas, and A. Richard Newton. State Encoding, pages 87-116. Springer US, Boston, MA, 1992.\n[212] Hiroshi Higashi, Tetsuto Minami, and Shigeki Nakauchi. Cooperative update of beliefs and statetransition functions in human reinforcement learning. Scientific Reports, 9(1):17704, 2019.\n[213] Siheng Chen, Yiyi Liao, Fei Wang, Gang Wang, Liang Wang, Yafei Wang, and Xichan Zhu. Toward the robustness of autonomous vehicles in the ai era. The Innovation, page 100780, 2024.\n[214] Yang Zhou, Lifan Wu, Ravi Ramamoorthi, and Ling-Qi Yan. Vectorization for fast, analytic, and differentiable visibility. ACM Trans. Graph., 40(3), July 2021.\n[215] Siva Sivamani Ganesh Kumar and Abhishek Gudipalli. A comprehensive review on payloads of unmanned aerial vehicle. The Egyptian Journal of Remote Sensing and Space Sciences, 27(4):637644, 2024.\n[216] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed H. Chi, Quoc V. Le, and Denny Zhou. Chain-of-thought prompting elicits reasoning in large language models. In Advances in Neural Information Processing Systems 35, NeurIPS, 2022.\n[217] Paul F Christiano, Jan Leike, Tom Brown, Miljan Martic, Shane Legg, and Dario Amodei. Deep reinforcement learning from human preferences. Advances in neural information processing systems, 30, 2017.\n[218] Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, et al. Training a helpful and harmless assistant with reinforcement learning from human feedback. arXiv preprint arXiv:2204.05862, 2022.\n[219] Feifan Song, Bowen Yu, Minghao Li, Haiyang Yu, Fei Huang, Yongbin Li, and Houfeng Wang. Preference ranking optimization for human alignment. arXiv preprint arXiv:2306.17492, 2023.\n[220] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal policy optimization algo- rithms. arXiv preprint arXiv:1707.06347, 2017.\n[221] Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D Manning, and Chelsea Finn. Direct preference optimization: Your language model is secretly a reward model. arXiv preprint arXiv:2305.18290, 2023.\n[222] Mohammad Gheshlaghi Azar, Zhaohan Daniel Guo, Bilal Piot, Remi Munos, Mark Rowland, Michal Valko, and Daniele Calandriello. A general theoretical paradigm to understand learning from human preferences. In International Conference on Artificial Intelligence and Statistics, pages 4447-4455. PMLR, 2024.\n[223] Kawin Ethayarajh, Winnie Xu, Niklas Muennighoff, Dan Jurafsky, and Douwe Kiela. Kto: Model alignment as prospect theoretic optimization. arXiv preprint arXiv:2402.01306, 2024.\n[224] Yongcheng Zeng, Guoqing Liu, Weiyu Ma, Ning Yang, Haifeng Zhang, and Jun Wang. Tokenlevel direct preference optimization. arXiv preprint arXiv:2404.11999, 2024.\n[225] Yu Meng, Mengzhou Xia, and Danqi Chen. Simpo: Simple preference optimization with a reference-free reward. arXiv preprint arXiv:2405.14734, 2024.\n[226] Jiwoo Hong, Noah Lee, and James Thorne. Orpo: Monolithic preference optimization without reference model. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, pages 11170-11189, 2024.\n[227] Xidong Feng, Ziyu Wan, Muning Wen, Stephen Marcus McAleer, Ying Wen, Weinan Zhang, and Jun Wang. Alphazero- like tree-search can guide large language model decoding and training. arXiv preprint arXiv:2309.17179, 2023.\n[228] Dan Zhang, Sining Zhoubian, Ziniu Hu, Yisong Yue, Yuxiao Dong, and Jie Tang. Rest-mcts*: Llm self-training via process reward guided tree search. arXiv preprint arXiv:2406.03816, 2024.\n[229] David Silver, Aja Huang, Chris J Maddison, Arthur Guez, Laurent Sifre, George Van Den Driessche, Julian Schrit- twieser, Ioannis Antonoglou, Veda Panneershelvam, Marc Lanctot, et al. Mastering the game of go with deep neural networks and tree search. nature, 529(7587):484-489, 2016.\n[230] Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Michal Podstawski, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Hubert Niewiadomski, Piotr Nyczyk, et al. Graph of thoughts: Solving elaborate problems with large language models. In Proceedings of the AAAI Conference on Artificial Intelligence, pages 17682-17690, 2024.\n[231] Yadong Zhang, Shaoguang Mao, Tao Ge, Xun Wang, Adrian de Wynter, Yan Xia, Wenshan Wu, Ting Song, Man Lan, and Furu Wei. Llm as a mastermind: A survey of strategic reasoning with large language models. arXiv preprint arXiv:2404.01230, 2024.\n[232] Wenyue Hua, Ollie Liu, Lingyao Li, Alfonso Amayuelas, Julie Chen, Lucas Jiang, Mingyu Jin, Lizhou Fan, Fei Sun, William Wang, et al. Game-theoretic llm: Agent workflow for negotiation games. arXiv preprint arXiv:2411.05990, 2024.\n[233] Zongyuan Li, Yanan Ni, Runnan Qi, Lumin Jiang, Chang Lu, Xiaojie Xu, Xiangbei Liu, Pengfei Li, Yunzheng Guo, Zhe Ma, et al. Llm-pysc2: Starcraft ii learning environment for large language models. arXiv preprint arXiv:2411.05348, 2024.\n[234] Muhammad Junaid Khan and Gita Sukthankar. Sc-phi2: A fine-tuned small language model for starcraft ii macroman- agement tasks. arXiv preprint arXiv:2409.18989, 2024.\n[235] Weiyu Ma, Qirui Mi, Yongcheng Zeng, Xue Yan, Yuqiao Wu, Runji Lin, Haifeng Zhang, and Jun Wang. Large language models play starcraft ii: Benchmarks and a chain of summarization approach. arXiv preprint arXiv:2312.11865, 2023.\n[236] Xuanfa Jin, Ziyan Wang, Yali Du, Meng Fang, Haifeng Zhang, and Jun Wang. Learning to discuss strategically: A case study on one night ultimate werewolf. arXiv preprint arXiv:2405.19946, 2024.\n[237] Suma Bailis, Jane Friedhoff, and Feiyang Chen. Werewolf arena: A case study in llm evaluation via social deduction. arXiv preprint arXiv:2407.13943, 2024.\n[238] Ayato Kitadai, Sinndy Dayana Rico Lugo, Yudai Tsurusaki, Yusuke Fukasawa, and Nariaki Nishino. Can ai with high reasoning ability replicate human-like decision making in economic experiments? arXiv preprint arXiv:2406.11426, 2024.\n[239] Eilam Shapira, Omer Madmon, Itamar Reinman, Samuel Joseph Amouyal, Roi Reichart, and Moshe Tennenholtz. Glee: A unified framework and benchmark for language-based economic environments. arXiv preprint arXiv:2410.05254, 2024.\n[240] Danny Driess, Fei Xia, Mehdi SM Sajjadi, Corey Lynch, Aakanksha Chowdhery, Brian Ichter, Ayzaan Wahid, Jonathan Tompson, Quan Vuong, Tianhe Yu, et al. Palm-e: An embodied multimodal language model. arXiv preprint arXiv:2303.03378, 2023.\n[241] Tsun-Hsuan Wang, Alaa Maalouf, Wei Xiao, Yutong Ban, Alexander Amini, Guy Rosman, Sertac Karaman, and Daniela Rus. Drive anywhere: Generalizable end-to-end autonomous driving with multi-modal foundation models. In 2024 IEEE International Conference on Robotics and Automation (ICRA), pages 6687-6694. IEEE, 2024.\n[242] Roya Firoozi, Johnathan Tucker, Stephen Tian, Anirudha Majumdar, Jiankai Sun, Weiyu Liu, Yuke Zhu, Shuran Song, Ashish Kapoor, Karol Hausman, et al. Foundation models in robotics: Applications, challenges, and the future. The International Journal of Robotics Research, page 02783649241281508, 2023.\n[243] Lili Fan, Yutong Wang, Hui Zhang, Changxian Zeng, Yunjie Li, Chao Gou, and Hui Yu. Multimodal perception and decision-making systems for complex roads based on foundation models. IEEE Transactions on Systems, Man, and Cybernetics: Systems, 2024.\n[244] Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar. Voyager: An open-ended embodied agent with large language models. arXiv preprint arXiv:2305.16291, 2023.\n[245] Xizhou Zhu, Yuntao Chen, Hao Tian, Chenxin Tao, Weijie Su, Chenyu Yang, Gao Huang, Bin Li, Lewei Lu, Xiaogang Wang, et al. Ghost in the minecraft: Generally capable agents for open-world environments via large language models with text-based knowledge and memory. arXiv preprint arXiv:2305.17144, 2023.\n[246] Sudha Rao, Weijia Xu, Michael Xu, Jorge Leandro, Ken Lobb, Gabriel DesGarennes, Chris Brockett, and Bill Dolan. Collaborative quest completion with llm-driven non-player characters in minecraft. arXiv preprint arXiv:2407.03460, 2024.\n[247] Parsa Hejabi, Elnaz Rahmati, Alireza S Ziabari, Preni Golazizian, Jesse Thomason, and Morteza Dehghani. Evaluating creativity and deception in large language models: A simulation framework for multi-agent balderdash. arXiv preprint arXiv:2411.10422, 2024.\n[248] Haochuan Wang, Xiachong Feng, Lei Li, Zhanyue Qin, Dianbo Sui, and Lingpeng Kong. Tmgbench: A systematic game benchmark for evaluating strategic reasoning abilities of llms. arXiv preprint arXiv:2410.10479, 2024.\n[249] Yizhe Huang, Xingbo Wang, Hao Liu, Fanqi Kong, Aoyang Qin, Min Tang, Xiaoxi Wang, SongChun Zhu, Mingjie Bi, Siyuan Qi, et al. Adasociety: An adaptive environment with social structures for multi-agent decision-making. arXiv preprint arXiv:2411.03865, 2024.\n[250] Zhiqiang Xie, Hao Kang, Ying Sheng, Tushar Krishna, Kayvon Fatahalian, and Christos Kozyrakis. Ai metropo- lis: Scaling large language model-based multi-agent simulation with out-of-order execution. arXiv preprint arXiv:2411.03519, 2024.\n[251] Aviral Kumar, Justin Fu, Matthew Soh, George Tucker, and Sergey Levine. Stabilizing off-policy q-learning via boot- strapping error reduction. Advances in neural information processing systems, 32, 2019.\n[252] Hoang Le, Cameron Voloshin, and Yisong Yue. Batch policy learning under constraints. In International Conference on Machine Learning, pages 3703-3712. PMLR, 2019.\n[253] Aviral Kumar, Aurick Zhou, George Tucker, and Sergey Levine. Conservative q-learning for offline reinforcement learning. Advances in Neural Information Processing Systems, 33:11791191, 2020.\n[254] Ilya Kostrikov, Ashvin Nair, and Sergey Levine. Offline reinforcement learning with implicit qlearning. arXiv preprint arXiv:2110.06169, 2021.\n[255] Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Misha Laskin, Pieter Abbeel, Aravind Srini- vas, and Igor Mordatch. Decision transformer: Reinforcement learning via sequence modeling. Advances in neural information processing systems, 34:15084-15097, 2021.\n[256] Zhendong Wang, Jonathan J Hunt, and Mingyuan Zhou. Diffusion policies as an expressive policy class for offline reinforcement learning. arXiv preprint arXiv:2208.06193, 2022.\n[257] Yixiu Mao, Hongchang Zhang, Chen Chen, Yi Xu, and Xiangyang Ji. Supported value regularization for offline rein- forcement learning. Advances in Neural Information Processing Systems, 36, 2024.\n[258] Yixiu Mao, Cheems Wang, Chen Chen, Yun Qu, and Xiangyang Ji. Offline reinforcement learning with ood state correction and ood action suppression. arXiv preprint arXiv:2410.19400, 2024.\n[259] Yixiu Mao, Qi Wang, Yun Qu, Yuhang Jiang, and Xiangyang Ji. Doubly mild generalization for offline reinforcement learning. arXiv preprint arXiv:2411.07934, 2024.\n[260] Justin Fu, Aviral Kumar, Ofir Nachum, George Tucker, and Sergey Levine. D4rl: Datasets for deep data-driven rein- forcement learning. arXiv preprint arXiv:2004.07219, 2020.\n[261] Jaesik Yoon, Taesup Kim, Ousmane Dia, Sungwoong Kim, Yoshua Bengio, and Sungjin Ahn. Bayesian model-agnostic meta-learning. Advances in neural information processing systems, 31, 2018.\n[262] Kate Rakelly, Aurick Zhou, Chelsea Finn, Sergey Levine, and Deirdre Quillen. Efficient off-policy meta-reinforcement learning via probabilistic context variables. In International conference on machine learning, pages 5331-5340. PMLR, 2019.\n[263] Qi Wang and Herke Van Hoof. Learning expressive meta-representations with mixture of expert neural processes. Advances in neural information processing systems, 35:26242-26255, 2022.\n[264] Luisa Zintgraf, Kyriacos Shiarlis, Maximilian Igl, Sebastian Schulze, Yarin Gal, Katja Hofmann, and Shimon Whiteson. Varibad: A very good method for bayes-adaptive deep rl via meta-learning. arXiv preprint arXiv:1910.08348, 2019.\n[265] Thomas G Dietterich. Hierarchical reinforcement learning with the max q-value function decomposition. Journal of artificial intelligence research, 13:227-303, 2000.\n[266] Tejas D Kulkarni, Karthik Narasimhan, Ardavan Saeedi, and Josh Tenenbaum. Hierarchical deep reinforcement learn- ing: Integrating temporal abstraction and intrinsic motivation. Advances in neural information processing systems, 29, 2016.\n[267] Yun Qu, Boyuan Wang, Jianzhun Shao, Yuhang Jiang, Chen Chen, Zhenbin Ye, Liu Linc, Yang Feng, Lin Lai, Hongyang Qin, et al. Hokoff: real game dataset from honor of kings and its offline reinforcement learning bench- marks. Advances in Neural Information Processing Systems, 36, 2024.\n[268] Dong Chen, Kaian Chen, Zhaojian Li, Tianshu Chu, Rui Yao, Feng Qiu, and Kaixiang Lin. Powernet: Multi-agent deep reinforcement learning for scalable powergrid control. IEEE Transactions on Power Systems, 37(2):1007-1017, 2021.\n[269] Jiawei Dong, Abdulsalam Yassine, Andy Armitage, and M Shamim Hossain. Multi-agent reinforcement learning for intelligent v2g integration in future transportation systems. IEEE Transactions on Intelligent Transportation Systems, 2023.\n[270] Kaiqing Zhang, Zhuoran Yang, Han Liu, Tong Zhang, and Tamer Basar. Fully decentralized multiagent reinforcement learning with networked agents. In International conference on machine learning, pages 5872-5881. PMLR, 2018.\n[271] Peter Sunehag, Guy Lever, Audrunas Gruslys, Wojciech Marian Czarnecki, Vinicius Zambaldi, Max Jaderberg, Marc Lanctot, Nicolas Sonnerat, Joel Z Leibo, Karl Tuyls, et al. Valuedecomposition networks for cooperative multi-agent learning. arXiv preprint arXiv:1706.05296, 2017.\n[272] Tabish Rashid, Mikayel Samvelyan, Christian Schroeder De Witt, Gregory Farquhar, Jakob Foerster, and Shimon Whiteson. Monotonic value function factorisation for deep multi-agent reinforcement learning. Journal of Machine Learning Research, 21(178):1-51, 2020.\n[273] Shengchao Hu, Li Shen, Ya Zhang, and Dacheng Tao. Communication learning in multi-agent systems from graph modeling perspective. arXiv preprint arXiv:2411.00382, 2024.\n[274] Eloi Alonso, Adam Jelley, Vincent Micheli, Anssi Kanervisto, Amos Storkey, Tim Pearce, and Franc, ois Fleuret. Diffu- sion for world modeling: Visual details matter in atari. arXiv preprint arXiv:2405.12399, 2024.\n[275] Yun Qu, Boyuan Wang, Yuhang Jiang, Jianzhun Shao, Yixiu Mao, Cheems Wang, Chang Liu, and Xiangyang Ji. Choices are more important than efforts: Llm enables efficient multi-agent exploration. arXiv preprint arXiv:2410.02511, 2024.\n[276] Yun Qu, Yuhang Jiang, Boyuan Wang, Yixiu Mao, Cheems Wang, Chang Liu, and Xiangyang Ji. Latent reward: Llm-empowered credit assignment in episodic reinforcement learning. arXiv preprint arXiv:2412.11120, 2024.\n[277] Yecheng Jason Ma, Joey Hejna, Ayzaan Wahid, Chuyuan Fu, Dhruv Shah, Jacky Liang, Zhuo Xu, Sean Kirmani, Peng Xu, Danny Driess, et al. Vision language models are in-context value learners. arXiv preprint arXiv:2411.04549, 2024.\n[278] Vincent Lim, Huang Huang, Lawrence Yunliang Chen, Jonathan Wang, Jeffrey Ichnowski, Daniel Seita, Michael Laskey, and Ken Goldberg. Real2sim2real: Self-supervised learning of physical single-step dynamic actions for planar robot casting. In 2022 International Conference on Robotics and Automation (ICRA), pages 8282-8289. IEEE, 2022.\n[279] Ajay Mandlekar, Danfei Xu, Josiah Wong, Soroush Nasiriany, Chen Wang, Rohun Kulkarni, Li Fei-Fei, Silvio Savarese, Yuke Zhu, and Roberto Mart’ın-Mart’ın. What matters in learning from offline human demonstrations for robot manipu- lation. arXiv preprint arXiv:2108.03298, 2021.\n[280] Michael Bain and Claude Sammut. A framework for behavioural cloning. In Machine Intelligence 15, pages 103-129, 1995.\n[281] Brianna Zitkovich, Tianhe Yu, Sichun Xu, Peng Xu, Ted Xiao, Fei Xia, Jialin Wu, Paul Wohlhart, Stefan Welker, Ayzaan Wahid, et al. Rt-2: Vision-language-action models transfer web knowledge to robotic control. In Conference on Robot Learning, pages 2165-2183. PMLR, 2023.\n[282] Yilun Du, Sherry Yang, Bo Dai, Hanjun Dai, Ofir Nachum, Josh Tenenbaum, Dale Schuurmans, and Pieter Abbeel. Learning universal policies via text-guided video generation. Advances in Neural Information Processing Systems, 36, 2024.\n[283] Moo Jin Kim, Karl Pertsch, Siddharth Karamcheti, Ted Xiao, Ashwin Balakrishna, Suraj Nair, Rafael Rafailov, Ethan Foster, Grace Lam, Pannag Sanketi, et al. Openvla: An open-source vision-language-action model. arXiv preprint arXiv:2406.09246, 2024.\n[284] Jake Bruce, Michael D Dennis, Ashley Edwards, Jack Parker-Holder, Yuge Shi, Edward Hughes, Matthew Lai, Aditi Mavalankar, Richie Steigerwald, Chris Apps, et al. Genie: Generative interactive environments. In Forty-first Interna- tional Conference on Machine Learning, 2024.\n[285] Robert McCarthy, Daniel CH Tan, Dominik Schmidt, Fernando Acero, Nathan Herr, Yilun Du, Thomas G Thuruthel, and Zhibin Li. Towards generalist robot learning from internet video: A survey. arXiv preprint arXiv:2404.19664, 2024.\n[286] Qi Wang, Yanghe Feng, Jincai Huang, Yiqin Lv, Zheng Xie, and Xiaoshan Gao. Large-scale generative simulation artificial intelligence: The next hotspot. The Innovation, 4(6), 2023.\n[287] Yufei Wang, Zhou Xian, Feng Chen, Tsun-Hsuan Wang, Yian Wang, Katerina Fragkiadaki, Zackory Erickson, David Held, and Chuang Gan. Robogen: Towards unleashing infinite data for automated robot learning via generative simu- lation. In Forty-first International Conference on Machine Learning, 2024.\n[288] Yunsong Zhou, Michael Simon, Zhenghao Peng, Sicheng Mo, Hongzi Zhu, Minyi Guo, and Bolei Zhou. Simgen: Simulator-conditioned driving scene generation. arXiv preprint arXiv:2406.09386, 2024.\n[289] Jenny Zhang, Joel Lehman, Kenneth Stanley, and Jeff Clune. Omni: Open-endedness via models of human notions of interestingness. In The Twelfth International Conference on Learning Representations, 2023.\n[290] Maxence Faldor, Jenny Zhang, Antoine Cully, and Jeff Clune. Omni-epic: Open-endedness via models of human notions of interestingness with environments programmed in code. arXiv preprint arXiv:2405.15568, 2024.\n[291] Abhishek Kadian, Joanne Truong, Aaron Gokaslan, Alexander Clegg, Erik Wijmans, Stefan Lee, Manolis Savva, Sonia Chernova, and Dhruv Batra. Sim2real predictivity: Does evaluation in simulation predict real-world performance? IEEE Robotics and Automation Letters, 5(4):66706677, 2020.\n[292] Lilian Weng. Llm-powered autonomous agents. lilianweng.github.io, Jun 2023.\n[293] Kevin J. Lang, Alex Waibel, and Geoffrey E. Hinton. A time-delay neural network architecture for isolated word recognition. Neural Networks, 3(1):23-43, 1990.\n[294] Jeffrey L. Elman. Finding structure in time. Cogn. Sci., 14(2):179-211, 1990.\n[295] Ronald J. Williams and David Zipser. A learning algorithm for continually running fully recurrent neural networks. Neural Comput., 1(2):270-280, 1989.\n[296] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural Comput., 9(8):17351780, 1997.\n[297] Anthony J Robinson and Frank Fallside. The utility driven dynamic error propagation network, volume 11. University of Cambridge Department of Engineering Cambridge, 1987.\n[298] C. Lee Giles, Clifford B. Miller, Dong Chen, Hsing-Hen Chen, Guo-Zheng Sun, and Yee-Chun Lee. Learning and extracting finite state automata with second-order recurrent neural networks. Neural Comput., 4(3):393-405, 1992.\n[299] Ilya Sutskever, Oriol Vinyals, and Quoc V. Le. Sequence to sequence learning with neural networks. In Zoubin Ghahramani, Max Welling, Corinna Cortes, Neil D. Lawrence, and Kilian Q. Weinberger, editors, Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems 2014, December 8-13 2014, Montreal, Quebec, Canada, pages 3104-3112, 2014.\n[300] Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. End-to-end memory networks. In Corinna Cortes, Neil D. Lawrence, Daniel D. Lee, Masashi Sugiyama, and Roman Garnett, editors, Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems 2015, December 7-12, 2015, Montreal, Quebec, Canada, pages 2440-2448, 2015.\n[301] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly learning to align and translate. In Yoshua Bengio and Yann LeCun, editors, 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings, 2015.\n[302] Johan Westo\", Patrick J. C. May, and Hannu Tiitinen. Memory stacking in hierarchical networks. Neural Comput., 28(2):327-353, 2016.\n[303] Jason Weston. Memory networks for recommendation. In Paolo Cremonesi, Francesco Ricci, Shlomo Berkovsky, and Alexander Tuzhilin, editors, Proceedings of the Eleventh ACM Conference on Recommender Systems, RecSys 2017, Como, Italy, August 27-31, 2017, page 4. ACM, 2017.\n[304] Jack W. Rae, Anna Potapenko, Siddhant M. Jayakumar, Chloe Hillier, and Timothy P. Lillicrap. Compressive trans- formers for long-range sequence modelling. In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net, 2020.\n[305] Zihang Dai, Zhilin Yang, Yiming Yang, Jaime G. Carbonell, Quoc Viet Le, and Ruslan Salakhutdinov. Transformer-xl: Attentive language models beyond a fixed-length context. In Anna Korhonen, David R. Traum, and Llu’is Ma`rquez, editors, Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019, Florence, Italy, July 28-August 2, 2019, Volume 1: Long Papers, pages 2978-2988. Association for Computational Linguistics, 2019.\n[306] David R. So, Quoc V. Le, and Chen Liang. The evolved transformer. In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, Proceedings of the 36th International Conference on Machine Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA, volume 97 of Proceedings of Machine Learning Research, pages 5877-5886. PMLR, 2019.\n[307] Mostafa Dehghani, Stephan Gouws, Oriol Vinyals, Jakob Uszkoreit, and Lukasz Kaiser. Universal transformers. In 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. OpenRe- view.net, 2019.\n[308] Patrick S. H. Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Ku\"ttler, Mike Lewis, Wen-tau Yih, Tim Rockta\"schel, Sebastian Riedel, and Douwe Kiela. Retrieval-augmented gen- eration for knowledge-intensive NLP tasks. In Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin, editors, Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, 2020.\n[309] Albert Gu and Tri Dao. Mamba: Linear-time sequence modeling with selective state spaces. CoRR, abs/2312.00752, 2023.\n[310] Earl D. Sacerdoti. The nonlinear nature of plans. In Advance Papers of the Fourth International Joint Conference on Artificial Intelligence, Tbilisi, Georgia, USSR, September 3-8, 1975, pages 206-214, 1975.\n[311] Peter E. Hart, Nils J. Nilsson, and Bertram Raphael. A formal basis for the heuristic determination of minimum cost paths. IEEE Trans. Syst. Sci. Cybern., 4(2):100-107, 1968.\n[312] Richard Fikes and Nils J. Nilsson. STRIPS: A new approach to the application of theorem proving to problem solving. In D. C. Cooper, editor, Proceedings of the 2nd International Joint Conference on Artificial Intelligence. London, UK, September 1-3, 1971, pages 608-620. William Kaufmann, 1971.\n[313] David Ha and Jürgen Schmidhuber. World models. CoRR, abs/1803.10122, 2018.\n[314] Jacob Andreas, Marcus Rohrbach, Trevor Darrell, and Dan Klein. Neural module networks. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 39-48, 2016.\n[315] Scott E. Reed and Nando de Freitas. Neural programmer-interpreters. In Yoshua Bengio and Yann LeCun, editors, 4th International Conference on Learning Representations, ICLR 2016, San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings, 2016.\n[316] Timo Schick, Jane Dwivedi-Yu, Roberto Dess`1, Roberta Raileanu, Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to use tools. In Alice Oh, Tristan Naumann, Amir Globerson, Kate Saenko, Moritz Hardt, and Sergey Levine, editors, Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10-16, 2023, 2023.\n[317] Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, Sihan Zhao, Lauren Hong, Runchu Tian, Ruobing Xie, Jie Zhou, Mark Gerstein, Dahai Li, Zhiyuan Liu, and Maosong Sun. Toolllm: Facilitating large language models to master 16000+ real-world apis. In The Twelfth International Conference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11, 2024. OpenReview.net, 2024.\n[318] Zhiyong Wu, Chengcheng Han, Zichen Ding, Zhenmin Weng, Zhoumianze Liu, Shunyu Yao, Tao Yu, and Lingpeng Kong. Os-copilot: Towards generalist computer agents with self-improvement. CoRR, abs/2402.07456, 2024.\n[319] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik R. Narasimhan, and Yuan Cao. React: Synergizing reasoning and acting in language models. In The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net, 2023.\n好的，这是从[320]开始继续整理的参考文献格式：\n[320] Shuofei Qiao, Runnan Fang, Ningyu Zhang, Yuqi Zhu, Xiang Chen, Shumin Deng, Yong Jiang, Pengjun Xie, Fei Huang, and Huajun Chen. Agent planning with world knowledge model. CoRR, abs/2405.14205, 2024.\n[321] Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar. Voyager: An open-ended embodied agent with large language models. Trans. Mach. Learn. Res., 2024, 2024.\n[322] Huandong Wang, Huan Yan, Can Rong, Yuan Yuan, Fenyu Jiang, Zhenyu Han, Hongjie Sui, Depeng Jin, and Yong Li. Multi-scale simulation of complex systems: a perspective of integrating knowledge and data. ACM Computing Surveys, 56(12):1-38, 2024.\n[323] Mohamed Amine Ben Rabia and Adil Bellabdaoui. Simulation-based analytics: A systematic literature review. Simu- lation Modelling Practice and Theory, 117:102511, 2022.\n[324] Bin Chen, Runkang Guo, Zhengqiu Zhu, Yong Zhao, Yatai Ji, Aiguo Chen, and Guangquan Cheng. A novel research pattern for the simulation of complex systems sigd. Journal of System Simulation, 36(12):2993, 2024.\n[325] Xiao Xue, Xiangning Yu, and Fei-Yue Wang. Chatgpt chats on computational experiments: From interactive intelli- gence to imaginative intelligence for design of artificial societies and optimization of foundational models. IEEE/CAA Journal of Automatica Sinica, 10(6):1357-1360, 2023.\n[326] Yong Zhao, Zhengqiu Zhu, Bin Chen, Sihang Qiu, Jincai Huang, Xin Lu, Weiyi Yang, Chuan Ai, Kuihua Huang, Cheng He, et al. Towards parallel intelligence: An interdisciplinary solution for complex systems. The Innovation, 2023.\n[327] Tianyuan Dai, Josiah Wong, Yunfan Jiang, Chen Wang, Cem Gokmen, Ruohan Zhang, Jiajun Wu, and Li Fei-Fei. Automated creation of digital cousins for robust policy learning. arXiv preprint arXiv:2410.07408, 2024.\n[328] Thomas Allen. Us department of defense modeling and simulation: new approaches and initiatives. Information \u0026 Security an International Journal, 23(23):32-48, 2009.\n[329] Xinyi Mou, Xuanwen Ding, Qi He, Liang Wang, Jingcong Liang, Xinnong Zhang, Libo Sun, Jiayu Lin, Jie Zhou, Xuanjing Huang, et al. From individual to society: A survey on social simulation driven by large language model-based agents. arXiv preprint arXiv:2412.03563, 2024.\n[330] Alexander Lavin, David Krakauer, Hector Zenil, Justin Gottschlich, Tim Mattson, Johann Brehmer, Anima Anandku- mar, Sanjay Choudry, Kamil Rocki, Atılım Gu\"nes, Baydin, et al. Simulation intelligence: Towards a new generation of scientific methods. arXiv preprint arXiv:2112.03235, 2021.\n[331] Lin Wu, Lizhe Wang, Nan Li, Tao Sun, Tangwen Qian, Yu Jiang, Fei Wang, and Yongjun Xu. Modeling the covid-19 outbreak in china through multi-source information fusion. The Innovation, 1(2), 2020.\n[332] Zhengqiu Zhu, Bin Chen, Hailiang Chen, Sihang Qiu, Changjun Fan, Yong Zhao, Runkang Guo, Chuan Ai, Zhong Liu, Zhiming Zhao, et al. Strategy evaluation and optimization with an artificial society toward a pareto optimum. The Innovation, 3(5), 2022.\n[333] Bin Chen, Runkang Guo, Zhengqiu Zhu, Chuan Ai, and Xiaogang Qiu. Simulation of covid-19 outbreak in nanjing lukou airport based on complex dynamical networks. Complex System Modeling and Simulation, 3(1):71-82, 2023.\n[334] Aleksei Petrenko, Erik Wijmans, Brennan Shacklett, and Vladlen Koltun. Megaverse: Simulating embodied agents at one million experiences per second. In International Conference on Machine Learning, pages 8556-8566. PMLR, 2021.\n[335] Yandan Yang, Baoxiong Jia, Peiyuan Zhi, and Siyuan Huang. Physcene: Physically interactable 3d scene synthesis for embodied ai. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 16262-16272, 2024.\n[336] Marcelo Jacinto, Joa~o Pinto, Jay Patrikar, John Keller, Rita Cunha, Sebastian Scherer, and António Pascoal. Pega- sus simulator: An isaac sim framework for multiple aerial vehicles simulation. In 2024 International Conference on Unmanned Aircraft Systems (ICUAS), pages 917922. IEEE, 2024.\n[337] Kanishka Rao, Chris Harris, Alex Irpan, Sergey Levine, Julian Ibarz, and Mohi Khansari. Rlcyclegan: Reinforce- ment learning aware simulation-to-real. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11157-11166, 2020.\n[338] Kaiqu Liang, Haimin Hu, Ryan Liu, Thomas L Griffiths, and Jaime Ferna’ndez Fisac. Rlhs: Mitigating misalignment in rlhf with hindsight simulation. arXiv preprint arXiv:2501.08617, 2025.\n[339] Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al. Emergent abilities of large language models. arXiv preprint arXiv:2206.07682, 2022.\n[340] Anthony Brohan, Noah Brown, Justice Carbajal, Yevgen Chebotar, Joseph Dabis, Chelsea Finn, Keerthana Gopalakr- ishnan, Karol Hausman, Alex Herzog, Jasmine Hsu, et al. Rt-1: Robotics transformer for real-world control at scale. arXiv preprint arXiv:2212.06817, 2022.\n[341] Trevor Strohman, Donald Metzler, Howard Turtle, and W Bruce Croft. Indri: A language modelbased search engine for complex queries. In Proceedings of the international conference on intelligent analysis, pages 2-6. Washington, DC., 2005.\n[342] David Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew Lai, Arthur Guez, Marc Lanctot, Laurent Sifre, Dharshan Kumaran, Thore Graepel, et al. Mastering chess and shogi by self-play with a general rein- forcement learning algorithm. arXiv preprint arXiv:1712.01815, 2017.\n[343] Gerald Tesauro. Td-gammon, a self-teaching backgammon program, achieves master-level play. Neural computation, 6(2):215-219, 1994.\n[344] Dmitry Kalashnikov, Alex Irpan, Peter Pastor, Julian Ibarz, Alexander Herzog, Eric Jang, Deirdre Quillen, Ethan Holly, Mrinal Kalakrishnan, Vincent Vanhoucke, et al. Scalable deep reinforcement learning for vision-based robotic manip- ulation. In Conference on robot learning, pages 651-673. PMLR, 2018.\n[345] Ilge Akkaya, Marcin Andrychowicz, Maciek Chociej, Mateusz Litwin, Bob McGrew, Arthur Petron, Alex Paino, Matthias Plappert, Glenn Powell, Raphael Ribas, et al. Solving rubik’s cube with a robot hand. arXiv preprint arXiv:1910.07113, 2019.\n[346] Jiankai Sun, De-An Huang, Bo Lu, Yun-Hui Liu, Bolei Zhou, and Animesh Garg. Plate: Visuallygrounded planning with transformers in procedural tasks. IEEE Robotics and Automation Letters, 7(2):4924-4930, 2022.\n[347] Wenjie Liu, Jian Sun, Gang Wang, Francesco Bullo, and Jie Chen. Data-driven resilient predictive control under denial- of-service. IEEE Transactions on Automatic Control, 68(8):4722-4737, August 2023.\n[348] Dingyuan Zhang, Dingkang Liang, Hongcheng Yang, Zhikang Zou, Xiaoqing Ye, Zhe Liu, and Xiang Bai. Sam3d: Zero-shot 3d object detection via segment anything model. arXiv preprint arXiv:2306.02245, 2023.\n[349] Yining Hong, Haoyu Zhen, Peihao Chen, Shuhong Zheng, Yilun Du, Zhenfang Chen, and Chuang Gan. 3d-llm: Injecting the 3d world into large language models. Advances in Neural Information Processing Systems, 36:20482-20494, 2023.\n[350] William Chen, Siyi Hu, Rajat Talak, and Luca Carlone. Leveraging large language models for robot 3d scene under- standing. arXiv preprint arXiv:2209.05629, 2022.\n[351] Weipu Zhang, Gang Wang, Jian Sun, Yetian Yuan, and Gao Huang. STORM: Efficient stochastic transformer based world models for reinforcement learning. Advances in Neural Information Processing Systems, 36, 2024.\n[352] Zhaohan Feng, Jie Chen, Wei Xiao, Jian Sun, Bin Xin, and Gang Wang. Learning hybrid policies for MPC with application to drone flight in unknown dynamic environments. Unmanned Systems, 12(02):429-441, 2024.\n[353] Ziyu Zhou, Gang Wang, Jian Sun, Jikai Wang, and Jie Chen. Efficient and robust time-optimal trajectory planning and control for agile quadrotor flight. IEEE Robotics and Automation Letters, 8(12):7913-7920, December 2023.\n[354] Yetian Yuan, Shuze Wang, Yunpeng Mei, Weipu Zhang, Jian Sun, and Gang Wang. Improving world models for robot arm grasping with backward dynamics prediction. International Journal of Machine Learning and Cybernetics, 15:3879-3891, April 2024.\n[355] Yitao Jiang, Luyang Zhao, Alberto Quattrini Li, Muhao Chen, and Devin Balkcom. Exploring spontaneous social interaction swarm robotics powered by large language models.\n[356] Zhao Mandi, Homanga Bharadhwaj, Vincent Moens, Shuran Song, Aravind Rajeswaran, and Vikash Kumar. Cacti: A framework for scalable multi-task multi-scene visual imitation learning. arXiv preprint arXiv:2212.05711, 2022.\n[357] Norman Di Palo, Arunkumar Byravan, Leonard Hasenclever, Markus Wulfmeier, Nicolas Heess, and Martin Riedmiller. Towards a unified agent with foundation models. arXiv preprint arXiv:2307.09668, 2023.\n[358] Minae Kwon, Sang Michael Xie, Kalesha Bullard, and Dorsa Sadigh. Reward design with language models. arXiv preprint arXiv:2303.00001, 2023.\n[359] Yifan Du, Junyi Li, Tianyi Tang, Wayne Xin Zhao, and Ji-Rong Wen. Zero-shot visual question answering with language model feedback. arXiv preprint arXiv:2305.17006, 2023.\n[360] Ramdane Tami, Boussaad Soualmi, Abdelkrim Doufene, Javier Ibanez, and Justin Dauwels. Machine learning method to ensure robust decision-making of avs. In 2019 IEEE Intelligent Transportation Systems Conference (ITSC), pages 1217-1222. IEEE, 2019.\n[361] Shengxi Gui, Shuang Song, Rongjun Qin, and Yang Tang. Remote sensing object detection in the deep learning era—a review. Remote Sensing, 16(2):327, 2024.\n[362] Ranganath R Navalgund, V Jayaraman, and PS Roy. Remote sensing applications: An overview. current science, pages 1747-1766, 2007.\n[363] Philipe Dias, Abhishek Potnis, Sreelekha Guggilam, Lexie Yang, Aristeidis Tsaris, Henry Medeiros, and Dalton Lunga. An agenda for multimodal foundation models for earth observation. In IGARSS 2023-2023 IEEE International Geo- science and Remote Sensing Symposium, pages 1237-1240. IEEE, 2023.\n[364] Yuchi Ma, Shuo Chen, Stefano Ermon, and David B Lobell. Transfer learning in environmental remote sensing. Remote Sensing of Environment, 301:113924, 2024.\n[365] Yezhen Cong, Samar Khanna, Chenlin Meng, Patrick Liu, Erik Rozi, Yutong He, Marshall Burke, David Lobell, and Stefano Ermon. Satmae: Pre-training transformers for temporal and multispectral satellite imagery. Advances in Neural Information Processing Systems, 35:197-211, 2022.\n[366] Colorado J Reed, Ritwik Gupta, Shufan Li, Sarah Brockman, Christopher Funk, Brian Clipp, Kurt Keutzer, Salvatore Candido, Matt Uyttendaele, and Trevor Darrell. Scale-mae: A scale-aware masked autoencoder for multiscale geospatial representation learning. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 4088-4099, 2023.\n[367] Xinye Wanyan, Sachith Seneviratne, Shuchang Shen, and Michael Kirley. Extending global-local view alignment for self-supervised learning with remote sensing imagery. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 2443-2453, 2024.\n[368] Wade A. Smith and Robert B. Randall. Rolling element bearing diagnostics using the case western reserve university data: A benchmark study. Mechanical Systems and Signal Processing, 64-65:100-131, 2015.\n[369] Yuma Koizumi, Shoichiro Saito, Hisashi Uematsu, Noboru Harada, and Keisuke Imoto. Toyadmos: A dataset of miniature-machine operating sounds for anomalous sound detection. In 2019 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA), pages 313-317, 2019.\n[370] Yunwei Zhang, Qiaochu Tang, Yao Zhang, Jiabin Wang, Ulrich Stimming, and Alpha Lee. Identifying degradation pat- terns of lithium ion batteries from impedance spectroscopy using machine learning. Nature Communications, 11:1706, 042020.\n[371] Yinjiao Xing, Wei He, Michael Pecht, and Kwok Leung Tsui. State of charge estimation of lithiumion batteries using the open-circuit voltage at various ambient temperatures. Applied energy, 113:106-115, 2014.\n[372] Erik Jakobsson, Erik Frisk, Mattias Krysander, and Robert Pettersson. A dataset for fault classification in rock drills, a fast oscillating hydraulic system. In Annual Conference of the PHM Society, 2022.\n[373] Yuhong Jin, Lei Hou, and Yushu Chen. A time series transformer based method for the rotating machinery fault diagnosis. Neurocomputing, 494:379-395, 2022.\n[374] Xiaohong Wang, Xudong Jiang, Henghui Ding, Yuqian Zhao, and Jun Liu. Knowledge-aware deep framework for collaborative skin lesion segmentation and melanoma recognition. Pattern Recognition, 120:108075, 2021.\n[375] Qi Li, Jinfeng Huang, Hongliang He, Xinran Zhang, Feibin Zhang, Zhaoye Qin, and Fulei Chu. Vsllava: a pipeline of large multimodal foundation model for industrial vibration signal analysis, 2024.\n[376] Arash Ajoudani, Andrea Maria Zanchettin, Serena Ivaldi, Alin Albu-Scha\"ffer, Kazuhiro Kosuge, and Oussama Khatib. Progress and prospects of the human-robot collaboration. Autonomous Robots, 42, 062018.\n[377] Maximilian Diehl, Chris Paxton, and Karinne Ramirez-Amaro. Automated generation of robotic planning domains from observations. In 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pages 6732-6738, 2021.\n[378] Keisuke Shirai, Cristian C. Beltran-Hernandez, Masashi Hamaya, Atsushi Hashimoto, Shohei Tanaka, Kento Kawa- harazuka, Kazutoshi Tanaka, Yoshitaka Ushiku, and Shinsuke Mori. Visionlanguage interpreter for robot task planning. In 2024 IEEE International Conference on Robotics and Automation (ICRA), pages 2051-2058, 2024.\n[379] Meng-Lun Lee, Sara Behdad, Xiao Liang, and Minghui Zheng. Task allocation and planning for product disassembly with human-robot collaboration. Robotics and Computer-Integrated Manufacturing, 76:102306, 2022.\n[380] Tian Yu, Jing Huang, and Qing Chang. Optimizing task scheduling in human-robot collaboration with deep multi-agent reinforcement learning. Journal of Manufacturing Systems, 60:487-499, 2021.\n[381] Anthony Brohan, Noah Brown, Justice Carbajal, Yevgen Chebotar, Joseph Dabis, Chelsea Finn, Keerthana Gopalakrish- nan, Karol Hausman, Alex Herzog, Jasmine Hsu, Julian Ibarz, Brian Ichter, Alex Irpan, Tomas Jackson, Sally Jesmonth, Nikhil J Joshi, Ryan Julian, Dmitry Kalashnikov, Yuheng Kuang, Isabel Leal, Kuang-Huei Lee, Sergey Levine, Yao Lu, Utsav Malla, Deeksha Manjunath, Igor Mordatch, Ofir Nachum, Carolina Parada, Jodilyn Peralta, Emily Perez, Karl Pertsch, Jornell Quiambao, Kanishka Rao, Michael Ryoo, Grecia Salazar, Pannag Sanketi, Kevin Sayed, Jaspiar Singh, Sumedh Sontakke, Austin Stone, Clayton Tan, Huong Tran, Vincent Vanhoucke, Steve Vega, Quan Vuong, Fei Xia, Ted Xiao, Peng Xu, Sichun Xu, Tianhe Yu, and Brianna Zitkovich. Rt-1: Robotics transformer for real-world control at scale, 2023.\n[382] Waleed Ejaz, Shree K. Sharma, Salman Saadat, Muhammad Naeem, Alagan Anpalagan, and N.A. Chughtai. A com- prehensive survey on resource allocation for cran in 5 g and beyond networks. Journal of Network and Computer Applications, 160:102638, 2020.\n[383] Gerald Kelechi Ijemaru, Ibrahim Adeyanju, Kehinde Olusuyi, T Ofusori, E Ngharamike, and AA Sobowale. Security challenges of wireless communications networks: a survey. Int. J. Appl. Eng. Res, 13(8):5680-5692, 2018.\n[384] Yifei Xu, Yuning Chen, Xumiao Zhang, Xianshang Lin, Pan Hu, Yunfei Ma, Songwu Lu, Wan Du, Zhuoqing Mao, Ennan Zhai, and Dennis Cai. Cloudeval-yaml: A practical benchmark for cloud configuration generation. In P. Gibbons, G. Pekhimenko, and C. De Sa, editors, Proceedings of Machine Learning and Systems, volume 6, pages 173-195, 2024.\n[385] Zhengfu He, Tianxiang Sun, Kuanning Wang, Xuanjing Huang, and Xipeng Qiu. Diffusionbert: Improving generative masked language models with diffusion models, 2022.\n[386] Rajdeep Mondal, Alan Tang, Ryan Beckett, Todd Millstein, and George Varghese. What do llms need to synthesize correct router configurations? In Proceedings of the 22nd ACM Workshop on Hot Topics in Networks, HotNets ‘23, page 189-195, New York, NY, USA, 2023. Association for Computing Machinery.\n[387] Sathiya Kumaran Mani, Yajie Zhou, Kevin Hsieh, Santiago Segarra, Trevor Eberl, Eliran Azulai, Ido Frizler, Ranveer Chandra, and Srikanth Kandula. Enhancing network management using code generated by large language models. In Proceedings of the 22nd ACM Workshop on Hot Topics in Networks, HotNets ‘23, page 196-204, New York, NY, USA, 2023. Association for Computing Machinery.\n[388] Markus Bayer, Philipp Kuehn, Ramin Shanehsaz, and Christian Reuter. Cysecbert: A domainadapted language model for the cybersecurity domain. ACM Transactions on Privacy and Security, 27(2):1-20, 2024.\n[389] Ehsan Aghaei, Xi Niu, Waseem Shadid, and Ehab Al-Shaer. Securebert: A domain-specific language model for cy- bersecurity. In International Conference on Security and Privacy in Communication Systems, pages 39-56. Springer, 2022.\n[390] Mohamed Amine Ferrag, Mthandazo Ndhlovu, Norbert Tihanyi, Lucas C Cordeiro, Merouane Debbah, Thierry Lestable, and Narinderjit Singh Thandi. Revolutionizing cyber threat detection with large language models: A privacy- preserving bert-based lightweight model for iot/iiot devices. IEEE Access, 2024.\n[391] Luiz Rodrigues, Filipe Dwan Pereira, Luciano Cabral, Dragan Gas`evic’, Geber Ramalho, and Rafael Ferreira Mello. As- sessing the quality of automatic-generated short answers using gpt-4. Computers and Education: Artificial Intelligence, 7:100248, 2024.\n[392] Nan Wu, Jun Xu, Jinqing Linghu, and Jie Huang. Real-time optimal control and dispatching strategy of multi-microgrid energy based on storage collaborative. International Journal of Electrical Power \u0026 Energy Systems, 160:110063, 2024.\n[393] L Huang. “big watt” to promote the application of power ai in the future., 2024.\n[394] Tanveer Ahmad, Hongyu Zhu, Dongdong Zhang, Rasikh Tariq, A Bassam, Fasee Ullah, Ahmed S AlGhamdi, and Sultan S Alshamrani. Energetics systems and artificial intelligence: Applications of industry 4.0. Energy Reports, 8:334-361, 2022.\n[395] Nils H van der Blij, Laura M Ramirez-Elizondo, Matthijs TJ Spaan, and Pavol Bauer. Grid sense multiple access: A decentralized control algorithm for dc grids. International Journal of Electrical Power \u0026 Energy Systems, 119:105818, 2020.\n[396] Zohaib Jan, Farhad Ahamed, Wolfgang Mayer, Niki Patel, Georg Grossmann, Markus Stumptner, and Ana Kuusk. Artificial intelligence for industry 4.0: Systematic review of applications, challenges, and opportunities. Expert Systems with Applications, 216:119456, 2023.\n[397] Tingting Chen, Vignesh Sampath, Marvin Carl May, Shuo Shan, Oliver Jonas Jorg, Juan Jose’ Aguilar Mart’ın, Florian Stamer, Gualtiero Fantoni, Guido Tosello, and Matteo Calaon. Machine learning in manufacturing towards industry 4.0: From ‘for now’ to ‘four-know’. Applied Sciences, 13(3), 2023.\n[398] Senthil Kumar Jagatheesaperumal, Mohamed Rahouti, Kashif Ahmad, Ala Al-Fuqaha, and Mohsen Guizani. The duo of artificial intelligence and big data for industry 4.0: Applications, techniques, challenges, and future research directions. IEEE Internet of Things Journal, 9(15):12861-12885, 2022.\n[399] National Research Council, Division on Engineering, Physical Sciences, Board on Mathematical Sciences, Their Ap- plications, Committee on Mathematical Foundations of Verification, and Uncertainty Quantification. Assessing the reliability of complex models: mathematical and statistical foundations of verification, validation, and uncertainty quantification. National Academies Press, 2012.\n[400] Charu C Aggarwal, Lagerstrom-Fife Aggarwal, and Lagerstrom-Fife. Linear algebra and optimization for machine learning, volume 156. Springer, 2020.\n[401] Guangchuang Yu. Thirteen years of clusterprofiler. The Innovation, 5(6), 2024.\n[402] Iman Ahmadianfar, Omid Bozorg-Haddad, and Xuefeng Chu. Gradient-based optimizer: A new metaheuristic opti- mization algorithm. Information Sciences, 540:131-159, 2020.\n[403] Haidong Li, Hongchuang Li, Ming Zhang, Chaolin Huang, and Xin Zhou. Direct imaging of pulmonary gas exchange with hyperpolarized xenon mri. The Innovation, 5(6), 2024.\n[404] Matthias Seeger, Florian Steinke, and Koji Tsuda. Bayesian inference and optimal design in the sparse linear model. In Artificial Intelligence and Statistics, pages 444-451. PMLR, 2007.\n[405] Kellie J Archer, Han Fu, Krzysztof Mro’zek, Deedra Nicolet, Alice S Mims, Geoffrey L Uy, Wendy Stock, John C Byrd, Wolfgang Hiddemann, Klaus H Metzeler, et al. Improving risk stratification for 2022 european leukemianet favorable-risk patients with acute myeloid leukemia. The Innovation, 5(6), 2024.\n[406] Christof Koch and Idan Segev. The role of single neurons in information processing. Nature neuroscience, 3(11):1171-1177, 2000.\n[407] Changyong Dou, Yunwei Tang, Nijun Jiang, Lin Yan, and Haifeng Ding. Analysis of sichuan wildfire based on the first synergetic observation from three payloads of sdgsat-1. The Innovation, 5(6), 2024.\n[408] Simon Haykin and Neural Network. A comprehensive foundation. Neural networks, 2(2004):41, 2004.\n[409] Salman Khan, Muzammal Naseer, Munawar Hayat, Syed Waqas Zamir, Fahad Shahbaz Khan, and Mubarak Shah. Transformers in vision: A survey. ACM computing surveys (CSUR), 54(10s):141, 2022.\n[410] Yi Tay, Dara Bahri, Donald Metzler, Da-Cheng Juan, Zhe Zhao, and Che Zheng. Synthesizer: Rethinking self-attention for transformer models. In International conference on machine learning, pages 10183-10192. PMLR, 2021.\n[411] Dandan Ma, Yuzhe Ma, Jinfu Ma, Qun Yang, Claudia Felser, and Guowei Li. Energy conversion materials need phonons. The Innovation, 5(6), 2024.\n[412] Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168, 2021.\n[413] Le’on Bottou. Stochastic gradient descent tricks. In Neural Networks: Tricks of the Trade: Second Edition, pages 421-436. Springer, 2012.\n[414] Yali Cui, Yi Wu, and Yingjin Yuan. Amplification editing empowers in situ large-scale dna duplication. The Innovation, 5(6), 2024.\n[415] Peng Xiao, Yongfeng Yin, Bin Liu, Bo Jiang, and Yashwant K Malaiya. Adaptive testing based on moment estimation. IEEE Transactions on Systems, Man, and Cybernetics: Systems, 50(3):911922, 2017.\n[416] Sujuan Xu, Runzhou Chen, Xinqi Zhang, Yufeng Wu, Liuyan Yang, Zongyi Sun, Zhitao Zhu, Aiping Song, Ze Wu, Ting Li, et al. The evolutionary tale of lilies: Giant genomes derived from transposon insertions and polyploidization. The Innovation, 5(6), 2024.\n[417] George Em Karniadakis, Ioannis G Kevrekidis, Lu Lu, Paris Perdikaris, Sifan Wang, and Liu Yang. Physics-informed machine learning. Nature Reviews Physics, 3(6):422-440, 2021.\n[418] Angran Li, Ruijia Chen, Amir Barati Farimani, and Yongjie Jessica Zhang. Reaction diffusion system prediction based on convolutional neural network. Scientific reports, 10(1):3894, 2020.\n[419] Stephan Rasp, Michael S Pritchard, and Pierre Gentine. Deep learning to represent subgrid processes in climate models. Proceedings of the national academy of sciences, 115(39):9684-9689, 2018.\n[420] Kamal Choudhary, Brian DeCost, Chi Chen, Anubhav Jain, Francesca Tavazza, Ryan Cohn, Cheol Woo Park, Alok Choudhary, Ankit Agrawal, Simon JL Billinge, et al. Recent advances and applications of deep learning methods in materials science. npj Computational Materials, 8(1):59, 2022.\n[421] Nan Xu, Wenyu Li, Peng Gong, and Hui Lu. Satellite altimeter observed surface water increase across lake-rich regions of the arctic. The Innovation, 5(6), 2024.\n[422] Samuel Kim, Peter Y Lu, Srijon Mukherjee, Michael Gilbert, Li Jing, Vladimir C eperic', and Marin Soljacic’. Integration of neural network-based symbolic regression in deep learning for scientific discovery. IEEE transactions on neural networks and learning systems, 32(9):4166-4177, 2020.\n[423] Guillaume Lample and Franc, ois Charton. Deep learning for symbolic mathematics. International Conference on Learning Representations, 2019.\n[424] Jakub Voznica, Anna Zhukova, Veronika Boskova, E Saulnier, F Lemoine, Mathieu MoslonkaLefebvre, and Olivier Gascuel. Deep learning from phylogenies to uncover the epidemiological dynamics of outbreaks. Nature Communica- tions, 13(1):3896, 2022.\n[425] Ahmet Murat Ozbayoglu, Mehmet Ugur Gudelek, and Omer Berat Sezer. Deep learning for financial applications: A survey. Applied soft computing, 93:106384, 2020.\n[426] Eric Edelman, Fabian Tijssen, Popke Rein Munniksma, Wim Bast, Harold Ten Bohmer, Nicole van Eldik, Marieke Spreeuwenberg, Wolfgang Buhre, and Frits van Merode. Clinical knowledge modeling: An essential step in the digital transformation of healthcare. The Innovation, 5(6), 2024.\n[427] Xiyi Yang, Jia Jia, Xiaoyu Zhou, and Shouyang Wang. The future of artificial intelligence: Time to embrace more international collaboration. The Innovation, 5(6), 2024.\n[428] Muning Wen, Runji Lin, Hanjing Wang, Yaodong Yang, Ying Wen, Luo Mai, Jun Wang, Haifeng Zhang, and Weinan Zhang. Large sequence models for sequential decision-making: a survey. Frontiers of Computer Science, 17(6):176349, 2023.\n[429] Weinan. Zhang. Large decision models. International Joint Conferences on Artificial Intelligence, pages 7062-7067, 2023.\n[430] Xu Wang, Sen Wang, Xingxing Liang, Dawei Zhao, Jincai Huang, Xin Xu, Bin Dai, and Qiguang Miao. Deep re- inforcement learning: A survey. IEEE Transactions on Neural Networks and Learning Systems, 35(4):5064-5078, 2022.\n[431] Emre Oral, Ria Chawla, Michel Wijkstra, Narges Mahyar, and Evanthia Dimara. From information to choice: A critical inquiry into visualization tools for decision making. IEEE Transactions on Visualization and Computer Graphics, 2023.\n[432] Zheng Chu, Jingchang Chen, Qianglong Chen, Weijiang Yu, Tao He, Haotian Wang, Weihua Peng, Ming Liu, Bing Qin, and Ting Liu. A survey of chain of thought reasoning: Advances, frontiers and future. arXiv preprint arXiv:2309.15402, 2023.\n[433] Tianyang Lin, Yuxin Wang, Xiangyang Liu, and Xipeng Qiu. A survey of transformers. AI open, 3:111-132, 2022.\n[434] Tianyu Wu, Shizhu He, Jingping Liu, Siqi Sun, Kang Liu, Qing-Long Han, and Yang Tang. A brief overview of chatgpt: The history, status quo and potential future development. IEEE/CAA Journal of Automatica Sinica, 10(5):1122-1136, 2023.\n[435] Michael Moor, Oishi Banerjee, Zahra Shakeri Hossein Abad, Harlan M Krumholz, Jure Leskovec, Eric J Topol, and Pranav Rajpurkar. Foundation models for generalist medical artificial intelligence. Nature, 616(7956):259-265, 2023.\n[436] Tao Tu, Shekoofeh Azizi, Danny Driess, Mike Schaekermann, Mohamed Amin, Pi-Chuan Chang, Andrew Carroll, Charles Lau, Ryutaro Tanno, Ira Ktena, et al. Towards generalist biomedical ai. NEJM AI, 1(3):AIoa2300138, 2024.\n[437] Karan Singhal, Shekoofeh Azizi, Tao Tu, S Sara Mahdavi, Jason Wei, Hyung Won Chung, Nathan Scales, Ajay Tanwani, Heather Cole-Lewis, Stephen Pfohl, et al. Large language models encode clinical knowledge. Nature, 620(7972):172-180, 2023.\n[438] Karan Singhal, Tao Tu, Juraj Gottweis, Rory Sayres, Ellery Wulczyn, Le Hou, Kevin Clark, Stephen Pfohl, Heather Cole-Lewis, Darlene Neal, et al. Towards expert-level medical question answering with large language models. arXiv preprint arXiv:2305.09617, 2023.\n[439] Xiaohong Liu, Hao Liu, Guoxing Yang, Zeyu Jiang, Shuguang Cui, Zhaoze Zhang, Huan Wang, Liyuan Tao, Yongchang Sun, Zhu Song, et al. A generalist medical language model for disease diagnosis assistance. Nature Medicine, pages 1-11, 2025.\n[440] Nicholas R Rydzewski, Deepak Dinakaran, Shuang G Zhao, Eytan Ruppin, Baris Turkbey, Deborah E Citrin, and Krishnan R Patel. Comparative evaluation of llms in clinical oncology. NEJM AI, 1(5):AIoa2300151, 2024.\n[441] Cyril Zakka, Rohan Shad, Akash Chaurasia, Alex R Dalal, Jennifer L Kim, Michael Moor, Robyn Fong, Curran Phillips, Kevin Alexander, Euan Ashley, et al. Almanac-retrieval-augmented language models for clinical medicine. NEJM AI, 1(2):AIoa2300068, 2024.\n[442] Ozan Unlu, Jiyeon Shin, Charlotte J Mailly, Michael F Oates, Michela R Tucci, Matthew Varugheese, Kavishwar Wagholikar, Fei Wang, Benjamin M Scirica, Alexander J Blood, et al. Retrieval-augmented generation-enabled gpt-4 for clinical trial screening. NEJM AI, page AIoa2400181, 2024.\n[443] Kyle Lam and Jianing Qiu. Foundation models: the future of surgical artificial intelligence? British Journal of Surgery, 111(4):znae090, 2024.\n[444] Yuanyuan Peng, Aidi Lin, Meng Wang, Tian Lin, Linna Liu, Jianhua Wu, Ke Zou, Tingkun Shi, Lixia Feng, Zhen Liang, et al. Enhancing ai reliability: A foundation model with uncertainty estimation for optical coherence tomography-based retinal disease diagnosis. Cell Reports Medicine, 2024.\n[445] Yuanyuan Tian, Zhiyuan Li, Yanrui Jin, Mengxiao Wang, Xiaoyang Wei, Liqun Zhao, Yunqing Liu, Jinlei Liu, and Chengliang Liu. Foundation model of ecg diagnosis: Diagnostics and explanations of any form and rhythm on ecg. Cell Reports Medicine, 5(12), 2024.\n[446] Jun Ma, Yuting He, Feifei Li, Lin Han, Chenyu You, and Bo Wang. Segment anything in medical images. Nature Communications, 15(1):654, 2024.\n[447] Christian Bluethgen, Pierre Chambon, Jean-Benoit Delbrouck, Rogier van der Sluijs, Małgorzata Połacin, Juan Manuel Zambrano Chaves, Tanishq Mathew Abraham, Shivanshu Purohit, Curtis P Langlotz, and Akshay S Chaudhari. A vision-language foundation model for the generation of realistic chest x-ray images. Nature Biomedical Engineering, pages 1-13, 2024.\n[448] Jinxi Xiang, Xiyue Wang, Xiaoming Zhang, Yinghua Xi, Feyisope Eweje, Yijiang Chen, Yuchen Li, Colin Bergstrom, Matthew Gopaulchan, Ted Kim, et al. A vision-language foundation model for precision oncology. Nature, pages 1-10, 2025.\n[449] Eugene Vorontsov, Alican Bozkurt, Adam Casson, George Shaikovski, Michal Zelechowski, Kristen Severson, Eric Zimmermann, James Hall, Neil Tenenholtz, Nicolo Fusi, et al. A foundation model for clinical-grade computational pathology and rare cancers detection. Nature medicine, pages 1-12, 2024.\n[450] Xiyue Wang, Junhan Zhao, Eliana Marostica, Wei Yuan, Jietian Jin, Jiayu Zhang, Ruijiang Li, Hongping Tang, Kan- ran Wang, Yu Li, et al. A pathology foundation model for cancer diagnosis and prognosis prediction. Nature, 634(8035):970-978, 2024.\n[451] Nadieh Khalili and Francesco Ciompi. Scaling data toward pan-cancer foundation models. Trends in Cancer, 2024.\n[452] Hugo Dalla-Torre, Liam Gonzalez, Javier Mendoza-Revilla, Nicolas Lopez Carranza, Adam Henryk Grzywaczewski, Francesco Oteri, Christian Dallago, Evan Trop, Bernardo P de Almeida, Hassan Sirelkhatim, et al. Nucleotide trans- former: building and evaluating robust foundation models for human genomics. Nature Methods, pages 1-11, 2024.\n[453] Haotian Cui, Chloe Wang, Hassaan Maan, Kuan Pang, Fengning Luo, Nan Duan, and Bo Wang. scgpt: toward building a foundation model for single-cell multi-omics using generative ai. Nature Methods, pages 1-11, 2024.\n[454] Xi Fu, Shentong Mo, Alejandro Buendia, Anouchka P Laurent, Anqi Shao, Maria del Mar AlvarezTorres, Tianji Yu, Jimin Tan, Jiayu Su, Romella Sagatelian, et al. A foundation model of transcription across human cell types. Nature, pages 1-9, 2025.\n[455] Pratik Ramprasad, Nidhi Pai, and Wei Pan. Enhancing personalized gene expression prediction from dna sequences using genomic foundation models. Human Genetics and Genomics Advances, 5(4), 2024.\n[456] Lavender Yao Jiang, Xujin Chris Liu, Nima Pour Nejatian, Mustafa Nasir-Moin, Duo Wang, Anas Abidin, Kevin Eaton, Howard Antony Riina, Ilya Laufer, Paawan Punjabi, et al. Health systemscale language models are all-purpose prediction engines. Nature, 619(7969):357-362, 2023.\n[457] Aaron Boussina, Rishivardhan Krishnamoorthy, Kimberly Quintero, Shreyansh Joshi, Gabriel Wardi, Hayden Pour, Nicholas Hilbert, Atul Malhotra, Michael Hogarth, Amy M Sitapati, et al. Large language models for more efficient reporting of hospital quality measures. NEJM AI, 1(11):AIcs2400420, 2024.\n[458] Xi Yang, Aokun Chen, Nima PourNejatian, Hoo Chang Shin, Kaleb E Smith, Christopher Parisien, Colin Compas, Cheryl Martin, Anthony B Costa, Mona G Flores, et al. A large language model for electronic health records. npj Digital Medicine, 5(1):194, 2022.\n[459] Akhil Vaid, Isotta Landi, Girish Nadkarni, and Ismail Nabeel. Using fine-tuned large language models to parse clinical notes in musculoskeletal pain disorders. The Lancet Digital Health, 5(12):e855-e858, 2023.\n[460] Dave Van Veen, Cara Van Uden, Louis Blankemeier, Jean-Benoit Delbrouck, Asad Aali, Christian Bluethgen, Anuj Pareek, Malgorzata Polacin, Eduardo Pontes Reis, Anna Seehofnerova’, et al. Adapted large language models can outperform medical experts in clinical text summarization. Nature medicine, 30(4):1134-1142, 2024.\n[461] Hanzhou Li, John T Moon, Saptarshi Purkayastha, Leo Anthony Celi, Hari Trivedi, and Judy W Gichoya. Ethics of large language models in medicine and medical research. The Lancet Digital Health, 5(6):e333-e335, 2023.\n[462] Zhuxin Xiong, Xiaofei Wang, Yukun Zhou, Pearse A. Keane, Yih Chung Tham, Ya Xing Wang, and Tien Yin Wong. How generalizable are foundation models when applied to different demographic groups and settings? NEJM AI, 0(0):AIcs2400497, 2024.\n[463] Paul Hager, Friederike Jungmann, Robbie Holland, Kunal Bhagat, Inga Hubrecht, Manuel Knauer, Jakob Vielhauer, Marcus Makowski, Rickmer Braren, Georgios Kaissis, et al. Evaluation and mitigation of the limitations of large language models in clinical decision-making. Nature medicine, 30(9):2613-2622, 2024.\n[464] Yinghao Zhu, Junyi Gao, Zixiang Wang, Weibin Liao, Xiaochen Zheng, Lifang Liang, Yasha Wang, Chengwei Pan, Ewen M Harrison, and Liantao Ma. Is larger always better? evaluating and prompting large language models for non-generative medical tasks. arXiv preprint arXiv:2407.18525, 2024.\n[465] Agustina D Saenz, Zach Harned, Oishi Banerjee, Michael D Abra`moff, and Pranav Rajpurkar. Autonomous ai systems in the face of liability, regulations and costs. npj Digital Medicine, 6(1):185, 2023.\n[466] Krishnamurthy Dvijotham, Jim Winkens, Melih Barsbey, Sumedh Ghaisas, Robert Stanforth, Nick Pawlowski, Patricia Strachan, Zahra Ahmed, Shekoofeh Azizi, Yoram Bachrach, et al. Enhancing the reliability and accuracy of ai-enabled diagnosis via complementarity-driven deferral to clinicians. Nature Medicine, 29(7):1814-1820, 2023.\n[467] Shreya Johri, Jaehwan Jeong, Benjamin A Tran, Daniel I Schlessinger, Shannon Wongvibulsin, Leandra A Barnes, Hong-Yu Zhou, Zhuo Ran Cai, Eliezer M Van Allen, David Kim, et al. An evaluation framework for clinical use of large language models in patient interaction tasks. Nature Medicine, pages 1-10, 2025.\n[468] Yuting He, Fuxiang Huang, Xinrui Jiang, Yuxiang Nie, Minghao Wang, Jiguang Wang, and Hao Chen. Foundation model for advancing healthcare: Challenges, opportunities, and future directions. arXiv preprint arXiv:2404.03264, 2024.\n[469] Arun James Thirunavukarasu, Darren Shu Jeng Ting, Kabilan Elangovan, Laura Gutierrez, Ting Fang Tan, and Daniel Shu Wei Ting. Large language models in medicine. Nature medicine, 29(8):1930-1940, 2023.\n[470] Zhao Wang, Chang Liu, Shaoting Zhang, and Qi Dou. Foundation model for endoscopy video analysis via large- scale self-supervised pre-train. In International Conference on Medical Image Computing and Computer-Assisted Intervention, pages 101-111. Springer, 2023.\n[471] Hugo Dalla-Torre, Liam Gonzalez, Javier Mendoza-Revilla, Nicolas Lopez Carranza, Adam Henryk Grzywaczewski, Francesco Oteri, Christian Dallago, Evan Trop, Bernardo P de Almeida, Hassan Sirelkhatim, et al. Nucleotide trans- former: building and evaluating robust foundation models for human genomics. Nature Methods, pages 1-11, 2024.\n[472] Nadav Brandes, Dan Ofer, Yam Peleg, Nadav Rappoport, and Michal Linial. Proteinbert: a universal deep-learning model of protein sequence and function. Bioinformatics, 38(8):2102-2110, 2022.\n[473] Kai Zhang, Jun Yu, Eashan Adhikarla, Rong Zhou, Zhiling Yan, Yixin Liu, Zhengliang Liu, Lifang He, Brian Davison, Xiang Li, et al. Biomedgpt: A unified and generalist biomedical generative pretrained transformer for vision, language, and multimodal tasks. arXiv e-prints, pages arXiv-2305, 2023.\n[474] Bobby Azad, Reza Azad, Sania Eskandari, Afshin Bozorgpour, Amirhossein Kazerouni, Islem Rekik, and Dorit Merhof. Foundational models in medical imaging: A comprehensive survey and future vision. CoRR, 2023.\n[475] Glyn Elwyn, Dominick Frosch, Richard Thomson, Natalie Joseph-Williams, Amy Lloyd, Paul Kinnersley, Emma Cord- ing, Dave Tomson, Carole Dodd, Stephen Rollnick, et al. Shared decision making: a model for clinical practice. Journal of general internal medicine, 27:1361-1367, 2012.\n[476] Hongjian Zhou, Fenglin Liu, Boyang Gu, Xinyu Zou, Jinfa Huang, Jinge Wu, Yiru Li, Sam S Chen, Peilin Zhou, Junling Liu, et al. A survey of large language models in medicine: Progress, application, and challenge. arXiv preprint arXiv:2311.05112, 2023.\n[477] Guangyu Wang, Guoxing Yang, Zongxin Du, Longjun Fan, and Xiaohu Li. Clinicalgpt: large language models finetuned with diverse medical data and comprehensive evaluation. arXiv preprint arXiv:2306.09968, 2023.\n[478] Weihao Gao, Zhuo Deng, Zhiyuan Niu, Fuju Rong, Chucheng Chen, Zheng Gong, Wenze Zhang, Daimin Xiao, Fang Li, Zhenjie Cao, et al. Ophglm: Training an ophthalmology large language-and-vision assistant based on instructions and dialogue. arXiv preprint arXiv:2306.12174, 2023.\n[479] Masoumeh Farhadi Nia, Mohsen Ahmadi, and Elyas Irankhah. Transforming dental diagnostics with artificial intelli- gence: Advanced integration of chatgpt and large language models for patient care. arXiv preprint arXiv:2406.06616, 2024.\n[480] Ana Sua’rez, Jaime Jime’nez, Mar’ıa Llorente de Pedro, Cristina Andreu-Va’zquez, V’ıctor D’ıazFlores Garc’ia, Mar- garita Go’mez Sa’nchez, and Yolanda Freire. Beyond the scalpel: Assessing chatgpt’s potential as an auxiliary intelligent virtual assistant in oral surgery. Computational and Structural Biotechnology Journal, 24:46-52, 2024.\n[481] Hossein Mohammad-Rahimi, Saeed Reza Motamedian, Mohammad Hossein Rohban, Joachim Krois, Sergio E Uribe, Erfan Mahmoudinia, Rata Rokhshad, Mohadeseh Nadimi, and Falk Schwendicke. Deep learning for caries detection: A systematic review. Journal of Dentistry, 122:104115, 2022.\n[482] Marta Revilla-Leo’n, Miguel Go’mez-Polo, Abdul B Barmak, Wardah Inam, Joseph YK Kan, John C Kois, and Orhan Akal. Artificial intelligence models for diagnosing gingivitis and periodontal disease: A systematic review. The Journal of Prosthetic Dentistry, 130(6):816-824, 2023.\n[483] Pongsapak Wongratwanich, Kiichi Shimabukuro, Masaru Konishi, Toshikazu Nagasaki, Masahiko Ohtsuka, Yoshikazu Suei, Takashi Nakamoto, Rinus G Verdonschot, Tomohiko Kanesaki, Pipop Sutthiprapaporn, et al. Do various imaging modalities provide potential early detection and diagnosis of medication-related osteonecrosis of the jaw? a review. Dentomaxillofacial Radiology, 50(6):20200417, 2021.\n[484] Rasheed Omobolaji Alabi, Omar Youssef, Matti Pirinen, Mohammed Elmusrati, Antti A Ma\"kitie, Ilmo Leivo, and Alhadi Almangush. Machine learning in oral squamous cell carcinoma: Current status, clinical concerns and prospects for future-a systematic review. Artificial intelligence in medicine, 115:102060, 2021.\n[485] Kritsasith Warin, Wasit Limprasert, Siriwan Suebnukarn, Teerawat Paipongna, Patcharapon Jantana, and Sothana Vicharueang. Maxillofacial fracture detection and classification in computed tomography images using convolutional neural network-based models. Scientific reports, 13(1):3434, 2023.\n[486] Nayansi Jha, Kwang-Sig Lee, and Yoon-Ji Kim. Diagnosis of temporomandibular disorders using artificial intelligence technologies: A systematic review and meta-analysis. PLoS One, 17(8):e0272715, 2022.\n[487] Duy MH Nguyen, Hoang Nguyen, Nghiem Diep, Tan Ngoc Pham, Tri Cao, Binh Nguyen, Paul Swoboda, Nhat Ho, Shadi Albarqouni, Pengtao Xie, et al. Lvm-med: Learning large-scale selfsupervised vision models for medical imag- ing via second-order graph matching. Advances in Neural Information Processing Systems, 36, 2024.\n[488] Weijia Feng, Lingting Zhu, and Lequan Yu. Cheap lunch for medical image segmentation by finetuning sam on few exemplars. In International MICCAI Brainlesion Workshop, pages 13-22. Springer, 2023.\n[489] Anirudh Shankar, TR Monisha, Skanda S Kumar, Aishwary Anurag, Ashwath Narayan, et al. Advancements in ai- driven dentistry: Tooth genai’s impact on dental diagnosis and treatment planning. In 2024 2nd International Conference on Networking, Embedded and Wireless Systems (ICNEWS), pages 1-7. IEEE, 2024.\n[490] Wenxi Yue, Jing Zhang, Kun Hu, Qiuxia Wu, Zongyuan Ge, Yong Xia, Jiebo Luo, and Zhiyong Wang. Part to whole: Collaborative prompting for surgical instrument segmentation. arXiv preprint arXiv:2312.14481, 2023.\n[491] Hsun-Liang Chan, Kelly Misch, and Hom-Lay Wang. Dental imaging in implant treatment planning. Implant dentistry, 19(4):288-298, 2010.\n[492] Yuepeng Wu, Yukang Zhang, Mei Xu, Yuchen Zheng, et al. Effectiveness of various general large language models in clinical consensus and case analysis in dental implantology: A comparative study. 2024.\n[493] Bahaaeldeen M Elgarba, Rocharles Cavalcante Fontenele, Mihai Tarce, and Reinhilde Jacobs. Artificial intelligence serving pre-surgical digital implant planning: A scoping review. Journal of Dentistry, page 104862, 2024.\n[494] Sheldon Baumrind, Edward L Korn, Robert L Boyd, and Raymond Maxwell. The decision to extract: part ii. analysis of clinicians’ stated reasons for extraction. American Journal of Orthodontics and Dentofacial Orthopedics, 109(4):393-402, 1996.\n[495] Ye-Hyun Kim, Jae-Bong Park, Min-Seok Chang, Jae-Jun Ryu, Won Hee Lim, and Seok-Ki Jung. Influence of the depth of the convolutional neural networks on an artificial intelligence model for diagnosis of orthognathic surgery. Journal of Personalized Medicine, 11(5):356, 2021.\n[496] WooSang Shin, Han-Gyeol Yeom, Ga Hyung Lee, Jong Pil Yun, Seung Hyun Jeong, Jong Hyun Lee, Hwi Kang Kim, and Bong Chul Kim. Deep learning based prediction of necessity for orthognathic surgery of skeletal malocclusion using cephalogram in korean individuals. BMC Oral Health, 21:1-7, 2021.\n[497] Hyuk-Il Choi, Seok-Ki Jung, Seung-Hak Baek, Won Hee Lim, Sug-Joon Ahn, Il-Hyung Yang, and Tae-Woo Kim. Artificial intelligent model with neural network machine learning for the diagnosis of orthognathic surgery. Journal of Craniofacial Surgery, 30(7):1986-1989, 2019.\n[498] Sreekanth Kumar Mallineni, Mallika Sethi, Dedeepya Punugoti, Sunil Babu Kotha, Zikra Alkhayal, Sarah Mubaraki, Fatmah Nasser Almotawah, Sree Lalita Kotha, Rishitha Sajja, Venkatesh Nettam, et al. Artificial intelligence in den- tistry: A descriptive review. Bioengineering, 11(12):1267, 2024.\n[499] Hao Ding, Jiamin Wu, Wuyuan Zhao, Jukka P Matinlinna, Michael F Burrow, and James KH Tsoi. Artificial intelligence in dentistry—a review. Frontiers in Dental Medicine, 4:1085251, 2023.\n[500] Dianhao Wu, Jingang Jiang, Jie Pan, Kun Qian, and Zhonghao Xue. Root canal preparation robot based on guiding strat- egy for safe remote therapy: System design and feasibility study (2023). IEEE/ASME Transactions on Mechatronics, 2024.\n[501] T Shan, FR Tay, and L Gu. Application of artificial intelligence in dentistry. Journal of dental research, 100(3):232-244, 2021.\n[502] Fet al Schwendicke, W Samek, and J Krois. Artificial intelligence in dentistry: chances and challenges. Journal of dental research, 99(7):769-774, 2020.\n[503] Sergio Salerno, Andrea Laghi, Marie-Claire Cantone, Paolo Sartori, Antonio Pinto, and Guy Frija. Overdiagnosis and overimaging: an ethical issue for radiological protection. La radiologia medica, 124:714-720, 2019.\n[504] Mikhail Kulyabin, Aleksei Zhdanov, Andrey Pershin, Gleb Sokolov, Anastasia Nikiforova, Mikhail Ronkin, Vasilii Borisov, and Andreas Maier. Segment anything in optical coherence tomography: Sam 2 for volumetric segmentation of retinal biomarkers. Bioengineering, 11(9):940, 2024.\n[505] Jie Zhang and Zong-ming Zhang. Ethics and governance of trustworthy medical artificial intelligence. BMC medical informatics and decision making, 23(1):7, 2023.\n[506] Yi-Da Tang, Er-Dan Dong, and Wen Gao. Llms in medicine: The need for advanced evaluation systems for disruptive technologies. The Innovation, 5(3), 2024.\n[507] Yin Yang, Shuangbin Xu, Yifan Hong, Yantong Cai, Wenli Tang, Jiao Wang, Bairong Shen, Hui Zong, and Guangchuang Yu. Computational modeling for medical data: From data collection to knowledge discovery. The Innovation Life, 2(3):100079-1, 2024.\n[508] Hao Guan and Mingxia Liu. Domain adaptation for medical image analysis: a survey. IEEE Transactions on Biomedical Engineering, 69(3):1173-1185, 2021.\n[509] Weijia Zhang, Jindong Han, Zhao Xu, Hang Ni, Hao Liu, and Hui Xiong. Towards urban general intelligence: A review and outlook of urban foundation models. arXiv preprint arXiv:2402.01749, 2024.\n[510] Yuxuan Liang, Haomin Wen, Yuqi Nie, Yushan Jiang, Ming Jin, Dongjin Song, Shirui Pan, and Qingsong Wen. Foun- dation models for time series analysis: A tutorial and survey. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pages 65556565, 2024.\n[511] Sarah Alnegheimish, Linh Nguyen, Laure Berti-Equille, and Kalyan Veeramachaneni. Large language models can be zero-shot anomaly detectors for time series? arXiv preprint arXiv:2405.14755, 2024.\n[512] Tian Zhou, Peisong Niu, Liang Sun, Rong Jin, et al. One fits all: Power general time series analysis by pretrained lm. Advances in neural information processing systems, 36:43322-43355, 2023.\n[513] Qingxiang Liu, Xu Liu, Chenghao Liu, Qingsong Wen, and Yuxuan Liang. Time-ffm: Towards lm-empowered federated foundation model for time series forecasting. arXiv preprint arXiv:2405.14252, 2024.\n[514] Zhonghang Li, Lianghao Xia, Jiabin Tang, Yong Xu, Lei Shi, Long Xia, Dawei Yin, and Chao Huang. Urbangpt: Spatio- temporal large language models. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pages 5351-5362, 2024.\n[515] Chenxi Liu, Sun Yang, Qianxiong Xu, Zhishuai Li, Cheng Long, Ziyue Li, and Rui Zhao. Spatialtemporal large language model for traffic prediction. arXiv preprint arXiv:2401.10134, 2024.\n[516] Abdul Fatir Ansari, Lorenzo Stella, Caner Turkmen, Xiyuan Zhang, Pedro Mercado, Huibin Shen, Oleksandr Shchur, Syama Sundar Rangapuram, Sebastian Pineda Arango, Shubham Kapoor, et al. Chronos: Learning the language of time series. arXiv preprint arXiv:2403.07815, 2024.\n[517] Yuan Yuan, Jingtao Ding, Jie Feng, Depeng Jin, and Yong Li. Unist: A prompt-empowered universal model for urban spatio-temporal prediction. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pages 4095-4106, 2024.\n[518] Yan Lin, Tonglong Wei, Zeyu Zhou, Haomin Wen, Jilin Hu, Shengnan Guo, Youfang Lin, and Huaiyu Wan. Trajfm: A vehicle trajectory foundation model for region and task transferability. arXiv preprint arXiv:2408.15251, 2024.\n[519] Yuanshao Zhu, James Jianqiao Yu, Xiangyu Zhao, Xuetao Wei, and Yuxuan Liang. Unitraj: Universal human trajectory modeling from billion-scale worldwide traces. arXiv preprint arXiv:2411.03859, 2024.\n[520] Xixuan Hao, Wei Chen, Yibo Yan, Siru Zhong, Kun Wang, Qingsong Wen, and Yuxuan Liang. Urbanvlp: A multi-granularity vision-language pre-trained foundation model for urban indicator prediction. arXiv preprint arXiv:2403.16831, 2024.\n[521] Congxi Xiao, Jingbo Zhou, Yixiong Xiao, Jizhou Huang, and Hui Xiong. Refound: Crafting a foundation model for urban region understanding upon language and visual foundations. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pages 3527-3538, 2024.\n[522] Siqi Lai, Zhao Xu, Weijia Zhang, Hao Liu, and Hui Xiong. Large language models as traffic signal control agents: Capacity and opportunity. arXiv preprint arXiv:2312.16044, 2023.\n[523] Zhilun Zhou, Yuming Lin, Depeng Jin, and Yong Li. Large language model for participatory urban planning. arXiv preprint arXiv:2402.17161, 2024.\n[524] Lincan Li, Jiaqi Li, Catherine Chen, Fred Gui, Hongjia Yang, Chenxiao Yu, Zhengguang Wang, Jianing Cai, Jun- long Aaron Zhou, Bolin Shen, et al. Political-llm: Large language models in political science. arXiv preprint arXiv:2412.06864, 2024.\n[525] Menglin Liu and Ge Shi. Poliprompt: A high-performance cost-effective llm-based text classification framework for political science. arXiv preprint arXiv:2409.01466, 2024.\n[526] Albaaji G F. SS V C, Hareendran A. Precision farming for sustainability: An agricultural intelligence model. Computers and Electronics in Agriculture, 2024.\n[527] Jiajia Li, Mingle Xu, Lirong Xiang, Dong Chen, Weichao Zhuang, Xunyuan Yin, and Zhaojian Li. Foundation models in smart agriculture: Basics, opportunities, and challenges. Computers and Electronics in Agriculture, 222:109032, 2024.\n[528] Zhiyu Zhang, Wenjian Ni, Shaun Quegan, Jingming Chen, Peng Gong, Luiz Carlos Estraviz Rodriguez, Huadong Guo, Jiancheng Shi, Liangyun Liu, Zengyuan Li, et al. Deforestation in latin america in the 2000s predominantly occurred outside of typical mature forests. The Innovation, 5(3), 2024.\n[529] Matheus Thomas Kuska, Mirwaes Wahabzada, and Stefan Paulus. Ai for crop production-where can large language models (llms) provide substantial value? Computers and Electronics in Agriculture, 221:108924, 2024.\n[530] Keong Tan. Large language models for crop yield prediction. 2024.\n[531] Yujiao Lyu, Pengxin Wang, Xueyuan Bai, Xuecao Li, Xin Ye, Yuchen Hu, and Jie Zhang. Machine learning techniques and interpretability for maize yield estimation using time-series images of modis and multi-source data. Computers and Electronics in Agriculture, 222:109063, 2024.\n[532] Federico Pallottino, Simona Violino, Simone Figorilli, Catello Pane, Jacopo Aguzzi, Giacomo Colle, Eugenio Nerio Nemmi, Alessandro Montaghi, Damianos Chatzievangelou, Francesca Antonucci, et al. Applications and perspectives of generative artificial intelligence in agriculture. Computers and Electronics in Agriculture, 230:109919, 2025.\n[533] Hongyan Zhu, Shuai Qin, Min Su, Chengzhi Lin, Anjie Li, and Junfeng Gao. Harnessing large vision and language models in agriculture: A review. arXiv preprint arXiv:2407.19679, 2024.\n[534] Yueyue Zhou, Hongping Yan, Kun Ding, Tingting Cai, and Yan Zhang. Few-shot image classification of crop diseases based on vision-language models. Sensors, 24(18):6109, 2024.\n[535] Xutong Wu, Bojie Fu, Shuai Wang, Yanxu Liu, Ying Yao, Yingjie Li, Zhenci Xu, and Jianguo Liu. Three main dimensions reflected by national sdg performance. The innovation, 4(6), 2023.\n[536] Wanchao Zhu, Weifu Li, Hongwei Zhang, and Lin Li. Big data and artificial intelligence-aided crop breeding: Progress and prospects. Journal of Integrative Plant Biology, 2024.\n[537] Muhammad Amjad Farooq, Shang Gao, Muhammad Adeel Hassan, Zhangping Huang, Awais Rasheed, Sarah Hearne, Boddupalli Prasanna, Xinhai Li, and Huihui Li. Artificial intelligence in plant breeding. Trends in Genetics, 2024.\n[538] Gengchen Mai, Weiming Huang, Jin Sun, Suhang Song, Deepak Mishra, Ninghao Liu, Song Gao, Tianming Liu, Gao Cong, Yingjie Hu, et al. On the opportunities and challenges of foundation models for geospatial artificial intelligence. arXiv preprint arXiv:2304.06798, 2023.\n[539] Junnan Li, Dongxu Li, Caiming Xiong, and Steven Hoi. Blip: Bootstrapping language-image pretraining for unified vision-language understanding and generation. In International conference on machine learning, pages 12888-12900. PMLR, 2022.\n[540] Guarino M. Tullo E, Finzi A. Environmental impact of livestock farming and precision livestock farming as a mitigation strategy. Science of the total environment, 2019.\n[541] Xiao Yang, Haixing Dai, Zihao Wu, Ramesh Bist, Sachin Subedi, Jin Sun, Guoyu Lu, Changying Li, Tianming Liu, and Lilong Chai. Sam for poultry science. arXiv preprint arXiv:2305.10254, 2023.\n[542] Xie Q. Bao J. Artificial intelligence in animal farming: A systematic literature review. Journal of Cleaner Production, 2022.\n[543] Na Liu, Jingwei Qi, Xiaoping An, and Yuan Wang. A review on information technologies applicable to precision dairy farming: Focus on behavior, health monitoring, and the precise feeding of dairy cows. Agriculture, 13(10):1858, 2023.\n[544] Wenjie Sun, Jie Zhang, Yujie Lei, and Danfeng Hong. Rsprotoseg: High spatial resolution remote sensing images segmentation based on non-learnable prototypes. IEEE Transactions on Geoscience and Remote Sensing, 2024.\n[545] Sheik Arafat, C Priya, R Premkumar, Haji Nishath SM, et al. Real time cattle health monitoring and early disease detection using iot and machine learning. In 2024 5th International Conference on Electronics and Sustainable Com- munication Systems (ICESC), pages 450-455. IEEE, 2024.\n[546] Md Mahfujul Islam, Shaharya Sourov Tonmoy, Sazzad Quayum, Al Russel Sarker, Sumaiya Umme Hani, and Moham- mad Abdul Mannan. Smart poultry farm incorporating gsm and iot. In 2019 International Conference on Robotics, Electrical and Signal Processing Techniques (ICREST), pages 277-280. IEEE, 2019.\n[547] Rishi Bommasani, Drew A Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael S Bernstein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill, et al. On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258, 2021.\n[548] Y Nie, Y Kong, X Dong, et al. A survey of large language models for financial applications: Progress, prospects and challenges. arXiv preprint arXiv:2406.11903, 2024.\n[549] E Brynjolfsson and A McAfee. The second machine age: Work, progress, and prosperity in a time of brilliant technolo- gies. WW Norton \u0026 company, 2014.\n[550] Wenhua Xu and Yuanqi Feng. Does fintech promote green economic growth in chinese cities? In 2024 7th International Conference on Humanities Education and Social Sciences (ICHESS 2024), pages 942-948. Atlantis Press, 2024.\n[551] AM Qatawneh, A Lutfi, and T Al Barrak. Effect of artificial intelligence (ai) on financial decisionmaking: Mediating role of financial technologies (fin-tech). HighTech and Innovation Journal, 5(3):759-773, 2024.\n[552] J Kriebel and L Stitz. Credit default prediction from user-generated text in peer-to-peer lending using deep learning. European Journal of Operational Research, 302(1):309-323, 2022.\n[553] DW Arner, DA Zetzsche, RP Buckley, et al. Fintech and regtech: Enabling innovation while preserving financial stability. Georgetown Journal of International Affairs, pages 47-58, 2017.\n[554] D Mhlanga. Financial inclusion in emerging economies: The application of machine learning and artificial intelligence in credit risk assessment. International journal of financial studies, 9(3):39, 2021.\n[555] J Duarte, S Siegel, and L Young. Trust and credit: The role of appearance in peer-to-peer lending. The Review of Financial Studies, 25(8):2455-2484, 2012.\n[556] Chunxiao Li, Hongchang Wang, Songtao Jiang, and Bin Gu. The effect of ai-enabled credit scoring on financial inclusion: Evidence from an underserved population of over one million. MIS Quarterly, 48(4), 2024.\n[557] T Chen and C Guestrin. Xgboost: A scalable tree boosting system. In Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining, pages 785-794, 2016.\n[558] J Delgadillo, J Kinyua, and C Mutigwe. Finsosent: Advancing financial market sentiment analysis through pretrained large language models. Big Data and Cognitive Computing, 8(8):87, 2024.\n[559] B Li and C Duan. Construction and optimization of macroeconomic data forecasting model based on machine learning. Journal of Electrical Systems, 20(3s):436-447, 2024.\n[560] S Takahashi, Y Chen, and K Tanaka-Ishii. Modeling financial time-series with generative adversarial networks. Physica A: Statistical Mechanics and its Applications, 527:121261, 2019.\n[561] P Hajek and R Henriques. Mining corporate annual reports for intelligent detection of financial statement fraud-a comparative study of machine learning methods. Knowledge-Based Systems, 128:139-152, 2017.\n[562] R Avacharmal. Leveraging supervised machine learning algorithms for enhanced anomaly detection in anti-money laundering (aml) transaction monitoring systems: A comparative analysis of performance and explainability. African Journal of Artificial Intelligence and Sustainable Development, 1(2):68-85, 2021.\n[563] F Teichmann, S Boticiu, and BS Sergi. Regtech-potential benefits and challenges for businesses. Technology in Society, 72:102150, 2023.\n[564] D Tapscott and A Tapscott. Blockchain Revolution: How the Technology Behind Bitcoin and Other Cryptocurrencies is Changing the World. Portfolio, 2017.\n[565] LW Cong, Z He, and J Li. Decentralized mining in centralized pools. The Review of Financial Studies, 34(3):1191-1235, 2021.\n[566] Q Yang, Y Liu, T Chen, et al. Federated machine learning: Concept and applications. ACM Transactions on Intelligent Systems and Technology (TIST), 10(2):1-19, 2019.\n[567] BD Mittelstadt, P Allo, M Taddeo, et al. The ethics of algorithms: Mapping the debate. Big Data \u0026 Society, 3(2):2053951716679679, 2016.\n[568] Luciano Floridi, Josh Cowls, Monica Beltrametti, Raja Chatila, Patrice Chazerand, Virginia Dignum, Christoph Luetge, Robert Madelin, Ugo Pagallo, Francesca Rossi, et al. Ai4people-an ethical framework for a good ai society: opportu- nities, risks, principles, and recommendations. Minds and machines, 28:689-707, 2018.\n[569] MT Ribeiro, S Singh, and C Guestrin. Why should i trust you? explaining the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, pages 1135-1144, 2016.\n[570] Hung Chau, Igor Labutov, Khushboo Thaker, Daqing He, and Peter Brusilovsky. Automatic concept extraction for domain and student modeling in adaptive textbooks. International Journal of Artificial Intelligence in Education, 31:820-846, 2021.\n[571] Qingtang Liu, Xinxin Zheng, Yaoyao Liu, Linjing Wu, Si Zhang, Ni Zhang, and Qiyun Wang. Exploration of the characteristics of teachers’ multimodal behaviours in problem-oriented teaching activities with different response levels. British Journal of Educational Technology, 55(1):181207, 2024.\n[572] Tunde Toyese Oyedokun. Assistive technology and accessibility tools in enhancing adaptive education. In Advancing Adaptive Education: Technological Innovations for Disability Support, pages 125-162. IGI Global Scientific Publish- ing, 2025.\n[573] Wadim Strielkowski, Veronika Grebennikova, Alexander Lisovskiy, Guzalbegim Rakhimova, and Tatiana Vasileva. Ai-driven adaptive learning for sustainable educational transformation. Sustainable Development, 2024.\n[574] Tiffanie Zaugg. Future innovations for assistive technology and universal design for learning. Assistive Technology and Universal Design for Learning: Toolkits for Inclusive Instruction, page 275, 2024.\n[575] Ismail Celik, Muhterem Dindar, Hanni Muukkonen, and Sanna Ja\"rvela\". The promises and challenges of artificial intelligence for teachers: A systematic review of research. TechTrends, 66(4):616-630, 2022.\n[576] Hanrong Zhang, Jingyuan Huang, Kai Mei, Yifei Yao, Zhenting Wang, Chenlu Zhan, Hongwei Wang, and Yongfeng Zhang. Agent security bench (ASB): formalizing and benchmarking attacks and defenses in llm-based agents. CoRR, abs/2410.02644, 2024.\n[577] Matthieu Meeus, Shubham Jain, Marek Rei, and Yves-Alexandre de Montjoye. Did the neurons read your book? document-level membership inference for large language models. In Davide Balzarotti and Wenyuan Xu, editors, 33rd USENIX Security Symposium, USENIX Security 2024, Philadelphia, PA, USA, August 14-16, 2024. USENIX Association, 2024.\n[578] Nishant Vishwamitra, Keyan Guo, Farhan Tajwar Romit, Isabelle Ondracek, Long Cheng, Ziming Zhao, and Hongxin Hu. Moderating new waves of online hate with chain-of-thought reasoning in large language models. In IEEE Sympo- sium on Security and Privacy, SP 2024, San Francisco, CA, USA, May 19-23, 2024, pages 788-806. IEEE, 2024.\n[579] Xueqi Cheng, Wei Chen, Huawei Shen, Shiguang Shan, Xilin Chen, and Guojie Li. Intelligent algorithm safety: Concepts, scientific problems and prospects. Bulletin of Chinese Academy of Sciences, 39, 2024.\n[580] Fa’bio Perez and Ian Ribeiro. Ignore previous prompt: Attack techniques for language models. CoRR, abs/2211.09527, 2022.\n[581] Xuchen Suo. Signed-prompt: A new approach to prevent prompt injection attacks against llmintegrated applications. CoRR, abs/2401.07612, 2024.\n[582] Yupei Liu, Yuqi Jia, Runpeng Geng, Jinyuan Jia, and Neil Zhenqiang Gong. Formalizing and benchmarking prompt injection attacks and defenses. In Davide Balzarotti and Wenyuan Xu, editors, 33rd USENIX Security Symposium, USENIX Security 2024, Philadelphia, PA, USA, August 14-16, 2024. USENIX Association, 2024.\n[583] Sahar Abdelnabi, Kai Greshake, Shailesh Mishra, Christoph Endres, Thorsten Holz, and Mario Fritz. Not what you’ve signed up for: Compromising real-world llm-integrated applications with indirect prompt injection. In Maura Pin- tor, Xinyun Chen, and Florian Trame`r, editors, Proceedings of the 16th ACM Workshop on Artificial Intelligence and Security, AISec 2023, Copenhagen, Denmark, 30 November 2023, pages 79-90. ACM, 2023.\n[584] Jingwei Yi, Yueqi Xie, Bin Zhu, Keegan Hines, Emre Kiciman, Guangzhong Sun, Xing Xie, and Fangzhao Wu. Bench- marking and defending against indirect prompt injection attacks on large language models. CoRR, abs/2312.14197, 2023.\n[585] Chong Xiang, Tong Wu, Zexuan Zhong, David A. Wagner, Danqi Chen, and Prateek Mittal. Certifiably robust RAG against retrieval corruption. CoRR, abs/2405.15556, 2024.\n[586] Zhaorun Chen, Zhen Xiang, Chaowei Xiao, Dawn Song, and Bo Li. Agentpoison: Red-teaming LLM agents via poisoning memory or knowledge bases. CoRR, abs/2407.12784, 2024.\n[587] Yifei Wang, Dizhan Xue, Shengjie Zhang, and Shengsheng Qian. Badagent: Inserting and activating backdoor attacks in LLM agents. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar, editors, Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2024, Bangkok, Thailand, August 11-16, 2024, pages 9811-9827. Association for Computational Linguistics, 2024.\n[588] Wenkai Yang, Xiaohan Bi, Yankai Lin, Sishuo Chen, Jie Zhou, and Xu Sun. Watch out for your agents! investigating backdoor threats to llm-based agents. CoRR, abs/2402.11208, 2024.\n[589] Tian Dong, Minhui Xue, Guoxing Chen, Rayne Holland, Yan Meng, Shaofeng Li, Zhen Liu, and Haojin Zhu. The philosopher’s stone: Trojaning plugins of large language models. In Network and Distributed System Security Sympo- sium, NDSS 2025. The Internet Society, 2025.\n[590] Evan Hubinger, Carson Denison, Jesse Mu, Mike Lambert, Meg Tong, Monte MacDiarmid, Tamera Lanham, Daniel M. Ziegler, Tim Maxwell, Newton Cheng, Adam S. Jermyn, Amanda Askell, Ansh Radhakrishnan, Cem Anil, David Duvenaud, Deep Ganguli, Fazl Barez, Jack Clark, Kamal Ndousse, Kshitij Sachan, Michael Sellitto, Mrinank Sharma, Nova DasSarma, Roger Grosse, Shauna Kravec, Yuntao Bai, Zachary Witten, Marina Favaro, Jan Brauner, Holden Karnofsky, Paul F. Christiano, Samuel R. Bowman, Logan Graham, Jared Kaplan, So\"ren Mindermann, Ryan Greenblatt, Buck Shlegeris, Nicholas Schiefer, and Ethan Perez. Sleeper agents: Training deceptive llms that persist through safety training. CoRR, abs/2401.05566, 2024.\n[591] Zhiyuan Yu, Xiaogeng Liu, Shunning Liang, Zach Cameron, Chaowei Xiao, and Ning Zhang. Don’t listen to me: Understanding and exploring jailbreak prompts of large language models. In Davide Balzarotti and Wenyuan Xu, edi- tors, 33rd USENIX Security Symposium, USENIX Security 2024, Philadelphia, PA, USA, August 14-16, 2024. USENIX Association, 2024.\n[592] Jiahao Yu, Xingwei Lin, Zheng Yu, and Xinyu Xing. Llm-fuzzer: Scaling assessment of large language model jail- breaks. In Davide Balzarotti and Wenyuan Xu, editors, 33rd USENIX Security Symposium, USENIX Security 2024, Philadelphia, PA, USA, August 14-16, 2024. USENIX Association, 2024.\n[593] Yi Liu, Gelei Deng, Zhengzi Xu, Yuekang Li, Yaowen Zheng, Ying Zhang, Lida Zhao, Tianwei Zhang, and Yang Liu. Jailbreaking chatgpt via prompt engineering: An empirical study. CoRR, abs/2305.13860, 2023.\n[594] Alexander Wei, Nika Haghtalab, and Jacob Steinhardt. Jailbroken: How does LLM safety training fail? In Alice Oh, Tristan Naumann, Amir Globerson, Kate Saenko, Moritz Hardt, and Sergey Levine, editors, Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10-16, 2023, 2023.\n[595] Zhuo Zhang, Guangyu Shen, Guanhong Tao, Siyuan Cheng, and Xiangyu Zhang. On large language models’ resilience to coercive interrogation. In IEEE Symposium on Security and Privacy, SP 2024, San Francisco, CA, USA, May 19-23, 2024, pages 826-844. IEEE, 2024.\n[596] Jiashu Xu, Mingyu Derek Ma, Fei Wang, Chaowei Xiao, and Muhao Chen. Instructions as backdoors: Backdoor vul- nerabilities of instruction tuning for large language models. In Kevin Duh, Helena Go’mez-Adorno, and Steven Bethard, editors, Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Lin- guistics: Human Language Technologies (Volume 1: Long Papers), NAACL 2024, Mexico City, Mexico, June 1621, 2024, pages 3111-3126. Association for Computational Linguistics, 2024.\n[597] Shuai Zhao, Jinming Wen, Anh Tuan Luu, Junbo Zhao, and Jie Fu. Prompt as triggers for backdoor attack: Examining the vulnerability in language models. In Houda Bouamor, Juan Pino, and Kalika Bali, editors, Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023, pages 12303-12317. Association for Computational Linguistics, 2023.\n[598] Xiangrui Cai, Haidong Xu, Sihan Xu, Ying Zhang, and Xiaojie Yuan. Badprompt: Backdoor attacks on continuous prompts. In Sanmi Koyejo, S. Mohamed, A. Agarwal, Danielle Belgrave, K. Cho, and A. Oh, editors, Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022, 2022.\n[599] Yanzhou Li, Tianlin Li, Kangjie Chen, Jian Zhang, Shangqing Liu, Wenhan Wang, Tianwei Zhang, and Yang Liu. Badedit: Backdooring large language models by model editing. In The Twelfth International Conference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11, 2024. OpenReview.net, 2024.\n[600] Neel Jain, Avi Schwarzschild, Yuxin Wen, Gowthami Somepalli, John Kirchenbauer, Ping-yeh Chiang, Micah Gold- blum, Aniruddha Saha, Jonas Geiping, and Tom Goldstein. Baseline defenses for adversarial attacks against aligned language models. CoRR, abs/2309.00614, 2023.\n[601] Xinxin Fan, Mengfan Li, Jia Zhou, Quanliang Jing, Chi Lin, Yunfeng Lu, and Jingping Bi. GCSA: A new adversarial example-generating scheme toward black-box adversarial attacks. IEEE Trans. Consumer Electron., 70(1):2038-2048, 2024.\n[602] Baoli Wang, Xinxin Fan, Quanliang Jing, Yueyang Su, Jingwei Li, and Jingping Bi. GTAT: adversarial training with generated triplets. In International Joint Conference on Neural Networks, IJCNN 2022, Padua, Italy, July 18-23, 2022, pages 1-8. IEEE, 2022.\n[603] Quanliang Jing, Shuo Liu, Xinxin Fan, Jingwei Li, Di Yao, Baoli Wang, and Jingping Bi. Can adversarial training benefit trajectory representation?: An investigation on robustness for trajectory similarity computation. In Mohammad Al Hasan and Li Xiong, editors, Proceedings of the 31st ACM International Conference on Information \u0026 Knowledge Management, Atlanta, GA, USA, October 17-21, 2022, pages 905-914. ACM, 2022.\n[604] Tong Liu, Yingjie Zhang, Zhe Zhao, Yinpeng Dong, Guozhu Meng, and Kai Chen. Making them ask and answer: Jailbreaking large language models in few queries via disguise and reconstruction. In Davide Balzarotti and Wenyuan Xu, editors, 33rd USENIX Security Symposium, USENIX Security 2024, Philadelphia, PA, USA, August 14-16, 2024. USENIX Association, 2024.\n[605] Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Yejin Bang, Andrea Madotto, and Pascale Fung. Survey of hallucination in natural language generation. ACM Comput. Surv., 55(12):248:1-248:38, 2023.\n[606] Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen Fu, Xinting Huang, Enbo Zhao, Yu Zhang, Yulong Chen, Longyue Wang, Anh Tuan Luu, Wei Bi, Freda Shi, and Shuming Shi. Siren’s song in the AI ocean: A survey on hallucination in large language models. CoRR, abs/2309.01219, 2023.\n[607] Nelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, and Percy Liang. Lost in the middle: How language models use long contexts. Trans. Assoc. Comput. Linguistics, 12:157-173, 2024.\n[608] Guilherme Penedo, Quentin Malartic, Daniel Hesslow, Ruxandra Cojocaru, Hamza Alobeidli, Alessandro Cappelli, Baptiste Pannier, Ebtesam Almazrouei, and Julien Launay. The refinedweb dataset for falcon LLM: outperforming curated corpora with web data only. In Alice Oh, Tristan Naumann, Amir Globerson, Kate Saenko, Moritz Hardt, and Sergey Levine, editors, Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10-16, 2023, 2023.\n[609] Shaobo Li, Xiaoguang Li, Lifeng Shang, Zhenhua Dong, Chengjie Sun, Bingquan Liu, Zhenzhou Ji, Xin Jiang, and Qun Liu. How pre-trained language models capture factual knowledge? A causal-inspired analysis. In Smaranda Muresan, Preslav Nakov, and Aline Villavicencio, editors, Findings of the Association for Computational Linguistics: ACL 2022, Dublin, Ireland, May 22-27, 2022, pages 1720-1732. Association for Computational Linguistics, 2022.\n[610] Nick McKenna, Tianyi Li, Liang Cheng, Mohammad Javad Hosseini, Mark Johnson, and Mark Steedman. Sources of hallucination by large language models on inference tasks. In Houda Bouamor, Juan Pino, and Kalika Bali, editors, Findings of the Association for Computational Linguistics: EMNLP 2023, Singapore, December 6-10, 2023, pages 2758-2774. Association for Computational Linguistics, 2023.\n[611] Saurav Kadavath, Tom Conerly, Amanda Askell, Tom Henighan, Dawn Drain, Ethan Perez, Nicholas Schiefer, Zac Hatfield-Dodds, Nova DasSarma, Eli Tran-Johnson, Scott Johnston, Sheer El Showk, Andy Jones, Nelson Elhage, Tristan Hume, Anna Chen, Yuntao Bai, Sam Bowman, Stanislav Fort, Deep Ganguli, Danny Hernandez, Josh Jacobson, Jackson Kernion, Shauna Kravec, Liane Lovitt, Kamal Ndousse, Catherine Olsson, Sam Ringer, Dario Amodei, Tom Brown, Jack Clark, Nicholas Joseph, Ben Mann, Sam McCandlish, Chris Olah, and Jared Kaplan. Language models (mostly) know what they know. CoRR, abs/2207.05221, 2022.\n[612] Zhangyue Yin, Qiushi Sun, Qipeng Guo, Jiawen Wu, Xipeng Qiu, and Xuanjing Huang. Do large language models know what they don’t know? In Anna Rogers, Jordan L. Boyd-Graber, and Naoaki Okazaki, editors, Findings of the As- sociation for Computational Linguistics: ACL 2023, Toronto, Canada, July 9-14, 2023, pages 8653-8665. Association for Computational Linguistics, 2023.\n[613] Claire Gardent, Anastasia Shimorina, Shashi Narayan, and Laura Perez-Beltrachini. Creating training corpora for NLG micro-planners. In Regina Barzilay and Min-Yen Kan, editors, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017, Vancouver, Canada, July 30 - August 4, Volume 1: Long Papers, pages 179-188. Association for Computational Linguistics, 2017.\n[614] Stephanie Lin, Jacob Hilton, and Owain Evans. Truthfulqa: Measuring how models mimic human falsehoods. In Smaranda Muresan, Preslav Nakov, and Aline Villavicencio, editors, Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2022, Dublin, Ireland, May 22-27, 2022, pages 3214-3252. Association for Computational Linguistics, 2022.\n[615] Sina Zarrieß, Henrik Voigt, and Simeon Schu\"z. Decoding methods in neural language generation: A survey. Inf., 12(9):355, 2021.\n[616] Nayeon Lee, Wei Ping, Peng Xu, Mostofa Patwary, Pascale Fung, Mohammad Shoeybi, and Bryan Catanzaro. Factu- ality enhanced language models for open-ended text generation. In Sanmi Koyejo, S. Mohamed, A. Agarwal, Danielle Belgrave, K. Cho, and A. Oh, editors, Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022, 2022.\n[617] Shehzaad Dhuliawala, Mojtaba Komeili, Jing Xu, Roberta Raileanu, Xian Li, Asli Celikyilmaz, and Jason Weston. Chain-of-verification reduces hallucination in large language models. In LunWei Ku, Andre Martins, and Vivek Sriku- mar, editors, Findings of the Association for Computational Linguistics, ACL 2024, Bangkok, Thailand and virtual meeting, August 11-16, 2024, pages 3563-3578. Association for Computational Linguistics, 2024.\n[618] Kenneth Li, Oam Patel, Fernanda B. Vie’gas, Hanspeter Pfister, and Martin Wattenberg. Inferencetime intervention: Eliciting truthful answers from a language model. In Alice Oh, Tristan Naumann, Amir Globerson, Kate Saenko, Moritz Hardt, and Sergey Levine, editors, Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10-16, 2023, 2023.\n[619] Miao Xiong, Zhiyuan Hu, Xinyang Lu, YIFEI LI, Jie Fu, Junxian He, and Bryan Hooi. Can llms express their uncer- tainty? an empirical evaluation of confidence elicitation in llms. In The Twelfth International Conference on Learning Representations, 2024.\n[620] Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov. Membership inference attacks against machine learning models. In 2017 IEEE symposium on security and privacy (SP), pages 3-18, 2017.\n[621] Nicholas Carlini, Florian Trame`r, Eric Wallace, Matthew Jagielski, Ariel Herbert-Voss, Katherine Lee, Adam Roberts, Tom B. Brown, Dawn Song, Ú lfar Erlingsson, Alina Oprea, and Colin Raffel. Extracting training data from large language models. In Michael D. Bailey and Rachel Greenstadt, editors, 30th USENIX Security Symposium, USENIX Security 2021, August 11-13, 2021, pages 2633-2650. USENIX Association, 2021.\n[622] Justus Mattern, Fatemehsadat Mireshghallah, Zhijing Jin, Bernhard Scho\"lkopf, Mrinmaya Sachan, and Taylor Berg- Kirkpatrick. Membership inference attacks against language models via neighbourhood comparison. In Anna Rogers, Jordan L. Boyd-Graber, and Naoaki Okazaki, editors, Findings of the Association for Computational Linguistics: ACL 2023, Toronto, Canada, July 914, 2023, pages 11330-11343. Association for Computational Linguistics, 2023.\n[623] Boxin Wang, Weixin Chen, Hengzhi Pei, Chulin Xie, Mintong Kang, Chenhui Zhang, Chejian Xu, Zidi Xiong, Ritik Dutta, Rylan Schaeffer, Sang T. Truong, Simran Arora, Mantas Mazeika, Dan Hendrycks, Zinan Lin, Yu Cheng, Sanmi Koyejo, Dawn Song, and Bo Li. Decodingtrust: A comprehensive assessment of trustworthiness in GPT models. In Alice Oh, Tristan Naumann, Amir Globerson, Kate Saenko, Moritz Hardt, and Sergey Levine, editors, Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10-16, 2023, 2023.\n[624] Dan Hendrycks, Collin Burns, Steven Basart, Andrew Critch, Jerry Li, Dawn Song, and Jacob Steinhardt. Aligning AI with shared human values. In 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021. OpenReview.net, 2021.\n[625] Yi Liu, Gelei Deng, Zhengzi Xu, Yuekang Li, Yaowen Zheng, Ying Zhang, Lida Zhao, Tianwei Zhang, and Yang Liu. Jailbreaking chatgpt via prompt engineering: An empirical study. CoRR, abs/2305.13860, 2023.\n[626] Zhijing Jin, Sydney Levine, Fernando Gonzalez Adauto, Ojasv Kamal, Maarten Sap, Mrinmaya Sachan, Rada Mihalcea, Josh Tenenbaum, and Bernhard Scho\"lkopf. When to make exceptions: Exploring language models as accounts of human moral judgment. In Sanmi Koyejo, S. Mohamed, A. Agarwal, Danielle Belgrave, K. Cho, and A. Oh, editors, Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022, 2022.\n[627] Kexin Huang, Xiangyang Liu, Qianyu Guo, Tianxiang Sun, Jiawei Sun, Yaru Wang, Zeyang Zhou, Yixu Wang, Yan Teng, Xipeng Qiu, Yingchun Wang, and Dahua Lin. Flames: Benchmarking value alignment of llms in chinese. In Kevin Duh, Helena Go’mez-Adorno, and Steven Bethard, editors, Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), NAACL 2024, Mexico City, Mexico, June 16-21, 2024, pages 4551-4591. Association for Computational Linguistics, 2024.\n[628] Jingnan Zheng, Han Wang, An Zhang, Tai D. Nguyen, Jun Sun, and Tat-Seng Chua. Ali-agent: Assessing llms’ align- ment with human values via agent-based evaluation. In Amir Globersons, Lester Mackey, Danielle Belgrave, Angela Fan, Ulrich Paquet, Jakub M. Tomczak, and Cheng Zhang, editors, Advances in Neural Information Processing Sys- tems 38: Annual Conference on Neural Information Processing Systems 2024, NeurIPS 2024, Vancouver, BC, Canada, December 10-15, 2024, 2024.\n[629] Jiyoung Lee, Minwoo Kim, Seungho Kim, Junghwan Kim, Seunghyun Won, Hwaran Lee, and Edward Choi. Kornat: LLM alignment benchmark for korean social values and common knowledge. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar, editors, Findings of the Association for Computational Linguistics, ACL 2024, Bangkok, Thailand and virtual meeting, August 11-16, 2024, pages 11177-11213. Association for Computational Linguistics, 2024.\n[630] Fan Bu, Zheng Wang, Siyi Wang, and Ziyao Liu. An investigation into value misalignment in llmgenerated texts for cultural heritage. CoRR, abs/2501.02039, 2025.\n[631] Soroush Vosoughi, Deb Roy, and Sinan Aral. The spread of true and false news online. science, 359(6380):1146-1151, 2018.\n[632] Yizhou Zhang, Karishma Sharma, Lun Du, and Yan Liu. Toward mitigating misinformation and social media manipu- lation in llm era. In Companion Proceedings of the ACM on Web Conference 2024, pages 1302-1305, 2024.\n[633] Adam DI Kramer, Jamie E Guillory, and Jeffrey T Hancock. Experimental evidence of massivescale emotional conta- gion through social networks. Proceedings of the National Academy of Sciences, 111(24):8788-8790, 2014.\n[634] Karan Singhal, Tao Tu, Juraj Gottweis, Rory Sayres, Ellery Wulczyn, Mohamed Amin, Le Hou, Kevin Clark, Stephen R Pfohl, Heather Cole-Lewis, et al. Toward expert-level medical question answering with large language models. Nature Medicine, pages 1-8, 2025.\n[635] Yikai Chen, Xiujie Huang, Fangjie Yang, Haiming Lin, Haoyu Lin, Zhuoqun Zheng, Qifeng Liang, Jinhai Zhang, and Xinxin Li. Performance of chatgpt and bard on the medical licensing examinations varies across different cultures: a comparison study. BMC Medical Education, 24(1):1372, 2024.\n[636] Jiaming Ji, Tianyi Qiu, Boyuan Chen, Borong Zhang, Hantao Lou, Kaile Wang, Yawen Duan, Zhonghao He, Jiayi Zhou, Zhaowei Zhang, et al. Ai alignment: A comprehensive survey. arXiv preprint arXiv:2310.19852, 2023.\n[637] Jing Yao, Xiaoyuan Yi, Shitong Duan, Jindong Wang, Yuzhuo Bai, Muhua Huang, Peng Zhang, Tun Lu, Zhicheng Dou, Maosong Sun, et al. Value compass leaderboard: A platform for fundamental and validated evaluation of llms values. arXiv preprint arXiv:2501.07071, 2025.\n[638] Shalom H Schwartz. An overview of the schwartz theory of basic values. Online readings in Psychology and Culture, 2(1):11, 2012.",
    "description": "基础模型与智能决策的进展、挑战与展望。决策智能从基于规则的发展为以人工智能驱动，实现了自适应和情境感知的决策。基础模型统一知识，促进在医疗及其他领域的可扩展、自适应决策。决策基础模型的进展依赖于安全、隐私以及人机伦理的保障。",
    "tags": [],
    "title": "基础模型与智能决策",
    "uri": "/agi/foundation-models-and-intelligent-decision-making.ch/index.html"
  },
  {
    "breadcrumb": "FlitSoft Docs \u003e  UAS \u003e  Aerodynamics",
    "content": "1. 概述 本设计文档旨在为小型固定翼无人机仿真系统提供逼真的飞行动力学与飞行控制方案，替代当前的简单PID+运动学模型，指导后续具体实现与集成。文档涵盖系统需求、6-DOF动力学模型、级联控制架构、模块接口、参数标定及实现建议等内容。\nC++代码实现\n2. 系统需求 实时性：仿真步长 ≤ 0.01s，支持 6-DOF 状态更新与控制运算。 精度：考虑升力、阻力、侧力及机动特性，航向/姿态/速度跟踪误差 ≤ 5%。 可扩展性：支持载荷变化、风场扰动、不同气动数据库切换。 接口兼容：保留现有接口文档中输入/输出字段，向后兼容。 3. 飞行动力学模型（6-DOF） 3.1 状态变量定义 位置与速度：$\\mathbf{r}=[x,y,z]^T$, $\\mathbf{v}=[u,v,w]^T$（机体坐标系）。 姿态与角速度：Euler 角 $[\\phi,\\theta,\\psi]^T$，角速率 $[p,q,r]^T$。 总状态向量：$\\mathbf{x}=[\\mathbf{r},\\mathbf{v},\\phi,\\theta,\\psi,p,q,r]^T$。 3.2 动力学方程 平动方程： $m\\dot{\\mathbf{v}}=\\mathbf{F}_a+\\mathbf{F}_g+\\mathbf{F}_t$\n$\\mathbf{F}_a$：气动力，包含升力、阻力、侧力，由攻角 $\\alpha$、侧滑角 $\\beta$ 及控制面偏角计算。 $\\mathbf{F}_g$：重力，在机体坐标系下投影。 $\\mathbf{F}_t$：推进力，由推力曲线或简单发动机模型获得。 转动方程： $\\mathbf{I}\\dot{\\boldsymbol{\\omega}}+\\boldsymbol{\\omega}\\times(\\mathbf{I}\\boldsymbol{\\omega})=\\mathbf{M}_a+\\mathbf{M}_t$\n$\\mathbf{M}_a$：气动力矩，依赖于控制面夹角与角速率。 $\\mathbf{M}_t$：发动机或尾舵力矩。 姿态更新： $\\dot{\\mathbf{R}}=\\mathbf{R}[\\boldsymbol{\\omega}]_\\times$ 或使用Euler角微分： $\\begin{bmatrix}\\dot{\\phi}\\\\\\dot{\\theta}\\\\\\dot{\\psi}\\end{bmatrix}=\\mathbf{E}(\\phi,\\theta)\\begin{bmatrix}p\\\\q\\\\r\\end{bmatrix}.$\n3.3 气动系数获取与典型值 系数 物理含义 典型值 单位 $C_{L0}$ 零攻角升力系数 0.2 — $C_{L_{\\alpha}}$ 升力曲线斜率 5.7 1/rad $C_{D0}$ 零升阻力系数 0.02 — $k$ 诱导阻力因子 $1/(\\pi AR e)\\approx0.066$ — $AR$ 展弦比 6 — $e$ 诱导阻力效率因子 0.8 — $C_{m0}$ 零攻角俯仰力矩系数 0.05 — $C_{m_{\\alpha}}$ 俯仰力矩斜率 -0.38 1/rad $C_{L_{\\delta_e}}$ 升力—升降舵偏导 0.8 1/rad $C_{m_{\\delta_e}}$ 俯仰力矩—升降舵偏导 -1.1 1/rad 注：数值来源于 Beard \u0026 McLain (2012)；Stevens \u0026 Lewis (2003)，可根据实际试验标定。\n3.4 数值集成 推荐使用 4/5 阶 Runge–Kutta 积分器，步长 0.005–0.01s，保证数值稳定性与精度。 4. 级联控制架构与典型增益 采用三级级联 PID 控制：外环生成姿态/速率指令，中环生成速率指令，内环生成舵面输出。\n4.1 外环（航迹／航路跟随，20 Hz） 航向控制\n误差：$\\tildeψ=ψ_d-ψ$ 控制：$φ_d=K_{p,ψ}\\tildeψ+K_{i,ψ}\\int\\tildeψdt$ 增益：$K_{p,ψ}=1.2,;K_{i,ψ}=0.01$ 高度控制\n误差：$\\tilde h=h_d-h$ 控制：$θ_d=K_{p,h}\\tilde h+K_{i,h}\\int\\tilde h dt$ 增益：$K_{p,h}=0.8,;K_{i,h}=0.005$ 空速控制\n误差：$\\tilde V=V_d-V$ 控制：$δ_T=K_{p,V}\\tilde V+K_{i,V}\\int\\tilde V dt$ 增益：$K_{p,V}=0.5,;K_{i,V}=0.02$ 偏航跟踪\n误差：$\\tildeψ=ψ_d-ψ$ 控制：$r_d=K_{p,ψ_r}\\tildeψ+K_{i,ψ_r}\\int\\tildeψdt$ 增益：$K_{p,ψ_r}=0.5,;K_{i,ψ_r}=0.02$ 4.2 中环（姿态／速率生成，50 Hz） 横滚角生成\n误差：$\\tildeφ=φ_d-φ$ 控制：$p_d=K_{p,φ}\\tildeφ+K_{d,φ}\\dot{\\tildeφ}$ 增益：$K_{p,φ}=5.5,;K_{d,φ}=1.2$ 俯仰角生成\n误差：$\\tildeθ=θ_d-θ$ 控制：$q_d=K_{p,θ}\\tildeθ+K_{i,θ}\\int\\tildeθdt+K_{d,θ}\\dot{\\tildeθ}$ 增益：$K_{p,θ}=6.0,;K_{i,θ}=0.2,;K_{d,θ}=1.0$ 偏航速率辅助\n可结合侧滑角环或直接使用 $r_d$。 4.3 内环（角速率控制，100 Hz） 横滚速率控制\n误差：$\\tilde p=p_d-p$ 控制：$δ_a=K_{p,p}\\tilde p+K_{d,p}\\dot{\\tilde p}$ 增益：$K_{p,p}=8.0,;K_{d,p}=1.5$ 俯仰速率控制\n误差：$\\tilde q=q_d-q$ 控制：$δ_e=K_{p,q}\\tilde q+K_{d,q}\\dot{\\tilde q}$ 增益：$K_{p,q}=9.0,;K_{d,q}=1.8$ 偏航速率控制\n误差：$\\tilde r=r_d-r$ 控制：$δ_r=K_{p,r}\\tilde r+K_{d,r}\\dot{\\tilde r}$ 增益：$K_{p,r}=4.0,;K_{d,r}=0.5$ 4.4 执行周期与时序 外环 20 Hz, 中环 50 Hz, 内环 100 Hz\n主循环示例：\nwhile(sim) { read_state(); if(time%0.05==0) external_loop(); if(time%0.02==0) attitude_loop(); rate_loop(); integrate_dynamics(Δt); log(); } 5. 接口与模块划分 模块 输入 输出 动力学模型 状态 $\\mathbf{x}$，控制 $[δ_T,δ_a,δ_e,δ_r]$ 更新后状态 $\\mathbf{x}_{t+Δt}$ 外环控制 目标航迹/姿态，当前状态 $ψ_d,θ_d,V_d,h_d,r_d,p_d,q_d$ 中环控制 $φ_d,θ_d,r_d$，当前姿态 $p_d,q_d,r_d$ 内环控制 $p_d,q_d,r_d$，当前角速 $δ_a,δ_e,δ_r$ 6. 参数标定与验证 开环仿真：验证动力学模型平飞稳定性。 阶跃响应测试：分析外环/中环/内环步响应特性。 闭环跟踪：执行航线跟随、高度保持、空速保持任务，记录误差。 蒙特卡洛测试：加入风/参数扰动，评估鲁棒性。 7. 实现建议 使用 Eigen 实现矩阵运算与 RK 积分。 将控制器与动力学模型封装为模块化接口（虚基类+派生）。 参数通过 JSON/YAML 配置加载，并支持在线调参。 日志与可视化：保存关键变量，用于离线分析与调优。 C++代码实现\n8. 参考文献 Stevens, B.L., \u0026 Lewis, F.L. (2003). Aircraft Control and Simulation. Wiley. Beard, R.W., \u0026 McLain, T.W. (2012). Small Unmanned Aircraft: Theory and Practice. Princeton University Press. JSBSim User Guide, PRIMES, Inc.",
    "description": "为小型固定翼无人机仿真系统提供逼真的飞行动力学与飞行控制方案，替代当前的简单PID+运动学模型。文档涵盖系统需求、6-DOF动力学模型、级联控制架构、模块接口、参数标定及实现建议等内容。",
    "tags": [],
    "title": "小型固定翼无人机飞行动力学模型",
    "uri": "/uas/fix_wing_uav_flight_sim/fix_wing_uav_flight_sim/index.html"
  },
  {
    "breadcrumb": "FlitSoft Docs \u003e  UAS \u003e  Trajectory Planning \u003e  kappa-trajectories",
    "content": "本文实现了一种实时算法，该算法生成 $\\kappa$-轨迹。如果 $\\kappa=1$，则 $\\kappa$ 轨迹以最短时间从航路点段 $\\overline{\\mathbf{w}_{i-1} \\mathbf{w}_{i}}$ 过渡到航路点段 $\\overline{\\mathbf{w}_{i} \\mathbf{w}_{i+1}}$。如果 $\\kappa=0$，则 $\\kappa$-轨迹执行一个最小时间过渡，前提是它直接通过 $\\mathbf{w}_{i}$。我们还将在本节中展示如何选择 $\\kappa$，使得 $\\kappa$-轨迹具有与原始航路点路径相同的路径长度。\n图6. 选择 $u$ 背后基本思想的图示。\n算法的基本思想如图6所示。右转和左转约束分别由方程(10)-(11)给出的 $\\mathcal{C}_{R}$ 和 $\\mathcal{C}_{L}$ 在不同时间点表示。时间的进程由 $t_{1}, \\ldots t_{6}$ 表示。为了避免图形过于复杂，图中未显示在时间 $t_{2}$ 和 $t_{5}$ 时的右转约束 $\\mathcal{C}_{R}$。在时间 $t_{1}$ 时，DTS 正在跟踪航路点段 $\\overline{\\mathbf{w}_{i-1} \\mathbf{w}_{i}}$。当左转圆 $\\mathcal{C}_{L}$ 在时间 $t_{2}$ 与 $\\mathcal{C}_{\\mathbf{p}(\\kappa)}$ 相交时，$u$ 被设置为 $-c$。左转约束被跟随，直到右转圆 $\\mathcal{C}_{R}$ 在时间 $t_{3}$ 与 $\\mathcal{C}_{\\mathbf{p}(\\kappa)}$ 完全一致。然后，DTS 变量 $u$ 被设置为 $+c$，右转约束被跟随，直到左转约束 $\\mathcal{C}_{L}$ 在时间 $t_{4}$ 与航路点段 $\\overline{\\mathbf{w}_{i} \\mathbf{w}_{i+1}}$ 相交。DTS 变量 $u$ 再次被设置为 $-c$，直到它在时间 $t_{5}$ 到达航路点段，此时 $u$ 被设置为零。\n对于 $\\kappa \\in [0,1)$，图7展示了DTS选择 $u$ 的流程图。DTS算法的名义状态是跟踪当前的航路点路径段。由于方程(7)-(9)是通过固定采样率求解器求解的，因此无法通过简单地设置 $u=0$ 来跟踪路径。使用的跟踪算法将在第五节中讨论。当DTS开始跟踪当前航路点段时，首先计算 $\\mathcal{C}_{p(\\kappa)}$ 的位置。如果转弯是顺时针转弯，则监测约束圆 $\\mathcal{C}_{L}$，直到它与 $\\mathcal{C}_{p(\\kappa)}$ 相交，此时 $u \\leftarrow -c$（图6中的时间 $t_{2}$）。当 $u = -c$ 时，DTS 的运动使得 $\\mathcal{C}_{L}$ 静止不动。然后监测约束圆 $\\mathcal{C}_{R}$，直到它与 $\\mathcal{C}_{p(\\kappa)}$ 完全重合，此时 $u \\leftarrow +c$（时间 $t_{3}$）。此时，$\\mathcal{C}_{R}$ 静止不动，监测 $\\mathcal{C}_{L}$，直到它从右侧与航路点段 $\\overline{\\mathbf{w}_{i} \\mathbf{w}_{i+1}}$ 相交，此时 $u \\leftarrow -c$（时间 $t_{4}$）。此时，约束圆 $\\mathcal{C}_{L}$ 静止不动，监测 $\\mathcal{C}_{R}$，直到它不再与 $\\overline{\\mathbf{w}_{i} \\mathbf{w}_{i+1}}$ 相交，此时恢复跟踪（时间 $t_{5}$）。如果转弯是逆时针方向，则遵循类似的步骤。\n切换时间通过找到圆和直线的交点来确定。在数字硬件中找到这些切换时间存在实际问题。这些问题及其相关影响将在第五节中讨论。\n图7. 针对 $\\kappa \\in [0,1)$ 的DTS算法框图\n如果 $\\kappa=1$，则DTS算法将大大简化。与 $\\kappa \\in [0,1)$ 的情况类似，第一步是确定 $\\mathcal{C}_{\\mathbf{p}(\\kappa)}$ 和转弯方向。如图8所示，对于顺时针转弯，DTS 跟踪直线路径段 $\\overline{\\mathbf{w}_{i-1} \\mathbf{w}_{i}}$，直到 $\\mathcal{C}_{R}$ 与 $\\mathcal{C}_{p(\\kappa)}$ 重合，此时 $u \\leftarrow +c$（图8中的时间 $t_{2}$）。然后，$\\mathcal{C}_{R}$ 静止不动，监测 $\\mathcal{C}_{L}$，直到整个圆位于航路点段 $\\overline{\\mathbf{w}_{i} \\mathbf{w}_{i+1}}$ 的左侧（时间 $t_{3}$），此时恢复跟踪。\n图8. 针对 $\\kappa=1$ 的DTS算法。\n以下定理断言，DTS算法实现了第三节中定义的极值 $\\kappa$-轨迹。\n定理 5：图7所示的DTS算法实现了第三节中定义的极值 $\\kappa$-轨迹。\nDTS算法可以根据所使用的应用配置为不同的模式。例如，可能希望选择 $\\kappa$ 以便轨迹与航路点的距离为 $D$。例如，这种模式可以用于确保附加到无人机上的传感器的探测范围经过航路点。如果 $D \\in \\left[0, R\\left(1 / \\sin \\frac{\\beta}{2} - 1\\right)\\right]$，那么通过使用方程(19)，可以简单地证明 $\\kappa$ 的正确选择是\n$$ \\kappa^{*}=\\frac{D}{R} \\frac{\\sin \\frac{\\beta}{2}}{1-\\sin \\frac{\\beta}{2}} . $$如果希望轨迹直接通过航路点，则选择 $\\kappa^{*} = 0$。另一方面，如果希望在航路点之间仅通过一次转弯过渡，则选择 $\\kappa^{*} = 1$。\n对于时间关键任务，通常希望根据航路点路径规划任务。然而，如果轨迹平滑过程改变了航路点路径的路径长度，那么任务的时间安排将受到影响。因此，希望选择 $\\kappa$，使得 $\\kappa$-轨迹的路径长度等于航路点路径的路径长度。为此，下面的引理推导了 $\\kappa$-轨迹路径长度的解析表达式。\n引理 6：如果 $\\kappa \\in [0,1]$，且 $R = \\hat{v} / c$，则图4中所示的 $\\kappa$-轨迹的路径长度由以下公式给出： $$ \\begin{aligned} \u0026\\mathcal{L}\\left(\\kappa, \\mathbf{w}_{i+1}, \\mathbf{w}_{i}, \\mathbf{w}_{i-1}\\right)=\\left\\|\\mathbf{w}_{i+1}-\\mathbf{w}_{i}\\right\\|+\\left\\|\\mathbf{w}_{i}-\\mathbf{w}_{i-1}\\right\\| \\\\ \u0026+2 R\\left(\\frac{\\pi-\\beta}{2}+2 \\cos ^{-1}(\\Xi(\\kappa, \\beta))-\\Xi(\\kappa, \\beta) \\sqrt{\\frac{1}{\\Xi(\\kappa, \\beta)^{2}}-1}-(1-\\kappa) \\cos \\frac{\\beta}{2}-\\kappa \\cot \\frac{\\beta}{2}\\right), \\end{aligned} $$where\n$$ \\beta=\\cos ^{-1}\\left(\\left(\\frac{\\mathbf{w}_{i+1}-\\mathbf{w}_{i}}{\\left\\|\\mathbf{w}_{i+1}-\\mathbf{w}_{i}\\right\\|}\\right)^{T}\\left(\\frac{\\mathbf{w}_{i}-\\mathbf{w}_{i-1}}{\\left\\|\\mathbf{w}_{i}-\\mathbf{w}_{i-1}\\right\\|}\\right)\\right), $$and\n$$ \\Xi(\\kappa, \\beta)=\\frac{(1+\\kappa)+(1-\\kappa) \\sin \\frac{\\beta}{2}}{2} . $$证明：参考图 9，我们看到 $$ \\begin{aligned} \\mathcal{L} \u0026=\\left\\|\\mathbf{w}_{i+1}-\\mathbf{w}_{i}\\right\\|+\\left\\|\\mathbf{w}_{i}-\\mathbf{w}_{i-1}\\right\\|-2\\left(\\overline{\\mathbf{w}_{i} c}+\\overline{c e}\\right)+2(R \\theta+R(\\pi / 2+\\theta-\\beta / 2)) \\\\ \u0026=\\left\\|\\mathbf{w}_{i+1}-\\mathbf{w}_{i}\\right\\|+\\left\\|\\mathbf{w}_{i}-\\mathbf{w}_{i-1}\\right\\|+2 R\\left(\\frac{\\pi-\\beta}{2}+2 \\theta-\\frac{\\overline{\\mathbf{w}_{i} c}+\\overline{c e}}{R}\\right) \\end{aligned} $$We note that\n$$ \\overline{c e}=\\sqrt{(R+\\overline{c d})^{2}-R^{2}} . $$根据正弦定律，\n$$ \\frac{\\overline{\\mathbf{w}_{i} c}}{\\sin \\left(\\frac{\\pi}{2}+\\theta-\\frac{\\beta}{2}\\right)}=\\frac{R+\\overline{\\mathbf{w}_{i} \\mathbf{p}(\\kappa)}}{\\sin \\left(\\frac{\\pi}{2}-\\theta\\right)}=\\frac{R-\\overline{c d}}{\\sin \\left(\\frac{\\beta}{2}\\right)} . $$ 图9. 引理 6 证明中的定义。\n通过解出 $\\overline{cd}$ 和 $\\overline{\\mathbf{w}_{i} c}$，我们得到：\n$$ \\begin{aligned} \\overline{c d} \u0026=R-\\left(R+\\overline{\\mathbf{w}_{i} \\mathbf{p}(\\kappa)}\\right) \\frac{\\sin \\left(\\frac{\\beta}{2}\\right)}{\\cos \\theta} \\\\ \\overline{\\mathbf{w}_{i} c} \u0026=\\left(R+\\overline{\\mathbf{w}_{i} \\mathbf{p}(\\kappa)}\\right) \\frac{\\cos \\left(\\theta-\\frac{\\beta}{2}\\right)}{\\cos \\theta}=\\left(R+\\overline{\\mathbf{w}_{i} \\mathbf{p}(\\kappa)}\\right)\\left(\\cos \\frac{\\beta}{2}+\\tan \\theta \\sin \\frac{\\beta}{2}\\right) . \\end{aligned} $$从图9，使用 $\\cos \\theta = \\frac{R}{R + \\overline{c d}}$，我们得到：\n$$ \\cos \\theta=\\frac{R+\\left(R+\\overline{\\mathbf{w}_{i} \\mathbf{p}(\\kappa)}\\right) \\sin \\left(\\frac{\\beta}{2}\\right)}{2 R} $$注意到 $\\beta \\in (0, \\pi)$ 并从方程(19)中代入，得到：\n$$ \\overline{\\mathbf{w}_{i} \\mathbf{p}(\\kappa)}=\\kappa R\\left(\\frac{1}{\\sin \\left(\\frac{\\beta}{2}\\right)}-1\\right) $$解出 $\\theta$，得到：\n$$ \\theta=\\cos ^{-1}\\left(\\frac{(1+\\kappa)+(1-\\kappa) \\sin \\frac{\\beta}{2}}{2}\\right)=\\cos ^{-1}(\\Xi(\\kappa, \\beta)) . $$将方程(36)和(38)代入方程(34)，得到：\n$$ \\overline{c e}=R \\sqrt{\\frac{4}{\\left[(1+\\kappa)+(1-\\kappa) \\sin \\frac{\\beta}{2}\\right]^{2}}-1}=R \\sqrt{\\frac{1}{\\Xi^{2}(\\kappa, \\beta)}-1} $$从图9中注意到 $\\tan \\theta = \\frac{\\overline{c e}}{R}$，并使用方程(40)，我们可以从方程(37)中解出 $\\overline{\\mathbf{w}_{i} c}$，得到：\n$$ \\begin{aligned} \\overline{\\mathbf{w}_{i} c} \u0026=R\\left((1-\\kappa)+\\frac{\\kappa}{\\sin \\frac{\\beta}{2}}\\right)\\left(\\cos \\frac{\\beta}{2}+\\sin \\frac{\\beta}{2} \\sqrt{\\frac{4}{\\left[(1+\\kappa)+(1-\\kappa) \\sin \\frac{\\beta}{2}\\right]^{2}}-1}\\right) \\\\ \u0026=R\\left((\\Xi(\\kappa, \\beta)-1) \\sqrt{\\frac{1}{\\Xi^{2}(\\kappa, \\beta)}-1}+(1-\\kappa) \\cos \\frac{\\beta}{2}+\\kappa \\cot \\frac{\\beta}{2}\\right) . \\end{aligned} $$因此，将方程(39)、(40)和(41)代入方程(33)得到方程(30)。\n从引理6可以看出，航路点路径 $\\overline{\\mathbf{w}_{i-1} \\mathbf{w}_{i} \\mathbf{w}_{i+1}}$ 和相关的 $\\kappa$-轨迹之间的路径长度差异由以下给出： $$ \\begin{aligned} \\Lambda\\left(\\kappa, \\mathbf{w}_{i+1}, \\mathbf{w}_{i}, \\mathbf{w}_{i-1}\\right)=2 R\\left(\\frac{\\pi-\\beta}{2}+2 \\cos ^{-1}(\\Xi(\\kappa, \\beta))-\\Xi(\\kappa, \\beta) \\sqrt{\\frac{1}{\\Xi(\\kappa, \\beta)^{2}}-1}\\right.\\\\ \u0026\\left.-(1-\\kappa) \\cos \\frac{\\beta}{2}-\\kappa \\cot \\frac{\\beta}{2}\\right) . \\end{aligned} $$以下引理将用于找到 $\\kappa$，使得 $\\kappa$-轨迹与航路点轨迹具有相同的路径长度。\n引理 7：如果 $\\beta \\in [0, \\pi)$ 且 $\\kappa \\in [0, 1]$，则 $\\Lambda$ 是 $\\kappa$ 的递减函数。此外，$\\left.\\Lambda\\left(0, \\mathbf{w}_{i+1}, \\mathbf{w}_{i}, \\mathbf{w}_{i-1}\\right)\\right)\u003e0$ 且 $\\Lambda\\left(1, \\mathbf{w}_{i+1}, \\mathbf{w}_{i}, \\mathbf{w}_{i-1}\\right)\u003c0$。\n证明：对式（42）关于 $\\kappa$ 求导，经过一些代数变换，得\n$$ \\frac{\\partial \\Lambda}{\\partial \\kappa} = 2R \\left[-\\frac{\\partial \\Xi}{\\partial \\kappa} \\sqrt{\\frac{1}{\\Xi^2} - 1} + \\frac{\\partial \\Xi}{\\partial \\kappa} \\frac{1}{\\sqrt{1-\\Xi^2}} \\left(-2 + \\frac{1}{\\Xi}\\right) + \\cot \\frac{\\beta}{2} \\left(\\sin \\frac{\\beta}{2} - 1\\right) \\right]. $$由式（32）知，$\\beta \\in [0,\\pi)$ 且 $\\kappa \\in [0,1]$ 意味着 $\\Xi \\geq 0$ 且\n$$ \\frac{\\partial \\Xi}{\\partial \\kappa} = \\frac{1 - \\sin \\frac{\\beta}{2}}{2} \u003e 0. $$因此，若\n$$ -2 + \\frac{1}{\\Xi} \\leq 0, $$则有\n$$ \\frac{\\partial \\Lambda}{\\partial \\kappa} \u003c 0. $$根据定义，有\n$$ \\begin{aligned} -2 + \\frac{1}{\\Xi} \u0026= -2 + \\frac{1 + \\sin \\frac{\\beta}{2}}{2} + \\kappa \\frac{1 - \\sin \\frac{\\beta}{2}}{2} \\\\ \u0026\\leq -2 + \\frac{1 + \\sin \\frac{\\beta}{2}}{2} + \\frac{1 - \\sin \\frac{\\beta}{2}}{2} \\\\ \u0026= -1. \\end{aligned} $$因此，$\\Lambda$ 关于 $\\kappa$ 是递减函数。\n具体表达式为\n$$ \\begin{aligned} \\Lambda\\left(\\kappa, \\mathbf{w}_{i+1}, \\mathbf{w}_i, \\mathbf{w}_{i-1}\\right) = 2R \\Bigg(\u0026 \\frac{\\pi - \\beta}{2} + 2 \\cos^{-1}(\\Xi(\\kappa, \\beta)) - \\Xi(\\kappa, \\beta) \\sqrt{\\frac{1}{\\Xi(\\kappa, \\beta)^2} - 1} \\\\ \u0026 - (1-\\kappa) \\cos \\frac{\\beta}{2} - \\kappa \\cot \\frac{\\beta}{2} \\Bigg). \\end{aligned} $$注意到\n$$ \\Xi(0, \\beta) = \\frac{1 + \\sin \\frac{\\beta}{2}}{2}, $$从式（42）经代数变换可得\n$$ \\Lambda(0, \\beta) = 2R \\left[ \\frac{\\pi - \\beta}{2} + 2 \\cos^{-1} \\left( \\frac{1 + \\sin \\frac{\\beta}{2}}{2} \\right) - \\sqrt{1 - \\frac{1}{4} \\left(1 + \\sin \\frac{\\beta}{2}\\right)^2} - \\cos \\frac{\\beta}{2} \\right]. $$注意 $\\Lambda(0, \\pi) = 0$，且\n$$ \\frac{\\partial \\Lambda}{\\partial (\\beta/2)}(0, \\beta) = 2R \\left[ \\left( \\sin \\frac{\\beta}{2} - 1 \\right) + \\frac{ \\cos \\frac{\\beta}{2} \\left( \\frac{1}{4} (1 + \\sin \\frac{\\beta}{2}) - 1 \\right) }{ \\sqrt{1 - \\frac{1}{4} (1 + \\sin \\frac{\\beta}{2})^2} } \\right]. $$由拉格朗日余项定理 [29]，存在 $a \\in (\\beta, \\pi)$，使得\n$$ \\Lambda(0, \\beta) = \\frac{\\partial \\Lambda}{\\partial (\\beta/2)} (0, a) \\left( \\frac{\\beta - \\pi}{2} \\right). $$容易证明，对于所有 $a \\in [0, \\pi)$，有\n$$ \\frac{\\partial \\Lambda}{\\partial (\\beta/2)} (0, a) \u003c 0, $$这意味着 $\\Lambda(0) \u003e 0$。\n另外注意\n$$ \\Xi(1, \\beta) = 1, $$由式（42）可得\n$$ \\Lambda(1, \\beta) = 2R \\left[ \\frac{\\pi - \\beta}{2} - \\cot \\frac{\\beta}{2} \\right]. $$对其求导得到\n$$ \\frac{\\partial \\Lambda}{\\partial (\\beta/2)} (1, \\beta) = \\cot^2 \\frac{\\beta}{2} \u003e 0. $$因此，根据拉格朗日余项定理，存在 $a \\in (\\beta, \\pi)$，使得\n$$ \\Lambda(1, \\beta) = \\cot^2 \\frac{\\beta}{2} \\left( \\frac{\\beta - \\pi}{2} \\right). $$这意味着对于所有 $\\beta \\in [0, \\pi)$，$\\Lambda(1, \\beta) \u003c 0$。\n对于时间关键任务，必须保证由DTS生成的轨迹的路径长度与原始航路点轨迹 $\\mathcal{P}$ 的路径长度相同。下一个定理表明，存在一个 $\\kappa \\in [0, 1]$ 使得路径长度相等。\n定理 8：如果 $\\Lambda\\left(\\kappa, \\mathbf{w}_{i-1}, \\mathbf{w}_{i}, \\mathbf{w}_{i+1}\\right)$ 如方程(42)所给出，其中 $\\beta \\in [0, \\pi)$ 如方程(31)所给出，且 $R = \\hat{v} / c$，则存在唯一的 $\\kappa^{*} \\in [0,1]$ 使得 $\\Lambda\\left(\\kappa^{*}\\right) = 0$。此外，对应于 $\\kappa^{*}$ 的 $\\kappa$-轨迹与航路点路径 $\\overline{\\mathbf{w}_{i-1} \\mathbf{w}_{i} \\mathbf{w}_{i+1}}$ 具有相同的路径长度，即： $$ L=\\left\\|\\mathbf{w}_{i}-\\mathbf{w}_{i-1}\\right\\|+\\left\\|\\mathbf{w}_{i+1}-\\mathbf{w}_{i}\\right\\| . $$此外，$\\kappa^{*}$ 可以通过使用二分查找算法高效地数值求解，精确度为 $\\bigcirc\\left(2^{-n}\\right)$，其中 $n$ 是 $\\Lambda$ 的函数评估次数。\n证明：由引理6可知，$\\Lambda$ 表示 $\\kappa$-轨迹与航路点路径的路径长度差。因此，若 $\\Lambda=0$，则两路径长度相等。由引理7知，存在唯一的 $\\kappa^* \\in [0,1)$，使得 $\\Lambda(\\kappa^*)=0$。\n由于 $\\Lambda(0) \u003e 0$ 且 $\\Lambda(1) \u003c 0$，二分法搜索的第一步选取 $\\kappa=0.5$。$\\Lambda(0.5)$ 的符号决定了 $\\kappa^*$ 所在区间，精确度达到 $2^{-1}$。后续函数调用进一步细化该估计值。",
    "description": "κ轨迹生成算法。κ=1：轨迹以最短时间过渡到下一个航段；κ=0：轨迹执行一个最小时间过渡，并直接通过航路点；求解κ∈[0,1]使轨迹具有与原始航路点路径等长",
    "tags": [],
    "title": "κ轨迹平滑",
    "uri": "/uas/trajectory_planning/kappa-trajectories/kappa-%E8%BD%A8%E8%BF%B9/index.html"
  },
  {
    "breadcrumb": "FlitSoft Docs \u003e  UAS \u003e  Trajectory Planning \u003e  kappa-trajectories",
    "content": "这个模块化的 C++ 代码，用于在给定 $\\kappa \\in [0,1]$ 的条件下，在航路点之间生成平滑的 $\\kappa$-轨迹点。\n该代码将专注于根据论文中的几何定义（Definition 3 和 Lemma 6 的证明图 Fig. 9 ）计算构成转弯的三个圆弧段以及与这些圆弧相切的入段点和出段点。\nC++实现代码\n核心思路： 确定几何参数：根据输入的三个航点 $w_{i-1}, w_i, w_{i+1}$，计算转弯角 $\\beta$（即论文中的 $\\beta_{corner}$，角 $w_{i-1}w_iw_{i+1}$），以及相关的方向向量。 计算 $p(\\kappa)$ 点：这是由参数 $\\kappa$ 控制的、位于角平分线上的一个关键点 。 确定中间圆弧 $\\mathcal{C}_{p(\\kappa)}$：该圆弧的圆心为 $c_d$，半径为 $R$，并通过 $p(\\kappa)$ 点。其起始点 $P_A$ 和终止点 $P_B$ 由角度 $\\theta = \\cos^{-1}(\\Xi(\\kappa,\\beta))$ 决定 。 确定过渡圆弧 $\\mathcal{C}_i$ 和 $\\mathcal{C}_{i+1}$： $\\mathcal{C}_i$ 连接入航线段和 $\\mathcal{C}_{p(\\kappa)}$，圆心为 $c_1$，在 $P_A$ 点与 $\\mathcal{C}_{p(\\kappa)}$ 相切，并与入航线段在 $T_1$ 点相切。 $\\mathcal{C}_{i+1}$ 连接 $\\mathcal{C}_{p(\\kappa)}$ 和出航线段，圆心为 $c_2$，在 $P_B$ 点与 $\\mathcal{C}_{p(\\kappa)}$ 相切，并与出航线段在 $T_2$ 点相切。 生成轨迹点：沿直线段 $w_{i-1} \\to T_1$，圆弧 $T_1 \\to P_A$，圆弧 $P_A \\to P_B$，圆弧 $P_B \\to T_2$，以及直线段 $T_2 \\to w_{i+1}$ 生成离散点。本代码将主要生成三个圆弧段的点以及切点 $T_1, T_2$。 代码说明： Point2D 结构体：用于表示二维坐标点和向量，并提供基本的向量运算（加减、数乘、点积、模长、单位化、旋转）。 TurnGeometry 结构体：用于存储生成结果，包括入航线段切点 T1、出航线段切点 T2 以及构成三个平滑圆弧的路径点序列。 KappaTrajectoryGenerator 类： generateTurnTrajectory 方法： 接收三个连续航点 w_im1, w_i, w_ip1，期望速度 v_hat，最大转向速率 turn_rate_c，kappa 参数以及每个圆弧段的点数。 计算转弯半径 $R = \\hat{v}/c$。 计算角 $w_{i-1}w_iw_{i+1}$ (代码中为 beta_corner)。 处理直线和U型转弯等退化情况。 计算角平分线向量 u_bisector。 根据公式 (19) 计算 $p(\\kappa)$ 点 (pk) 。 计算中间圆弧 $\\mathcal{C}_{p(\\kappa)}$ 的圆心 c_d。 根据公式 (32) 和 (39) 计算 $\\Xi(\\kappa, \\beta)$ (xi_val) 和 $\\theta$ (theta_xi) 。 确定转弯方向 (turn_direction_sign)。 计算中间圆弧的起止点 P_A 和 P_B。 计算第一个过渡圆弧 $\\mathcal{C}_i$ 的圆心 c_1 和第二个过渡圆弧 $\\mathcal{C}_{i+1}$ 的圆心 c_2。这两个圆弧分别与中间圆弧在 P_A 和 P_B 点相切。 计算入航线段与 $\\mathcal{C}_i$ 的切点 T1 (tangent_point_on_incoming_segment) 和出航线段与 $\\mathcal{C}_{i+1}$ 的切点 T2 (tangent_point_on_outgoing_segment)。 调用 addArcPoints 辅助函数，依次生成三个圆弧段（$T_1 \\to P_A$， $P_A \\to P_B$， $P_B \\to T_2$）上的离散点，并存入 result.path_points。 addArcPoints 辅助方法： 根据圆心、起点、终点、半径和转弯方向，通过插值计算圆弧上的多个点。 它会处理角度的周期性，并尝试选择最短的弧线路径。 如何在无人机仿真系统中使用：\n集成代码：将 Point2D、TurnGeometry 和 KappaTrajectoryGenerator 的代码集成到您的项目中。 实例化生成器：KappaTrajectoryGenerator generator; 路径规划流程： 对于一条由多个航点 $W_0, W_1, ..., W_N$ 组成的路径。 第一段直线：$W_0$ 到 $W_1$ (如果只有一个航段)。 对于每个转弯点 $W_k$ (由 $W_{k-1}, W_k, W_{k+1}$ 定义，其中 $k=1, ..., N-1$)： 调用 turn_geom = generator.generateTurnTrajectory(W_{k-1}, W_k, W_{k+1}, v_hat, c_rate, kappa_val_for_this_turn, ...)。 kappa_val_for_this_turn 可以是固定的，也可以是通过前一个回复中的 KappaTrajectorySolver (等长$\\kappa$-轨迹算法) 计算得出的 $\\kappa^*$。 如果 turn_geom.is_valid 为真： 前一个航段的终点（或 $W_0$）连接到 turn_geom.tangent_point_on_incoming_segment (直线)。 然后是 turn_geom.path_points 中的平滑圆弧点。 然后从 turn_geom.tangent_point_on_outgoing_segment 连接到下一个转弯的入切点（或最终航点 $W_N$）(直线)。 将这些点序列组合起来，形成完整的平滑路径。 重要提示：\n坐标系：确保所有输入的航点坐标都使用一致的二维坐标系。 单位：确保速度（米/秒）、转向速率（弧度/秒）的单位正确。 退化情况：代码中对直线和接近U型转弯的情况进行了初步处理。在这些情况下，三圆弧模型会退化，可能需要根据实际需求采用更特定的平滑策略（例如，对于U型转弯，直接使用一个半径为R的半圆）。 addArcPoints的鲁棒性：addArcPoints 中的角度处理逻辑是为了确保圆弧按正确的方向（顺时针/逆时针）和最短路径生成。在某些极端情况下，可能仍需微调。 点密度：num_points_per_arc 参数控制每个圆弧的平滑程度。值越大，轨迹越平滑，但点也越多。 此代码提供了一个基于论文几何定义的 $\\kappa$-轨迹生成框架。您可以根据仿真系统的具体需求进行调整和扩展。\n代码优化内容 对于 $\\kappa=1$，根据论文中的描述和图示 (如图8 )，路径会简化为从入航线段直接过渡到一个单一的转弯圆弧，然后再连接到出航线段。这个单一圆弧的圆心就是论文图3中描述的内切圆 $\\overline{\\mathcal{C}}$ 的圆心，并且该圆弧会通过点 $\\overline{p}$ (即 $p(1)$)。三圆弧模型在这种情况下会自然地退化：中间的圆弧长度变为零（因为 $\\theta_{Xi}=0$），而两边的过渡圆弧会合并。\n对于 $\\kappa=0$，路径应直接经过航点 $w_i$ 。三圆弧几何结构依然适用，其中 $p(0) = w_i$，意味着中间的圆弧会通过 $w_i$。\n以下是优化后的代码。主要改动包括：\n针对 $\\kappa=1$ 的显式处理：当 kappa 接近1时，采用简化的单圆弧逻辑生成路径。 针对 $\\kappa=0$ 的处理：虽然通用逻辑已能处理，但代码中明确了此时 $p(\\kappa)$ 即为 $w_i$。 代码结构和注释：调整了部分代码结构，增加了更多中文注释，提高了可读性。 数值稳定性：对一些关键计算（如 sin_beta_half 接近零）增加了检查。 addArcPoints 优化：改进了 addArcPoints 中处理角度的逻辑，使其更鲁棒，并确保不会重复添加起点。 主要优化和改动点：\nkappa = 1 的特殊处理：\n当 std::abs(kappa - 1.0) \u003c epsilon 时，代码会进入一个专门的分支。 在此分支中，它计算点 $p(1)$ (论文中的 $\\overline{p}$ ) 和以此点及半径 $R$ 定义的单个转弯圆弧的圆心 (论文图3中的 $\\overline{\\mathcal{C}}$ 的圆心 )。 然后计算入航线段和出航线段与这个单一圆弧的切点 $T_1$ 和 $T_2$。 最后，只调用一次 addArcPoints 来生成 $T_1$ 和 $T_2$ 之间的单一圆弧段。这符合论文中对 $\\kappa=1$ 时轨迹的描述，即一个更简单的、最短时间的转弯 。 kappa = 0 的处理：\n当 std::abs(kappa) \u003c epsilon 时，明确将 pk (即 $p(\\kappa)$) 设置为 w_i。 这确保了当 $\\kappa=0$ 时，轨迹的中间部分会经过（或非常接近）原始转弯点 $w_i$，符合论文描述。 后续的计算（c_d, theta_xi 等）会基于 pk = w_i 进行，三圆弧模型依然适用。 addArcPoints 函数改进：\n在添加圆弧点之前，会检查 points_vec 是否为空，或者新圆弧的起点 start_point 是否与 points_vec 的最后一个点足够接近。如果是，则不重复添加 start_point，避免路径点序列中出现不必要的重复点。 对 angle_diff 的调整逻辑进行了优化，以更准确地处理跨越 $\\pm\\pi$ 的情况，并确保转弯方向正确。 如果起点和终点非常接近，会直接添加终点并返回，避免不必要的插值。 数值稳定性与错误处理：\n对除零操作（如向量单位化、除以scalar）增加了更严格的检查（比较小的 epsilon）。 对 sin(beta_corner / 2.0) 过小的情况增加了检查，因为它是多个公式的分母。 对 acos 的输入 dot_product 和 xi_val 进行了钳位，确保它们在 [-1, 1] 范围内。 TurnGeometry 结构体中增加了 info 字段，用于返回生成过程中的一些提示信息或错误信息。 退化情况处理：\n代码对 beta_corner 接近0（直线）或 $\\pi$（U型转弯）的情况进行了处理。在这些情况下，$\\kappa$-轨迹模型可能会退化，代码会返回一个简化的结果（例如，对于直线，返回 $w_i$ 作为路径点）。 这些改动使得代码在处理特定的 $\\kappa$ 值时更加精确和高效，同时也提高了其在各种几何情况下的鲁棒性。\n代码输出内容 该C++代码（KappaTrajectoryGenerator 类中的 generateTurnTrajectory 方法）最终给用户（调用该方法的代码模块）提供的输出内容是一个名为 TurnGeometry 的结构体对象。这个结构体包含以下几个部分：\ntangent_point_on_incoming_segment (类型：Point2D):\n这是计算出的平滑转弯路径与入航线段（由 w_im1 和 w_i 定义）相切的切点 $T_1$ 的二维坐标。无人机将沿直线飞向此点，然后开始转弯。 tangent_point_on_outgoing_segment (类型：Point2D):\n这是计算出的平滑转弯路径与出航线段（由 w_i 和 w_ip1 定义）相切的切点 $T_2$ 的二维坐标。无人机完成转弯后，将从此点开始沿直线飞向下一个目标。 path_points (类型：std::vector\u003cPoint2D\u003e):\n这是一个包含多个 Point2D 对象的动态数组（向量）。这些点共同构成了从切点 $T_1$ 开始，经过一个或三个平滑圆弧，到达切点 $T_2$ 的实际平滑转弯路径上的离散点序列。 这些点的顺序是沿着飞行方向的。 点的数量取决于输入参数 num_points_per_arc 以及转弯的具体几何形状（例如，对于 $\\kappa=1$ 的情况，总点数可能大约是 num_points_per_arc * 3，因为代码中为单圆弧分配了更多点；对于三圆弧情况，总点数大约是 num_points_per_arc * 3，如果中间圆弧长度不为零）。 is_valid (类型：bool):\n一个布尔标志，指示本次平滑转弯几何路径的计算是否成功且有效。如果输入参数不合理（例如，航点重合、转向速率为零、$\\kappa$ 值超出范围）或计算中遇到无法处理的退化情况，此标志会设为 false。 info (类型：std::string):\n一个字符串，用于存储关于本次路径生成的附加信息。这可能包括： 成功生成时的提示信息（例如，“Kappa=1: 单圆弧转弯模式。” 或 “Kappa=0: 路径将通过航点 w_i。\"）。 发生错误或遇到退化情况时的具体描述信息。 总结来说，用户调用该函数后，会得到构成一个完整平滑转弯所需的关键几何信息：\n转弯的起点 ($T_1$) 和终点 ($T_2$) 在原直线路径上的精确位置。 连接 $T_1$ 和 $T_2$ 的一系列平滑曲线上的离散坐标点。 一个状态标志表明计算结果是否可用。 相关的状态或错误文本信息。 仿真系统中的路径规划模块可以使用这些输出数据来构建最终的飞行路径：它会将前一段的直线路径连接到 $T_1$，然后使用 path_points 中的点序列作为转弯部分，最后从 $T_2$ 连接到后一段的直线路径。\n输出曲线的离散化 连接 $T_1$ 和 $T_2$ 的一系列平滑曲线上的离散坐标点，是按照以下原则进行离散化的：\n该平滑曲线是由一个或三个连续的圆弧段组成的。代码中的 addArcPoints 函数负责对每一个单独的圆弧段进行离散化。其原则是：\n等角度间隔 (Equiangular Discretization)：\n对于构成平滑转弯的每一个圆弧段（例如，从 $T_1$ 到 $P_A$，或 $P_A$ 到 $P_B$，或 $P_B$ 到 $T_2$），函数首先计算出该圆弧段的起始角度和终止角度（相对于圆心）。 然后，根据这两个角度和转弯方向，确定圆弧的总张角（angle_diff）。 这个总张角会被分割成 num_points 个（num_points 是传递给 addArcPoints 函数的参数，对应于您在 generateTurnTrajectory 中设置的 num_points_per_arc）相等的小角度。 通过在起始角度上累加这些小角度间隔，得到一系列中间角度。 圆上点计算：\n对于每一个通过等角度间隔计算出来的中间角度，利用圆的参数方程（$x = center_x + R \\cdot \\cos(\\text{angle})$, $y = center_y + R \\cdot \\sin(\\text{angle})$）计算出该角度在圆弧上的对应点的二维坐标。 点序列的生成：\naddArcPoints 函数会将当前处理的圆弧段的起点加入到总路径点列表 path_points 中（除非它与列表中的最后一个点重复）。 然后，它会通过上述的等角度间隔方法，依次生成 num_points 个点，并将这些点加入到 path_points 列表中。最后一个生成的点将是当前圆弧段的终点。 总之：\n整个平滑曲线（$T_1 \\to T_2$）是由一个或三个圆弧段拼接而成。 每个圆弧段都是通过在其总张角内进行均匀的角度分割来离散化的。 离散点的数量由 num_points_per_arc 参数控制，它决定了每个圆弧段（除了起点之外）将被近似为多少个小直线段。这个值越大，生成的曲线点越多，路径看起来越平滑，但计算量和数据量也相应增加。 因此，离散化的核心原则是在每个构成转弯的圆弧上，以相等的角度增量来采样点。\nC++实现代码",
    "description": "针对模块化的κ轨迹点生成 C++ 代码的详细说明。用于在给定 κ∈ [0,1] 的条件下，在航路点之间生成平滑的 κ-轨迹点。",
    "tags": [],
    "title": "κ轨迹点生成代码说明",
    "uri": "/uas/trajectory_planning/kappa-trajectories/kappa%E8%BD%A8%E8%BF%B9%E7%82%B9%E7%94%9F%E6%88%90c++%E4%BB%A3%E7%A0%81%E8%AF%B4%E6%98%8E/index.html"
  },
  {
    "breadcrumb": "FlitSoft Docs \u003e  UAS \u003e  Velocity Planning",
    "content": "该文档描述了算法的数学模型、约束条件以及求解流程。文档中的符号和公式与代码中的计算逻辑相对应，详细说明了如何根据输入参数（如轨迹弧长 $S$、总飞行时间$T$、进入速度 $v_{In}$、期望速度 $v_{Des}$、最小/最大速度 $v_{min}, v_{max}$、最大加速度 $a_{Max} $和最大加加速度 $j_{Max}$）计算出整个轨迹在仿真步长 $dt$ 下的速度、加速度和加加速度曲线，同时在后段尽可能保持接近期望速度飞行，并通过二分查找调整 $v_{Des}$ 以匹配目标弧长。\n1. 引言 本模型旨在为无人机轨迹规划提供一条平滑的 S 曲线速度规划方案。给定目标轨迹弧长 $S$ 与总飞行时间 $T$，输入参数包括进入速度 $v_{in}$ 与期望速度 $v_{des}$（代码中记为 vIn 与 vDes），同时受到速度上下限 $v_{min}, v_{max}$ 以及动态约束：最大加速度 $a_{max}$ 和最大加加速度 $j_{max}$ 的限制。整个模型通过先计算变速（过渡）阶段的 S 曲线段，再补充恒速段（定速阶段），最后利用二分查找方法调整期望速度以匹配目标弧长，从而生成一组离散时间点上的速度、加速度和加加速度数据。\n在线计算器链接\nC++代码库： https://github.com/flitai/Velocity_Plan/\n2. 模型参数与符号定义 输入参数：\n$S$ : 轨迹弧长（米） $T$ : 总飞行时间（秒） $v_{in}$ : 进入速度（米/秒） $v_{des}$ : 期望速度（米/秒） $v_{min}$ : 最小允许速度（米/秒） $v_{max}$ : 最大允许速度（米/秒） $a_{max}$ : 最大加速度（米/秒²） $j_{max}$ : 最大加加速度（米/秒³） $dt$ : 仿真步长（秒） 其他符号：\n$\\Delta v = v_{des} - v_{in}$ $s = \\text{sgn}(\\Delta v)$，正表示加速，负表示减速。 3. S 曲线变速段设计 为实现平滑过渡，S 曲线变速段分为两种情况，根据 $|\\Delta v|$ 与 $\\frac{a_{max}^2}{j_{max}}$ 的关系区分为【梯形 S 曲线】与【三角形 S 曲线】。\n3.1 梯形 S 曲线 当\n$$ |\\Delta v| \\ge \\frac{a_{max}^2}{j_{max}}, $$ 采用梯形 S 曲线，其分为三个子段：\n上升阶段（加加速阶段）：\n时间区间：$t \\in [0, T_j]$，其中\n$$ T_j = \\frac{a_{max}}{j_{max}}. $$ 动态表达式： $$ \\begin{aligned} j(t) \u0026= s\\, j_{max},\\\\ a(t) \u0026= s\\, j_{max}\\, t,\\\\ v(t) \u0026= v_{in} + \\frac{s\\, j_{max}\\, t^2}{2}. \\end{aligned} $$ 恒定加速阶段：\n时间区间：$t \\in (T_j,\\, T_j + T_a]$，其中\n$$ T_a = \\frac{|\\Delta v|}{a_{max}} - T_j. $$ 动态表达式： $$ \\begin{aligned} j(t) \u0026= 0,\\\\ a(t) \u0026= s\\, a_{max},\\\\ v(t) \u0026= v_{in} + \\frac{s\\, a_{max}^2}{2j_{max}} + s\\, a_{max}(t - T_j). \\end{aligned} $$ 下降阶段（减加速阶段）：\n时间区间：$t \\in (T_j+T_a,\\, T_{conv}]$，其中\n$$ T_{conv} = 2T_j + T_a. $$ 定义局部时间 $\\tau = t - (T_j+T_a)$，动态表达式： $$ \\begin{aligned} j(t) \u0026= -s\\, j_{max},\\\\ a(t) \u0026= s\\, a_{max} - s\\, j_{max}\\, \\tau,\\\\ v(t) \u0026= v_{in} + \\frac{s\\, a_{max}^2}{2j_{max}} + s\\, a_{max}\\, T_a + s\\Big(a_{max}\\tau - \\frac{j_{max}\\, \\tau^2}{2}\\Big). \\end{aligned} $$ 3.2 三角形 S 曲线 当\n$$ |\\Delta v| \u003c \\frac{a_{max}^2}{j_{max}}, $$ 采用三角形 S 曲线，其分为两个子段：\n上升阶段：\n时间区间：$t \\in [0, T']$，其中\n$$ T' = \\sqrt{\\frac{|\\Delta v|}{j_{max}}}. $$ 动态表达式： $$ \\begin{aligned} j(t) \u0026= s\\, j_{max},\\\\ a(t) \u0026= s\\, j_{max}\\, t,\\\\ v(t) \u0026= v_{in} + \\frac{s\\, j_{max}\\, t^2}{2}. \\end{aligned} $$ 下降阶段：\n时间区间：$t \\in (T',\\, 2T']$，设 $\\tau = t - T'$，动态表达式： $$ \\begin{aligned} j(t) \u0026= -s\\, j_{max},\\\\ a(t) \u0026= s\\, j_{max}(T' - \\tau),\\\\ v(t) \u0026= v_{in} + \\frac{s\\, j_{max}\\, T'^2}{2} + s\\Big(j_{max}\\, T'\\,\\tau - \\frac{j_{max}\\,\\tau^2}{2}\\Big). \\end{aligned} $$ 此时，总变速段时间为\n$$ T_{conv} = 2T'. $$ 4. 定速阶段 在变速阶段（$t \\le T_{conv}$）结束后，进入定速阶段，设定：\n$$ v(t) = v_{des},\\quad a(t)=0,\\quad j(t)=0,\\quad \\text{for } t \\in (T_{conv},\\, T]. $$ 定速阶段的位移为\n$$ S_{const} = v_{des}\\,(T - T_{conv}). $$ 5. 总位移匹配与 vDes 调整 整个飞行的总位移为： $$ S_{total} = S_{conv} + S_{const}, $$ 其中\n$S_{conv} = \\int_{0}^{T_{conv}} v(t)\\, dt$（变速段的累计位移）， $S_{const} = v_{des}\\,(T - T_{conv})$。 目标是满足\n$$ S_{total} = S. $$由于直接根据初始参数计算得到的 $S_{total}$ 可能与目标 $S$ 不符，代码中采用二分查找法在允许范围 $[v_{min}, v_{max}]$ 内调整期望速度 $v_{des}$，使得修正后的 $v_{des}$ 满足 $$ \\left|S_{conv} + v_{des}\\,(T - T_{conv}) - S\\right| \u003c \\epsilon, $$ 其中 $\\epsilon$ 为容忍误差（例如 0.001 米）。\n同时，通过比例因子\n$$ \\text{scaleFactor} = \\frac{v_{des}^{*}}{v_{des}}, $$ 记录调整幅度，以便反馈用户。\n6. 离散化与仿真步骤 时间离散化：\n将总飞行时间 $T$ 以步长 $dt$ 离散为 $N = \\lceil T/dt \\rceil$ 个时间点。\n按阶段计算：\n对于 $t \\le T_{conv}$ 的点，依据所选 S 曲线（梯形或三角形）分别计算对应的 $v(t)$、$a(t)$ 与 $j(t)$，同时累加位移 $S_{conv}$。 对于 $t \u003e T_{conv}$ 的点，设 $v(t) = v_{des}$（调整后的值），位移按 $v_{des} \\times dt$ 累加。 数据输出：\n生成离散的时间序列数据，格式为\n$$ \\{t_k,\\, v(t_k),\\, a(t_k),\\, j(t_k)\\},\\quad k=0,1,\\ldots, N, $$ 用于后续图形显示和进一步分析。\n7. 模型求解流程 初始计算：\n根据输入参数计算 $\\Delta v$ 和符号 $s$。判断 $|\\Delta v|$ 是否满足梯形 S 曲线条件，从而计算对应的 $T_j, T_a$（或 $T'$），进而确定变速阶段时间 $T_{conv}$。\n积分求位移：\n对变速段进行数值积分获得 $S_{conv}$，再计算定速段位移 $S_{const}$，从而得出 $S_{total}$。\n二分查找调整 $v_{des}$：\n若 $S_{total}$ 与目标 $S$ 存在误差，则在 $[v_{min}, v_{max}]$ 范围内采用二分查找调整 $v_{des}$，直到满足误差要求。\n生成输出数据：\n依据调整后的 $v_{des}$ 与计算结果生成全程的速度、加速度与加加速度数据，并输出曲线信息与统计指标。\n8. 总结 本 S 曲线速度规划模型在满足总飞行时间 $T$ 与轨迹弧长 $S$ 的严格约束下，通过以下步骤实现：\n变速段设计： 根据 $v_{in}$ 与 $v_{des}$ 之间的差值，选择梯形或三角形 S 曲线生成平滑的加速/减速过渡，计算出变速段时间 $T_{conv}$ 与累计位移 $S_{conv}$。 定速段补充： 变速结束后，采用定速 $v_{des}$ 飞行，确保后段尽可能长以接近期望速度。 迭代优化： 采用二分查找调整期望速度 $v_{des}$（同时记录比例因子），以确保总体位移匹配目标 $S$。 离散仿真： 按照步长 $dt$ 离散生成整段轨迹的速度、加速度和加加速度数据。 该模型不仅实现了速度规划的平滑性和安全性，同时在后段尽可能保持接近飞出速度飞行，从而满足特定飞行性能的要求。",
    "description": "旨在为无人机轨迹规划提供一条平滑的 S 曲线速度规划方案。通过先计算变速（过渡）阶段的 S 曲线段，再补充恒速段（定速阶段），最后利用二分查找方法调整期望速度以匹配目标弧长，从而生成一组离散时间点上的速度、加速度和加加速度数据。",
    "tags": [],
    "title": "三段S曲线速度规划模型",
    "uri": "/uas/velocity_plan/%E4%B8%89%E6%AE%B5s%E6%9B%B2%E7%BA%BF%E9%80%9F%E5%BA%A6%E8%A7%84%E5%88%92%E6%A8%A1%E5%9E%8B/index.html"
  },
  {
    "breadcrumb": "FlitSoft Docs \u003e  UAS \u003e  Formation Control",
    "content": "Zhou Chao, Shao-Lei Zhou, Lei Ming, and Wen-Guang Zhang\nDepartment of Control Engineering, Naval Aeronautical and Astronautical University, YanTai 264001, China\nCorrespondence should be addressed to Zhou Chao, rickzhou2010@126.com\n摘要 我们在非线性模型预测控制（NMPC）框架下设计了一种分布式、无碰撞的编队飞行控制律。编队构型在虚拟参考点坐标系中确定。通过代价惩罚实现避障，通过代价惩罚结合新的优先级策略实现机间防碰撞。\nC++代码实现\n1. 引言 近年来，关于多智能体系统协同控制的研究已得到广泛开展。推动这一研究热潮的动力之一，是分布式多无人机（UAV）在分布式感知和协同作业中的应用 [1]。在多无人机协同控制问题的若干主要子问题中，编队飞行具有重要意义，并得到了广泛研究 $[2,3]$。多无人机编队飞行的主要目标，是在控制整体群体行为的同时，实现期望的群体编队形状 [2]。\n针对无人机编队飞行，已提出多种控制方案，如PID方法 [3]、势场法 $[4,5]$、约束力法 [2]、自适应输出反馈法 [6]、滑模控制法 [7] 和基于一致性的方法 [8]。但这些方法无法显式地考虑约束条件，如固定翼无人机的失速速度、角转速约束以及控制输入饱和约束。基于优化的方法能够恰当地处理这些约束，已被证明是解决编队控制问题较为成功的方法之一。其中最为流行的优化方法之一是模型预测控制（MPC）方法。\n模型预测控制（Model Predictive Control, MPC），或称滚动时域控制（Receding Horizon Control, RHC），是一种反馈控制方案，在每一个时间步都要求解一次轨迹优化问题。将最优序列中的第一个控制输入应用于系统，并在随后的每一步重复进行优化 [9]。目前该领域研究非常活跃，Mayne 等人在 [10] 对该方法做了详尽综述。它已被广泛用于动态较慢的系统，如化工过程。随着现代计算机运算速度的提升，其应用领域已扩展到多智能体控制和大规模分布式控制问题。其广泛应用的一个动因，是MPC能够处理其他方法难以解决的控制和状态硬约束。集中式MPC已被应用于多车协同控制 [11]，但单次优化所需的计算量会迅速变得难以承受，且随着无人车数量的增加，计算复杂度呈极差的扩展性。为了解决这一问题，分布式模型预测控制（DMPC）方法 [12] 通过将优化划分为更小的子问题被提出。\n编队控制策略对于编队控制问题而言至关重要。文献中，针对编队控制问题主要有三种信息结构方法：即领航-跟随（leader-follower）[13]、虚拟结构（virtual structure）[14] 和行为方法（behavioral approach）[15]。大多数多智能体编队控制研究采用领航-跟随结构，其中部分无人机设为领航机，其余为跟随机。这一方法易于理解与实现，但对领航机故障不具备鲁棒性。尽管虚拟领航者策略被提出以提升鲁棒性，但链式结构导致其抗扰能力较差 [13]。在虚拟结构方法中，将整个编队视为一个虚拟刚体结构。各个无人机不是跟踪轨迹，而是跟踪一个运动点，从而允许虚拟结构与另一无人机相连接 [12]。由于编队内所有智能体被视作单一对象，群体的引导比其他方法更为容易。但编队只能实现同步机动，且难以考虑避障问题 [16]。行为方法则为每架无人机设计若干期望行为，包括保持队形、目标追踪和防碰撞/避障。每架无人机的控制动作是各行为控制的加权平均 [17]。该方法适用于不确定环境，但缺乏严格的理论分析。\n基于MPC的多无人机编队控制问题已被广泛研究，如 [18-21]。在 [20] 中，采用了双模MPC方法实现机器人编队控制。为了保证系统稳定性，双模控制器需在MPC控制与终端状态控制之间切换。部分学者专门研究了MPC方法下的无人机编队飞行问题 [22-28]。其中，[22,24] 主要研究了紧密编队飞行问题，[25-28] 仅在MPC问题建模中采用了无人机线性动力学模型。[23] 在MPC建模中采用了无人机非线性动力学模型和领航-跟随结构进行编队飞行控制器设计，利用Karush-Kuhn-Tucker (KKT) 变量实现防碰撞机动，但需要动态选择合适变量以平衡轨迹跟踪与防碰撞之间的权衡。\n序贯二次规划（Sequential Quadratic Program, SQP）是求解非线性规划（NLP）问题最有效的方法之一。它采用罚函数或优值函数以促进全局收敛性。然而，在实际应用中通常难以选择合适的罚参数。为避免罚参数设置带来的实际问题，Fletcher 和 Leyffer [29] 引入了一种SQP信赖域算法的过滤器，以提升全局收敛性。\n本文中，我们在非线性MPC框架下设计了一种分布式无人机编队飞行控制律。采用虚拟参考点控制策略以确定编队形态。\n在本文中，我们在非线性MPC框架下设计了一种分布式无人机编队飞行控制律。采用虚拟参考点控制策略来确定编队构型。本文的主要贡献在于，通过新的代价惩罚项实现了避障保障。机间防碰撞则通过代价函数与优先级策略相结合，并利用延迟的邻居信息来实现。为简化问题，假设编队飞行中所用的所有数据均未受到过程噪声和测量噪声的影响。\n本文其余部分安排如下：第2节给出了问题的形式化描述。第3节设计了基于非线性模型预测控制的无碰撞编队飞行控制律。第4节展示了仿真结果，并在性能方面将本算法与其他方法进行了对比。最后，第5节给出了总结与未来工作展望。\n2. 问题描述 2.1. 二维无人机动力学模型 一种常见的无人机控制系统是双环结构，其中姿态动力学由内环控制，位置动力学由外环控制。在编队飞行的多无人机群体背景下，外环还包含一个能够实现并保持给定编队构型的控制器。为简化分析，本文分析了无人机在水平平面内的二维运动 [30]，并将无人机的内环动力学建模为一阶模型：\n$$ \\begin{gather*} \\dot{x}_{i}=v_{i} \\sin \\psi_{i} \\\\ \\dot{y}_{i}=v_{i} \\cos \\psi_{i} \\\\ \\dot{\\psi}_{i}=\\frac{g \\tan \\gamma_{i}}{v_{i}} \\tag{2.1}\\\\ \\dot{v}_{i}=\\frac{1}{\\alpha_{v}}\\left(v_{i}^{c}-v_{i}\\right) \\\\ \\dot{\\gamma}_{i}=\\frac{1}{\\alpha_{\\gamma}}\\left(\\gamma_{i}^{c}-\\gamma_{i}\\right) \\end{gather*} $$其中，$\\left(x_{i}, y_{i}\\right), \\psi_{i}, v_{i}$ 和 $\\gamma_{i}$ 分别为无人机 $i$ 的惯性位置、航向角、速度和滚转角。$v_{i}^{c}$ 和 $\\gamma_{i}^{c}$ 分别为下发给无人机 $i$ 自动驾驶仪的指令速度和滚转角；$g$ 为重力常数。$\\alpha_{v}$ 和 $\\alpha_{\\gamma}$ 为正数常量。\n通常，无人机编队飞行时会有一个参考轨迹。动力学与运动学约束限制了无人机无法跟踪任意参考轨迹。借鉴文献 [31]，我们假设编队飞行轨迹生成器生成的参考轨迹满足以下方程：\n$$ \\begin{gather*} \\dot{x}_{r}=v_{r} \\cos \\psi_{r} \\\\ \\dot{y}_{r}=v_{r} \\sin \\psi_{r} \\tag{2.2}\\\\ \\dot{\\psi}_{r}=w_{r} \\end{gather*} $$其中 $v_{r}$ 和 $w_{r}$ 为分段连续且一致有界的量，满足以下约束条件：\n$$ \\begin{gather*} 0",
    "description": "在非线性模型预测控制（NMPC）框架下设计了一种分布式、无碰撞的编队飞行控制律。编队构型在虚拟参考点坐标系中确定。通过代价惩罚实现避障，通过代价惩罚结合新的优先级策略实现机间防碰撞。",
    "tags": [],
    "title": "基于非线性模型预测控制的无人机编队飞行",
    "uri": "/uas/formation-control/%E5%9F%BA%E4%BA%8E%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B%E6%8E%A7%E5%88%B6%E7%9A%84%E6%97%A0%E4%BA%BA%E6%9C%BA%E7%BC%96%E9%98%9F%E9%A3%9E%E8%A1%8C/index.html"
  },
  {
    "breadcrumb": "FlitSoft Docs \u003e  UAS \u003e  Trajectory Planning \u003e  kappa-trajectories",
    "content": "Real-time dynamic trajectory smoothing for unmanned air vehicles 无人机实时动态轨迹平滑 Article in Control Systems Technology, IEEE Transactions on · June 2005\nSource: IEEE Xplore\nErik P. Anderson, Randal W. Beard, Timothy W. McLain\nBrigham Young University - Provo Main Campus\n本文综述： 动态轨迹平滑是无人机（UAV）轨迹规划中的一项重要技术。它用于生成平滑且可行的轨迹，这些轨迹满足运动学约束，同时确保无人机在航路点之间高效过渡。该方法旨在最小化无人机与直线路径的偏差，同时适应车辆的动态特性，如速度和航向约束。\n在实时无人机操作中，动态轨迹平滑使得无人机能够在飞行过程中持续调整并适应环境。该技术的主要优点是能够确保平滑、时间最优的过渡，同时最小化计算负载，使其非常适合用于计算资源有限的实时系统。\n实时动态轨迹平滑的主要特点包括：\n与航路点路径规划的集成：该方法能够与基于航路点的路径规划算法轻松集成，特别是那些生成直线路径的算法。 低计算开销：它可以通过最小的计算成本实现，且在无人机跟踪路径时实时生成轨迹。 最小化偏差：该方法减少了无人机偏离规划路径的时间，从而提供更精确的跟踪和高效的路径跟随。 适应性：该算法能够适应无人机的动态能力，包括速度和航向约束，确保生成的轨迹对于无人机的运动动态是可行的。 该方法特别适用于无人机需要做出实时决策的应用，如自主飞行、监视和环境监测。它提供了一种可靠且高效的方式来管理无人机的路径跟踪，并在动态和变化的环境中保持最佳性能。\n摘要 本文提出了一种实时、可行的轨迹生成算法，用于无人驾驶飞行器 (UAV) 通过一系列航路点飞行。 庞特里亚金的最小原理 (Pontryagin’s Minimum Principle) 用于证明由算法生成的连接航点的直线路径段之间的转换是时间最优的。 此外，算法可以配置为动态可行轨迹与直线航路点路径具有相同的路径长度。 详细描述了与算法相关的实现问题。 仿真研究表明了所提出方法的有效性。\n关键词 轨迹生成， 无人机（UAVs）， 最优控制。\n1. 引言 近年来计算、传感和电池技术的进步使得无人驾驶技术成为军事和商业应用中可行的选择[1]，[2]。美国军方的宏伟愿景是到2020年，其三成的部队将是无人化的[3]。为了使无人驾驶技术更加有用，开发自主、半自主和协作行为至关重要。所有这些行为的核心是自动轨迹生成算法。\n对于无人机（UAVs），轨迹生成问题的复杂性在于以下几个方面。首先，无人机是非线性动态系统，且阶数相对较高。车辆的非线性动态对可行轨迹提出了多个约束。特别是，无人机的航向速率约束对轨迹施加了曲率限制，而失速和空气动力学推力的限制则对车辆的最小和最大速度提出了约束。因此，无人机轨迹生成问题本质上与移动机器人轨迹生成问题不同，后者没有速度或航向速率约束。第二个挑战是轨迹生成器必须实时运行，以响应不断变化的操作情况，并支持自主性和协作性。\n我们的特别关注点是无人机的协作定时问题$[4]，[5]，[6]$。例如，在同时拦截问题中，一组无人机必须穿越动态变化的威胁区域，以与其他无人机同时到达各自的目的地。当威胁出现时，整个团队必须重新规划路径，以满足同时到达的约束条件。为了解决这个问题，我们最近提出了一种基于图1所示分层架构的协作控制技术[7]，[8]。如图1所示，协调定时管理器生成一组目标，并附有预计到达时间（ETA）数据。我们对协调定时管理器的处理方法在[7]，[8]中有详细介绍。本论文特别重要的是，协调定时管理器基于直线航路点路径规划协作任务。动态轨迹平滑器（DTS）的作用是将航路点路径平滑成满足无人机动态约束的时间参数化轨迹。然而，如果DTS生成的轨迹与原始航路点路径的路径长度不同，那么预计到达时间（ETA）将发生变化，从而使得协调定时管理器生成的协作定时计划失效。因此，我们希望DTS生成的轨迹与原始航路点路径具有相同的路径长度。\n图1. 动态轨迹平滑器（DTS）是整体系统架构中的关键部分。\n这些考虑因素提出了一个有趣的挑战：设计一个轨迹生成算法，该算法\n在一组航路点之间平滑过渡，最小化与相关航路点路径的偏差，\n满足无人机动力学所施加的曲率和速度约束，\n保持与相关航路点路径相同的路径长度，并\n实时运行。\n本文的目的是介绍一种符合这些目标的轨迹生成算法。\n尽管本文介绍的轨迹生成技术特别适用于协作定时任务，但它也可以应用于时间要求可能不那么严格的问题。例如，可能希望直接飞越航路点，同时最小化与原始航路点路径的偏差。另一种可能的情景是，无人机携带一个具有有限维度探测范围的传感器[9]。可能希望配置轨迹生成器，使得无人机在指定距离内通过航路点，同时最小化直线路径段之间的过渡时间。因此，我们将扩展问题陈述，包含可实时实现的轨迹，这些轨迹可以配置为（1）生成与原始航路点路径相同路径长度的轨迹，（2）在最小化与原始航路点路径偏差的同时直接通过航路点，（3）以最短时间在航路点之间过渡，或（4）以最小化与直线路径段的偏差的方式通过航路点的指定距离。\n我们的方法基于飞机的局部可达区域和基本几何学。从这个意义上讲，它类似于[4]、[10]、[11]中报告的方法。在[10]中，证明了满足曲率约束的两点之间的最短路径由圆和直线路径段组成。参考文献[11]在Dubins的思想基础上，给定运动学和路径约束，算法地找到Dubins圆和直线路径的最优位置，从而为无人机生成可行轨迹。在[4]中，Dubins圆作为圆角叠加在通过Voronoi图生成的直线航路点路径的交汇处。我们的方法与[4]、[10]、[11]不同，轨迹是通过动态过程实时生成的。我们的方法不是插入圆角并事先规划轨迹，而是在飞行过程中动态生成轨迹。这样做的优点是算法更能响应动态变化的环境，并且算法将计算分配到时间上，使得该算法能够在实时环境中实现。\n最近，文献中出现了几种其他的无人机路径规划方法。这些方法大致可以分为三类：概率地图（probabilistic maps）、微分平坦性（differential flatness）和最优控制技术（optimal control techniques）。\n概率道路图方法，如[12]中所述，使用一组运动原语为每个车辆随机生成一组路径段。如果生成的路径段是可行的（例如，无碰撞），则该路径段会被添加到可能路径的树中。该算法继续扩展树，直到到达目标配置。概率道路图在无人直升机中的应用在[13]、[14]中有所描述。不幸的是，这项工作不能直接应用于当前问题，因为它依赖于直升机的悬停能力。参考文献[15]描述了概率道路图的分析技术。概率道路图的缺点是，当计算时间无限制时，它们只能保证以概率1找到可行路径。\n最近，微分平坦性技术已被应用于无人机轨迹生成问题。[16]中对微分平坦性及其在移动机器人中的应用进行了很好的概述。[17]中描述了一种使用微分平坦性的移动机器人路径规划/轨迹生成方法。[18]中给出了一种基于微分平坦性的生成可行无人机轨迹的计算方法。[19]中给出了基于线性矩阵不等式（LMI）对[18]的扩展。在参考文献[20]中，引入了群体平坦性概念，并应用于无人机编队飞行问题。微分平坦性方法的缺点是，通常很难将协调约束表示为平坦空间的凸区域。此外，找到平坦空间轨迹所需的优化技术通常无法在实时中实现。\n最优控制方法用于路径规划，旨在最小化成本指标，同时满足车辆的可行性约束。[21]中，轨迹被参数化为样条曲线，使用非线性优化技术来找到样条系数。参考文献[22]使用样条曲线和非线性优化技术平滑通过直线航路点路径。参考文献[23]推导了一种有趣的方法，用于为不通过航路点而是平滑通过点的航路点路径创建样条轨迹。在参考文献[24]中，使用庞特里亚金最大值原理证明，移动机器人的最优路径由一系列旋转和直线机动组成。在[25]中，使用庞特里亚金原理证明，如果机器人的速度是恒定的，则最优轨迹由一系列恒速弧线和直线段组成。最优控制技术的难点在于，它们仅在约束和配置较简单时才在计算上可行。\n本文的主要贡献是开发了一种轨迹生成技术，将航路点路径平滑为动态可行的轨迹。我们算法的显著特点是其计算复杂度低，从而便于实时实现，能够对动态环境做出反应，并且容易配置以满足路径长度约束，如相等路径长度或在指定距离内通过航路点。\n本文的其余部分将按如下结构组织。问题定义和数学基础将在第二节给出。在第三节中，我们定义了一类轨迹，称为$\\kappa$-轨迹，并证明$\\kappa$-轨迹是受约束的时间最优轨迹，即它们满足庞特里亚金最小值原理[26]。论文的核心结果在第四节中呈现，在这一节中，我们介绍了一种实时算法，该算法生成$\\kappa$-轨迹，并展示了如何配置该算法以生成最小过渡时间轨迹、航路点轨迹以及与原始航路点路径具有相同路径长度的轨迹。在第五节中，我们讨论了使算法在数字硬件上运行所需的若干实现问题。第六节展示了该算法在多个仿真场景中的有效性。最后，第七节提供了一些结论。\n2. 问题陈述与预备知识 在定义问题时，我们假设无人机以恒定高度飞行，并配备了能够接收速度和航向命令的内环自动驾驶仪。根据[27]，我们假设受到速度保持和航向保持自动驾驶仪控制的无人机动力学为一阶：\n$$ \\begin{aligned} \\dot{z}_{x} \u0026=v \\cos \\psi \\quad\\quad(1)\\\\ \\dot{z}_{y} \u0026=v \\sin \\psi \\quad\\quad(2)\\\\ \\dot{\\psi} \u0026=\\alpha_{\\psi}\\left(\\psi^{c}-\\psi\\right) \\quad\\quad(3)\\\\ \\dot{v} \u0026=\\alpha_{v}\\left(v^{c}-v\\right) \\quad\\quad(4) \\end{aligned} $$其中，$\\alpha_{\\psi}$ 和 $\\alpha_{v}$ 是已知常数，依赖于自动驾驶仪的实现。此外，基础的无人机动力学约束了航向速率和速度，如下所示：\n$$ -c \\leq \\dot{\\psi} \\leq c \\quad\\quad(5) $$$$ 0 \u003c v_{\\min } \\leq v \\leq v_{\\max } \\quad\\quad(6) $$定义 1: 如果存在输入 $\\psi^{c}(t)$ 和 $v^{c}(t)$，使得当 $\\mathbf{z}(0)=\\mathbf{z}^{d}(0)$ 时，$\\mathbf{z}(t)=\\mathbf{z}^{d}(t)$，并且动力学方程(1)-(4)和约束(5)-(6)在所有 $t \\geq 0$ 时都得到满足，则称轨迹 $\\mathbf{z}^{d}(t)=\\left(z_{x}^{d}, z_{y}^{d}\\right)^{T}$ 为动态可行的。\n图 1 所示的动态轨迹平滑器 (DTS) 的输入是航路点路径 $$ \\mathcal{P}=\\left\\{v,\\left\\{\\mathbf{w}_{1}, \\mathbf{w}_{2}, \\ldots, \\mathbf{w}_{N}\\right\\}\\right\\} $$其中，$v \\in\\left[v_{\\min }, v_{\\max }\\right]$ 是无人机的期望速度，$\\mathbf{w}_{i} \\in \\mathbb{R}^{2}$ 表示以惯性坐标表示的航路点。\n我们方法的基本思想是为轨迹生成器赋予一个类似于无人机动力学的数学结构。特别地，DTS由以下微分方程给出： $$ \\begin{aligned} \\dot{\\hat{z}}_{x} \u0026=\\hat{v} \\cos \\hat{\\psi} \\quad\\quad(7) \\\\ \\dot{\\hat{z}}_{y} \u0026=\\hat{v} \\sin \\hat{\\psi} \\quad\\quad(8)\\\\ \\dot{\\hat{\\psi}} \u0026=u \\quad\\quad(9) \\end{aligned} $$其中，$u \\in[-c, c]$ 是将被选择以满足指定目标的输入。我们将假设轨迹以恒定速度 $\\hat{v} \\in\\left[v_{\\min }, v_{\\max }\\right]$ 行驶。注意，如果 $\\hat{\\mathbf{z}}(0)=\\mathbf{z}(0)$，则方程(7)-(9)保证生成动态可行的轨迹。因此，可行性问题是预先得到满足的。方程(7)-(9)通过固定步长的常微分方程（ODE）求解器求解，并实时传播。换句话说，DTS的输出与无人机动力学的演变在时间上相对应。如果使用四阶Runge-Kutta算法[28]，则每个采样周期内需要计算四次$u$。因此，计算复杂度依赖于$u$的计算。\n注意，如果 $u=+c$，则方程(7)-(8)中给出的DTS描绘出一个右旋圆，如图2所示。类似地，如果 $u=-c$，则DTS描绘出一个左旋圆。如图2所示，DTS的局部可达区域由这两个圆所界定。定义局部可达区域的圆的半径为 $R=\\hat{v} / c$。注意，随着期望速度的增加，最小转弯半径也会增加。如果 $(\\hat{\\mathbf{z}}, \\hat{\\psi})$，其中 $\\hat{\\mathbf{z}}=\\left(\\hat{z}_{x}, \\hat{z}_{y}\\right)^{T}$ 是DTS的配置，那么界定可达区域的两个圆的圆心给出为\n$$ \\begin{aligned} \u0026\\mathbf{c}_{R}(t)=\\hat{\\mathbf{z}}(t)+R\\left(\\begin{array}{c} -\\sin (\\hat{\\psi}(t)) \\\\ \\cos (\\hat{\\psi}(t)) \\end{array}\\right) \\quad\\quad(10) \\\\ \u0026\\mathbf{c}_{L}(t)=\\hat{\\mathbf{z}}+R\\left(\\begin{array}{c} \\sin (\\hat{\\psi}(t)) \\\\ -\\cos (\\hat{\\psi}(t)) \\end{array}\\right) \\quad\\quad(11) \\end{aligned} $$对应的半径为 $R$ 的圆分别表示为 $\\mathcal{C}_{L}$ 和 $\\mathcal{C}_{R}$。由于可达区域的边界由已知圆心和半径的圆所定义，因此，可以通过计算效率较高的方式来找到可达区域与直线和圆的交点。\n图2. DTS的局部可达区域。\n在第三节中，我们将定义一类可行轨迹，并证明它们满足庞特里亚金最小值原理的必要条件，用于最小化从一个航路点段到下一个航路点段的过渡时间，同时满足动力学方程(1)-(4)和约束(5)-(6)。为了准确起见，我们回顾庞特里亚金最小值原理[26]，其可以表述如下。\n定义 2: 给定动力学系统 $\\dot{x}=f(x, u)$，初始条件为 $x_{0}$，终端约束集 $\\chi=\\left\\{x \\in \\mathbb{R}^{n}: g(x)=0\\right\\}$ 和控制约束集 $\\mathcal{U}=\\left\\{u \\in \\mathbb{R}^{m}: h(u) \\geq 0\\right\\}$，其中 $f, g: \\mathbb{R}^{n} \\rightarrow \\mathbb{R}^{q}$ 和 $h$ 是连续可微的，并且 $\\frac{\\partial g}{\\partial x}$ 和 $\\frac{\\partial h}{\\partial u}$ 的秩是满秩的，控制策略 $u^{*}(t)$ 是关于成本函数 $J=\\int_{0}^{T} l(x, u) d t$ 的极值控制策略，其中 $l$ 是连续可微的，若存在一个连续分段可微的函数 $\\lambda(t) \\in \\mathbb{R}^{n}$ 和常数 $\\rho \\in \\mathbb{R}^{q}$，使得以下方程得到满足 $$ \\begin{aligned} \\dot{x}^{*} \u0026=\\frac{\\partial H}{\\partial \\lambda}\\left(x^{*}, u^{*}, \\lambda^{*}\\right) \\\\ \\dot{\\lambda}^{*} \u0026=-\\frac{\\partial H}{\\partial x}\\left(x^{*}, u^{*}, \\lambda^{*}\\right) \\\\ \\lambda^{*}(T) \u0026=\\frac{\\partial g}{\\partial x}\\left(x^{*}(T)\\right)^{T} \\rho \\\\ g\\left(x^{*}(T)\\right) \u0026=0 \\\\ u^{*}(t) \u0026=\\arg \\min _{u \\in \\mathcal{U}} H\\left(x^{*}, u, \\lambda^{*}\\right) \\\\ H\\left(x^{*}, u^{*}, \\lambda^{*}\\right) \u0026=0, \\end{aligned} $$其中，$H(x, u, \\lambda)=l(x, u)+\\lambda^{T} f(x, u)$ 是系统的哈密顿量。\n最小时间极值轨迹是关于成本函数 $J = \\int_{0}^{T} dt$ 的极值轨迹。\n3. 极值轨迹 在本节中，我们定义了一类动态可行轨迹，称为 $\\kappa$-轨迹，并证明它们是最小时间极值轨迹。\n考虑由三个航路点 $\\mathbf{w}_{i-1}$、$\\mathbf{w}_{i}$ 和 $\\mathbf{w}_{i+1}$ 定义的航路点路径，设 $$ \\begin{aligned} \\mathbf{q}_{i} \u0026=\\frac{\\mathbf{w}_{i}-\\mathbf{w}_{i-1}}{\\left\\|\\mathbf{w}_{i}-\\mathbf{w}_{i-1}\\right\\|} \\\\ \\mathbf{q}_{i+1} \u0026=\\frac{\\mathbf{w}_{i+1}-\\mathbf{w}_{i}}{\\left\\|\\mathbf{w}_{i+1}-\\mathbf{w}_{i}\\right\\|} \\end{aligned} $$将沿着相应路径段的单位向量表示为图3所示。令 $\\beta$ 表示 $\\mathbf{q}_{i}$ 和 $\\mathbf{q}_{i+1}$ 之间的夹角，我们得到\n图3. 在$\\kappa$-轨迹定义中使用的内切圆。\n$$ \\beta=\\cos ^{-1}\\left(\\mathbf{q}_{i+1}^{T} \\mathbf{q}_{i}\\right) . $$如图3所示，设 $\\overline{\\mathcal{C}}$ 为半径为 $R=\\hat{v} / c$ 的圆，其圆心位于由三个航路点形成的角的平分线上，使得该圆与直线 $\\overline{\\mathbf{w}_{i-1} \\mathbf{w}_{i}}$ 和 $\\overline{\\mathbf{w}_{i} \\mathbf{w}_{i+1}}$ 恰好在每条直线上各相交一个点。$\\beta$ 的平分线将与 $\\overline{\\mathcal{C}}$ 在两个位置相交。令 $\\overline{\\mathbf{p}}$ 为最接近 $\\mathbf{w}_{i}$ 的交点。\n从图 3 可以看出，\n$$ \\sin \\left(\\frac{\\beta}{2}\\right)=\\frac{R}{\\left\\|\\overline{\\mathbf{p}}-\\mathbf{w}_{i}\\right\\|+R} . $$通过对该表达式进行变形，可发现$\\mathbf{w}_{i}$ 和 $\\overline{\\mathbf{p}}$ 之间的距离为 $$ \\left\\|\\overline{\\mathbf{p}}-\\mathbf{w}_{i}\\right\\|=R\\left(\\frac{1}{\\sin \\left(\\frac{\\beta}{2}\\right)}-1\\right) $$沿三个航路点形成的角的平分线指向的单位矢量由下式给出 $$ \\overline{\\mathbf{q}}=\\frac{\\mathbf{q}_{i+1}-\\mathbf{q}_{i}}{\\left\\|\\mathbf{q}_{i+1}-\\mathbf{q}_{i}\\right\\|} $$因此，点 $\\overline{\\mathbf{p}}$ 由下式给出\n$$ \\overline{\\mathbf{p}}=\\mathbf{w}_{i}+R\\left(\\frac{1}{\\sin \\left(\\frac{\\beta}{2}\\right)}-1\\right) \\overline{\\mathbf{q}} $$设 p(κ) 表示在 $\\mathbf{w}_{i}$和$\\overline{\\mathbf{p}}$之间的直线（位于角平分线上）上的一个参数化点。 $$ \\mathbf{p}(\\kappa)=\\mathbf{w}_{i}+\\kappa R\\left(\\frac{1}{\\sin \\left(\\frac{\\beta}{2}\\right)}-1\\right) \\overline{\\mathbf{q}} $$其中$\\kappa \\in[0,1]$。 显然 $\\mathbf{p}(0)=\\mathbf{w}_{i}$，并且 $\\mathbf{p}(1)=\\overline{\\mathbf{p}}$。\n其中，$\\kappa \\in[0,1]$。显然，$\\mathbf{p}(0)=\\mathbf{w}_{i}$，而 $\\mathbf{p}(1)=\\overline{\\mathbf{p}}$。\n如图4所示，设 $\\mathcal{C}_{\\mathbf{p}(\\kappa)}$ 为半径为 $R=\\hat{v} / c$ 的圆，其圆心位于 $\\overline{\\mathbf{q}}$ 的方向上，并与 $\\mathbf{p}(\\kappa)$ 相交。此外，设 $\\mathcal{C}_{i}$ 为半径为 $R$ 的圆，放置在使其与 $\\mathcal{C}_{\\mathbf{p}(\\kappa)}$ 和 $\\overline{\\mathbf{w}_{i-1} \\mathbf{w}_{i}}$ 各相交一个位置的地方。类似地，定义 $\\mathcal{C}_{i+1}$，如图4所示。\n定义 3：$\\kappa$-轨迹定义为通过以下方式构建的轨迹：沿着线段 $\\overline{\\mathbf{w}_{i-1} \\mathbf{w}_{i}}$ 行驶，直到与 $\\mathcal{C}_{i}$ 相交，接着沿着该圆行驶直到与 $\\mathcal{C}_{\\mathbf{p}(\\kappa)}$ 相交，继续沿该圆行驶直到与 $\\mathcal{C}_{i+1}$ 相交，再沿该圆行驶直到与线段 $\\overline{\\mathbf{w}_{i} \\mathbf{w}_{i+1}}$ 相交，如图4所示。\n图. 4. 一个动态可行的$\\kappa$-轨迹。\n定理 4：图4所示的$\\kappa$-轨迹是唯一的、动态可行的最小时间极值轨迹，它从航路点段 $\\overline{\\mathbf{w}_{i-1} \\mathbf{w}_{i}}$ 过渡到航路点段 $\\overline{\\mathbf{w}_{i} \\mathbf{w}_{i+1}}$ 并直接通过 $\\mathbf{p}(\\kappa)$。\n证明：注意，图4所示的$\\kappa$-轨迹关于$\\beta$的平分线是对称的。由于对称性，只需证明从$\\mathbf{p}(\\kappa)$到线段$\\overline{\\mathbf{w}_{i} \\mathbf{w}_{i+1}}$的轨迹是最小时间极值轨迹。为了不失一般性，进行坐标变换，使得线段$\\overline{\\mathbf{w}_{i} \\mathbf{w}_{i+1}}$位于$Y$轴上，如图5所示。考虑具有初始条件的时间最优控制问题：\nFig. 5. 变换坐标中的时间最优控制问题。\n$$ \\left(\\begin{array}{c} \\hat{\\mathbf{z}}(0) \\\\ \\hat{\\psi}(0) \\end{array}\\right)=\\left(\\begin{array}{c} \\mathbf{p}(\\kappa) \\\\ \\theta \\equiv \\frac{\\pi-\\beta}{2} \\end{array}\\right) $$以及边界约束由以下给出：\n$$ g(x)=\\left(\\begin{array}{c} \\mathbf{n}^{T} \\hat{\\mathbf{z}}(T) \\\\ \\hat{\\psi}(T) \\end{array}\\right)=\\mathbf{0} $$其中，$\\mathbf{n}=(1,0)^{T}$ 是线段 $\\overline{\\mathbf{w}_{i} \\mathbf{w}_{i+1}}$ 的法向量，且 $\\hat{\\psi}(T)=0$。终端约束确保在时间 $T$ 时，DTS 位于线段上，并且与期望方向对齐。该系统的哈密顿量由以下给出： $$ H=1+\\lambda_{1} \\hat{v} \\cos \\hat{\\psi}+\\lambda_{2} \\hat{v} \\sin \\hat{\\psi}+\\lambda_{3} u $$我们推测，bang-bang控制策略\n$$ u^*(t) \\;=\\; \\begin{cases} -c, \u0026 0 \\le t \u003c t_{1},\\\\ c, \u0026 t_{1} \\le t \\le T \\end{cases} $$是最小时间极值轨迹，并且证明由此得到的系统轨迹满足方程(12)-(17)。方程(12)显然得到满足，因为 $\\partial H / \\partial \\lambda = (\\hat{v} \\cos \\hat{\\psi}, \\hat{v} \\sin \\hat{\\psi}, u)^{T}$。方程(13)和(14)导致以下常微分方程（ODE）系统： $$ \\begin{aligned} \\dot{\\lambda}_{1}^{*} \u0026=0 \\\\ \\dot{\\lambda}_{2}^{*} \u0026=0 \\\\ \\dot{\\lambda}_{3}^{*} \u0026=\\lambda_{1}^{*} \\hat{v} \\sin \\hat{\\psi}^{*}-\\lambda_{2}^{*} \\hat{v} \\cos \\hat{\\psi}^{*} \\end{aligned} $$边界约束为\n$$ \\begin{aligned} \u0026\\lambda_{1}^{*}(T)=\\rho_{1} n_{x}=0 \\\\ \u0026\\lambda_{2}^{*}(T)=\\rho_{1} n_{y}=\\rho_{1} \\\\ \u0026\\lambda_{3}^{*}(T)=\\rho_{2} \\end{aligned} $$因此，$\\lambda_{1}^{*}(t) \\equiv 0$ 和 $\\lambda_{2}^{*}(t) \\equiv \\rho_{1}$。通过从 $t=T$ 反向积分 $\\dot{\\hat{\\psi}}^{*}=u^{*}$，以及从 $t=0$ 正向积分，得到：\n$$ \\hat{\\psi}^{*}(t)= \\begin{cases}-c t+\\theta, \u0026 0 \\leq t \\leq t_{1} \\\\ c(t-T), \u0026 t_{1} \\leq t \\leq T\\end{cases} $$在 $t=t_{1}$ 处强制连续性得到：\n$$ t_{1}=\\frac{T}{2}+\\frac{\\theta}{2 c} $$通过从 $t=T$ 反向积分 $\\dot{\\lambda}_{3}$ 得到：\n$$ \\lambda_{3}^{*}(t)= \\begin{cases}\\frac{\\rho_{1} \\hat{v}}{c} \\sin (-c t+\\theta)+k_{1}, \u0026 0 \\leq t \\leq t_{1} \\\\ -\\frac{\\rho_{1} \\hat{v}}{c} \\sin (c(t-T))+k_{2}, \u0026 t_{1} \\leq t \\leq T\\end{cases} $$where\n$$ \\begin{aligned} \u0026k_{1}=-\\frac{2 \\rho_{1} \\hat{v}}{c} \\sin \\left(\\frac{\\theta}{2}-\\frac{c T}{2}\\right)+\\rho_{2} \\\\ \u0026k_{2}=\\rho_{2} \\end{aligned} $$这些由连续性和终端条件决定。沿着 $\\left(x^{*}, \\lambda^{*}, u^{*}\\right)$ 评估哈密顿量，我们得到：\n$$ H\\left(x^{*}, \\lambda^{*}, u^{*}\\right)=1+\\lambda_{2}^{*} \\hat{v} \\sin \\left(\\hat{\\psi}^{*}\\right)+\\lambda_{3}^{*} u^{*}= \\begin{cases}1-c k_{1}, \u0026 0 \\leq t \\leq t_{1} \\\\ 1+c k_{2}, \u0026 t_{1} \\leq t \\leq T\\end{cases} $$因此，方程(17)要求 $\\rho_{2} = -1 / c$ 并且\n$$ \\rho_{1}=-\\frac{1}{\\hat{v} \\sin \\left(\\frac{\\theta}{2}-\\frac{T c}{2}\\right)}, $$这在 $c T - \\theta \\neq 2 \\pi n$ 对于任何整数 $n$ 时是有限的。通过显式地求解 $T$，我们将证明 $\\rho_{1}$ 是良好定义的。从物理角度来看，只有当从一个段到下一个段的过渡中发生循环时，$c T - \\theta$ 才能等于 $2 \\pi$（或其整数倍）。通过积分 $\\dot{\\hat{z}}_{y}$，我们得到：\n$$ \\hat{z}_{y}= \\begin{cases}\\frac{\\hat{v}}{c} \\cos (-c t+\\theta)-\\frac{\\hat{v}}{c} \\cos \\theta, \u0026 0 \\leq t \\leq t_{1} \\\\ -\\frac{\\hat{v}}{c} \\cos (c(t-T))+\\frac{2 \\hat{v}}{c} \\cos \\left(\\frac{\\theta}{2}-\\frac{c T}{2}\\right)-\\frac{\\hat{v}}{c} \\cos \\theta, \u0026 t_{1} \\leq t \\leq T\\end{cases} $$我们选择 $T$ 为使得 $\\hat{z}_{y}(T) = 0$ 的最小正数。从方程(24)中，$\\hat{z}_{y}(T) = 0$ 意味着\n$$ \\cos \\left(\\frac{\\theta}{2}-\\frac{c T}{2}\\right)=\\frac{1+\\cos \\theta}{2} . $$由于 $0 \u003c \\frac{1 + \\cos \\theta}{2} \u003c 1$，总是存在一个实数 $\\theta / 2 - c T / 2$ 满足方程(25)。因此，\n$$ T=\\frac{\\theta}{c}-\\frac{2}{c} \\cos ^{-1}\\left(\\frac{1+\\cos \\theta}{2}\\right) . $$Define\n$$ \\Gamma(\\alpha) \\triangleq \\frac{\\theta}{c}-\\frac{2}{c} \\alpha $$我们现在确定在表达式(26)中应选择哪个角度来计算 $\\arccos (\\cdot)$。设 $\\alpha \\equiv \\arccos (\\beta)$，其中 $0\u003c\\beta\u003c1$ 有一个解 $\\alpha_{1}$，满足 $0\u003c\\alpha_{1}\u003c\\frac{\\pi}{2}$，另一个解为 $\\alpha_{2}$，满足 $-\\frac{\\pi}{2}\u003c\\alpha_{2}\u003c0$。实际上，$\\alpha_{2} = -\\alpha_{1}$。如果我们选择 $\\alpha$ 使得 $\\alpha \u003e \\frac{\\pi}{2}$，则 $T$ 将是负数，得到的是不可接受的解。另一方面，如果我们选择 $\\alpha$ 使得 $\\alpha \u003c -\\frac{\\pi}{2}$，即 $\\alpha = \\alpha_{2} - 2 \\pi n = -\\alpha_{1} - 2 \\pi n$，其中 $n$ 是正整数，那么 $0 \u003c \\Gamma(\\alpha_{2}) \u003c \\Gamma(\\alpha)$。因此，在寻找最小的正 $T$ 时，我们只需要考虑 $\\alpha = \\alpha_{1}$ 或 $\\alpha_{2}$。因此，最小的正 $T$ 由以下给出：\n$$ T=\\min _{\\Gamma\\left(\\alpha_{i}\\right) \\geq 0}\\left\\{\\Gamma\\left(\\alpha_{1}\\right), \\Gamma\\left(\\alpha_{2}\\right)\\right\\} . $$回到关于 $\\rho_{1}$ 是否如方程(23)中所表达的那样是良好定义的问题，注意到根据(25)且由于 $0 \u003c \\theta \u003c \\frac{\\pi}{2}$，我们有 $0 \u003c \\frac{1 + \\cos \\theta}{2} \u003c 1$。因此，$\\theta / 2 - T c / 2 \\neq n \\pi$ 对于任何整数 $n$，所以 $\\rho_{1}$ 的方程是良好定义的。我们还可以看到 $\\rho_{1}$ 非零，因此 $\\lambda_{2}^{*}(t) \\neq 0$。\n我们已经证明了条件(12)-(17)得到了满足。为了完整性，我们还给出 $\\hat{z}_{x}^{*}$ 的表达式：\n$$ \\hat{z}_{x}(t)=\\left\\{\\begin{array}{ll} -\\frac{\\hat{v}}{c} \\sin (-c t+\\theta)+\\frac{\\hat{v}}{c} \\sin \\theta \u0026 0 \\leq t \\leq t_{1} \\\\ \\frac{\\hat{v}}{c} \\sin (c(t-T))-\\frac{2 v}{c} \\sin \\left(\\frac{\\theta}{2}-\\frac{T c}{2}\\right)+\\frac{\\hat{v}}{c} \\sin \\theta \u0026 t_{1} \\leq t \\leq T \\end{array} .\\right. $$4. 动态轨迹平滑 在本节中，我们介绍了一种实时算法，该算法生成 $\\kappa$-轨迹。如果 $\\kappa=1$，则 $\\kappa$ 轨迹以最短时间从航路点段 $\\overline{\\mathbf{w}_{i-1} \\mathbf{w}_{i}}$ 过渡到航路点段 $\\overline{\\mathbf{w}_{i} \\mathbf{w}_{i+1}}$。如果 $\\kappa=0$，则 $\\kappa$-轨迹执行一个最小时间过渡，前提是它直接通过 $\\mathbf{w}_{i}$。我们还将在本节中展示如何选择 $\\kappa$，使得 $\\kappa$-轨迹具有与原始航路点路径相同的路径长度。\n图6. 选择 $u$ 背后基本思想的图示。\n算法的基本思想如图6所示。右转和左转约束分别由方程(10)-(11)给出的 $\\mathcal{C}_{R}$ 和 $\\mathcal{C}_{L}$ 在不同时间点表示。时间的进程由 $t_{1}, \\ldots t_{6}$ 表示。为了避免图形过于复杂，图中未显示在时间 $t_{2}$ 和 $t_{5}$ 时的右转约束 $\\mathcal{C}_{R}$。在时间 $t_{1}$ 时，DTS 正在跟踪航路点段 $\\overline{\\mathbf{w}_{i-1} \\mathbf{w}_{i}}$。当左转圆 $\\mathcal{C}_{L}$ 在时间 $t_{2}$ 与 $\\mathcal{C}_{\\mathbf{p}(\\kappa)}$ 相交时，$u$ 被设置为 $-c$。左转约束被跟随，直到右转圆 $\\mathcal{C}_{R}$ 在时间 $t_{3}$ 与 $\\mathcal{C}_{\\mathbf{p}(\\kappa)}$ 完全一致。然后，DTS 变量 $u$ 被设置为 $+c$，右转约束被跟随，直到左转约束 $\\mathcal{C}_{L}$ 在时间 $t_{4}$ 与航路点段 $\\overline{\\mathbf{w}_{i} \\mathbf{w}_{i+1}}$ 相交。DTS 变量 $u$ 再次被设置为 $-c$，直到它在时间 $t_{5}$ 到达航路点段，此时 $u$ 被设置为零。\n对于 $\\kappa \\in [0,1)$，图7展示了DTS选择 $u$ 的流程图。DTS算法的名义状态是跟踪当前的航路点路径段。由于方程(7)-(9)是通过固定采样率求解器求解的，因此无法通过简单地设置 $u=0$ 来跟踪路径。使用的跟踪算法将在第五节中讨论。当DTS开始跟踪当前航路点段时，首先计算 $\\mathcal{C}_{p(\\kappa)}$ 的位置。如果转弯是顺时针转弯，则监测约束圆 $\\mathcal{C}_{L}$，直到它与 $\\mathcal{C}_{p(\\kappa)}$ 相交，此时 $u \\leftarrow -c$（图6中的时间 $t_{2}$）。当 $u = -c$ 时，DTS 的运动使得 $\\mathcal{C}_{L}$ 静止不动。然后监测约束圆 $\\mathcal{C}_{R}$，直到它与 $\\mathcal{C}_{p(\\kappa)}$ 完全重合，此时 $u \\leftarrow +c$（时间 $t_{3}$）。此时，$\\mathcal{C}_{R}$ 静止不动，监测 $\\mathcal{C}_{L}$，直到它从右侧与航路点段 $\\overline{\\mathbf{w}_{i} \\mathbf{w}_{i+1}}$ 相交，此时 $u \\leftarrow -c$（时间 $t_{4}$）。此时，约束圆 $\\mathcal{C}_{L}$ 静止不动，监测 $\\mathcal{C}_{R}$，直到它不再与 $\\overline{\\mathbf{w}_{i} \\mathbf{w}_{i+1}}$ 相交，此时恢复跟踪（时间 $t_{5}$）。如果转弯是逆时针方向，则遵循类似的步骤。\n切换时间通过找到圆和直线的交点来确定。在数字硬件中找到这些切换时间存在实际问题。这些问题及其相关影响将在第五节中讨论。\n图7. 针对 $\\kappa \\in [0,1)$ 的DTS算法框图\n如果 $\\kappa=1$，则DTS算法将大大简化。与 $\\kappa \\in [0,1)$ 的情况类似，第一步是确定 $\\mathcal{C}_{\\mathbf{p}(\\kappa)}$ 和转弯方向。如图8所示，对于顺时针转弯，DTS 跟踪直线路径段 $\\overline{\\mathbf{w}_{i-1} \\mathbf{w}_{i}}$，直到 $\\mathcal{C}_{R}$ 与 $\\mathcal{C}_{p(\\kappa)}$ 重合，此时 $u \\leftarrow +c$（图8中的时间 $t_{2}$）。然后，$\\mathcal{C}_{R}$ 静止不动，监测 $\\mathcal{C}_{L}$，直到整个圆位于航路点段 $\\overline{\\mathbf{w}_{i} \\mathbf{w}_{i+1}}$ 的左侧（时间 $t_{3}$），此时恢复跟踪。\n图8. 针对 $\\kappa=1$ 的DTS算法。\n以下定理断言，DTS算法实现了第三节中定义的极值 $\\kappa$-轨迹。\n定理 5：图7所示的DTS算法实现了第三节中定义的极值 $\\kappa$-轨迹。\nDTS算法可以根据所使用的应用配置为不同的模式。例如，可能希望选择 $\\kappa$ 以便轨迹与航路点的距离为 $D$。例如，这种模式可以用于确保附加到无人机上的传感器的探测范围经过航路点。如果 $D \\in \\left[0, R\\left(1 / \\sin \\frac{\\beta}{2} - 1\\right)\\right]$，那么通过使用方程(19)，可以简单地证明 $\\kappa$ 的正确选择是\n$$ \\kappa^{*}=\\frac{D}{R} \\frac{\\sin \\frac{\\beta}{2}}{1-\\sin \\frac{\\beta}{2}} . $$如果希望轨迹直接通过航路点，则选择 $\\kappa^{*} = 0$。另一方面，如果希望在航路点之间仅通过一次转弯过渡，则选择 $\\kappa^{*} = 1$。\n对于时间关键任务，通常希望根据航路点路径规划任务。然而，如果轨迹平滑过程改变了航路点路径的路径长度，那么任务的时间安排将受到影响。因此，希望选择 $\\kappa$，使得 $\\kappa$-轨迹的路径长度等于航路点路径的路径长度。为此，下面的引理推导了 $\\kappa$-轨迹路径长度的解析表达式。\n引理 6：如果 $\\kappa \\in [0,1]$，且 $R = \\hat{v} / c$，则图4中所示的 $\\kappa$-轨迹的路径长度由以下公式给出： $$ \\begin{aligned} \u0026\\mathcal{L}\\left(\\kappa, \\mathbf{w}_{i+1}, \\mathbf{w}_{i}, \\mathbf{w}_{i-1}\\right)=\\left\\|\\mathbf{w}_{i+1}-\\mathbf{w}_{i}\\right\\|+\\left\\|\\mathbf{w}_{i}-\\mathbf{w}_{i-1}\\right\\| \\\\ \u0026+2 R\\left(\\frac{\\pi-\\beta}{2}+2 \\cos ^{-1}(\\Xi(\\kappa, \\beta))-\\Xi(\\kappa, \\beta) \\sqrt{\\frac{1}{\\Xi(\\kappa, \\beta)^{2}}-1}-(1-\\kappa) \\cos \\frac{\\beta}{2}-\\kappa \\cot \\frac{\\beta}{2}\\right), \\end{aligned} $$where\n$$ \\beta=\\cos ^{-1}\\left(\\left(\\frac{\\mathbf{w}_{i+1}-\\mathbf{w}_{i}}{\\left\\|\\mathbf{w}_{i+1}-\\mathbf{w}_{i}\\right\\|}\\right)^{T}\\left(\\frac{\\mathbf{w}_{i}-\\mathbf{w}_{i-1}}{\\left\\|\\mathbf{w}_{i}-\\mathbf{w}_{i-1}\\right\\|}\\right)\\right), $$and\n$$ \\Xi(\\kappa, \\beta)=\\frac{(1+\\kappa)+(1-\\kappa) \\sin \\frac{\\beta}{2}}{2} . $$证明：参考图 9，我们看到 $$ \\begin{aligned} \\mathcal{L} \u0026=\\left\\|\\mathbf{w}_{i+1}-\\mathbf{w}_{i}\\right\\|+\\left\\|\\mathbf{w}_{i}-\\mathbf{w}_{i-1}\\right\\|-2\\left(\\overline{\\mathbf{w}_{i} c}+\\overline{c e}\\right)+2(R \\theta+R(\\pi / 2+\\theta-\\beta / 2)) \\\\ \u0026=\\left\\|\\mathbf{w}_{i+1}-\\mathbf{w}_{i}\\right\\|+\\left\\|\\mathbf{w}_{i}-\\mathbf{w}_{i-1}\\right\\|+2 R\\left(\\frac{\\pi-\\beta}{2}+2 \\theta-\\frac{\\overline{\\mathbf{w}_{i} c}+\\overline{c e}}{R}\\right) \\end{aligned} $$We note that\n$$ \\overline{c e}=\\sqrt{(R+\\overline{c d})^{2}-R^{2}} . $$根据正弦定律，\n$$ \\frac{\\overline{\\mathbf{w}_{i} c}}{\\sin \\left(\\frac{\\pi}{2}+\\theta-\\frac{\\beta}{2}\\right)}=\\frac{R+\\overline{\\mathbf{w}_{i} \\mathbf{p}(\\kappa)}}{\\sin \\left(\\frac{\\pi}{2}-\\theta\\right)}=\\frac{R-\\overline{c d}}{\\sin \\left(\\frac{\\beta}{2}\\right)} . $$ 图9. 引理 6 证明中的定义。\n通过解出 $\\overline{cd}$ 和 $\\overline{\\mathbf{w}_{i} c}$，我们得到：\n$$ \\begin{aligned} \\overline{c d} \u0026=R-\\left(R+\\overline{\\mathbf{w}_{i} \\mathbf{p}(\\kappa)}\\right) \\frac{\\sin \\left(\\frac{\\beta}{2}\\right)}{\\cos \\theta} \\\\ \\overline{\\mathbf{w}_{i} c} \u0026=\\left(R+\\overline{\\mathbf{w}_{i} \\mathbf{p}(\\kappa)}\\right) \\frac{\\cos \\left(\\theta-\\frac{\\beta}{2}\\right)}{\\cos \\theta}=\\left(R+\\overline{\\mathbf{w}_{i} \\mathbf{p}(\\kappa)}\\right)\\left(\\cos \\frac{\\beta}{2}+\\tan \\theta \\sin \\frac{\\beta}{2}\\right) . \\end{aligned} $$从图9，使用 $\\cos \\theta = \\frac{R}{R + \\overline{c d}}$，我们得到：\n$$ \\cos \\theta=\\frac{R+\\left(R+\\overline{\\mathbf{w}_{i} \\mathbf{p}(\\kappa)}\\right) \\sin \\left(\\frac{\\beta}{2}\\right)}{2 R} $$注意到 $\\beta \\in (0, \\pi)$ 并从方程(19)中代入，得到：\n$$ \\overline{\\mathbf{w}_{i} \\mathbf{p}(\\kappa)}=\\kappa R\\left(\\frac{1}{\\sin \\left(\\frac{\\beta}{2}\\right)}-1\\right) $$解出 $\\theta$，得到：\n$$ \\theta=\\cos ^{-1}\\left(\\frac{(1+\\kappa)+(1-\\kappa) \\sin \\frac{\\beta}{2}}{2}\\right)=\\cos ^{-1}(\\Xi(\\kappa, \\beta)) . $$将方程(36)和(38)代入方程(34)，得到：\n$$ \\overline{c e}=R \\sqrt{\\frac{4}{\\left[(1+\\kappa)+(1-\\kappa) \\sin \\frac{\\beta}{2}\\right]^{2}}-1}=R \\sqrt{\\frac{1}{\\Xi^{2}(\\kappa, \\beta)}-1} $$从图9中注意到 $\\tan \\theta = \\frac{\\overline{c e}}{R}$，并使用方程(40)，我们可以从方程(37)中解出 $\\overline{\\mathbf{w}_{i} c}$，得到：\n$$ \\begin{aligned} \\overline{\\mathbf{w}_{i} c} \u0026=R\\left((1-\\kappa)+\\frac{\\kappa}{\\sin \\frac{\\beta}{2}}\\right)\\left(\\cos \\frac{\\beta}{2}+\\sin \\frac{\\beta}{2} \\sqrt{\\frac{4}{\\left[(1+\\kappa)+(1-\\kappa) \\sin \\frac{\\beta}{2}\\right]^{2}}-1}\\right) \\\\ \u0026=R\\left((\\Xi(\\kappa, \\beta)-1) \\sqrt{\\frac{1}{\\Xi^{2}(\\kappa, \\beta)}-1}+(1-\\kappa) \\cos \\frac{\\beta}{2}+\\kappa \\cot \\frac{\\beta}{2}\\right) . \\end{aligned} $$因此，将方程(39)、(40)和(41)代入方程(33)得到方程(30)。\n从引理6可以看出，航路点路径 $\\overline{\\mathbf{w}_{i-1} \\mathbf{w}_{i} \\mathbf{w}_{i+1}}$ 和相关的 $\\kappa$-轨迹之间的路径长度差异由以下给出： $$ \\begin{aligned} \\Lambda\\left(\\kappa, \\mathbf{w}_{i+1}, \\mathbf{w}_{i}, \\mathbf{w}_{i-1}\\right)=2 R\\left(\\frac{\\pi-\\beta}{2}+2 \\cos ^{-1}(\\Xi(\\kappa, \\beta))-\\Xi(\\kappa, \\beta) \\sqrt{\\frac{1}{\\Xi(\\kappa, \\beta)^{2}}-1}\\right.\\\\ \u0026\\left.-(1-\\kappa) \\cos \\frac{\\beta}{2}-\\kappa \\cot \\frac{\\beta}{2}\\right) . \\end{aligned} $$以下引理将用于找到 $\\kappa$，使得 $\\kappa$-轨迹与航路点轨迹具有相同的路径长度。\n引理 7：如果 $\\beta \\in [0, \\pi)$ 且 $\\kappa \\in [0, 1]$，则 $\\Lambda$ 是 $\\kappa$ 的递减函数。此外，$\\left.\\Lambda\\left(0, \\mathbf{w}_{i+1}, \\mathbf{w}_{i}, \\mathbf{w}_{i-1}\\right)\\right)\u003e0$ 且 $\\Lambda\\left(1, \\mathbf{w}_{i+1}, \\mathbf{w}_{i}, \\mathbf{w}_{i-1}\\right)\u003c0$。\n证明：对式（42）关于 $\\kappa$ 求导，经过一些代数变换，得\n$$ \\frac{\\partial \\Lambda}{\\partial \\kappa} = 2R \\left[-\\frac{\\partial \\Xi}{\\partial \\kappa} \\sqrt{\\frac{1}{\\Xi^2} - 1} + \\frac{\\partial \\Xi}{\\partial \\kappa} \\frac{1}{\\sqrt{1-\\Xi^2}} \\left(-2 + \\frac{1}{\\Xi}\\right) + \\cot \\frac{\\beta}{2} \\left(\\sin \\frac{\\beta}{2} - 1\\right) \\right]. $$由式（32）知，$\\beta \\in [0,\\pi)$ 且 $\\kappa \\in [0,1]$ 意味着 $\\Xi \\geq 0$ 且\n$$ \\frac{\\partial \\Xi}{\\partial \\kappa} = \\frac{1 - \\sin \\frac{\\beta}{2}}{2} \u003e 0. $$因此，若\n$$ -2 + \\frac{1}{\\Xi} \\leq 0, $$则有\n$$ \\frac{\\partial \\Lambda}{\\partial \\kappa} \u003c 0. $$根据定义，有\n$$ \\begin{aligned} -2 + \\frac{1}{\\Xi} \u0026= -2 + \\frac{1 + \\sin \\frac{\\beta}{2}}{2} + \\kappa \\frac{1 - \\sin \\frac{\\beta}{2}}{2} \\\\ \u0026\\leq -2 + \\frac{1 + \\sin \\frac{\\beta}{2}}{2} + \\frac{1 - \\sin \\frac{\\beta}{2}}{2} \\\\ \u0026= -1. \\end{aligned} $$因此，$\\Lambda$ 关于 $\\kappa$ 是递减函数。\n具体表达式为\n$$ \\begin{aligned} \\Lambda\\left(\\kappa, \\mathbf{w}_{i+1}, \\mathbf{w}_i, \\mathbf{w}_{i-1}\\right) = 2R \\Bigg(\u0026 \\frac{\\pi - \\beta}{2} + 2 \\cos^{-1}(\\Xi(\\kappa, \\beta)) - \\Xi(\\kappa, \\beta) \\sqrt{\\frac{1}{\\Xi(\\kappa, \\beta)^2} - 1} \\\\ \u0026 - (1-\\kappa) \\cos \\frac{\\beta}{2} - \\kappa \\cot \\frac{\\beta}{2} \\Bigg). \\end{aligned} $$注意到\n$$ \\Xi(0, \\beta) = \\frac{1 + \\sin \\frac{\\beta}{2}}{2}, $$从式（42）经代数变换可得\n$$ \\Lambda(0, \\beta) = 2R \\left[ \\frac{\\pi - \\beta}{2} + 2 \\cos^{-1} \\left( \\frac{1 + \\sin \\frac{\\beta}{2}}{2} \\right) - \\sqrt{1 - \\frac{1}{4} \\left(1 + \\sin \\frac{\\beta}{2}\\right)^2} - \\cos \\frac{\\beta}{2} \\right]. $$注意 $\\Lambda(0, \\pi) = 0$，且\n$$ \\frac{\\partial \\Lambda}{\\partial (\\beta/2)}(0, \\beta) = 2R \\left[ \\left( \\sin \\frac{\\beta}{2} - 1 \\right) + \\frac{ \\cos \\frac{\\beta}{2} \\left( \\frac{1}{4} (1 + \\sin \\frac{\\beta}{2}) - 1 \\right) }{ \\sqrt{1 - \\frac{1}{4} (1 + \\sin \\frac{\\beta}{2})^2} } \\right]. $$由拉格朗日余项定理 [29]，存在 $a \\in (\\beta, \\pi)$，使得\n$$ \\Lambda(0, \\beta) = \\frac{\\partial \\Lambda}{\\partial (\\beta/2)} (0, a) \\left( \\frac{\\beta - \\pi}{2} \\right). $$容易证明，对于所有 $a \\in [0, \\pi)$，有\n$$ \\frac{\\partial \\Lambda}{\\partial (\\beta/2)} (0, a) \u003c 0, $$这意味着 $\\Lambda(0) \u003e 0$。\n另外注意\n$$ \\Xi(1, \\beta) = 1, $$由式（42）可得\n$$ \\Lambda(1, \\beta) = 2R \\left[ \\frac{\\pi - \\beta}{2} - \\cot \\frac{\\beta}{2} \\right]. $$对其求导得到\n$$ \\frac{\\partial \\Lambda}{\\partial (\\beta/2)} (1, \\beta) = \\cot^2 \\frac{\\beta}{2} \u003e 0. $$因此，根据拉格朗日余项定理，存在 $a \\in (\\beta, \\pi)$，使得\n$$ \\Lambda(1, \\beta) = \\cot^2 \\frac{\\beta}{2} \\left( \\frac{\\beta - \\pi}{2} \\right). $$这意味着对于所有 $\\beta \\in [0, \\pi)$，$\\Lambda(1, \\beta) \u003c 0$。\n对于时间关键任务，必须保证由DTS生成的轨迹的路径长度与原始航路点轨迹 $\\mathcal{P}$ 的路径长度相同。下一个定理表明，存在一个 $\\kappa \\in [0, 1]$ 使得路径长度相等。\n定理 8：如果 $\\Lambda\\left(\\kappa, \\mathbf{w}_{i-1}, \\mathbf{w}_{i}, \\mathbf{w}_{i+1}\\right)$ 如方程(42)所给出，其中 $\\beta \\in [0, \\pi)$ 如方程(31)所给出，且 $R = \\hat{v} / c$，则存在唯一的 $\\kappa^{*} \\in [0,1]$ 使得 $\\Lambda\\left(\\kappa^{*}\\right) = 0$。此外，对应于 $\\kappa^{*}$ 的 $\\kappa$-轨迹与航路点路径 $\\overline{\\mathbf{w}_{i-1} \\mathbf{w}_{i} \\mathbf{w}_{i+1}}$ 具有相同的路径长度，即： $$ L=\\left\\|\\mathbf{w}_{i}-\\mathbf{w}_{i-1}\\right\\|+\\left\\|\\mathbf{w}_{i+1}-\\mathbf{w}_{i}\\right\\| . $$此外，$\\kappa^{*}$ 可以通过使用二分查找算法高效地数值求解，精确度为 $\\bigcirc\\left(2^{-n}\\right)$，其中 $n$ 是 $\\Lambda$ 的函数评估次数。\n证明：由引理6可知，$\\Lambda$ 表示 $\\kappa$-轨迹与航路点路径的路径长度差。因此，若 $\\Lambda=0$，则两路径长度相等。由引理7知，存在唯一的 $\\kappa^* \\in [0,1)$，使得 $\\Lambda(\\kappa^*)=0$。\n由于 $\\Lambda(0) \u003e 0$ 且 $\\Lambda(1) \u003c 0$，二分法搜索的第一步选取 $\\kappa=0.5$。$\\Lambda(0.5)$ 的符号决定了 $\\kappa^*$ 所在区间，精确度达到 $2^{-1}$。后续函数调用进一步细化该估计值。\n5. 实现问题 在本节中，我们讨论一些实际的实现问题，这些问题必须解决，以确保DTS算法在数字硬件上的稳健行为。实时实现要求通过数值常微分方程（ODE）求解器（例如，Runge-Kutta）使用固定时间步长来求解方程(7)-(9)。固定时间步长为检测图6中显示的切换时间带来了几个问题。例如，假设DTS正在跟踪直线路径段 $\\overline{\\mathbf{w}_{i-1} \\mathbf{w}_{i}}$，并且算法正在寻找 $\\mathcal{C}_{L}$ 与 $\\mathcal{C}_{\\mathbf{p}(\\kappa)}$ 的交点，以检测切换时间 $t_{2}$，那么我们可能遇到图10所示的情况。圆 $\\mathcal{C}_{L}$ 可能不会恰好在采样时间处与圆 $\\mathcal{C}_{\\mathbf{p}(\\kappa)}$ 相交。因此，我们需要一种稳健的方法来检测圆和直线的交点，并且还需要指示何时错过了交点。\n图10. 固定采样率对切换时间检测的影响.\n为此，定义函数\n$$ \\begin{aligned} \\Psi(\\mathbf{a}, \\mathbf{b}) \u0026 \\triangleq \\operatorname{sign}\\left\\{\\left[\\left(\\begin{array}{l} \\mathbf{a} \\\\ 0 \\end{array}\\right) \\times\\left(\\begin{array}{l} \\mathbf{b} \\\\ 0 \\end{array}\\right)\\right] \\cdot \\hat{\\mathbf{k}}\\right\\} \\\\ \u0026=\\operatorname{sign}\\left[a_{x} b_{y}-b_{x} a_{y}\\right] \\end{aligned} $$其中，$\\hat{\\mathbf{k}}$ 是指向平面的单位向量。函数 $\\Psi$ 可以用于多个目的。首先，如果 $\\mathbf{q}_{i}$ 和 $\\mathbf{q}_{i+1}$ 分别是沿着路径 $\\overline{\\mathbf{w}_{i-1} \\mathbf{w}_{i}}$ 和 $\\overline{\\mathbf{w}_{i} \\mathbf{w}_{i+1}}$ 的单位向量，如图4所示，则转弯的方向由 $\\Psi\\left(\\mathbf{q}_{i}, \\mathbf{q}_{i+1}\\right)$ 给出，其中 $\\Psi\\left(\\mathbf{q}_{i}, \\mathbf{q}_{i+1}\\right)\u003e0$ 表示从当前路径段到下一个路径段的转弯是顺时针（右转），而 $\\Psi\\left(\\mathbf{q}_{i}, \\mathbf{q}_{i+1}\\right)\u003c0$ 表示转弯是逆时针（左转）。函数 $\\Psi$ 还可以用于将 $\\mathbb{R}^{2}$ 平面划分为两个不同的半平面，如图11所示。参考图6，我们将讨论切换时间 $t_{2}$ 到 $t_{5}$ 的稳健检测。\n图11. $\\Psi$ 将 $\\mathbb{R}^{2}$ 划分为两个不同的子区域。\n切换时间 $t_{2}$。回想一下，圆 $\\mathcal{C}_{L}$ 的圆心是 $\\mathbf{c}_{L}$，圆 $\\mathcal{C}_{\\mathbf{p}(\\kappa)}$ 的圆心是 $\\mathbf{p}(\\kappa)$，从图12可以看出，$\\mathcal{C}_{L}$ 和 $\\mathcal{C}_{\\mathbf{p}(\\kappa)}$ 的圆心之间的距离为 $\\left\\|\\mathbf{c}_{L}-\\mathbf{p}(\\kappa)\\right\\|$。在切换时间 $t_{2}$ 之前，这个距离大于 $2 R$。在切换时间 $t_{2}$ 之后，这个距离小于 $2 R$。因此，可以通过监测 $\\left\\|\\mathbf{c}_{L}-\\mathbf{p}(\\kappa)\\right\\|$ 来确定切换时间 $t_{2}$，假设在某个采样时间，这个量小于 $2 R$。\n然而，如果 $\\kappa \\approx 1$，则可能在切换时间 $t_{2}$ 的交点前后，$\\left\\|\\mathbf{c}_{L}-\\mathbf{p}(\\kappa)\\right\\| \u003e 2 R$，正如图12所示。因此，\n图12. 当 $\\kappa \\approx 1$ 时，有限采样时间的影响。\n同时，还需要检测何时 $\\mathbf{c}_{L}$ 从半平面 $\\mathcal{S}_{1}$ 移动到半平面 $\\mathcal{S}_{2}$。根据图11的指导，可以通过监测 $\\Psi\\left(\\mathbf{c}_{L}-\\mathbf{p}(\\kappa), R(\\pi / 2) \\mathbf{q}_{i}\\right)$ 的符号来完成这一点，其中\n$$ R(\\phi)=\\left(\\begin{array}{cc} \\cos \\phi \u0026 -\\sin \\phi \\\\ \\sin \\phi \u0026 \\cos \\phi \\end{array}\\right) $$如果 $\\Psi\\left(\\mathbf{c}_{L}-\\mathbf{p}(\\kappa), R(\\pi / 2) \\mathbf{q}_{i}\\right) \u003e 0$，则 $\\mathbf{c}_{L} \\in \\mathcal{S}_{1}$，否则 $\\mathbf{c}_{L} \\in \\mathcal{S}_{2}$。\n切换时间 $t_{3}$。切换时间 $t_{3}$ 也可以通过半平面论证来检测。如图13所示，$t_{3}$ 发生在圆 $\\mathcal{C}_{R}\\left(\\mathbf{c}_{R}\\right)$ 的圆心从 $\\mathcal{S}_{1}$ 过渡到 $\\mathcal{S}_{2}$ 时，可以通过以下函数来检测： $$ \\Psi\\left(\\mathbf{c}_{R}-\\mathbf{c}_{L}, \\frac{\\mathbf{p}(\\kappa)-\\mathbf{c}_{L}}{\\left\\|\\mathbf{p}(\\kappa)-\\mathbf{c}_{L}\\right\\|}\\right) $$ 图13. 切换时间 $t_{3}$。\n切换时间 $t_{4}$。稳健地检测切换时间 $t_{4}$ 可以通过以下方式完成。首先，在切换时间 $t_{3}$，将 $\\mathbf{c}_{L}$ 的位置通过平分角 $\\beta$ 的直线进行反射。定义 $\\beta$ 的平分线的单位向量由方程(18)给出。通过由 $\\overline{\\mathbf{q}}$ 描述的直线反射一个向量，使用的是 Householder 变换 [30]。\n$$ H(\\overline{\\mathbf{q}})=\\left(\\begin{array}{cc} 1-2 \\bar{q}_{y}^{2} \u0026 2 \\bar{q}_{x} \\bar{q}_{y} \\\\ 2 \\bar{q}_{x} \\bar{q}_{y} \u0026 1-2 \\bar{q}_{x}^{2} \\end{array}\\right) $$因此，如图 14 所示，我们有\n$$ \\mathbf{c}_{L}\\left(t_{4}\\right)=\\mathbf{w}_{i}+H(\\overline{\\mathbf{q}})\\left(\\mathbf{c}_{L}\\left(t_{3}\\right)-\\mathbf{w}_{i}\\right) $$ 图. 14. 切换时间 $t_{4}$.\n下一步是等待直到 $\\mathbf{c}_L$ 穿过由 $\\overline{\\mathbf{q}}$ 定义的半平面，该半平面包含 $\\mathbf{c}_L(t_4)$。参考图14，我们正在寻找从半平面 $S_1$ 到 $S_2$ 的过渡。当以下表达式从 -1 切换到 +1 时，稳健地识别这种过渡：\n$$ \\Psi\\left(\\mathbf{c}_L - \\mathbf{w}_i, \\overline{\\mathbf{q}}\\right) $$最后一步是寻找 $\\mathcal{C}_{L}$ 与线段 $\\overline{\\mathbf{w}_{i} \\mathbf{w}_{i+1}}$ 的交点。参考图14，当 $\\mathbf{c}_{L}$ 从半平面 $\\mathcal{S}_{3}$ 穿越到半平面 $\\mathcal{S}_{4}$ 时，或者换句话说，当以下表达式从 $-1$ 切换到 $+1$ 时，稳健地识别这种过渡：\n$$ \\Psi\\left(\\mathbf{c}_{L} - \\mathbf{c}_{L}(t_4), \\frac{\\mathbf{p}(\\kappa) - \\mathbf{c}_{L}(t_4)}{\\left\\|\\mathbf{p}(\\kappa) - \\mathbf{c}_{L}(t_4)\\right\\|}\\right) $$切换时间 $t_{5}$。切换时间 $t_{5}$ 的检测与切换时间 $t_{3}$ 的检测类似。\n最后一个实现问题是由于在切换时间 $t_{5}$ 时，DTS 可能与航路点段 $\\overline{\\mathbf{w}_{i} \\mathbf{w}_{i+1}}$ 没有完美对齐，因此将 $u=0$ 会导致 DTS 偏离航路点段。在直线路段期间，我们需要有一个跟踪算法，使得 DTS 能够渐近地跟踪航路点段，同时仍然满足约束 $-c \\leq u \\leq c$。\n图15. 航路点跟踪\n参考图15，设 $\\psi_{i}^{d} = \\tan^{-1}\\left(q_{i y} / q_{i x}\\right)$ 为航路点路径所形成的角度。为了简化开发，我们将原点移至 $\\mathbf{w}_{i-1}$ 并将数据旋转 $\\psi_{i}^{d}$。因此，我们有： $$ \\begin{aligned} \u0026\\mathbf{e}=\\left(\\begin{array}{c} e_{\\|} \\\\ e_{\\perp} \\end{array}\\right)=R\\left(\\phi_{i}^{d}\\right)\\left(\\mathbf{z}-\\mathbf{w}_{i-1}\\right) \\\\ \u0026\\mathbf{\\dot { e }}=\\left(\\begin{array}{c} \\dot{e}_{\\|} \\\\ \\dot{e}_{\\perp} \\end{array}\\right)=\\left(\\begin{array}{c} v \\cos \\left(\\psi-\\psi_{i}^{d}\\right) \\\\ v \\sin \\left(\\psi-\\psi_{i}^{d}\\right) \\end{array}\\right) \\end{aligned} $$控制目标是使得 $e_{\\perp}$ 和 $\\psi - \\psi_{i}^{d}$ 渐近地趋于零，同时满足控制约束 $u \\in [-c, c]$。以下定理描述了如何实现这一目标。\n**定理 9：**给定非线性系统 $$ \\begin{aligned} \\dot{e}_{\\perp} \u0026=v \\sin \\left(\\psi-\\psi_{i}^{d}\\right) \\\\ \\dot{\\psi} \u0026=u \\end{aligned} $$带有控制约束 $u \\in[-c, c]$ 其中 $v$ 是一个正常数。 如果 $$ u=-\\operatorname{sat}_{c}\\left[\\frac{\\cos ^{3}\\left(\\psi-\\psi_{i}^{d}\\right)}{\\gamma}\\left(\\frac{k_{1} e_{\\perp}}{\\sqrt{e_{\\perp}^{2}+v^{2}}}+k_{2} \\sin \\left(\\psi-\\psi_{i}^{d}\\right)\\right)\\right], $$其中 $\\gamma c \u003e 1, 0 \u003c k_{1} \u003c \\gamma c$，且 $k_{2} \u003e 0$，则原点是渐近稳定的，并且吸引域为 $\\Omega = (-\\infty, \\infty) \\times \\left(\\psi_{i}^{d} - \\pi / 2, \\psi_{i}^{d} + \\pi / 2\\right)$。\n证明：由于对于所有 $\\psi \\in \\Omega$，有 $\\cos \\left(\\psi - \\psi_{i}^{d}\\right) \u003e 0$，变量变换\n$$ \\begin{aligned} \u0026\\zeta_{1} = \\frac{e_{\\perp}}{v}, \\\\ \u0026\\zeta_{2} = \\sin(\\psi - \\psi_i^d) \\end{aligned} $$是一个微分同胚，变换后系统为\n$$ \\begin{aligned} \u0026\\dot{\\zeta}_{1} = \\zeta_{2}, \\\\ \u0026\\dot{\\zeta}_{2} = \\sqrt{1 - \\zeta_{2}^2} \\, u, \\end{aligned} $$变换后的控制律为\n$$ u = -\\operatorname{sat}_c \\left[ \\frac{(1 - \\zeta_{2}^2)^{3/2}}{\\gamma} \\left( \\frac{k_1 \\zeta_1}{\\sqrt{\\zeta_1^2 + 1}} + k_2 \\zeta_2 \\right) \\right]. $$在变换坐标下，定义区域为 $\\Omega = (-\\infty, \\infty) \\times (-1, 1)$。考虑值函数\n$$ V(\\zeta) = k_1 \\sqrt{\\zeta_1^2 + 1} - 1 + \\frac{\\gamma}{2} \\frac{\\zeta_2^2}{1 - \\zeta_2^2}, $$注意 $V$ 在 $\\Omega$ 上正定，且当 $\\zeta$ 接近 $\\Omega$ 边界时，$V \\to +\\infty$。对式（47）求导得\n$$ \\dot{V} = \\zeta_2 \\left( \\frac{k_1 \\zeta_1}{\\sqrt{\\zeta_1^2 + 1}} + \\frac{\\gamma u}{(1 - \\zeta_2^2)^{3/2}} \\right). $$当控制信号 $u$ 未被饱和时，直接代入得\n$$ \\dot{V} = -k_2 \\zeta_2^2. $$考虑 $u$ 被正向饱和的情况，此时\n$$ \\dot{V} = \\zeta_2 \\left( \\frac{k_1 \\zeta_1}{\\sqrt{\\zeta_1^2 + 1}} + \\frac{\\gamma c}{(1 - \\zeta_2^2)^{3/2}} \\right), $$且 $u = c$ 意味着\n$$ -\\frac{(1 - \\zeta_2^2)^{3/2}}{\\gamma} \\left( \\frac{k_1 \\zeta_1}{\\sqrt{\\zeta_1^2 + 1}} + k_2 \\zeta_2 \\right) \u003e c. $$重排后得到\n$$ \\frac{k_1 \\zeta_1}{\\sqrt{\\zeta_1^2 + 1}} \u003c -\\frac{\\gamma c}{(1 - \\zeta_2^2)^{3/2}} - k_2 \\zeta_2. $$因此，若 $\\zeta\\_2 \u003e 0$，则\n$$ \\dot{V} \u003c -k_2 \\zeta_2^2. $$另一方面，若 $\\zeta\\_2 \u003c 0$，则需要满足\n$$ \\frac{k_1 \\zeta_1}{\\sqrt{\\zeta_1^2 + 1}} + \\frac{\\gamma c}{(1 - \\zeta_2^2)^{3/2}} \u003e 0. $$当 $\\zeta\\_1 \\geq 0$ 时，该不等式显然成立。若 $\\zeta\\_1 \u003c 0$，则有\n$$ -\\frac{k_1 \\zeta_1}{\\sqrt{\\zeta_1^2 + 1}} \u003c k_1 \u003c \\gamma c \u003c \\frac{\\gamma c}{(1 - \\zeta_2^2)^{3/2}}. $$由于 $u$ 被负向饱和时也可用类似推理证明，故 $\\dot{V}$ 是半负定的，且定义集合\n$$ \\hat{\\Omega} \\triangleq \\{ \\zeta \\in \\Omega : \\dot{V} = 0 \\} = \\{ \\zeta \\in \\Omega : \\zeta_2 = 0 \\}. $$在 $\\hat{\\Omega}$ 上，系统动力学简化为\n$$ \\begin{aligned} \\dot{\\zeta}_1 \u0026= 0, \\\\ \\dot{\\zeta}_2 \u0026= -\\operatorname{sat}_c \\left[ \\frac{k_1}{\\gamma} \\frac{\\zeta_1}{\\sqrt{\\zeta_1^2 + 1}} \\right]. \\end{aligned} $$这迫使系统轨迹离开 $\\hat{\\Omega}$，除非 $\\zeta_{1} = 0$。因此，$\\hat{\\Omega}$ 中的最大不变集是原点，定理通过 LaSalle 不变性原理 [31], [32] 得出。\n系统（45）与控制（46）的相位图如图16所示，展示了不同的 $\\gamma$、$k_{1}$ 和 $k_{2}$ 值。\n6. 仿真 $\\kappa$-路径算法具有较小的计算负载，并且可以实时运行。在对 $1.8 \\mathrm{GHz}$ 的奔腾级计算机进行的 200,000 次迭代测试中，算法的执行时间呈双峰分布。如果模拟车辆正在转弯，则每个时间步长的平均运行时间约为 $39 \\mu \\mathrm{s}$；而如果车辆在路径的直线段上，则每个步骤的平均运行时间约为 $16 \\mu \\mathrm{s}$。该算法的计算简便性使其能够在计算资源有限的无人机应用中实现。\n。 图16. 转换后的跟踪问题的相位图。\n$\\kappa$-路径算法的仿真结果显示在图17中，包括最小时间过渡（$\\kappa=1$）、通过航路点的过渡（$\\kappa=0$）以及匹配原始直线路径长度的过渡（$\\kappa$ 在 0 到 1 之间变化）。平滑算法在路径飞行过程中实时运行。当路径上的一个转弯完成时，平滑算法会查看下两个航路点并计算下一个转弯的平滑过渡。\n对于图17中显示的最小时间过渡，可以看出，与 $\\kappa=1$ 对应的转弯圆心的位置会根据相邻路径段之间的角度 $\\beta$ 发生变化。通过航路点的 $\\kappa=0$ 转弯圆也具有相同的特点。对于等长路径，导致路径长度相等的每个转弯的 $\\kappa$ 值依赖于相邻路径段之间的 $\\beta$ 角度。对于等长路径的最后四个转弯，$\\kappa$ 值分别为 $0.266, 0.136, 0.406, 0.374$。通常，角度越尖锐，$\\kappa$ 值越小，以平衡路径长度。图18显示了连接在锐角上的航路点段路径的特写视图。最小时间、通过航路点和等长过渡之间的差异可以清楚地看到。\nFig. 17. Sample trajectories.\nFig. 18. Sample trajectories - close up.\n7. 结论 我们开发了一种生成点约束、时间极值轨迹（称为 $\\kappa$-路径）的方法，用于在航路点路径的连续路径段之间进行过渡。这些路径满足动力学输入约束，模拟了无人机的动态能力，并通过一个简单的实时算法实现。此外，我们还开发了一种方法，能够推导出与原始直线路径具有相同长度的 $\\kappa$-路径。\n动态轨迹平滑方法有几个优点。首先，它可以与生成直线路径的航路点路径规划算法轻松集成。其次，该方法具有低计算开销。事实上，轨迹是在实时生成的，随着无人机沿路径飞行。第三，动态轨迹平滑器最小化了车辆偏离直线路径的时间。这些优点使得该方法成为无人机应用中可行的实现替代方案。\n附录1：庞特里亚金最小值原理 庞特里亚金最小值原理（Pontryagin’s Minimum Principle，简称PMP）是最优控制理论中的一个基本定理，用于求解最优控制问题。它由俄罗斯数学家庞特里亚金（Lev Pontryagin）于1950年代提出，旨在通过构造哈密顿量并求解适当的条件，来确定系统在给定约束下的最优控制策略。\n庞特里亚金最小值原理的基本思想 在最优控制问题中，我们通常希望在满足一定约束的情况下，使得某个性能指标（通常是某种形式的成本函数）最小化或最大化。庞特里亚金最小值原理通过引入一个拉格朗日乘子（即伴随变量）来将这一优化问题转化为求解哈密顿量最小化的问题。\n数学表述 考虑一个标准的最优控制问题，其形式为：\n状态方程： $$ \\dot{x}(t) = f(x(t), u(t)), \\quad t \\in [0, T] $$ 其中，$x(t)$ 是系统状态，$u(t)$ 是控制输入，$f(x, u)$ 是状态方程。\n性能指标： $$ J = \\int_0^T L(x(t), u(t)) dt + \\Phi(x(T)) $$ 其中，$L(x(t), u(t))$ 是每个时间点的即时成本，$\\Phi(x(T))$ 是终端成本。\n庞特里亚金最小值原理的步骤： 构造哈密顿量： 定义哈密顿量： $$ H(x, u, \\lambda) = L(x, u) + \\lambda^T f(x, u) $$ 其中，$\\lambda$ 是伴随变量（即拉格朗日乘子），用于表示系统状态方程的约束。\n必要条件： 最优控制和状态轨迹满足以下条件：\n控制的最小化条件：最优控制$u^*(t)$应当使得哈密顿量$H(x, u, \\lambda)$ 对$u$求导数的结果为零，即： $$ \\frac{\\partial H}{\\partial u} = 0 $$ 状态方程：状态方程必须满足： $$ \\dot{x}(t) = \\frac{\\partial H}{\\partial \\lambda} $$ 伴随方程：伴随变量的动态方程为： $$ \\dot{\\lambda}(t) = -\\frac{\\partial H}{\\partial x} $$ 边界条件：给定终端约束条件，可以得出伴随变量的边界条件。\n最优性条件： 对于最优控制问题，满足上述条件的控制策略和状态轨迹称为最优解。\n应用 庞特里亚金最小值原理广泛应用于各类最优控制问题，包括但不限于：\n航迹规划：为飞行器、无人机等的运动规划提供最优控制策略。 机器人控制：求解移动机器人、机械臂等的最优运动轨迹。 经济学与金融学：用于资源分配、投资组合优化等问题。 庞特里亚金最小值原理在处理复杂的动态系统时非常强大，特别是对于非线性、约束性强的系统。\n理解 庞特里亚金最小值原理（Pontryagin’s Minimum Principle，简称PMP）是用来求解最优控制问题的一个重要方法。在最优控制问题中，我们通常希望找到一种控制策略，使得某个目标（比如最小化时间、能量或成本）在一定的约束条件下达到最优。\n想象你驾驶一辆车，目标是以最短的时间从起点到达终点。你需要选择如何控制油门和刹车的力度，这就是控制问题。在这个过程中，车的速度、位置等状态随时间变化，而你想要通过合理地选择控制输入（油门和刹车）来使得车在规定的时间内到达目的地，并且尽量减少油耗或者其他的成本。\n庞特里亚金最小值原理就是帮助你找到这个“最优驾驶策略”的工具。\n原理的核心思想： 状态与控制的关系： 系统的状态（比如车的位置和速度）是由你控制的输入（比如油门、刹车）来决定的。最优控制问题的目标就是找到一个控制输入序列，使得系统在运行过程中满足某些约束（比如车速不能超过一定的限制，或者油量不能用完）并且在一定的性能指标下（比如最短时间）最优化。\n伴随变量： 为了处理这种问题，庞特里亚金原理引入了“伴随变量”。这些伴随变量是用来衡量状态变化对目标函数的影响的。它们相当于对你控制行为的反馈信号，告诉你当前的控制策略是否接近最优。\n最优控制的条件： 庞特里亚金最小值原理通过构建一个哈密顿量（哈密顿量是状态、控制输入和伴随变量的组合）来描述问题，并要求控制策略在满足系统约束的前提下，使得哈密顿量最小。换句话说，你的目标是调整控制策略，使得哈密顿量值最小。\n动态方程： 通过这个原理，可以得到一组动态方程，描述了如何通过控制输入来调整状态（比如车的速度和位置），以及如何调整伴随变量，直到达到最优解。\n举个简单的例子： 假设你想开车从城市A到城市B，目标是最短时间内到达，同时油费最省。庞特里亚金最小值原理的应用，就是通过引入适当的控制变量（如油门、刹车）和一些中间计算（比如伴随变量，衡量油费和时间的影响），帮助你找到最合适的驾驶策略。\n总结： 庞特里亚金最小值原理的核心就是：在满足约束的情况下，找到一种控制策略，使得某个目标（比如时间、能量等）最优化。这个过程涉及到通过建立“哈密顿量”和伴随变量来描述系统，并通过求解相应的方程来得到最优控制策略。\n附录2: 求解 $\\kappa$‐轨迹的伪代码 下面给出求解 $\\kappa$‐轨迹的伪代码，既体现了输入与输出数据结构的设计，也展示了主要的求解逻辑过程。伪代码中以三个连续航路点（$w_{i-1}$, $w_i$, $w_{i+1}$）以及 UAV 参数作为输入，输出关键参数 $\\kappa^*$ 和对应的参数化点 $p(\\kappa^*)$（同时也可扩展生成完整的轨迹）。\n数据结构设计 Waypoint\n用于表示二维航路点\nDataStructure Waypoint: x: real y: real UAVParameters\n表示无人机相关参数\nDataStructure UAVParameters: v: real // 固定或期望速度 c: real // 最大航向速率 (rad/s) dt: real // 数值积分步长（如需要生成完整轨迹时使用） totalTime: real // 总模拟/规划时间 PlannerInput\n封装所有规划输入\nDataStructure PlannerInput: waypoints: list of Waypoint // 航路点序列 params: UAVParameters KappaTrajectoryOutput\n保存求解结果（可扩展为整个轨迹）\nDataStructure KappaTrajectoryOutput: kappa_star: real // 求解得到的 κ* p_kappa: Waypoint // 根据 κ* 计算得到的关键交点 p(κ*) // 如果需要，还可以包含生成的轨迹序列，如 states: list of State 伪代码 Function SolveKappaTrajectory(w_im1: Waypoint, w_i: Waypoint, w_ip1: Waypoint, params: UAVParameters) -\u003e KappaTrajectoryOutput: // 1. 计算转弯半径 R R ← params.v / params.c // 2. 计算两个航路段的单位向量 q_i ← Normalize(w_i - w_im1) // q_i = (w_i - w_im1) / ||w_i - w_im1|| q_ip1 ← Normalize(w_ip1 - w_i) // q_ip1 = (w_ip1 - w_i) / ||w_ip1 - w_i|| // 3. 计算两航段间的夹角 β beta ← arccos(Dot(q_i, q_ip1)) // 4. 计算角平分线方向单位向量 q_bar diff ← q_ip1 - q_i if Norm(diff) ≈ 0 then q_bar ← Perpendicular(q_i) // 当航段近似平行时，取 q_i 的垂直方向 else q_bar ← Normalize(diff) // 5. 利用二分搜索求解 κ* 使得路径长度差 Λ(κ) = 0 kappa_star ← BisectionSolveKappa(beta, R, tolerance = 1e-6, maxIter = 50) // 6. 根据公式 (19) 计算关键交点 p(κ*) // p(κ) = w_i + κ * R * (1/sin(β/2) - 1) * q_bar factor ← R * (1 / sin(beta / 2) - 1) p_kappa ← w_i + kappa_star * factor * q_bar // 7. 封装输出 output.kappa_star ← kappa_star output.p_kappa ← p_kappa return output ------------------------------------------------------------- Function BisectionSolveKappa(beta: real, R: real, tolerance: real, maxIter: integer) -\u003e real: low ← 0.0 high ← 1.0 lambda_low ← ComputeLambda(0.0, beta, R) lambda_high ← ComputeLambda(1.0, beta, R) // 根据引理要求：Λ(0) \u003e 0, Λ(1) \u003c 0 if lambda_low \u003c 0 or lambda_high \u003e 0 then Error(\"输入参数不满足 Λ(0) \u003e 0 或 Λ(1) \u003c 0\") for iter from 1 to maxIter do: mid ← (low + high) / 2 lambda_mid ← ComputeLambda(mid, beta, R) if abs(lambda_mid) \u003c tolerance then return mid end if if lambda_mid \u003e 0 then low ← mid else high ← mid end if end for return mid // 最大迭代次数后返回近似解 ------------------------------------------------------------- Function ComputeLambda(kappa: real, beta: real, R: real) -\u003e real: // 计算辅助量 sin_half_beta ← sin(beta / 2) cos_half_beta ← cos(beta / 2) cot_half_beta ← cos_half_beta / sin_half_beta // cot(β/2) // Ξ(κ,β) = ((1 + κ) + (1 - κ)* sin(β/2)) / 2 Xi ← ((1 + kappa) + (1 - kappa) * sin_half_beta) / 2 // 计算各项：Λ(κ) = 2R * [ (π-β)/2 + 2·acos(Xi) - Xi·sqrt(1/(Xi^2)-1) - (1-κ)·cos(β/2) - κ·cot(β/2) ] term1 ← (π - beta) / 2 term2 ← 2 * arccos(Xi) term3 ← Xi * sqrt(1 / (Xi*Xi) - 1) term4 ← (1 - kappa) * cos_half_beta term5 ← kappa * cot_half_beta lambda_value ← 2 * R * (term1 + term2 - term3 - term4 - term5) return lambda_value ------------------------------------------------------------- // 辅助函数：向量归一化 Function Normalize(vector: Waypoint) -\u003e Waypoint: norm_val ← sqrt(vector.x^2 + vector.y^2) return Waypoint(vector.x / norm_val, vector.y / norm_val) // 辅助函数：向量减法 Operator Subtract(a: Waypoint, b: Waypoint) -\u003e Waypoint: return Waypoint(a.x - b.x, a.y - b.y) // 辅助函数：向量点乘 Function Dot(a: Waypoint, b: Waypoint) -\u003e real: return a.x * b.x + a.y * b.y // 辅助函数：向量加法和数乘同理 ------------------------------------------------------------- 说明 输入部分：\n三个航路点 $w_{i-1}$, $w_i$, $w_{i+1}$（数据结构 Waypoint）， UAV 参数（数据结构 UAVParameters），例如速度 $v$ 和最大航向速率 $c$ 用于计算转弯半径 $R = v/c$。 核心求解流程：\n计算两段航线的单位向量，并由此求得夹角 $\\beta$； 计算角平分方向 $q_{\\text{bar}}$； 定义路径长度差函数 $\\Lambda(\\kappa)$（见 ComputeLambda），并利用二分搜索 (BisectionSolveKappa) 求解使得 $\\Lambda(\\kappa) = 0$ 的 $\\kappa^*$； 根据公式 (19) 计算关键点 $p(\\kappa^*)$。 输出部分：\n返回一个数据结构 KappaTrajectoryOutput，包含求解得到的 $\\kappa^*$ 和对应的关键交点 $p(\\kappa^*)$。 如果需要，还可以进一步扩展为完整的轨迹（如通过 DTS 状态机生成 UAV 状态序列）。 该伪代码为实现 $\\kappa$‐轨迹求解提供了一个整体框架，实际代码实现时可根据具体应用要求进行扩展与细化。\n附录3 $\\kappa$ 的物理含义 在这篇论文中，κ是一个控制无人机如何在直线航点路径段之间过渡的参数。它的值在0到1之间，决定了一个特殊点p(κ)在两个连续路径段之间角度平分线上的位置。\nκ的物理含义随其值而变化：\n当κ = 0时：轨迹直接穿过航点。这确保无人机精确到达每个航点，但可能不是最高效的过渡方式。\n当κ = 1时：轨迹在航点段之间实现最小时间过渡，只使用一次转弯。这在时间上更高效，但与原始航点的偏离更大。\n当0 \u003c κ \u003c 1时：轨迹代表了一种在通过航点和高效转弯之间的折中方案。\n作者还展示了如何计算特定的κ值，使得生成的平滑轨迹具有与原始航点路径（带有尖角的路径）完全相同的路径长度。这对于需要精确保持路径长度的协同定时任务特别有用。\n本质上，κ是一个设计参数，允许轨迹生成器根据不同的任务需求进行配置——无论是优先考虑精确的航点跟踪、最小过渡时间，还是保持原始路径长度。\n附录4 κ轨迹平滑算法伪代码 by Claude Sonnet 3.7 以下是基于Anderson、Beard和McLain的论文\"无人机实时动态轨迹平滑\"中提出的κ轨迹平滑算法的伪代码：\n算法：动态轨迹平滑（DTS） 输入: - 航点序列 W = {w₁, w₂, ..., wₙ} - 期望速度 v̂ - 最大转向率 c - κ参数 (0 ≤ κ ≤ 1)，控制平滑度 输出: - 平滑的动态可行轨迹 初始化: R = v̂/c // 最小转弯半径 i = 1 // 当前航点索引 ẑ = w₁ // 初始位置 ψ̂ = 方向(w₂ - w₁) // 初始航向 主循环: 当 i \u003c n 时: // 计算相邻航点段之间的单位向量 qᵢ = (wᵢ - wᵢ₋₁)/‖wᵢ - wᵢ₋₁‖ qᵢ₊₁ = (wᵢ₊₁ - wᵢ)/‖wᵢ₊₁ - wᵢ‖ // 计算航点段之间的角度 β = cos⁻¹(qᵢᵀqᵢ₊₁) // 计算角度平分线的单位向量 q̄ = (qᵢ₊₁ - qᵢ)/‖qᵢ₊₁ - qᵢ‖ // 计算p(κ)点的位置 p(κ) = wᵢ + κR((1/sin(β/2)) - 1)q̄ // 计算转弯方向 turnDirection = sign(qᵢ × qᵢ₊₁) // 跟踪当前航点段直到需要转弯 当 ẑ在wᵢ₋₁wᵢ线段上 且 还未达到转弯点: u = trackPathSegment(ẑ, ψ̂, wᵢ₋₁, wᵢ) 更新 ẑ, ψ̂ 通过微分方程: ẑ̇ₓ = v̂cos(ψ̂) ẑ̇ᵧ = v̂sin(ψ̂) ψ̂̇ = u // 执行转弯序列 如果 turnDirection \u003e 0: // 顺时针转弯 // 转弯序列1：左-右-左 u = -c // 开始左转 等待直到右转弯圆心CR与p(κ)重合 u = +c // 开始右转 等待直到左转弯圆心CL与wᵢwᵢ₊₁线段相交 u = -c // 开始左转 等待直到航向与wᵢwᵢ₊₁线段对齐 否则: // 逆时针转弯 // 转弯序列2：右-左-右 u = +c // 开始右转 等待直到左转弯圆心CL与p(κ)重合 u = -c // 开始左转 等待直到右转弯圆心CR与wᵢwᵢ₊₁线段相交 u = +c // 开始右转 等待直到航向与wᵢwᵢ₊₁线段对齐 i = i + 1 // 移动到下一个航点 函数 trackPathSegment(ẑ, ψ̂, w₁, w₂): // 计算航点段方向 qᵢ = (w₂ - w₁)/‖w₂ - w₁‖ ψᵈ = atan2(qᵢᵧ, qᵢₓ) // 计算横向偏差 e⊥ = ((ẑ - w₁) × qᵢ) · k̂ // k̂是指向平面外的单位向量 // 计算控制输入 u = -satₖ[cos³(ψ̂ - ψᵈ)/γ · (k₁e⊥/√(e⊥² + v̂²) + k₂sin(ψ̂ - ψᵈ))] 返回 u 这个伪代码表示了论文中基本的动态轨迹平滑算法的核心逻辑。在实际实现中，还需要考虑以下几点：\n使用鲁棒的方法检测转弯点和转弯完成点（论文第V节详细讨论） 处理数值积分误差和离散时间步长引起的问题 针对最小时间转弯(κ=1)的特殊情况简化 为保持路径长度不变的情况计算适当的κ值（论文中使用二分法搜索） 算法的主要优点是计算复杂度低，适合实时实现，且可以灵活配置以满足不同的任务需求。\n附录5 $k=1$的轨迹平滑简化模型 基本定义与参数 在κ=1的情况下，动态轨迹平滑模型是为了实现两个直线航点段之间的最小时间转弯。以下是形式化的说明：\n核心参数 航点序列：$W = \\{w_1, w_2, ..., w_n\\}$，其中每个$w_i \\in \\mathbb{R}^2$表示二维平面上的位置点 期望速度：$\\hat{v} \\in [v_{min}, v_{max}]$，表示无人机沿轨迹的恒定速度 最大转向率：$c \u003e 0$，受无人机动力学限制的最大转向率 最小转弯半径：$R = \\hat{v}/c$，由速度和最大转向率决定 航点段方向向量 第$i$段航点路径的单位方向向量：$q_i = \\frac{w_i - w_{i-1}}{\\|w_i - w_{i-1}\\|}$ 第$i+1$段航点路径的单位方向向量：$q_{i+1} = \\frac{w_{i+1} - w_i}{\\|w_{i+1} - w_i\\|}$ 角度定义 相邻航点段之间的夹角：$\\beta = \\cos^{-1}(q_i^T q_{i+1})$，其中$\\beta \\in [0, \\pi)$ 角度平分线的单位向量：$\\bar{q} = \\frac{q_{i+1} - q_i}{\\|q_{i+1} - q_i\\|}$ κ=1的几何构造 对于κ=1的情况，我们构造一个具有特定几何特性的轨迹：\n特殊点p(1) 当κ=1时，特殊点p(1)定义为： $$p(1) = w_i + R\\left(\\frac{1}{\\sin(\\beta/2)} - 1\\right)\\bar{q}$$几何意义：p(1)是角度平分线上的一点，距离航点$w_i$足够远，使得以p(1)为圆心、半径为R的圆$C_{p(1)}$与两个航点段相切。\n转弯圆确定 转弯方向由$\\Psi(q_i, q_{i+1})$确定，其中函数$\\Psi$定义为： $$\\Psi(a, b) = \\text{sign}((a \\times b) \\cdot \\hat{k})$$ 其中$\\hat{k}$是指向平面外的单位向量。\n如果$\\Psi(q_i, q_{i+1}) \u003e 0$（顺时针转弯），转弯圆是右转圆$C_R$ 如果$\\Psi(q_i, q_{i+1}) \u003c 0$（逆时针转弯），转弯圆是左转圆$C_L$ 动力学系统 无人机的运动由以下动力学系统描述： $$\\dot{\\hat{z}}_x = \\hat{v}\\cos\\hat{\\psi}$$ $$\\dot{\\hat{z}}_y = \\hat{v}\\sin\\hat{\\psi}$$ $$\\dot{\\hat{\\psi}} = u$$其中控制输入$u \\in [-c, c]$受限于最大转向率。\nκ=1的转弯控制策略 对于κ=1的情况，控制策略分为三个阶段：\n1. 直线段跟踪阶段 无人机沿航点段$w_{i-1}w_i$直线飞行，直到达到转弯点。这个阶段的控制为： $$u = -\\text{sat}_c\\left[\\frac{\\cos^3(\\hat{\\psi} - \\psi^d)}{\\gamma}\\left(\\frac{k_1 e_\\perp}{\\sqrt{e_\\perp^2 + \\hat{v}^2}} + k_2\\sin(\\hat{\\psi} - \\psi^d)\\right)\\right]$$其中：\n$\\psi^d = \\text{atan2}(q_{i,y}, q_{i,x})$是期望航向 $e_\\perp$是横向偏差 $k_1, k_2, \\gamma$是控制参数 2. 转弯执行阶段 当无人机达到转弯点时，根据转弯方向执行一次恒定率转弯：\n对于顺时针转弯：\n当右转圆心$c_R$与$C_{p(1)}$圆心重合时，设定$u = +c$ 保持$u = +c$直到航向与下一航点段对齐 对于逆时针转弯：\n当左转圆心$c_L$与$C_{p(1)}$圆心重合时，设定$u = -c$ 保持$u = -c$直到航向与下一航点段对齐 3. 下一直线段跟踪阶段 当转弯完成后，无人机开始跟踪下一个航点段$w_i w_{i+1}$，控制策略回到第1阶段。\n转弯点检测条件 转弯点的检测是基于当前位置的转弯圆心与$C_{p(1)}$的位置关系：\n对于顺时针转弯，当$\\|c_R - p(1)\\| = 0$时开始转弯 对于逆时针转弯，当$\\|c_L - p(1)\\| = 0$时开始转弯 其中$c_R$和$c_L$分别是： $$c_R(t) = \\hat{z}(t) + R\\begin{pmatrix} -\\sin(\\hat{\\psi}(t)) \\\\ \\cos(\\hat{\\psi}(t)) \\end{pmatrix}$$ $$c_L(t) = \\hat{z}(t) + R\\begin{pmatrix} \\sin(\\hat{\\psi}(t)) \\\\ -\\cos(\\hat{\\psi}(t)) \\end{pmatrix}$$转弯完成检测条件 转弯完成的检测基于航向与目标航点段的对齐：\n转弯完成条件：$|\\hat{\\psi} - \\psi_{i+1}^d| \u003c \\epsilon$ 其中$\\psi_{i+1}^d = \\text{atan2}(q_{i+1,y}, q_{i+1,x})$是下一航点段的期望航向 $\\epsilon$是一个小的容许误差 最小时间特性 κ=1时的轨迹具有时间最优性，这可以通过庞特里亚金最小原理证明。对于给定的最大转向率约束，这种单次转弯的轨迹能以最短的时间从一个航点段过渡到下一个航点段。\n这种轨迹的最优性表现为：控制输入$u$在整个转弯过程中总是取极值（$+c$或$-c$），形成所谓的\"bang-bang\"控制策略，这正是时间最优控制的特点。\nACKNOWLEDGMENTS This work was partially funded by AFOSR grants F49620-01-1-0091 and F49620-02-C-0094, and by DARPA grant NBCH1020013.\nREFERENCES [1] M. Pachter and P. R. Chandler, “Challenges of autonomous control,” IEEE Control Systems Magazine, vol. 18, no. 4, pp. 92-97, August $1998 .$\n[2] “http://www.fas.org/irp/program/collect/uav.htm,\"\n[3] “http://www.dtic.mil/jv2020/,\" .\n[4] P.R. Chandler, S. Rasumussen, and M. Pachter, “UAV cooperative path planning,” in Proceedings of the AIAA Guidance, Navigation, and Control Conference, Denver, CO, August 2000, AIAA Paper No. AIAA-2000-4370.\n[5] Timothy McLain and Randal Beard, “Cooperative rendezvous of multiple unmanned air vehicles,” in Proceedings of the AIAA Guidance, Navigation and Control Conference, Denver, CO, August 2000, Paper no. AIAA-2000-4369.\n[6] Timothy W. McLain, Phillip R. Chandler, Steven Rasmussen, and Meir Pachter, “Cooperative control of UAV rendezvous,” in Proceedings of the American Control Conference, Arlington, VA, June 2001, pp. 2309-2314.\n[7] Timothy W. McLain and Randal W. Beard, “Coordination variables, coordination functions, and cooperative timing missions,” AIAA Journal of Guidance, Control and Dynamics, (in review).\n[8] Randal W. Beard, Timothy W. McLain, and Michael Goodrich, “Coordinated target assignment and intercept for unmanned air vehicles,” in Proceedings of the IEEE International Conference on Robotics and Automation, Washington DC, May 2002, pp. 2581-2586.\n[9] Phillip R. Chandler, Meir Pachter, Dharba Swaroop, Jeffrey M. Fowler, Jason K. Howlett, Steven Rasmussen, Corey Schumacher, and Kendall Nygard, “Complexity in UAV cooperative control,” in Proceedings of the American Control Conference, Anchorage, AK, May $2002 .$\n[10] L. E. Dubins, “On curves of minimal length with a constraint on average curvature, and with prescribed initial and terminal positions and tangents,” American Journal of Mathematics, vol. 79, pp. 497-516, $1957 .$\n[11] Guang Yang and Vikram Kapila, “Optimal path planning for unmanned air vehicles with kinematic and tactical constraints,” in Proceedings of the IEEE Conference on Decision and Control, Las Vegas, NV, 2002, pp. 1301-1306.\n[12] David Hsu, Robert Kindel, Jean-Claude Latombe, and Stephen Rock, “Randomized kinodynamic motion planning with moving obstacles,” in Algorithmic and Computational Robotics: New Directions, pp. 247-264f. A. K. Peters, $2001 .$\n[13] Emilio Frazzoli, Munther A. Dahleh, and Eric Feron, “Real-time motion planning for agile autonomous vehicles,” in Proceedings of the American Control Conference, Arlington VA, June 2001, pp. 43-49. [14] Emilio Frazzoli, Muther A. Dahleh, and Eric Feron, “Real-time motion planning for agile autonomous vehicles,” Journal of Guidance, Control, and Dynamics, vol. 25, no. 1, pp. 116-129, January-February $2002 .$\n[15] Andrew Ladd and Lydia E. Kavraki, “Generalizing the analysis of PRM,” in Proceedings of the IEEE International Conference on Robotics and Automation, Washington DC, May 2002, pp. 2120-2125.\n[16] Michiel J. Van Nieuwstadt and Richard M. Murray, “Real time trajectory generation for differentially flat systems,” International Journal of Robust and Nonlinear Control, vol. 8, no. 11, pp. 995-1020, $1998 .$\n[17] Florent Lamiraux, Sepanta Sekhavat, and Jean-Paul Laumond, “Motion planning and control for Hilare pulling a trailer,” IEEE Transactions on Robotics and Automation, vol. 15, no. 4, pp. 640-652, August 1999 .\n[18] Nadeem Faiz, Sunil K. Agrawal, and Richard M. Murray, “Trajectory planning of differentially flat systems with dynamics and inequalities,” AIAA Journal of Guidance, Control and Dynamics, vol. 24, no. 2, pp. 219-227, MarchApril $2001 .$\n[19] Ravi K. Prasanth, Jovan D. Boskovic, Sai-Ming Li, and Raman K. Mehra, “Initial study of autonomous trajectory generation for unmanned aerial vehicles,” in Proceedings of the IEEE Conference on Decision and Control, Orlando, FL, December 2001, pp. 640-645.\n[20] Stephen T. Pledgie, Yongxing Hao, Armando M. Ferreira, Sunil K. Agrawal, and Robert Murphey, “Groups of unmanned vehicles: Differential flatness, trajectory planning, and control,” in Proceedings of the IEEE International Conference on Robotics and Automation, Washington DC, May 2002, pp. 3461-3466.\n[21] Oleg A. Yakimenko, “Direct method for rapid prototyping of near-optimal aircraft trajectories,” AIAA Journal of Guidance, Control and Dynamics, vol. 23, no. 5, pp. 865-875, September-October $2000 .$\n[22] Kevin B. Judd and Timothy W. McLain, “Spline based path planning for unmanned air vehicles,” in Proceedings of the AIAA Guidance, Navigation and Control Conference, Montreal, CA, August 2001, AIAA, pp. Paper no. AIAA2001-4238.\n[23] Shan Sun, Magnus B. Egerstedt, and Clyde F. Martin, “Control theoretic smoothing splines,” IEEE Transactions on Automatic Control, vol. 45, no. 12, pp. 2271-2279, December 2000 .\n[24] Devin J. Balkcom and Matthew T. Mason, “Extremal trajectories for bounded velocity differential drive robots,” in Proceedings of the IEEE International Conference on Robotics and Automation, San Francisco, April 2000, pp. 2479-2484\n[25] Jong-Suk Choi and Byung Kook Kim, “Near-time-optimal trajectory planning for wheeled mobile robots with translational and rotational sections,” IEEE Transactions on Robotics and Automation, vol. 17, no. 1, pp. 85-90, February $2001 .$\n[26] Thomas L. Vincent and Walter J. Grantham, Nonlinear and Optimal Control Systems, John Wiley \u0026 Sons, Inc., 1997.\n[27] Andrew W. Proud, Meir Pachter, and John J. D’Azzo, “Close formation flight control,” in Proceedings of the AIAA Guidance, Navigation, and Control Conference and Exhibit, Portland, OR, August 1999, American Institute of Aeronautics and Astronautics, pp. 1231-1246, Paper no. AIAA-99-4207.\n[28] Richard L. Burden and J. Douglas Faires, Numerical Analysis, PWS-KENT Publishing Company, Boston, fourth edition edition, 1988 .\n[29] Patrick M. Fitzpatrick, Advanced Calculus: A Course in Mathematical Analysis, PWS Publishing Company, 20 Park Plaza, Boston, MA, 02116-4324, $1996 .$\n[30] Todd K. Moon and Wynn C. Stirling, Mathematical Methods and Algorithms, Prentice Hall, Englewood Cliffs, New Jersey, $2000 .$\n4, $\\mathrm{PP} .520-527,1960$.\n[32] Hassan K. Khalil, Nonlinear Systems, Prentice Hall, Upper Saddle River, NJ, 2nd edition, 1996.",
    "description": "一种实时、可行的轨迹生成算法，用于无人机通过一系列航路点飞行。 特别地，算法可配置为动态可行轨迹与直线航路点路径具有相同的路径长度。 该文还详细描述了与算法相关的实现问题。",
    "tags": [],
    "title": "无人机实时动态轨迹平滑",
    "uri": "/uas/trajectory_planning/kappa-trajectories/real-time_dynamic_trajectory_smoothing_for_unmanne-ch/index.html"
  },
  {
    "breadcrumb": "FlitSoft Docs \u003e  UAS \u003e  Trajectory Planning \u003e  kappa-trajectories",
    "content": "摘要 本报告针对DTS（Dynamically Time‐Scaled）算法生成的轨迹，提出一种基于二分查找的数值方法，用以求解参数 $\\kappa^*$，从而使得生成的 $\\kappa$-轨迹路径长度与原始航路点轨迹 $\\mathcal{P}$ 的路径长度完全一致。该方法依托于路径长度差函数 $\\Lambda(\\kappa)$ 在区间 $[0,1]$ 上的单调性和端点符号异号性质，通过迭代逼近 $\\Lambda(\\kappa)=0$ 的唯一解，实现了时间关键任务下轨迹光滑与时序约束的双重满足。\nC++实现代码\n1. 问题描述 原始路径 $\\mathcal{P} = \\overline{\\mathbf{w}_{i-1}\\mathbf{w}_i\\mathbf{w}_{i+1}}$ 的路径长度\n$$ L_{\\rm orig} = \\|\\mathbf{w}_i - \\mathbf{w}_{i-1}\\| + \\|\\mathbf{w}_{i+1} - \\mathbf{w}_i\\|. $$ $\\kappa$-轨迹 在参数 $\\kappa\\in[0,1]$ 下生成对应的平滑转弯路径，其路径长度可表示为\n$$ L(\\kappa) = L_{\\rm orig} + \\Lambda(\\kappa), $$其中 $\\Lambda(\\kappa)$ 如式(42)所定义。 目标：求解唯一的 $\\kappa^*\\in[0,1]$，使得\n$$ L(\\kappa^*) = L_{\\rm orig} \\quad\\Longleftrightarrow\\quad \\Lambda(\\kappa^*) = 0. $$ 2. 数学背景 路径长度差函数 $\\Lambda(\\kappa)$ 引理6给出 $\\kappa$-轨迹的路径长度差解析表达式：\n$$ \\begin{aligned} \\Lambda(\\kappa) \u0026=2R\\Bigl(\\tfrac{\\pi-\\beta}{2} +2\\cos^{-1}\\bigl(\\Xi(\\kappa,\\beta)\\bigr) -\\Xi(\\kappa,\\beta)\\sqrt{\\tfrac{1}{\\Xi(\\kappa,\\beta)^2}-1}\\\\ \u0026\\quad\\;-\\,(1-\\kappa)\\cos\\tfrac{\\beta}{2} -\\kappa\\cot\\tfrac{\\beta}{2}\\Bigr), \\end{aligned} $$其中 $\\beta = \\cos^{-1}\\bigl(\\hat{\\mathbf{t}}_{i,i+1}^T\\hat{\\mathbf{t}}_{i-1,i}\\bigr)$，\n$\\Xi(\\kappa,\\beta)=\\tfrac{(1+\\kappa)+(1-\\kappa)\\sin(\\beta/2)}{2}$，\n$R=\\hat v/c$。 单调性和端点条件\n$\\Lambda(\\kappa)$ 关于 $\\kappa$ 递减，且 $\\Lambda(0)\u003e0$, $\\Lambda(1)\u003c0$（引理7） 。 因此，存在且仅存在唯一 $\\kappa^*\\in(0,1)$ 使得 $\\Lambda(\\kappa^*)=0$（定理8）。 3. 算法设计 3.1 输入与输出 输入\n三点坐标 $\\mathbf{w}_{i-1},\\mathbf{w}_i,\\mathbf{w}_{i+1}$。 预设速度 $\\hat v$ 与转向速率 $c$，计算半径 $R=\\hat v/c$。 目标精度 $\\varepsilon$（如 $10^{-6}$）。 输出\n唯一的 $\\kappa^*\\in[0,1]$，满足 $\\Lambda(\\kappa^*)=0$。 3.2 路径差函数计算 计算夹角 $\\beta$。 对给定 $\\kappa$，按引理6公式计算 $\\Lambda(\\kappa)$。 注意数值鲁棒性，避免在 $\\Xi\\approx0$ 或 $\\Xi\\approx1$ 时出现除零或浮点不稳定。 3.3 二分查找流程 设定区间 $[a,b]=[0,1]$。\n计算 $f(a)=\\Lambda(a)$, $f(b)=\\Lambda(b)$，验端点符号异号。\n重复直到 $|b-a|\u003c\\varepsilon$：\n令 $m=(a+b)/2$，计算 $f(m)=\\Lambda(m)$。 若 $f(m)\u003e0$，则令 $a\\leftarrow m$；否则令 $b\\leftarrow m$。 返回 $\\kappa^*=(a+b)/2$。\n3.4 终止条件与复杂度 终止条件：区间长度 $|b-a|\u003c\\varepsilon$。 迭代次数：$N=O(\\log_2(1/\\varepsilon))$。 每次迭代成本：一次 $\\Lambda$ 评估，涉及若干三角函数与平方根。总体时间复杂度 $O(\\log(1/\\varepsilon))$。 4. 伪代码 function FindKappaStar(w_prev, w_i, w_next, v_hat, c, eps): R ← v_hat / c compute β = arccos(dot(normalize(w_next - w_i), normalize(w_i - w_prev))) define Lambda(κ): Xi = ((1+κ) + (1-κ)*sin(β/2)) / 2 return 2*R*( (π-β)/2 + 2*arccos(Xi) - Xi*sqrt(1/Xi^2 - 1) - (1-κ)*cos(β/2) - κ*cot(β/2) ) a ← 0; b ← 1 f_a ← Lambda(a); f_b ← Lambda(b) assert f_a \u003e 0 and f_b \u003c 0 while (b - a) \u003e eps: m ← (a + b) / 2 f_m ← Lambda(m) if f_m \u003e 0: a ← m else: b ← m return (a + b) / 2 5. 实现注意事项 数值稳定性：\n对 $\\Xi$ 接近 0 或 1 时，使用 max(min(Xi,1-δ), δ) 限幅。 三角函数参数应以弧度制调用。 DTS 系统集成：\n在轨迹生成前调用 FindKappaStar，获取 $\\kappa^*$。 将 $\\kappa^*$ 传入 DTS 控制律，生成平滑转弯命令序列。 性能优化：\n对于多段路径，可复用相同 $\\beta$ 及 $R$ 计算。 可并行计算各段 $\\kappa^*$。 6. 小结 报告提出的基于二分查找的算法，能高效、准确地求解使 DTS 生成轨迹与原始航路点轨迹等长的参数 $\\kappa^*$。该方法简单易实现，时间复杂度 $O(\\log(1/\\varepsilon))$，适用于实时轨迹规划系统。",
    "description": "一种基于二分查找的数值方法，用以求解参数 κ，从而使得生成的 κ-轨迹路径长度与原始航路点路径长度完全一致。",
    "tags": [],
    "title": "等长轨迹κ求解算法设计",
    "uri": "/uas/trajectory_planning/kappa-trajectories/%E7%AD%89%E9%95%BF%E8%BD%A8%E8%BF%B9kappa%E6%B1%82%E8%A7%A3%E7%AE%97%E6%B3%95/index.html"
  },
  {
    "breadcrumb": "FlitSoft Docs \u003e  UAS \u003e  Aerodynamics",
    "content": "用户手册 https://jsbsim-team.github.io/jsbsim-reference-manual/\n本部分解释了如何使用 JSBSim 进行模拟运行、创建飞行器模型、编写脚本，以及如何执行其他不涉及对 JSBSim 程序代码进行更改的任务。\nJSBSim 软件提供了许多现成可用的飞行器模型示例。一旦用户熟悉了进行模拟所需的所有步骤和设置，可能会希望查看这些示例，并详细了解更有经验的 JSBSim 用户是如何实现某些特定模型的。\n该项目和发行版中包含的飞行器模型不包含任何专有、敏感或机密数据。所有数据均来源于教材（如 Stevens 和 Lewis 的《Aircraft Control and Simulation》以及 Sutton 的《Rocket Propulsion Elements》）、公开的技术报告（见：NASA技术报告网站和AIAA网站），或其他公开数据（如FAA网站）。JSBSim 发行版中包含的飞行器模型，以及与现有商业或军事飞行器名称相对应的模型，都是基于公开信息制作的近似模型，仅供教育或娱乐使用。\n概述 什么是 JSBSim？ 从应用程序编程的角度来看，JSBSim 是一个主要用 C++ 编程语言编写的程序代码集合（其中包括一些 C 语言例程）。组成 JSBSim 的一些 C++ 类用于建模物理实体，如大气、飞行控制系统或引擎。某些类封装了诸如运动方程、矩阵、四元数或向量等概念或数学构造。一些类管理其他对象的集合。总的来说，JSBSim 应用程序接受控制输入，计算并汇总来自这些控制输入和环境的力矩，并在离散时间步中推进飞行器的状态（速度、方位、位置等）。\nJSBSim 已经在各种平台上构建和运行，如 Windows 或 Linux 系统上的 PC、苹果 Macintosh 以及硅谷图形公司的 IRIX 操作系统。自由的 GNU g++ 编译器可以轻松编译 JSBSim，其他如 Borland 和 Microsoft 的编译器也能很好地工作。更多信息请参见《程序员指南》。\n从最终用户的角度来看（例如进行研究的学生），JSBSim 可以被视为一个“黑箱”，它通过 XML 格式的输入文件进行提供。这些 XML 文件包含了航天器、引擎、脚本等的描述。当这些文件被加载到 JSBSim 中时，它们指示 JSBSim 模拟该飞行器的飞行情况，作为更大仿真框架的一部分（例如 FlightGear 或 OpenEaagles），或者在批处理模式下以比实际时间更快的速度运行。每次运行 JSBSim 都会生成包含模拟飞行器性能和动态数据的文件。\n从软件集成者的角度来看（例如将 JSBSim 集成到更大仿真框架中的人员），JSBSim 是一个可以被调用的库，提供输入（如飞行员的控制输入），并返回输出（描述飞行器在某一时刻的位置）。\n它适合谁，如何使用？ JSBSim 飞行动力学模型（FDM）软件库旨在易于理解，特别适合高年级航空航天工程学生。由于其配置简便，它也已被业界专业人士用于多种场景。它已经被集成到更大、更全面的飞行模拟应用程序和架构中（例如 FlightGear、Outerra 和 OpenEaagles），并且已被用作工业和学术界的批量模拟工具。\n使用示例 Aerocross Echo Hawk JSBSim 被用于 Aerocross Echo Hawk UAV 的硬件在环（HITL）测试。编写了自定义代码以通过 RS-232/422/485、模拟模拟输入/输出、离散输入/输出和套接字与飞行硬件（基于 PC/104 的系统）接口，但核心仿真代码仍为未经修改的 JSBSim 代码。飞行员/操作员培训也依赖于 JSBSim 作为六自由度（6-DoF）仿真模型。\nDuPont Aerospace 公司 JSBSim 曾在 DuPont Aerospace 公司与 Matlab 一起用于实时 HITL 仿真和飞行员/操作员培训。DuPont Aerospace 公司的 Rex duPont 解释了该项目：\n在 1990 年代，DuPont Aerospace 公司正在研发一种飞机，测试其垂直起降风扇喷气运输机的概念。我们开发了一个基于 Microsoft Windows 的飞行模拟器，用于测试拟议飞行器的飞行特性。然而，我们需要一个可以在实时中使用的仿真系统，以便能够在操作飞行执行器的全尺寸模型上测试飞行特性。我们最终选择了 FlightGear 模拟器，并使用了 JSBSim 飞行动力学模型，因为我们可以获得完整的代码，它的组织方式很好，使我们能够创建新的子程序来匹配我们的飞机，同时也有可用的支持。\n我们同时开发了一个 Matlab 模拟器，用于开发更有效的自动驾驶仪引导系统，因为我们的主要任务是仅使用自动驾驶仪起飞并保持悬停 30 秒。这将明确显示控制系统是否足够强大。因此，我们在 Matlab 模拟器和 JSBSim 派生模拟器的每个相关模块中内建了一系列单元测试，提供一系列输入以交叉验证，确保两个系统同步。\n我们使用 JSBSim 系统测试了一些 Matlab 模型难以测试的动态问题，尤其是涉及飞行员感受和过渡至悬停过程中的可控性问题。这些问题在纯控制系统领域（如 Matlab 中）很难评估，因为过渡过程中，基础的力结构随着空气动力学力量的增强和纯推力控制力的减少而不断变化。\n我们还对气动仿真中关键参数的估算误差敏感度进行了参数研究。这些研究通过让飞行员执行一系列标准机动来完成，目的是测试当一个或多个参数降低 50% 时飞机的响应（飞行员不知道是哪一个参数被改变）。\n我们也对伺服带宽进行了模拟，测试飞行特性在何种情况下变得不可接受。这有助于定义所需的特性。飞行员对控制系统的需求几乎总是与理论上最佳的参数不同。\n此外，我们开发了多种 HUD 显示系统，以便在悬停过程中操作时提供帮助，在这种情况下需要非常精确的地面速度控制。最终我们实现了一个系统，允许一个甚至没有飞行员执照的年轻工程师起飞并保持悬停在恒定高度 30 秒以上，偏差不超过 1 英尺。\n我们最终于 2007 年 9 月 30 日成功实现了自动驾驶仪控制的起飞和悬停，两次飞行的持续时间大约为 45 秒。两次飞行都因为其中一台发动机燃料耗尽而终止，而不是因为控制问题。\nMITRE 空中交通研究 JSBSim 在 MITRE 用于开发一个 6-DoF 模拟系统，模拟飞行管理系统（FMS）在连续下降进场（CDA）和优化下降进场（OPD）过程中的行为。MITRE 使用了 JSBSim 的独立版本（用于批量运行）和与 FlightGear 集成的版本。此外，还创建了附加的控制系统组件，以支持特定的横向和纵向导航研究。\nJSBSim 还被扩展为通过套接字向 MITRE 的其他应用程序输出消息，该应用程序提供了类似于空中交通管制员所看到的视图。\n美国交通部 在与美国交通部合作的项目中，开发了一个使用 JSBSim 作为六自由度（6-DoF）仿真核心的人类飞行员数学模型。\n意大利那不勒斯大学 Federico II 那不勒斯大学拥有一个基于 FlightGear 和 JSBSim 的运动座舱飞行/驾驶模拟器。该模拟器具有三屏视觉显示，提供 190 度的视场。JSBSim 源代码经过修改，提供了力反馈能力。\nJSBSim 在那不勒斯大学被用作支持近地飞行操作风险评估的工具。考虑到碰撞风险研究中的实际问题之一是评估在机场区域内新增障碍物（如建筑物或雷达塔）对飞行操作的威胁。风险评估是通过改变障碍物的几何形状和位置来进行的。评估程序基于对飞机轨迹与“正常”飞行路径的统计偏差分析，评估某一轨迹穿越给定的“保护”区域的概率。为此框架，操作场景被正式描述和实现，以便运行多个计算机模拟。\n弗劳恩霍夫风能系统研究所 在与意大利那不勒斯大学 Federico II 合作的研究中，弗劳恩霍夫风能系统研究所（IWES）的研究人员研究了轻型飞机飞行通过或接近风力涡轮机尾流时的尾流相遇问题。\n为了这项研究，开发了一个软件应用程序框架，用于生成和控制在指定风场和湍流场下的飞行仿真场景。JSBSim 被用作该框架中的飞行动力学模型，并通过调整其自动驾驶仪系统来模拟飞行员在导航过程中的真实行为。风力涡轮机尾流中的风分布是通过 OpenFOAM 计算的，并作为输入提供给动态模型。\n南非试飞学院（TFASA） 南非试飞学院使用 JSBSim 作为地面可变稳定系统（VSS）模拟器的基础，用于飞行员训练。基础飞行器模型的空气动力学稳定性和控制系数被修改，以展示它们对飞行任务的影响。还对执行器进行了建模，以展示它们在不同延迟、滞后和速率限制条件下对飞行员输入输出（PIO）的潜在影响。\n模拟的飞行器包括固定翼飞机和旋翼飞机，并配有可编程的力反馈控制装置，用于展示飞行控制机械特性（FCMC）的影响。\nJSBSim 与 Prepar3D 集成，利用 Prepar3D 的外部视觉系统，渲染到三块大型 LCD 屏幕或通过三投影仪系统呈现 180 度视图。\n仿真 虽然 JSBSim 用户不需要了解飞行模拟器操作的所有细节，但理解其基本工作原理是有帮助的。以下是一些重要的概念。\n参考坐标系用于描述飞行器模型中各种项目的位置和布局。 在定义飞行器模型时，单位的指定具有灵活性——支持英制单位和公制单位。 使用“属性”使得 JSBSim 成为一个通用模拟器，提供了一种通过参数（或变量）接口与各种系统进行交互的方法。属性广泛用于描述飞机和发动机特性配置文件中。 数学在飞行物理建模中发挥着重要作用。JSBSim 使用数据表格，因为飞行动力学特性通常存储在表格中。JSBSim 还允许设置任意代数函数，从而广泛自由地描述气动和飞行控制特性。 用户至少需要具备基本的飞行器飞行力学知识，了解飞机飞行时的常规力和力矩。 理解飞行控制和系统建模方法是成功和有效仿真的关键。 参考坐标系 在描述对象的位置、飞机的姿态和方向，或为给定的飞行条件指定输入时，需要理解一些基本的参考坐标系。以下是对这些坐标系的简要介绍：\n结构坐标系，或“构造坐标系” 该坐标系是常见的制造商参考坐标系，用于定义飞机上的各个点，例如重心位置、所有轮子的位置信息、飞行员视点、点质量、推进器等。JSBSim 飞机配置文件中的项目就是使用此坐标系来定位的。\n在结构坐标系中，X 轴沿着机身长度方向延伸，指向飞机尾部，Y 轴指向飞机右翼，Z 轴则朝上。通常，这个坐标系的原点 $O_C$ 位于飞机前部（例如机头尖端、单发动机飞机的机头防火墙处，或者位于机头前方的一段距离）。这个坐标系通常被命名为 $\\mathcal{F}_{\\mathrm{C}}=\\left\\{O_{\\mathrm{C}}, x_{\\mathrm{C}}, y_{\\mathrm{C}}, z_{\\mathrm{C}}\\right\\}$.。\n结构（或构造）坐标系的飞机参考坐标系，原点 $O_C$。除了结构坐标系轴 $x_C$, $y_C$, zC 外，还展示了标准机体坐标系轴 $x_B$, $y_B$, $z_B$，它们的原点在重心 G 处。飞行员的视点位于 PEP。\nX 轴通常与机身中心线重合，并且通常与推力轴重合（例如在单发动机螺旋桨飞机中，它通过螺旋桨轴心）。沿 $x_C$ 轴的位置称为站位，沿 zC 轴的位置称为水线位置，沿 $y_C$ 轴的位置称为尾线位置。\n这是从 3D 建模软件 Blender 中截取的屏幕截图，展示了 Cessna 172 的模型及其结构坐标系 $\\mathcal{F}_{\\mathrm{C}}=\\left\\{O_{\\mathrm{C}}, x_{\\mathrm{C}}, y_{\\mathrm{C}}, z_{\\mathrm{C}}\\right\\}$。在这个例子中，原点 $O_C$ 位于驾驶舱内，靠近仪表盘。\n注意，JSBSim 模拟的飞机的原点可以位于任意位置，因为 JSBSim 内部仅使用重心（CG）与各个物体之间的相对距离——而不是物体的绝对位置。\n在结构坐标系中确定的重心位置（CG）为点 G。\n根据结构坐标系位置定义的地面接触点。\n结构坐标系中的两个关键点位置 $P_{\\mathrm{ARP}}$ 和 $P_{\\mathrm{CG}, \\mathrm{EW}}$ ，分别为气动力矩的极点和空重 CG（空机重心）。机翼根部的形状和弦长也被勾画出来。\n除了 $P_{\\mathrm{CG}, \\mathrm{EW}}$，还展示了两个重要的位置，$P_{\\text {Pilot }}$ 和 $P_{\\text {Right Pass }}$ ，分别代表飞行员和右侧乘客的质量集中点。\n机体坐标系 在 JSBSim 中，机体坐标系类似于结构坐标系，但沿 $y_C$ 轴旋转 180 度，原点与重心（CG）重合。通常，机体坐标系是通过已知飞机重心 G 位置和纵向结构轴 $x_C$ 方向来定义的。$x_B$ 轴应选择与 $x_C$ 轴平行，且从 G 指向机头的正方向。\n机体轴坐标系通常命名为$\\mathcal{F}_{\\mathrm{B}}=\\left\\{G, x_{\\mathrm{B}}, y_{\\mathrm{B}}, z_{\\mathrm{B}}\\right\\}$。$x_B$ 轴称为滚转轴，指向前方，$y_B$ 轴称为俯仰轴，指向右翼，$z_B$ 轴称为偏航轴，指向飞机腹部。\n标准的飞机机体轴坐标系，原点在重心 G 处。\n在机体坐标系中，飞机的力和力矩被相加，结果加速度被积分以得到速度。\n稳定坐标系，或“气动坐标系” 这个坐标系是根据相对风矢量相对于机体的瞬时方向来定义的。如果为了简化假设空气相对于地球静止（无风），且 $\\boldsymbol{V}$ 是飞机质心相对于地球固定观察者的速度矢量（也称为 $\\boldsymbol{V}_{\\mathrm{CM} / \\mathrm{E}}$，以强调相对运动），那么 $-\\boldsymbol{V}$ 就是相对风速，$V=\\|V\\|$是空速。\n该坐标系命名为 $\\mathcal{F}_{\\mathrm{A}}=\\left\\{G, x_{\\mathrm{A}}, y_{\\mathrm{A}}, z_{\\mathrm{A}}\\right\\}$，其中轴 $x_{\\mathrm{A}}$ 指向相对风矢量投影到飞机对称平面 $x_{\\mathrm{B}} z_{\\mathrm{B}}$ 上的方向。轴 $y_{\\mathrm{A}}$ 仍然指向右翼，并与机体轴 $y_{\\mathrm{B}}$ 重合，轴 $z_{\\mathrm{A}}$ 完成右手坐标系。\n气动坐标系，定义了气动角度 $\\alpha_{\\mathrm{B}}$ 和 $\\beta$.\n这两个轴 $x_{\\mathrm{A}}$ 和 $z_{\\mathrm{A}}$ 根据定义属于飞机的对称面，但它们在飞行过程中可能会旋转，因为相对风速矢量 $V$ 相对于飞行器的方向可能会发生变化。上图展示了如何构建气动坐标系。两个轴 $x_{\\mathrm{A}}$ 和 $x_{\\mathrm{B}}$ 之间的夹角是飞机的迎角 $\\alpha_{\\mathrm{B}}$。相对风的瞬时方向 $\\boldsymbol{V}$ 与其在平面 $x_{\\mathrm{B}} z_{\\mathrm{B}}$ 上的投影之间形成的夹角是侧滑角 $\\beta$。\n这个坐标系，在一些手册中被称为稳定坐标系，在此也称为“气动坐标系”，因为瞬时气动合力 $\\mathcal{F}_{\\mathrm{A}}$ 在 $z_{\\mathrm{A}}$ 轴上的投影 $Z_{\\mathrm{A}}$ 定义了气动升力。具体来说，升力 $L$ 是这样定义的：$-L$ 是气动合力 $\\mathcal{F}_{\\mathrm{A}}$ 沿 $z_{\\mathrm{A}}$ 轴的分量，即 $Z_{\\mathrm{A}}=-L$。\n为了更好地理解上述描述，考虑一个在飞行力学中常见的典型动作：零侧滑（或“协调”）、保持恒定高度的匀速转弯。在这种情况下，机翼会倾斜，升力也会倾斜。在这种转弯中，气动合力 $\\mathcal{F}_{\\mathrm{A}}$ 是倾斜的，而 $x_{\\mathrm{A}}$ 轴保持水平。一般来说，升力作为一个矢量总是定义在飞机的对称面内。\n在恒定高度的匀速协调转弯中，倾斜升力的情况。倾斜角 $\\phi_{\\mathrm{W}}$ 是绕相对风速矢量的旋转。当速度矢量与北方对齐时，运动被定格在时间上。协调转弯意味着 $\\beta=0$，恒定高度意味着 $x_{\\mathrm{A}}$ 轴保持水平。\n备注 —— 在动态稳定性研究中，“稳定坐标系”与上述的气动坐标系略有不同：飞机飞行力学和稳定性约定中的稳定坐标系不过是一个特定的机体固定坐标系，定义是基于初始的对称、稳定、机翼水平、恒定高度的飞行状态。该状态给出了 $x_S$ 的方向（在该特定飞行姿态下与 $x_A$ 重合）。因此，在动态稳定性研究中，稳定坐标系与气动坐标系不同，是固定在飞行器上的。\n在 JSBSim 中，稳定坐标系 $\\mathcal{F}_{\\mathrm{S}}=\\left\\{G, x_{\\mathrm{S}}, y_{\\mathrm{S}}, z_{\\mathrm{S}}\\right\\}$ 代表了气动坐标系。\n地心惯性坐标系（ECI）和地心固定坐标系（ECEF） 地心惯性坐标系（或简称“惯性坐标系”）$\\mathcal{F}_{\\mathrm{ECI}}=\\left\\{O_{\\mathrm{ECI}}, x_{\\mathrm{ECI}}, y_{\\mathrm{ECI}}, z_{\\mathrm{ECI}}\\right\\}$固定，其原点位于地球中心。其笛卡尔坐标轴相对于恒星保持固定，为飞机（或航天器）运动方程提供最简洁的参考坐标系。正 $z_{\\mathrm{ECI}}$ 轴穿过地球的地理北极。$x_{\\mathrm{ECI}}$ 和 $y_{\\mathrm{ECI}}$ 轴位于赤道平面内。$x_{\\mathrm{ECI}}$ 轴始终与从太阳质心到地球在春分时的轨道位置的连线平行。下图展示了 ECI 系统。\n地心惯性（ECI）坐标系和地心固定（ECEF）坐标系。\n地心地固参考系（ECEF）的坐标轴，如 $x_{\\mathrm{ECEF}}$、$y_{\\mathrm{ECEF}}$ 和 $z_{\\mathrm{ECEF}}$，也如上图所示。ECEF 坐标轴相对于地球保持固定。这个笛卡尔系统的原点 $O_{\\mathrm{ECEF}}$，与惯性坐标系一样，位于地球的质心。$z_{\\mathrm{ECEF}}$ 轴也沿着地球的自转轴，并与 $z_{\\mathrm{ECI}}$ 轴重合。$x_{\\mathrm{ECEF}}$ 和 $y_{\\mathrm{ECEF}}$ 轴都位于赤道平面内，且正 $x_{\\mathrm{ECEF}}$ 轴通过本初子午线（格林威治子午线）。ECEF 坐标系绕惯性坐标系的 $z_{\\mathrm{ECI}}$ 轴以角速度 $\\omega_{\\mathrm{E}}$ 逆时针旋转。地球的角速度 $\\omega_{\\mathrm{E}}$ 近似等于 $2 \\pi / 24$ 弧度/小时。\n北向切平面坐标系 当假设地球表面有数学表示（如椭球体或近似球体）时，可以定义一个切平面坐标系。选取与地表某一点 $O_{\\mathrm{E}}$ 相切的平面作为参考。一个叫做“北向切平面坐标系”的地理坐标系 $\\mathcal{F}_{\\mathrm{E}}=\\left\\{O_{\\mathrm{E}}, x_{\\mathrm{E}}, y_{\\mathrm{E}}, z_{\\mathrm{E}}\\right\\}$ 具有固定原点 $O_{\\mathrm{E}}$，其平面 $x_{\\mathrm{E}} y_{\\mathrm{E}}$ 与切平面重合。轴 $x_{\\mathrm{E}}$ 指向地理北方，轴 $y_{\\mathrm{E}}$ 指向东方，最后，轴 $z_{\\mathrm{E}}$ 指向地面，平行于椭球体的法线（如果使用近似球体代替椭球体，则该轴指向地球中心）。因此，坐标系 $\\mathcal{F}_{\\mathrm{E}}$ 也被称为切平面 NED 坐标系（North-East-Down）。\n地心固定（ECEF）坐标系、地理坐标、切平面坐标系和局部垂直坐标系。\n局部垂直局部水平坐标系，或局部 NED 坐标系 局部垂直坐标系$\\mathcal{F}_{\\mathrm{V}}=\\left\\{G, x_{\\mathrm{V}}, y_{\\mathrm{V}}, z_{\\mathrm{V}}\\right\\}$ 与飞机在空间中的朝向无关，而仅由其重心相对于某个便捷的地球固定观察者的位置定义。如果 $G_{\\mathrm{GT}}$ 是重心在地面上的投影（即“地面跟踪”），则坐标平面 $x_{\\mathrm{V}} y_{\\mathrm{V}}$ 平行于在 $G_{\\mathrm{GT}}$ 处与地球表面局部切平面的平面——即平面 $x_{\\mathrm{E}} y_{\\mathrm{E}}$，其中 $O_{\\mathrm{E}} \\equiv G_{\\mathrm{GT}}$。然后，轴 $x_{\\mathrm{V}}$ 指向地理北方，轴 $y_{\\mathrm{V}}$ 指向东，最后，轴 $z_V$ 指向地球中心的下方。因此，坐标系 $\\mathcal{F}_{\\mathrm{V}}$ 也被称为局部NED（载机）坐标系。\n飞机体坐标系和局部垂直坐标系（NED坐标系）。图中还展示了飞机的欧拉角：航向角 $\\psi$（图中为负），俯仰角 $\\theta$，和滚转角 $\\phi$。\nNED惯例确保飞机的重量是一个力，在坐标系 $\\mathcal{F}_{\\mathrm{V}}$ 中的分量为 $(0,0, m g)$，其中 $m$ 是飞机的质量，$g$ 是重力加速度。\n上述图展示了一个包含两个坐标系 $\\mathcal{F}_{\\mathrm{V}}$ 和 $\\mathcal{F}_{\\mathrm{B}}$ 的飞机。定义机体坐标系相对于局部NED坐标系的朝向的欧拉角是飞机的欧拉角。对于大气飞行器，定义欧拉角时使用的旋转序列是“3-2-1”。这定义了相对于固定在地球上的观察者的航向角 $\\psi$、俯仰角 $\\theta$ 和滚转角 $\\phi$。\n飞机的欧拉角旋转序列。坐标系$\\mathcal{F}_{\\mathrm{E}}=\\left\\{O_{\\mathrm{E}}, x_{\\mathrm{E}}, y_{\\mathrm{E}}, z_{\\mathrm{E}}\\right\\}$ 是一个地球固定的 NED 坐标系，原点 $O_{\\mathrm{E}}$ 位于地面某处（或海平面），且平面 $x_{\\mathrm{E}} y_{\\mathrm{E}}$ 与地球表面相切。如果地面跟踪点 $G_{\\mathrm{GT}}$ 离 $O_{\\mathrm{E}}$ 不远，则地球坐标系 $\\mathcal{F}_{\\mathrm{E}}$ 的轴线与局部 NED 坐标系 $\\mathcal{F}_{\\mathrm{V}}=\\left\\{G, x_{\\mathrm{V}}, y_{\\mathrm{V}}, z_{\\mathrm{V}}\\right\\}$的轴线平行。\n风坐标系 除了升力，瞬时气动合力矢量 $\\mathcal{F}_{\\mathrm{A}}$ 在参考系中还有两个分量，其中 $z_{\\mathrm{A}}$ 是第三轴。该参考系称为风参考系 $\\mathcal{F}_{\\mathrm{W}}=\\left\\{G, x_{\\mathrm{W}}, y_{\\mathrm{W}}, z_{\\mathrm{W}}\\right\\}$。\n风参考系的定义是将 $x_W$ 轴沿相对风的方向，并且其正方向与运动方向一致。这意味着 $x_{\\mathrm{W}}$ 与向量 $\\boldsymbol{V}$ 重合。风参考系的第三轴沿升力作用线定义，即 $z_{\\mathrm{W}} \\equiv z_{\\mathrm{A}}$。最后，第二轴 $y_{\\mathrm{W}}$ 被选择以完成右手坐标系。风参考系的第三轴始终处于机体对称面（也叫“参考面”）内。由于飞机的姿态随着相对风 $-\\boldsymbol{V}$ 的变化而变化，所有三个风轴会相对于机体轴旋转。\n力矢量 $\\mathcal{F}_{\\mathrm{A}}$ 沿着 $\\boldsymbol{V}$ 方向的分量 $X_{\\mathrm{W}}$ 定义了气动阻力：气动阻力 $D$ 满足 $X_{\\mathrm{W}}=-D$。在存在非零侧滑角 $\\beta$ 的情况下，气动合力 $\\mathcal{F}_{\\mathrm{A}}$ 会沿横向轴 $y_{\\mathrm{W}}$ 产生第三个非零分量，即侧向力分量 $Y_{\\mathrm{W}}$。\n当侧滑角 $\\beta$ 为零时，风参考系和气动参考系重合。仅在这种情况下，$y_{\\mathrm{W}}$ 与 $y_{\\mathrm{A}}$ 和 $y_{\\mathrm{B}}$ 重合，且垂直于参考面 $x_{\\mathrm{B}} z_{\\mathrm{B}}$。\n下图显示了飞机在平稳空气中的爬升飞行的标准参考系。当围绕 $z_{\\mathrm{W}}$ 轴旋转角度 $-\\beta$ 时，风参考系 $\\mathcal{F}_{\\mathrm{W}}$ 可以与气动参考系 $\\mathcal{F}_{\\mathrm{A}}$ 重合。\n标准参考系和飞机在平稳空气中的爬升飞行。质心速度矢量 $\\boldsymbol{V}$ 与水平面形成飞行路径角 $\\gamma$。标准的三个气动合力分量 $D$、$L$ 和 $Y_{\\mathrm{A}}$ 也已显示。\n因此，风参考系 $\\mathcal{F}_{\\mathrm{W}}$ 可以通过先绕 $z_{\\mathrm{W}}$ 轴旋转角度 $-\\beta$，再绕 $y_{\\mathrm{A}}$ 轴旋转角度 $\\alpha_{\\mathrm{B}}$，与机体参考系 $\\mathcal{F}_{\\mathrm{B}}$ 重合。 $$ \\mathcal{F}_{\\mathrm{W}} \\xrightarrow{-\\beta \\curvearrowright z_{\\mathrm{W}}} \\mathcal{F}_{\\mathrm{A}} \\xrightarrow{\\alpha_{\\mathrm{B}} \\curvearrowright y_{\\mathrm{A}}} \\mathcal{F}_{\\mathrm{B}} \\tag{1} $$气动结果力在机体轴上的分量则表示如下：\n$$ \\left\\{\\begin{array}{c} X_{\\mathrm{B}} \\\\ Y_{\\mathrm{B}} \\\\ Z_{\\mathrm{B}} \\end{array}\\right\\}=\\left[\\begin{array}{ccc} \\cos \\alpha_{\\mathrm{B}} \u0026 0 \u0026 -\\sin \\alpha_{\\mathrm{B}} \\\\ 0 \u0026 1 \u0026 0 \\\\ \\sin \\alpha_{\\mathrm{B}} \u0026 0 \u0026 \\cos \\alpha_{\\mathrm{B}} \\end{array}\\right]\\left[\\begin{array}{ccc} \\cos \\beta \u0026 \\sin (-\\beta) \u0026 0 \\\\ -\\sin (-\\beta) \u0026 \\cos \\beta \u0026 0 \\\\ 0 \u0026 0 \u0026 1 \\end{array}\\right]\\left\\{\\begin{array}{c} -D \\\\ Y_{\\mathrm{W}} \\\\ -L \\end{array}\\right\\} \\tag{2} $$这些表示了气动阻力、侧向力和升力。\n单位 JSBSim 在内部计算中几乎 exclusively 使用英制单位。然而，也可以在配置文件中输入一些参数时使用不同的单位。为了避免混淆，建议总是指定单位。单位使用 unit 属性进行指定。例如，翼展的规格如下所示：\n\u003cwingspan unit=\"FT\"\u003e 35.8 \u003c/wingspan\u003e 上述声明指定了一个 35.8 英尺的翼展。以下声明将翼展指定为米单位，这将导致翼展在读取时转换为 35.8 英尺：\n\u003cwingspan unit=\"M\"\u003e 10.91 \u003c/wingspan\u003e 这两条关于翼展的声明实际上是等效的。\nJSBSim 目前支持以下单位：\n长度\nunit= 单位 FT 英尺 IN 英寸 M 米 KM 千米 面积\nunit= 单位 M2 平方米 FT2 平方英尺 体积\nunit= 单位 FT3 立方英尺 CC 立方厘米 M3 立方米 LTR 升 质量和重量\nunit= 单位 LBS 磅（质量） KG 千克 惯性矩\nunit= 单位 SLUG*FT2 磅*英尺² KG*M2 千克*米² 角度\nunit= 单位 RAD 弧度 DEG 度 弹簧力\nunit= 单位 N/M 牛顿/米 LBS/FT 磅/英尺 阻尼力\nunit= 单位 N/M/SEC 牛顿/(米·秒) LBS/FT/SEC 磅/(英尺·秒) 功率\nunit= 单位 WATTS 瓦特 HP 马力 力\nunit= 单位 LBS 磅 N 牛顿 速度\nunit= 单位 KTS 节 FT/SEC 英尺/秒 M/S 米/秒 扭矩\nunit= 单位 N*M 牛顿·米 FT*LBS 磅·英尺 压力\nunit= 单位 PSF 磅/平方英尺 PSI 磅/平方英寸 ATM 大气压 PA 牛顿/平方米 INHG 英寸汞柱 属性系统 仿真程序需要管理大量的状态信息。对于特别庞大的程序，数据管理任务可能会引发一些问题：\n贡献者越来越难以掌握所需的多个接口，以进行任何有用的程序扩展，因此贡献进展变慢。 运行时的可配置性变得越来越困难，因为不同的模块使用不同的机制（环境变量、自定义规范文件、命令行选项等）。 模块初始化的顺序变得复杂且脆弱，因为一个模块的初始化例程可能需要从未初始化的模块设置或获取状态信息。 通过附加脚本、规范文件等进行扩展的能力仅限于程序提供的状态信息，且非编码开发人员往往要等待较长时间才能获得开发人员添加新变量的支持。 属性管理器系统提供了一个单一的接口，用于选择程序的状态信息，并允许在运行时动态创建新的用户指定的变量。后一种能力对于 JSBSim 控制系统模型尤其重要，因为组成飞机控制律的各个控制系统组件（PID 控制器、开关、加法器、增益等）仅在配置文件中存在。在运行时——在解析组件定义之后——这些组件将被实例化，属性管理器将创建一个属性来存储每个组件的输出值。\n属性本身类似于具有选择性限制可见性（只读或读写）的全局变量，它们被分类到一个层次结构的树形结构中，类似于 Unix 文件系统的结构。属性树的结构包括根节点、子节点（类似子目录）和终端节点（属性）。类似于 Unix 文件系统，属性可以相对于当前节点或根节点进行引用。节点可以像符号链接文件或目录到其他文件或目录一样，附加到其他节点上。属性在整个 JSBSim 和 FlightGear 中用于引用程序代码中的特定参数。属性名称的形式如下：position/h-sl-ft 和 aero/qbar-psf。\n为了说明使用属性和配置文件的强大功能，考虑一下高性能喷气式飞机模型的案例。假设在示例飞机的控制面板上添加了一个新的开关，允许飞行员在飞行控制系统（FCS）中覆盖俯仰限制。对于 FlightGear，仪表面板是在配置文件中定义的，开关也在那里定义以进行视觉显示。该开关定义还会分配一个属性名称。在 JSBSim 飞机规范文件中的飞行控制部分，分配给仪表面板定义中俯仰覆盖开关的相同属性名称可以用于根据开关位置引导控制律通过所需路径。无需修改任何代码。\n特定的仿真参数可以通过属性在 JSBSim 和配置文件规范中进行访问和设置。如前所述，“属性”是我们用来描述可以从配置文件或命令行中访问或设置的参数的术语。\n许多属性是标准属性——即所有飞行器始终存在的属性。气动系数、发动机、推进器以及飞行控制/自动驾驶模型也会具有动态定义的属性。这是因为，直到读取相关的飞行器配置文件后，整个气动系数、发动机等的集合才会被确定。要访问这些参数，必须知道使用的属性命名约定。例如，X-15 模型的飞行控制系统包括以下组件：\n\u003cflight_control name=\"X-15\"\u003e \u003cchannel name=\"Pitch\"\u003e \u003csummer name=\"fcs/pitch-trim-sum\"\u003e \u003cinput\u003e fcs/elevator-cmd-norm \u003c/input\u003e \u003cinput\u003e fcs/pitch-trim-cmd-norm \u003c/input\u003e \u003cclipto\u003e \u003cmin\u003e -1 \u003c/min\u003e \u003cmax\u003e 1 \u003c/max\u003e \u003c/clipto\u003e \u003c/summer\u003e \u003caerosurface_scale name=\"fcs/pitch-command-scale\"\u003e \u003cinput\u003e fcs/pitch-trim-sum \u003c/input\u003e \u003crange\u003e \u003cmin\u003e -50 \u003c/min\u003e \u003cmax\u003e 50 \u003c/max\u003e \u003c/range\u003e \u003c/aerosurface_scale\u003e \u003cpure_gain name=\"fcs/pitch-gain-1\"\u003e \u003cinput\u003e fcs/pitch-command-scale \u003c/input\u003e \u003cgain\u003e -0.36 \u003c/gain\u003e \u003c/pure_gain\u003e \u003c/channel\u003e \u003c/flight_control\u003e 在上面的例子中，第一个组件（fcs/pitch-trim-sum）接收来自两个地方的输入，即已知的静态属性 fcs/elevator-cmd-norm 和 fcs/pitch-trim-cmd-norm。接下来的组件将接收第一个组件的输出作为输入。第二个组件列出的输入属性为 fcs/pitch-trim-sum。继续上述示例，最后一个组件 fcs/pitch-gain-1 接收前一个组件的输出 fcs/pitch-command-scale，该属性名为 fcs/pitch-command-scale。\n因此，现在我们已经可以访问 JSBSim 内部的许多参数，并且我们知道如何组装 JSBSim 中的飞行控制系统（FCS）。在 FCS 中使用的相同组件，也可以用来构建自动驾驶系统或其他系统。\n数学 函数 JSBSim 中的函数规范是一个强大且多功能的资源，允许在 JSBSim 配置文件中定义代数函数。函数的语法在概念上类似于 MathML（数学标记语言，http://www.w3.org/Math/），但它更加简洁和紧凑。\n一个函数定义由一个操作、一个值、一个表格或一个属性（评估为值）组成。当前支持的操作有：\nsum（接受 n 个参数） difference（接受 n 个参数） product（接受 n 个参数） quotient（接受 2 个参数） pow（接受 2 个参数） exp（接受 2 个参数） abs（接受 n 个参数） sin（接受 1 个参数） cos（接受 1 个参数） tan（接受 1 个参数） asin（接受 1 个参数） acos（接受 1 个参数） atan（接受 1 个参数） atan2（接受 2 个参数） min（接受 n 个参数） max（接受 n 个参数） avg（接受 n 个参数） fraction（接受 1 个参数） mod（接受 2 个参数） lt（小于，接受 2 个参数） le（小于等于，接受 2 个参数） gt（大于，接受 2 个参数） ge（大于等于，接受 2 个参数） eq（等于，接受 2 个参数） nq（不等于，接受 2 个参数） and（接受 n 个参数） or（接受 n 个参数） not（接受 1 个参数） if-then（接受 2-3 个参数） switch（接受 2 个或更多参数） random（高斯随机数，无参数） integer（接受 1 个参数） 一个操作在配置文件中的定义示例如下：\n\u003csum\u003e \u003cvalue\u003e 3.14159 \u003c/value\u003e \u003cproperty\u003e velocities/qbar \u003c/property\u003e \u003cproduct\u003e \u003cvalue\u003e 0.125 \u003c/value\u003e \u003cproperty\u003e metrics/wingarea \u003c/property\u003e \u003c/product\u003e \u003c/sum\u003e 在上述例子中，sum 元素包含了其他三个项。它的计算过程可以用代数表达式表示为： $$ 3.14159+\\text { qbar }+(0.125 \\cdot \\text { wingarea }) $$ 一个完整的函数定义（例如在气动部分的配置文件中使用的）包括 function 元素和其他元素。需要注意的是，函数定义中只能有一个非可选（非文档）元素——即一个操作元素。该元素不能包含多个直接子操作、property、table 或 value 元素。几乎总是，函数元素中的第一个操作将是乘积（product）或和（sum）。例如：\n\u003cfunction name=\"aero/moment/roll_moment_due_to_yaw_rate\"\u003e \u003cdescription\u003e Roll moment due to yaw rate \u003c/description\u003e \u003cproduct\u003e \u003cproperty\u003e aero/qbar-area \u003c/property\u003e \u003cproperty\u003e metrics/bw-ft \u003c/property\u003e \u003cproperty\u003e velocities/r-aero-rad_sec \u003c/property\u003e \u003cproperty\u003e aero/bi2vel \u003c/property\u003e \u003ctable\u003e \u003cindependentVar\u003e aero/alpha-rad \u003c/independentVar\u003e \u003ctableData\u003e 0.000 0.08 0.094 0.19 ... ... \u003c/tableData\u003e \u003c/table\u003e \u003c/product\u003e \u003c/function\u003e 在函数定义中，最“底层”的元素总是一个值或一个属性，它本身不能包含其他元素。如所示，操作可以包含值、属性、表格或其他操作。\n在 JSBSim 中，某些操作仅接受一个参数。然而，这个参数可以是一个操作（例如 sum），而该操作可以包含其他项。需要记住的一点是，任何此类包含的操作都将计算出一个单一的值 —— 这正是三角函数所要求的（除了 atan2，它接受两个参数）。\n最后，在函数定义中，有一些简写别名可以用来代替标准的元素标签，从而使得表达式更加简洁。属性、值和表格通常用 \u003cproperty\u003e、\u003cvalue\u003e 和 \u003ctable\u003e 标签来引用。但是，在函数定义中，以上这些元素可以使用 \u003cp\u003e、\u003cv\u003e 和 \u003ct\u003e 标签来代替。因此，之前的示例可以简化为以下格式：\n\u003cfunction name=\"aero/moment/roll_moment_due_to_yaw_rate\"\u003e \u003cdescription\u003eRoll moment due to yaw rate\u003c/description\u003e \u003cproduct\u003e \u003cp\u003e aero/qbar-area \u003c/p\u003e \u003cp\u003e metrics/bw-ft \u003c/p\u003e \u003cp\u003e aero/bi2vel \u003c/p\u003e \u003cp\u003e velocities/r-aero-rad_sec \u003c/p\u003e \u003ct\u003e \u003cindependentVar\u003e aero/alpha-rad \u003c/independentVar\u003e \u003ctableData\u003e 0.000 0.08 0.094 0.19 ... ... \u003c/tableData\u003e \u003c/t\u003e \u003c/product\u003e \u003c/function\u003e 在气动建模中，表格函数可以用来表示影响升力和阻力的地面效应因子。下图解释了地面效应：\n为了了解如何在 JSBSim 中建模地面效应，我们可以查看 Cessna 172 Skyhawk 模型。这一模型在文件 \u003cJSBSim-root-dir\u003e/aircraft/c172p/c172p.xml 中实现。在该 XML 文件的 \u003caerodynamics/\u003e 块中，建模了两个无量纲因子, $K_{C_{D, \\mathrm{ge}}}$ 和 $K_{C_L, \\mathrm{ge}}$,它们是无量纲地面高度的函数，并被视为升力和阻力的乘数。这些因子如下所示：\n\u003cfunction name=\"aero/function/kCDge\"\u003e \u003cdescription\u003eChange in drag due to ground effect\u003c/description\u003e \u003cproduct\u003e \u003cvalue\u003e1.0\u003c/value\u003e \u003ctable\u003e \u003cindependentVar\u003e aero/h_b-mac-ft \u003c/independentVar\u003e \u003ctableData\u003e 0.0000 0.4800 0.1000 0.5150 0.1500 0.6290 0.2000 0.7090 0.3000 0.8150 0.4000 0.8820 0.5000 0.9280 0.6000 0.9620 0.7000 0.9880 0.8000 1.0000 0.9000 1.0000 1.0000 1.0000 1.1000 1.0000 \u003c/tableData\u003e \u003c/table\u003e \u003c/product\u003e \u003c/function\u003e \u003cfunction name=\"aero/function/kCLge\"\u003e \u003cdescription\u003eChange in lift due to ground effect\u003c/description\u003e \u003cproduct\u003e \u003cvalue\u003e1.0\u003c/value\u003e \u003ctable\u003e \u003cindependentVar\u003e aero/h_b-mac-ft \u003c/independentVar\u003e \u003ctableData\u003e 0.0000 1.2030 0.1000 1.1270 0.1500 1.0900 0.2000 1.0730 0.3000 1.0460 0.4000 1.0550 0.5000 1.0190 0.6000 1.0130 0.7000 1.0080 0.8000 1.0060 0.9000 1.0030 1.0000 1.0020 1.1000 1.0000 \u003c/tableData\u003e \u003c/table\u003e \u003c/product\u003e \u003c/function\u003e 下图展示了表示因子 $K_{C_{D, \\text{ ge}}}$ 和 $K_{C_{L, \\text{ ge}}}$ 的表格函数 aero/function/kCDge 和 aero/function/kCLge ，分别表示因地面效应引起的阻力和升力的变化。它们的图形化表示如下，显示了相对于无量纲地面高度 $h/(b/2)$ 的变化。在飞机离地面高度小于机翼半个翼展 $b/2$ 时，可以观察到地面效应；而在更高的高度时，这两个因子值趋于 1。\n以上图表展示了无量纲地面高度 $h/(b/2)$ 的函数，定义了 c172p 飞机气动模型中的 aero/function/kCLge 和 aero/function/kCDge 属性。\n表格 在 JSBSim 中，可以定义一维、二维或三维查找表，用于气动学和函数定义。对于一个单一的“向量”查找表，格式如下：\n\u003ctable name=\"property_name_0\"\u003e \u003cindependentVar lookup=\"row\"\u003e property_name_1 \u003c/independentVar\u003e \u003ctableData\u003e key_1 value_1 key_2 value_2 ... ... key_n value_n \u003c/tableData\u003e \u003c/table\u003e 在这个例子中，\u003cindependentVar/\u003e 元素的 lookup=\"row\" 属性是可选的；默认假设 independentVar 是行变量。一个实际的示例如下：\n\u003ctable\u003e \u003cindependentVar lookup=\"row\"\u003e aero/alpha-rad \u003c/independentVar\u003e \u003ctableData\u003e -1.57 1.500 -0.26 0.033 0.00 0.025 0.26 0.033 1.57 1.500 \u003c/tableData\u003e \u003c/table\u003e 数据表格中的第一列代表查找索引（或 断点，或键）。在这个例子中，查找索引是 aero/alpha-rad（迎角，以弧度为单位）。如果 aero/alpha-rad 的值为 0.26 弧度，则查找表返回的值为 0.033。\n二维表的定义如下：\n\u003ctable name=\"property_name_0\"\u003e \u003cindependentVar lookup=\"row\"\u003e property_name_1 \u003c/independentVar\u003e \u003cindependentVar lookup=\"column\"\u003e property_name_2 \u003c/independentVar\u003e \u003ctableData\u003e {col_1_key col_2_key ... col_n_key } {row_1_key} {col_1_data col_2_data ... col_n_data} {row_2_key} {... ... ... ... } { ... } {... ... ... ... } {row_n_key} {... ... ... ... } \u003c/tableData\u003e \u003c/table\u003e 数据是以网格格式呈现的。以下是一个实际示例，其中 aero/alpha-rad 是行查找（迎角的断点排列在第一列），fcs/flap-pos-deg 是列查找（襟翼位置的角度，分别为 0、10、20 和 30 度）：\n\u003ctable\u003e \u003cindependentVar lookup=\"row\"\u003e aero/alpha-rad \u003c/independentVar\u003e \u003cindependentVar lookup=\"column\"\u003e fcs/flap-pos-deg \u003c/independentVar\u003e \u003ctableData\u003e 0.0 10.0 20.0 30.0 -0.0523599 8.96747e-05 0.00231942 0.0059252 0.00835082 -0.0349066 0.000313268 0.00567451 0.0108461 0.0140545 -0.0174533 0.00201318 0.0105059 0.0172432 0.0212346 0.0 0.0051894 0.0168137 0.0251167 0.0298909 0.0174533 0.00993967 0.0247521 0.0346492 0.0402205 0.0349066 0.0162201 0.0342207 0.0457119 0.0520802 0.0523599 0.0240308 0.0452195 0.0583047 0.0654701 0.0698132 0.0333717 0.0577485 0.0724278 0.0803902 0.0872664 0.0442427 0.0718077 0.088081 0.0968405 \u003c/tableData\u003e \u003c/table\u003e 三维查找表的定义如下：\n\u003ctable name=\"property_name_0\"\u003e \u003cindependentVar lookup=\"row\"\u003e property_name_1 \u003c/independentVar\u003e \u003cindependentVar lookup=\"column\"\u003e property_name_2 \u003c/independentVar\u003e \u003cindependentVar lookup=\"table\"\u003e property_name_3 \u003c/independentVar\u003e \u003ctableData breakpoint=\"table_1_key\"\u003e {col_1_key col_2_key ... col_n_key } {row_1_key} {col_1_data col_2_data ... col_n_data} {row_2_key} {... ... ... ... } { ... } {... ... ... ... } {row_n_key} {... ... ... ... } \u003c/tableData\u003e \u003ctableData breakpoint=\"table_2_key\"\u003e {col_1_key col_2_key ... col_n_key } {row_1_key} {col_1_data col_2_data ... col_n_data} {row_2_key} {... ... ... ... } { ... } {... ... ... ... } {row_n_key} {... ... ... ... } \u003c/tableData\u003e ... \u003ctableData breakpoint=\"table_n_key\"\u003e {col_1_key col_2_key ... col_n_key } {row_1_key} {col_1_data col_2_data ... col_n_data} {row_2_key} {... ... ... ... } { ... } {... ... ... ... } {row_n_key} {... ... ... ... } \u003c/tableData\u003e \u003c/table\u003e 请注意 \u003ctableData/\u003e 元素中的 breakpoint 属性。以下是一个示例：\n\u003ctable\u003e \u003cindependentVar lookup=\"row\"\u003e fcs/row-value \u003c/independentVar\u003e \u003cindependentVar lookup=\"column\"\u003e fcs/column-value \u003c/independentVar\u003e \u003cindependentVar lookup=\"table\"\u003e fcs/table-value \u003c/independentVar\u003e \u003ctableData breakPoint=\"-1.0\"\u003e -1.0 1.0 0.0 1.0000 2.0000 1.0 3.0000 4.0000 \u003c/tableData\u003e \u003ctableData breakPoint=\"0.0000\"\u003e 0.0 10.0 2.0 1.0000 2.0000 3.0 3.0000 4.0000 \u003c/tableData\u003e \u003ctableData breakPoint=\"1.0\"\u003e 0.0 10.0 20.0 2.0 1.0000 2.0000 3.0000 3.0 4.0000 5.0000 6.0000 10.0 7.0000 8.0000 9.0000 \u003c/tableData\u003e \u003c/table\u003e 插值：表格中的值是线性插值的，且不会在表格的限制值之外进行外推。表格返回的最大值是已定义的最大值。 一维插值 一些仿真中的查找表——尤其是气动数据——可能是四维、五维、六维，甚至更多维度的。Interpolate1d 返回通过对提供的值进行一维插值的结果，其中第一个直接子元素的值表示查找表中的查找值，后续的值对表示自变量和因变量。第一个提供的子元素预期是一个属性。插值不会进行外推，如果提供的查找值超出了定义的范围，则返回最高值。其格式如下：\n\u003cinterpolate1d\u003e {property, value, table, function} {property, value, table, function} {property, value, table, function} ... \u003c/interpolate1d\u003e 示例：如果 mach 为 0.4，插值将返回 0.375。如果 mach 为 1.5，插值将返回 0.60。\n\u003cinterpolate1d\u003e \u003cp\u003e velocities/mach \u003c/p\u003e \u003cv\u003e 0.00 \u003c/v\u003e \u003cv\u003e 0.25 \u003c/v\u003e \u003cv\u003e 0.80 \u003c/v\u003e \u003cv\u003e 0.50 \u003c/v\u003e \u003cv\u003e 0.90 \u003c/v\u003e \u003cv\u003e 0.60 \u003c/v\u003e \u003c/interpolate1d\u003e 上面的示例非常简单。一个更复杂的示例可能会在任何参数（除了第一个）中使用函数。这意味着断点向量可能是变量——尽管这并不常见——但更重要的是，查找向量（第二列）中的值可能是 1、2 或 3 维度的函数表元素。参数甚至可以是嵌套的 interpolate1d 元素。例如：\n\u003cfunction name=\"whatever\"\u003e \u003cinterpolate1d\u003e \u003cp\u003e velocities/mach \u003c/p\u003e \u003cv\u003e 0.00 \u003c/v\u003e \u003ctable\u003e ... table definition ... \u003c/table\u003e \u003cv\u003e 0.80 \u003c/v\u003e \u003ctable\u003e ... table definition ... \u003c/table\u003e \u003cv\u003e 0.90 \u003c/v\u003e \u003ctable\u003e ... table definition ... \u003c/table\u003e \u003c/interpolate1d\u003e \u003c/function\u003e 进一步扩展：\n\u003cfunction name=\"bigWhatever1\"\u003e \u003cinterpolate1d\u003e \u003cp\u003e aero/qbar-psf \u003c/p\u003e \u003cv\u003e 0 \u003c/v\u003e \u003cinterpolate1d\u003e \u003cp\u003e velocities/mach \u003c/p\u003e \u003cv\u003e 0.00 \u003c/v\u003e \u003ctable\u003e ... table 1 definition ... \u003c/table\u003e \u003cv\u003e 0.80 \u003c/v\u003e \u003ctable\u003e ... table 2 definition ... \u003c/table\u003e \u003cv\u003e 0.90 \u003c/v\u003e \u003ctable\u003e ... table 3 definition ... \u003c/table\u003e \u003c/interpolate1d\u003e \u003cv\u003e 65 \u003c/v\u003e \u003cinterpolate1d\u003e \u003cp\u003e velocities/mach \u003c/p\u003e \u003cv\u003e 0.00 \u003c/v\u003e \u003ctable\u003e ... table 1 definition ... \u003c/table\u003e \u003cv\u003e 0.80 \u003c/v\u003e \u003ctable\u003e ... table 2 definition ... \u003c/table\u003e \u003cv\u003e 0.90 \u003c/v\u003e \u003ctable\u003e ... table 3 definition ... \u003c/table\u003e \u003c/interpolate1d\u003e \u003cv\u003e 90 \u003c/v\u003e \u003cinterpolate1d\u003e \u003cp\u003e velocities/mach \u003c/p\u003e \u003cv\u003e 0.00 \u003c/v\u003e \u003ctable\u003e ... table 1 definition ... \u003c/table\u003e \u003cv\u003e 0.80 \u003c/v\u003e \u003ctable\u003e ... table 2 definition ... \u003c/table\u003e \u003cv\u003e 0.90 \u003c/v\u003e \u003ctable\u003e ... table 3 definition ... \u003c/table\u003e \u003c/interpolate1d\u003e \u003c/interpolate1d\u003e \u003c/function\u003e 上面的结构实际上提供了一个五维查找表。在实践中，这会非常庞大且混乱，但这就是实现方式。 :-)\n不过，这里还有更多。对于非常非常大的气动数据库，有时某些气动系数可能不需要计算。例如，地面效应气动系数只在接近地面时才需要计算。当地面效应不对气动力和力矩产生影响时，为什么还要浪费 CPU 循环呢？我们可以使用 ifthen 元素来跳过昂贵的计算。ifthen 元素的工作方式如下：\n如果第一个直接子元素的值为 1，则返回第二个直接子元素的值，否则返回第三个子元素的值。\n\u003cifthen\u003e {property, value, table, or other function element} {property, value, table, or other function element} {property, value, table, or other function element} \u003c/ifthen\u003e 示例：如果 flight-mode 大于 2，则返回 0.00，否则返回属性 control/pitch-lag 的值。\n\u003cifthen\u003e \u003cgt\u003e \u003cp\u003e executive/flight-mode \u003c/p\u003e \u003cv\u003e 2 \u003c/v\u003e \u003c/gt\u003e \u003cv\u003e 0.00 \u003c/v\u003e \u003cp\u003e control/pitch-lag \u003c/p\u003e \u003c/ifthen\u003e 在我们的例子中，可以如下编写五维查找表查询，除非起落架已放下，否则返回零：\n\u003cfunction name=\"propertyname\"\u003e \u003cifthen\u003e \u003clt\u003e \u003cp\u003e position/altitudeMSL \u003c/p\u003e \u003cv\u003e 90 \u003c/v\u003e \u003c/lt\u003e \u003cinterpolate1d\u003e \u003cp\u003e aero/qbar-psf \u003c/p\u003e \u003cv\u003e 0 \u003c/v\u003e \u003cinterpolate1d\u003e \u003cp\u003e velocities/mach \u003c/p\u003e \u003cv\u003e 0.00 \u003c/v\u003e \u003ctable\u003e ... table 1 definition ... \u003c/table\u003e \u003cv\u003e 0.80 \u003c/v\u003e \u003ctable\u003e ... table 2 definition ... \u003c/table\u003e \u003cv\u003e 0.90 \u003c/v\u003e \u003ctable\u003e ... table 3 definition ... \u003c/table\u003e \u003c/interpolate1d\u003e \u003cv\u003e 65 \u003c/v\u003e \u003cinterpolate1d\u003e \u003cp\u003e velocities/mach \u003c/p\u003e \u003cv\u003e 0.00 \u003c/v\u003e \u003ctable\u003e ... table 1 definition ... \u003c/table\u003e \u003cv\u003e 0.80 \u003c/v\u003e \u003ctable\u003e ... table 2 definition ... \u003c/table\u003e \u003cv\u003e 0.90 \u003c/v\u003e \u003ctable\u003e ... table 3 definition ... \u003c/table\u003e \u003c/interpolate1d\u003e \u003cv\u003e 90 \u003c/v\u003e \u003cinterpolate1d\u003e \u003cp\u003e velocities/mach \u003c/p\u003e \u003cv\u003e 0.00 \u003c/v\u003e \u003ctable\u003e ... table 1 definition ... \u003c/table\u003e \u003cv\u003e 0.80 \u003c/v\u003e \u003ctable\u003e ... table 2 definition ... \u003c/table\u003e \u003cv\u003e 0.90 \u003c/v\u003e \u003ctable\u003e ... table 3 definition ... \u003c/table\u003e \u003c/interpolate1d\u003e \u003c/interpolate1d\u003e \u003cv\u003e 0 \u003c/v\u003e \u003c/ifthen\u003e \u003c/function\u003e 上面的例子在某种程度上是没有实际意义的，但格式是正确的。从性能角度来看，这是有效的，因为表格只有在查找时确实需要时才会被执行。\n力与力矩 空气动力学 有几种方法可以模拟作用在飞机上的空气动力学力和力矩（扭矩）。JSBSim 最初采用的是系数积累法。在系数积累法中，升力（例如）是通过将所有升力贡献相加来确定的。贡献的具体内容根据飞机的不同和模型的精度而有所不同，但升力的贡献可以包括来自以下方面的贡献：\n机翼 升降舵 襟翼 空气动力学系数是一些数字，这些数字在乘以某些其他值（如动态压力和机翼面积）后，结果就是一个力或力矩。这些系数可以来自飞行试验报告或教科书，或者可以通过软件（如 Digital DATCOM 或其他商业软件）或手工计算来得出。最终，JSBSim 增加了对作为函数指定的空气动力学属性的支持。在配置文件的 \u003caerodynamics\u003e 部分中，有六个子部分，分别代表 3 个力轴和 3 个力矩轴（总共六个自由度）。空气动力学部分的基本布局如下：\n\u003caerodynamics\u003e \u003caxis name=\"DRAG\"\u003e { 力的贡献 } \u003c/axis\u003e \u003caxis name=\"SIDE\"\u003e { 力的贡献 } \u003c/axis\u003e \u003caxis name=\"LIFT\"\u003e { 力的贡献 } \u003c/axis\u003e \u003caxis name=\"ROLL\"\u003e { 力矩的贡献 } \u003c/axis\u003e \u003caxis name=\"PITCH\"\u003e { 力矩的贡献 } \u003c/axis\u003e \u003caxis name=\"YAW\"\u003e { 力矩的贡献 } \u003c/axis\u003e \u003c/aerodynamics\u003e 并非所有单独的轴都是必需的。JSBSim 支持几组标准的轴系统：\n\"DRAG\"、\"SIDE\"、\"LIFT\"（风轴） \"X\"、\"Y\"、\"Z\"（机体轴） \"AXIAL\"、\"SIDE\"、\"NORMAL\"（机体轴） 所有三个系统都接受 \"ROLL\"、\"PITCH\"、\"YAW\" 轴的定义。轴系统不能混合使用。在轴元素中，函数用于定义对该轴总力或力矩的各个贡献。在 JSBSim 中，函数是被广泛使用的。在定义力或力矩时，函数可以使用表格、常数、三角函数或其他标准 C 库函数。仿真参数通过属性进行引用。以下是一个例子：\n\u003cfunction name=\"aero/force/lift_due_to_flap_deflection\"\u003e \u003cdescription\u003e襟翼偏转引起的升力贡献\u003c/description\u003e \u003cproduct\u003e \u003cproperty\u003eaero/function/ground-effect-factor-lift\u003c/property\u003e \u003cproperty\u003eaero/qbar-area\u003c/property\u003e \u003ctable\u003e \u003cindependentVar\u003efcs/flap-pos-deg\u003c/independentVar\u003e \u003ctableData\u003e 0.0 0.0 10.0 0.20 20.0 0.30 30.0 0.35 \u003c/tableData\u003e \u003c/table\u003e \u003c/product\u003e \u003c/function\u003e 在此例中，以上内容的文字描述如下：该函数的值是 ground-effect-factor-lift、qbar-area 和通过表格确定的值的乘积，表格根据襟翼位置（以度为单位）进行索引。\n在 \u003caxis/\u003e 部分中的所有函数都会相加，并以适当的方式应用于飞机。然而，这种格式具有一定的灵活性。那些在任何 \u003caxis/\u003e 部分之外指定的函数会被创建和计算，但它们本身并不会直接贡献到任何力或力矩的总值中。然而，它们可以被引用到位于 \u003caxis/\u003e 部分内的其他函数中。这种技术允许将可能应用于多个单独函数的计算一次性执行，并多次使用。这个技术还可以进一步扩展，实际上，空气动力学系数可以在 \u003caxis/\u003e 定义外计算出来，然后在函数定义内通过乘以各种因子（属性）将它们转换为力和力矩，并最终在 \u003caxis/\u003e 定义中应用。\n力与力矩的例子：瞬时升力 作为一个例子，我们来分析瞬时升力 $L(t)$。它可以通过以下积累公式表示：\n$$ L=L_{\\text {basic }}\\left(\\alpha_{\\mathrm{B}}, \\phi_{\\text {hyst }}\\right)+\\Delta L\\left(\\delta_{\\text {flap }}\\right)+\\Delta L\\left(\\delta_{\\mathrm{e}}\\right)+\\Delta L\\left(\\dot{\\alpha}_{\\mathrm{B}}\\right)+\\Delta L(q) \\tag{1} $$其中，$\\alpha_B$、$\\delta_{\\text{flap}}$、$\\delta_e$、$\\dot{\\alpha}_B$ 和 $q$ 是常见的飞机状态变量。无量纲标量 $\\phi_{\\text{hyst}}$ 通常等于 0，当攻角较大时（接近失速情况，当空气动力学滞后效应被建模时），它的值为 1。\n公式 (1) 中的项 $L_{\\text{basic}}\\left(\\alpha_B, \\phi_{\\text{hyst}}\\right)$ 被称为“基本”贡献，它依赖于攻角。我们知道，增加攻角会增加升力——直到某个点为止。升力通常被定义为飞行动态压力（“qbar”，$\\bar{q}$，或者对于空气动力学家而言是 $\\bar{q}_{\\infty}$）与机翼面积（$S_W$ 或简写为 $S$）和升力系数（$C_L$）的乘积。在本例中，升力系数通过查找表来确定，使用 $\\alpha_B$ 和 $\\phi_{\\text{hyst}}$ 作为查找表的索引：\n\u003cfunction name=\"aero/force/lift_from_alpha\"\u003e \u003cdescription\u003e 升力由于攻角 \u003c/description\u003e \u003cproduct\u003e \u003cproperty\u003e aero/qbar-psf \u003c/property\u003e \u003cproperty\u003e metrics/Sw-sqft \u003c/property\u003e \u003cproperty\u003e aero/function/kCLge \u003c/property\u003e \u003ctable\u003e \u003cindependentVar lookup=\"row\"\u003e aero/alpha-rad \u003c/independentVar\u003e \u003cindependentVar lookup=\"column\"\u003e aero/stall-hyst-norm \u003c/independentVar\u003e \u003ctableData\u003e 0.0000 1.0000 -0.0900 -0.2200 -0.2200 0.0000 0.2500 0.2500 0.0900 0.7300 0.7300 0.1000 0.8300 0.7800 0.1200 0.9200 0.7900 0.1400 1.0200 0.8100 0.1600 1.0800 0.8200 0.1700 1.1300 0.8300 0.1900 1.1900 0.8500 0.2100 1.2500 0.8600 0.2400 1.3500 0.8800 0.2600 1.4400 0.9000 0.2800 1.4700 0.9200 0.3000 1.4300 0.9500 0.3200 1.3800 0.9900 0.3400 1.3000 1.0500 0.3600 1.1500 1.1500 \u003c/tableData\u003e \u003c/table\u003e \u003c/product\u003e \u003c/function\u003e 基本升力系数\n$$ C_{L, \\text{ basic }}=\\frac{L_{\\text{ basic }}\\left(\\alpha_B, \\phi_{\\text{hyst }}\\right)}{\\bar{q} S} \\tag{2} $$下面是根据攻角 $\\alpha_B$ 和 $\\phi_{\\text{hyst}}$ 绘制的基本升力系数 $C_{L,\\text{basic}}$ 的曲线。\n上图显示了与 c172p 空气动力学模型中名为 aero/coefficient/CLwbh 的查找表相对应的二元函数 $C_{L,\\text{basic}}(\\alpha_B, \\phi_{\\text{hyst}})$。\nTODO 完成本小节内容。\n该图表示了与 c172p 空气动力学模型中名为 aero/coefficient/CDwbh 的查找表相对应的二元函数 $C_{D,\\text{basic}}(\\alpha_B, \\delta_{\\text{flap}})$。\nTODO 完成本小节内容。\n推力 (Propulsion) 推力部分通常涉及发动机的性能以及与之相关的空气动力学效应。在 JSBSim 中，推力系统通常通过对发动机的建模来实现，这包括计算气流、转速、油门设置和其他影响推力的因素。推力的计算需要依赖于多种因素，比如油门位置、发动机转速、飞行状态等。\n\u003cpropulsion\u003e \u003cengine name=\"engine1\"\u003e \u003cthrustModel\u003egeneric\u003c/thrustModel\u003e \u003crpm\u003e2000\u003c/rpm\u003e \u003cpower\u003e180\u003c/power\u003e \u003cfuelFlow\u003e50\u003c/fuelFlow\u003e \u003cthrust\u003e \u003cfunction\u003ethrust_from_rpm\u003c/function\u003e \u003c/thrust\u003e \u003c/engine\u003e \u003c/propulsion\u003e 在此示例中，我们定义了一个名为 engine1 的发动机，使用了 generic 的推力模型，并为其指定了转速、功率和油耗等参数。推力是通过某个特定的函数来计算的，比如根据发动机转速来推算。\n重量 (Weight) 飞机的重量是影响飞行的关键因素，它包括飞机的自重、载荷以及油料的质量等。重量的变化直接影响到升力、飞行速度以及燃料消耗等参数。在 JSBSim 中，重量可以通过以下方式进行建模：\n\u003cweight\u003e \u003cemptyWeight\u003e1500\u003c/emptyWeight\u003e \u003cmaxTakeoffWeight\u003e2500\u003c/maxTakeoffWeight\u003e \u003cfuelWeight\u003e \u003cproperty\u003efuel/weight\u003c/property\u003e \u003c/fuelWeight\u003e \u003c/weight\u003e 在此示例中，定义了飞机的空重、最大起飞重量以及燃料重量。燃料的重量由 fuel/weight 属性控制，表示当前燃料的质量。\n地面接触 (Ground Contact) 地面接触模型用于模拟飞机与地面之间的交互力和接触点。这些交互力包括着陆、起飞时的冲击力，以及滑行时的摩擦力。在 JSBSim 中，地面接触模型通常包括以下几个部分：\n摩擦力：模拟飞机与地面之间的摩擦。 起落架：描述起落架的刚度、阻尼和承载能力。 接触力：模拟飞机与地面接触时产生的垂直力和水平力。 \u003cgroundContact\u003e \u003ccontact\u003e \u003csurfaceType\u003easphalt\u003c/surfaceType\u003e \u003cfrictionCoefficient\u003e0.8\u003c/frictionCoefficient\u003e \u003clandingGear\u003e \u003cmodel\u003ebasic\u003c/model\u003e \u003cstiffness\u003e2000\u003c/stiffness\u003e \u003cdamping\u003e100\u003c/damping\u003e \u003c/landingGear\u003e \u003c/contact\u003e \u003c/groundContact\u003e 在此示例中，定义了地面接触的表面类型（如沥青）、摩擦系数，以及起落架的刚度和阻尼特性。\n飞行控制与系统建模 将飞机视为一般的动力学系统，它受控制输入向量 $\\boldsymbol{u}$ 的作用。输入的数量和类型可能取决于具体考虑的飞机类型。对于常规配置的飞机，输入的最小配置通常为： $$ \\boldsymbol{u}=\\left[\\delta_{\\mathrm{T}}, \\delta_{\\mathrm{a}}, \\delta_{\\mathrm{e}}, \\delta_{\\mathrm{r}}\\right] \\tag{1} $$ 其中，$\\delta_{\\mathrm{T}}$ 是油门设定，$\\delta_{\\mathrm{a}}$、$\\delta_{\\mathrm{e}}$ 和 $\\delta_{\\mathrm{r}}$ 分别是右副翼、升降舵和方向舵的角度偏转。这些量有标准符号，且它们的范围可能会根据具体的飞机设计有所不同。在飞行仿真中，它们的变化通常与驾驶舱中相应控制的归一化设置相关。\n通常油门的设定范围从 0（空闲）到 +1（最大功率）。从概念上讲，$\\delta_{\\mathrm{T}}$ 可视为实际飞行速度和高度下最大推力输出的当前分数。\n操纵杆的偏转范围通常从 −1 到 +1。\n这些映射通常取决于控制律的存在，这些控制律可能会改变飞行员操作对实际效应器偏转和推力输出的最终影响。\n从数学的角度看，无论是考虑实际的气动表面偏转和推力输出，还是归一化的命令范围，它们都被视为控制变量 $\\boldsymbol{u}$ 的一组边界。\n必须再次强调，控制输入的数量和类型是特定飞机的特征。即使在相同的广泛类别中，两种飞机设计也可能呈现出本质上不同的控制配置和数量。但一般来说，它们至少有相同的“主要”控制：一对副翼，一个主要的纵向控制，即一对对称运动的升降舵，以及一个方向舵。在许多情况下，水平尾翼也具有相对于机身参考线的可变安装角度，这个角度通常称为 $i_{\\mathrm{H}}$，大多数飞行力学教材中都有涉及。\n约定 标准飞机气动控制表面。\n气动建模概述 线性化的迎角系数： $$ C_m=C_{m 0}+C_{m \\alpha} \\alpha_{\\mathrm{B}}+C_{m \\delta_{\\mathrm{e}}} \\delta_{\\mathrm{e}}+C_{m i_{\\mathrm{H}}} i_{\\mathrm{H}}+\\left(C_{m q} q+C_{m \\dot{\\alpha}} \\dot{\\alpha}_{\\mathrm{B}}\\right) \\frac{\\bar{c}}{2 V} \\tag{2} $$ 在 c172p 模型中，升降舵通道的命令与偏转逻辑。操纵杆的移动与迎角调整杆的调节组合，归一化并映射到区间 [−1,1]。该通道的输出是一个实数变量 fcs/elevator-pos-rad，表示一个等效的升降舵偏转 $\\delta_{\\mathrm{e}}^\\star = \\delta_{\\mathrm{e}} + \\delta_{\\mathrm{e}, \\mathrm{tab}}^\\star$。其中，$\\delta_{\\mathrm{e}, \\mathrm{tab}}^\\star$ 是等效于实际升降舵调整角度 $\\delta_{\\mathrm{e}, \\mathrm{tab}}$ 的偏转角度。$\\delta_{\\mathrm{e}}$ 的范围是 [$\\delta_{\\mathrm{e}, \\mathrm{min}}$, $\\delta_{\\mathrm{e}, \\mathrm{max}}$]。尾部以移动的表面偏转来表示，既有等效条件下（上方）也有实际条件下（下方）的偏转。\n推力建模概述 一架双引擎螺旋桨飞机。在机体坐标系中，推进器、推力应用点和推力矢量的方向位置。\n与 c172p 的 FDM 中的实体 “推进器” 和 “油箱” 相关的位置。",
    "description": "如何使用 JSBSim 进行模拟运行、创建飞行器模型、编写脚本，以及如何执行其他不涉及对 JSBSim 程序代码进行更改的任务。",
    "tags": [],
    "title": "JSBSim User manual",
    "uri": "/uas/fix_wing_uav_flight_sim/jsbsim_user_manual/index.html"
  },
  {
    "breadcrumb": "FlitSoft Docs \u003e  UAS \u003e  Aerodynamics",
    "content": "https://jsbsim-team.github.io/jsbsim-reference-manual/\nJSBSim 是一个轻量级的数据驱动型非线性六自由度（6DoF）批处理仿真应用，旨在建模飞机的飞行动力学与控制。从最早的版本开始，JSBSim 就受益于其成长过程中的开源开发环境，以及众多用户对其持续改进所提出的各种想法。\n本在线参考手册是一个社区合作项目，旨在让用户和开发者了解软件的所有功能。\n许可证： JSBSim 根据 GNU 较宽通用公共许可证（LGPL）授权。\nAcknowledgements 这款软件是许多人多年来共同努力的成果。\nTony Peden 几乎从 JSBSim 的第一天起就开始为其发展做出贡献。他负责初始化和修剪代码。Tony 还将 David Megginson 的属性系统集成到了 JSBSim 中。Tony 来自俄亥俄州立大学，拥有航空与航天工程学位。\nDavid Culp 为 JSBSim 开发了涡轮发动机模型，并设计了多个使用该模型的飞机，包括 T-38。David 拥有多种军用和民用飞机的飞行经验，包括 T-38、波音 707、727、737、757、767、SGS 2-32 和 OV-10。David 是一名航空航天工程师，毕业于美国空军学院。\nDavid Megginson 曾长期参与 FlightGear 的核心开发工作。David 将我们的飞行动力学与他的一般航空飞行经验相结合，以帮助实现最大程度的真实感，除此之外，他还设计了 FlightGear 和 JSBSim 所使用的属性系统。他以对 XML 技术的贡献而闻名，并编写了 FlightGear 和 JSBSim 使用的 easyXML 解析器。\nErik Hofman 做了多方面的工作，包括寻找飞机数据、创建飞行模型（如 F-16），并进行一些编程工作。他还测试了 IRIX 兼容性。Erik 拥有计算机科学学位。\nMathias Frölich 增加了一个多功能的每个起落架的地面高度能力，并做了许多其他贡献。Mathias 是一位来自德国的数学家。\nAgostino De Marco 为 JSBSim 创建了一个广泛适用的成本/惩罚修剪分析功能，并曾在那不勒斯大学单独使用 JSBSim 或与 FlightGear 一起使用 JSBSim。\n来自英国的 David Luff 提供了最初的活塞发动机模型，Ron Jensen 对其进行了不断的改进。\n拥有多年仿真经验的工程师 Lee Duke 和 Bill Galbraith 提出了许多建议和想法，帮助改进了 JSBSim。\n来自 NASA 兰利研究中心的 Bruce Jackson，参与了多种仿真系统的开发与应用，长期以来一直给予支持和帮助，他许多年前用 C 语言编写的仿真代码（“LaRCSim”）对 JSBSim 的早期开发具有启发意义。\nCurt Olson 协调 FlightGear 及其一些构成部分（SimGear）的开发，多年来在仿真、控制理论和其他许多话题的讨论中给予了极大的帮助。与 FlightGear 社区的合作使 JSBSim 成为一个更好的工具。\n最后，用户和开发者社区的努力使 JSBSim 达到了今天的水平。感谢所有曾经花时间报告 bug 或请求新功能的人。\n前言 JSBSim 于 1996 年构思，作为一个轻量级、数据驱动型、非线性的六自由度（6DoF）批处理仿真应用，旨在建模飞机的飞行动力学与控制。从最早的版本开始，JSBSim 就受益于其成长过程中的开源开发环境，以及众多用户对其持续改进所提出的各种想法。\n本手册简介 本在线文档分为多个部分。这是因为 JSBSim 可以从不同的角度进行查看：作为飞行器模型开发者的视角，作为将 JSBSim 集成到完整飞行仿真架构中并配有视觉效果的集成者视角，或者作为希望通过添加额外功能来适配或增强 JSBSim 的软件开发者视角。\n文档的 快速入门 部分（第零部分）解释了如何快速开始使用 JSBSim。\n接下来的第一部分是 用户手册，它解释了如何使用 JSBSim 进行仿真运行、创建飞机模型、编写脚本，并执行其他不涉及更改 JSBSim 程序代码的任务。\n第二部分是 程序员手册，解释了 JSBSim 的架构——代码是如何组织的，如何工作。\n第三部分是 公式手册，其中包含了 JSBSim 中存在的数学模型和算法的描述。\n第四部分是一些示例和案例研究，展示了 JSBSim 的使用情况。\n本文档不包含的内容 本文档不是关于推导运动方程和飞行动力学的详尽参考书。有关此类内容，请参阅 (Stevens:Lewis:Johnson:2015) 和 (Zipfel:2003)。然而，本文档旨在成为 JSBSim 的权威文档。\n快速入门 要高效使用 JSBSim，您可能需要采用 程序员的态度。这意味着您需要自行下载源代码并在您的平台上进行编译。只要您的计算机上安装了正确的工具，这其实是一个简单的过程。\n对于急于使用的人，提供了自动远程构建过程，能够交付最新的库二进制文件。您可以通过以下链接找到这些二进制文件：\nFlightGear 项目开发者提供的构建版本 (Jenkins 服务器) Linux 版 JSBSim 构建（Linux CentOS 7 虚拟机） 前往工作区 build.flightgear.org:8080/job/JSBSim/ws，下载所有文件为 Zip 压缩包。解压文件，进入 /JSBSim/build/src/ 文件夹，您会找到：可执行文件 JSBSim 和静态库文件 libJSBSim.a。\nWindows 版 JSBSim 构建 前往工作区 build.flightgear.org:8080/job/JSBSim-win/ws，下载所有文件为 Zip 压缩包。解压文件，进入 /JSBSim-win/build/src/Debug/ 文件夹，您会找到：可执行文件 JSBSim.exe 和静态库文件 JSBSim.lib。\n提供预编译 JSBSim 二进制文件的工作是 FlightGear 项目的 持续集成与交付服务 的一部分。如需了解有关 Jenkins 持续集成的更多信息，您可以 访问此链接。\nJSBSim 团队提供的构建版本 (Travis 服务器 和 AppVeyor 服务器) JSBSim 团队提供了自己的持续集成服务，交付适用于 Ubuntu 14.04.5 LTS（Trusty Tahr）和 MS Windows 的 x64 二进制文件。发布版本标记为 v2018a（或更高版本），可以从 GitHub 仓库的 发布区 下载。\n要查看最新构建的当前状态，可以访问以下链接：\nUbuntu 版 Travis 构建（包括 Python 2.7 和 3.6 的测试） Windows 版 AppVeyor 构建（无测试） 那么，您想要模拟这架飞机的飞行吗？\n获取源代码 JSBSim 的 GitHub 仓库可以通过以下链接访问：github.com/JSBSim-Team/jsbsim。该仓库镜像了 SourceForge 上的原始仓库：sourceforge.net/projects/jsbsim。\n下载源代码所需的工具 您需要安装 Git 软件。Git 是一个 版本控制软件，用于记录文件或文件集随时间的变化，以便您可以随时回溯到特定版本。JSBSim 的软件源代码文件是通过 Git 进行版本控制的。\n要安装 Git，请 访问下载页面，并选择适合您平台的版本。您可以通过两种方式在本地使用 Git：通过 GUI 客户端，或通过命令行（例如在 Linux 或 Windows 上使用 Bash shell）。\n安装完 Git 后，假设您将通过命令行使用 Git，您可以从以下两个位置之一 克隆 JSBSim 的公开源代码仓库。\n从 SourceForge 下载 在这种情况下，克隆仓库的 Git 命令是（HTTPS 模式）\n\u003e git clone https://git.code.sf.net/p/jsbsim/code jsbsim-code 或者（SSH 模式）\n\u003e git clone git://git.code.sf.net/p/jsbsim/code jsbsim-code 从 GitHub 下载 在这种情况下，克隆仓库的 Git 命令是（HTTPS 模式）\n\u003e git clone https://github.com/JSBSim-Team/jsbsim.git jsbsim-code 或者（SSH 模式）\n\u003e git clone git@github.com:JSBSim-Team/jsbsim.git jsbsim-code 那么，您想要模拟这架飞机的飞行吗？\n构建程序和库 JSBSim 可以通过 CMake 或 Microsoft Visual Studio 进行构建。如果您使用的是 Mac OSX 或 Linux 平台，必须使用 CMake。如果您是 Windows 用户，可以选择任意一种工具。\nJSBSim 使用标准 C++98/C99 编写，并且没有外部依赖，因此您只需要在您的平台上安装 C/C++ 编译器即可。\n使用 CMake 构建 CMake 是一个跨平台的构建和测试软件的工具。它可以生成用于使用 GNU make 或 Microsoft Visual Studio 构建 JSBSim 的文件。为了将构建文件与源代码分开，最好在单独的目录中构建 JSBSim。\n\u003e cd jsbsim-code \u003e mkdir build \u003e cd build CMake 不构建 软件，它生成文件 供 多种构建工具使用。以下命令假定您使用 GNU make 来构建 JSBSim。\n首先，您应该调用 CMake 然后执行 make\n\u003e cmake .. \u003e make 这将编译各种类并构建 JSBSim 应用程序，最终文件将位于 build/src 目录下。\n传递给 CMake 的选项 CMake 可以使用多个参数来调整 JSBSim 的构建。以下是不同的选项，您可以根据需要独立使用它们或任意组合。\n传递参数给编译器 如果您想设置编译器选项，可以通过传递标志给 CMake 来构建 JSBSim 的 Debug 版本。JSBSim 也使用 C 语言编写了一些代码，您可以为 C++ 和 C 编译器设置选项。\n\u003e cmake -DCMAKE_CXX_FLAGS_DEBUG=\"-g -Wall\" -DCMAKE_C_FLAGS_DEBUG=\"-g -Wall\" -DCMAKE_BUILD_TYPE=Debug .. \u003e make 或者，您也可以构建 JSBSim 的发布版本，并请求 GNU Make 使用 4 核心来加速可执行文件的构建。\n\u003e cmake -DCMAKE_CXX_FLAGS_RELEASE=\"-O3 -march=native -mtune=native\" -DCMAKE_C_FLAGS_RELEASE=\"-O3 -march=native -mtune=native\" -DCMAKE_BUILD_TYPE=Release .. \u003e make -j4 构建 Expat 或使用系统库 JSBSim 使用 Expat 库 来读取 XML 文件。Expat 源代码与 JSBSim 源代码一起提供，并在构建过程中与 JSBSim 一起编译。然而，如果 Expat 已经安装在您的平台上，您可能更倾向于使用系统的 Expat 库，以避免重复。在这种情况下，您应该将 SYSTEM_EXPAT 标志传递给 CMake：\n\u003e cmake -DSYSTEM_EXPAT=ON .. \u003e make 构建 JSBSim 的 Python 模块 JSBSim 的 Python 模块也可以通过 CMake 来构建。为此，您需要在您的平台上安装 Cython。CMake 将自动检测到 Cython 并构建 Python 模块。\n使用 Microsoft Visual Studio 构建 在 Visual Studio 中，您可以打开项目文件 JSBSim.vcxproj 来加载 JSBSim 项目。该项目文件将配置 Visual Studio 来构建 JSBSim 可执行文件。\n注意 1： JSBSim 的官方构建工具是 CMake。Visual Studio 项目文件作为一种便利工具提供，并不保证始终与代码保持同步。\n注意 2： 从 Visual Studio 2017 开始，Microsoft 已将 CMake 包含在内，因此您应该能够直接从 CMake 文件在 VS2017 中构建 JSBSim。\n测试 JSBSim JSBSim 附带了一个测试套件，用于自动检查构建是否正确。该测试套件位于 tests 目录中，并使用 Python 编写，因此您需要先构建 JSBSim 的 Python 模块。\n测试套件可以在 build 目录中使用 ctest 运行。可以使用 -j 选项在多个核心上并行运行测试（例如，以下示例中使用 4 核心）。\n\u003e ctest -j4 安装 JSBSim 一旦 JSBSim 被构建和测试完成，您可以将 C++ 头文件和库安装到平台范围内。为此，您可以在 build 目录中调用 GNU make：\n\u003e make install 安装 Python 模块 如果您除了 C++ 头文件和库外，还计划安装 JSBSim 的 Python 模块，那么必须将 INSTALL_PYTHON_MODULE 标志传递给 CMake：\n\u003e cmake -DINSTALL_PYTHON_MODULE=ON .. \u003e make \u003e make install 另外，您也可以通过在 build 目录中执行以下命令手动安装 Python 模块：\n\u003e cd tests \u003e python setup.py install 那么，您想模拟这架飞机的飞行吗？\n使用 Visual Studio 构建 随着 Visual Studio 2017 开始支持 CMake，现在有两种方法可以使用 Visual Studio 2017 构建 JSBSim 及其各种组件。一种是使用标准的 Visual Studio 项目文件（*.vcxproj），用于构建 JSBSim 主程序、Aeromatic++ 等组件，另一种是通过 Visual Studio 使用 CMake 来构建 JSBSim 及其各种组件。\n使用 git 检出 JSBSim 源代码。在这些示例中，源代码已检出到：\nC:\\source\\JSBSim 使用 VS 2017 项目文件构建 选择 文件 → 打开 → 项目/解决方案 … 菜单选项。\n浏览到 JSBSim 源代码所在的位置，选择根目录下的 JSBSim.sln 文件，在本例中是：\nC:\\source\\JSBSim\\JSBSim.sln 项目文件已配置为将编译器和链接器的中间文件以及最终输出文件存储在 JSBSim 源代码树之外的目录中，即存储在 C:\\source\\JSBSim\\src 外部。\n例如，JSBSim 和 Aeromatic 的中间文件将存储在以下目录中：\nC:\\source\\JSBSim\\Debug\\x64\\JSBSim C:\\source\\JSBSim\\Debug\\x64\\aeromatic 输出文件将位于：\nC:\\source\\JSBSim\\Debug 使用 VS 2017 CMake 支持构建 选择 文件 → 打开 → CMake … 菜单选项。\n浏览到 JSBSim 源代码所在的位置，选择根目录下的 CMakeLists.txt 文件，在本例中是：\nC:\\source\\JSBSim\\CMakeLists.txt 共有 4 种构建配置：x86、x64 以及每种版本的 Debug 和 Release。选择您想要构建的配置。\n然后使用 CMake 菜单选项选择您想要构建的组件。\n默认情况下，Visual Studio 将配置 CMake 构建到源代码树之外，默认使用用户主目录中的一个构建目录，并且将 GUID（全球唯一标识符）作为目录路径的一部分。您将在 Visual Studio 的输出窗口中看到生成的路径，例如：\n工作目录：C:\\Users\\Sean\\CMakeBuilds\\3f00c6d9-d323-5a32-8a90-665138817fd4\\build\\x64-Release 例如，如果您不想将 CMake 构建文件放在主目录中，可以通过 CMake → 更改 CMake 设置 菜单选项生成一个 CMakeSettings.json 文件，并编辑 buildRoot 和 installRoot 属性。\n最后，Visual Studio 还支持执行 JSBSim 测试。\n运行程序 这里所指的 JSBSim 仓库所在的路径将被称为 \u003cJSBSim-root-dir\u003e。如果您是从源代码构建了 JSBSim，您将在 \u003cJSBSim-root-dir\u003e/src/ 子目录下找到可执行文件（在 Linux 上为 JSBSim，在 Windows 上为 JSBSim.exe）。这是 JSBSim 独立应用程序，您可能希望将其复制到根目录中：\n\u003cJSBSim-root-dir\u003e$ cp src/JSBSim . 运行独立 JSBSim 应用程序时，可能会指定多个选项。\n\u003cJSBSim-root-dir\u003e$ JSBSim 用法（方括号中的项是可选的）： JSBSim [脚本名称] [输出指令文件名称] \u003c选项\u003e 选项： --help 返回使用信息 --version 返回版本号 --outputlogfile=\u003c文件名\u003e 设置/替换数据日志文件的名称 --logdirectivefile=\u003c文件名\u003e 设置数据日志指令文件的名称 --root=\u003c路径\u003e 设置 JSBSim 根目录（即 `src/` 所在目录） --aircraft=\u003c文件名\u003e 设置要模拟的飞机名称 --script=\u003c文件名\u003e 指定要运行的脚本 --realtime 指定按实际世界时间运行 --nice 指示 JSBSim 以低 CPU 使用率运行 --suspend 指定在初始化后暂停仿真 --initfile=\u003c文件名\u003e 指定要使用的初始化文件 --catalog 指示 JSBSim 列出该模型的所有属性 （--catalog 可以与 --aircraft 选项一起在命令行中指定， 或单独指定，同时指定飞机名称，例如 --catalog=c172） --end-time=\u003c时间\u003e 指定仿真结束时间（例如，time=20.5） --property=\u003cname=value\u003e 设置属性的值。 例如：--property=simulation/integrator/rate/rotational=1 注意：选项后跟文件名时，等号两边不能有空格 您可以通过提供脚本名称来运行 JSBSim：\n\u003cJSBSim-root-dir\u003e$ JSBSim --script=scripts/c1723.xml TODO\n完善页面内容。\n那么，您想模拟这架飞机的飞行吗？\n获取支持 获取 JSBSim 支持的最佳方式是注册 GitHub 账户并 关注 JSBSim 仓库：github.com/JSBSim-Team/jsbsim。您可以订阅单独的对话，包括问题（issues）、拉取请求（pull requests）和团队讨论，即使您没有关注该仓库或不是讨论所在团队的成员。如果您不再对某个对话感兴趣，可以随时取消订阅未来的通知。\n要了解更多信息，请阅读此指南。",
    "description": "旨在让用户和开发者了解JSBSim软件的所有功能。",
    "tags": [],
    "title": "JSBSim Quickstart",
    "uri": "/uas/fix_wing_uav_flight_sim/jsbsim_quickstart/index.html"
  },
  {
    "breadcrumb": "FlitSoft Docs \u003e  Visualization",
    "content": "原文链接\n1、引言 Tacview 1.5引入了一种新的通用公共文件格式。目的是要克服以前格式的复杂性，同时使其功能更强大。\n和之前一样，这个新的文件格式仍是以纯[UTF-8]文本编写。这样，可以很容易地用最简单的编程语言来导出飞行数据。 Tacview 1.4.3中引入了调试日志，它的语法很容易被阅读，现在很容易诊断出任何输出问题。这种新格式非常简单，如果数据量不是天文数字的话甚至都可以用手工编写！\n尽管格式简单，但它提供了一种非常强大的方式来实时设置和更改战场上任何物体的任何属性。例如，现在可以即时更改联盟、颜色甚至对象的类型！同样，您可以轻松设置和更改全局属性，例如天气。\n重要的是要注意，Tacview尚不支持的数据将保留并在原始遥测窗口中可见。如果您认为重要数据应由Tacview本地支持并显示，请随时与我们联系。\n2、ACMI 2.1 文件格式入门 先从最简单的文件开始：\nFileType=text/acmi/tacview FileVersion=2.1 首先任何ACMI文件中必须具有上述两行强制性的文件头。 这个文件头告诉Tacview期望使用哪种格式。 后面的任何数据都是可选的。\n当然从道理上说，即使Tacview会正常加载这个空文件，但我们也需要更多数据才能使其有用！ 这是一个更有意义的文件：\nFileType=text/acmi/tacview FileVersion=2.1 0,ReferenceTime=2011-06-02T05:00:00Z #47.13 3000102,T=41.6251307|41.5910417|2000.14,Name=C172 为了更好地理解这种结构，我们需要知道，除了其头两行的文件头之外，文件的每一行都可以是：\n符号＃后的数字表示相对于ReferenceTime以秒为单位的一个新的时间帧 对象ID（在此示例中为0和3000102），后跟任意多个用逗号分隔的属性，并使用等号 =为每个属性赋予一个新值。 第三种可能性（此处未显示 ），以减号 - 开头的行，后面跟着的是我们要从战场中删除的对象ID（可能被摧毁或超出记录范围）。 下面让我们详细了解每一行的语法：\n0,ReferenceTime=2011-06-02T05:00:00Z 此行将值 2011-06-02T05:00:00Z 赋予给ID=0的始终是全局对象“零”的ReferenceTime属性。换句话说：此行定义用于确定整个飞行记录的基准/参考时间。 为了更好地理解这个含义，让我们看一下接下来这行：\n#47.13 该行定义了一个相对于ReferenceTime的时间帧（以秒为单位）。 在这种情况下，这意味着以下事件或属性发生在ReferenceTime + 47.13秒⇒2011-06-02T05:00:00Z + 47.13⇒2011-06-02T05:00:47.13Z\n再看下一行：\n3000102,T=41.6251307|41.5910417|2000.14,Name=C172 该行定义了对象3000102的两个属性。为节省空间，对象ID以十六进制表示，没有任何前缀或前导零。\n第一个属性T（代表Transform）是一种特殊的属性，用于定义空间中的对象坐标。稍后我们将了解T支持哪些语法。现在，我们仅关注这种情况：T =经度|纬度|高度。\n请注意，纬度和经度以度表示。正值朝北和朝东。由于整个文件始终采用公制，因此高度以米[MSL]表示（海平面以上，在某些国家中也称为ASL）。\n后面的属性名称显然定义了对象名称Name是C172，这是指定Cessna 172飞机的一种缩写。\n创建飞行记录的所有基本知识就是这些了，然后我们将这个飞机向东移动一点。为此，我们可以简单地在文件中添加另一帧：\n#49 3000102,T=41.626|| 如所见，我们在2011-06-02T05:00:49Z的时间帧为飞机定义了新的经度值41.626。\n可能已经注意到，我们不需要再次指定飞机名称，只是因为自上条记录以来就没有改变过！ 与上一条记录的另一个区别是我们省略了纬度和海拔参数，因为它们也没有改变。 在生成长途飞行数据时，这有助于节省大量空间。 虽然飞机通常机动性很强，但这种优化特别适用于可以静止不动或时不时移动的地面物体。\n3、文件结构详解 为更好地了解ACMI文件的结构，下面让我们一起总结一下文件的要求和与文件格式有关的一些技巧：\n3.1 要求 文本数据必须以UTF-8格式写入。 从而文本属性就支持所有语言。 所有数据都以公制表示，以米为单位，如用米每秒数表示速度、用度表示角度、UTC时间等。 对象ID使用64位十六进制数字表示（不带前缀或前导零以节省空间） 对象0用于定义全局属性（如ReferenceTime或Briefing） 当要赋予一个包含逗号的文本属性时，必须在其前面加上转义字符 \\，以便Tacview不会将其解释为字符串的结尾。 Briefing=Here is a text value\\, which contains an escaped comma in it! 3.2 技巧 为了节省空间，强烈建议仅使用LF \\n字符结束行。 使用UTF-8 字节顺序标记（BOM ）标头为文本数据添加前缀码会更干净。 整个文本数据可以包装在zip或7z容器中，以节省带宽或磁盘空间。 数据可以乱序显示， Tacview会在内存中重新排序。 4、对象坐标 现在，让我们仔细看看对象坐标的不同表示法。 为了优化文件大小，Tacview提供了四种不同的表示法。\n这是两个示例：导出一个子弹坐标时，我们不需要有关其旋转角度的任何数据。 相反的例子是飞行模拟器中的飞机在像Falcon 4.0这样的平面世界中飞行：在这种情况下，为了获得准确的重放，我们需要导出飞机在平面世界中的原始位置、旋转以及在球形的世界的坐标 。 这样，飞机不仅可以在Tacview的球形世界中正确显示，而且遥测计算也可在对象的原始坐标系中完成，因此屏幕上见到的数字将与在原始飞行模拟器中看到的数字匹配。\nObject Position Syntax Purpose T = Longitude | Latitude | Altitude 球形世界中的简单对象（通常是子弹之类的次要对象）。 也可以与没有旋转信息的低端数据源（如GPX文件）相关。 T = Longitude | Latitude | Altitude | U | V 来自平面世界坐标的简单对象。 U＆V代表本机x和y。 即使原始坐标以英尺为单位，也不要忘记换算为以米为单位。 海拔高度不重复省略掉了，因为原始世界坐标和球形世界坐标都一样。 T = Longitude | Latitude | Altitude | Roll | Pitch | Yaw 球形世界中的复杂对象。 飞机向右滚转时，滚转为正。 起飞时俯仰为正。 偏航角相对于正北的顺时针方向夹角。 T = Longitude | Latitude | Altitude | Roll | Pitch | Yaw | U | V | Heading 来自平面世界的复杂对象。 和之前一样。 航向（Heading）是相对于平面世界正北的偏航角。 之所以需要这样做，是因为由于投影误差，原始世界的北通常与球形世界的北并不一致。 请记住，您可以省略自上次以来未更改的组件。 这样可以节省很多空间。\n如果某些数据丢失（例如，对象旋转），Tacview将会去尽量模拟它，以提供良好的重放。 与优化无关，在对象生命周期中，应为每个对象保留相同的数据表示法。 如果在某一时刻使用了不同的表示法，Tacview将会把对象升级为更复杂的表示法。 但是，由于最初缺乏数据，最终结果可能难以预料。\n5、全局属性 我们已经看到，最重要的全局属性之一是ReferenceTime。 显然，您可以在飞行记录中注入许多其他元数据，以使重放更加详细。\n文本属性 Property Name Meaning DataSource 源模拟器，控制台或文件格式。\nDataSource=DCS 2.0.0.48763 DataSource=GPX File DataRecorder 用于记录数据的软件或硬件。\nDataRecorder=Tacview 1.5 DataRecorder=Falcon 4.0 ReferenceTime 当前任务的基准时间（UTC）。 该时间与每个帧偏移（以秒为单位）相结合，以获得每个数据样本最终的绝对UTC时间。\nReferenceTime=2011-06-02T05:00:00Z RecordingTime 记录（文件）创建（UTC）时间。\nRecordingTime=2016-02-18T16:44:12Z Author 创建此记录的作者或操作员。\nAuthor=Lt. Cmdr. Rick 'Jester' Heatherly Title 任务/飞行的标题或名称。\nTitle=Counter Attack Category 飞行/任务的类别。\nCategory=Close air support Briefing 包含飞行/任务简介的自由文本。 Briefing=Destroy all SCUD launchers Debriefing 包含任务报告的自由文本。\nDebriefing=Managed to stay ahead of the airplane. Comments 关于飞行的自由评论。 不要忘记转义任何要插入注释中的行尾字符。\nComments=Part of the recording is missing because of technical difficulties. 5.2 数字属性 Property Name Unit Meaning ReferenceLongitude ReferenceLatitude deg 这些属性用于通过将坐标以一个中间点为原点来减小文件大小。 它们会被加到每个对象的经度和纬度来求得最终坐标。 ReferenceLongitude=-129 ReferenceLatitude=43 5.3 事件 事件可用于将任何类型的文本、记号和调试信息注入飞行记录中。 它们有点特殊：它们像属性一样被声明，但是与属性不同，您可以在同一帧中声明多个事件而不会覆盖前一个事件。\n这是有关如何注入事件的示例：\n#8.62 0,Event=Message|3000100|Here is a generic event linked to the object 3000100 0,Event=Bookmark|Here is a bookmark to highlight a specific part of the mission! #8.72 0,Event=Debug|Here is some debug text, visible only with the /Debug:on command line option 事件声明的结构：\nEvent = EventType | FirstObjectId | SecondObjectId | ... | EventText 对于每个事件，我们必须首先声明事件的类型（例如：标记），然后可选地声明有关对象的ID。 例如，当用户双击事件时，Tacview将使用这些ID将摄像机自动围绕相关对象居中。 最后一部分是强制性的文本信息。 虽然可以提供空白文本，但是建议您提供有用的信息，从而可以充分利用报告。\n这是Tacview当前支持的不同类型的事件：\nEvent Name Meaning Message 通用事件。0,Event=Message|705|Maverick has violated ATC directives Bookmark 记号在时间线和事件日志中突出显示。 它们很容易发现，并且易于突出飞行中的某些部分，例如轰炸或受训者最后着陆时。0,Event=Bookmark|Starting precautionary landing practice Debug 调试事件高亮显示，很容易在时间轴和事件日志中发现。 由于必须将它们用于开发目的，因此仅在使用命令行启动Tacview时带上参数/Debug:on时才会显示它们0,Event=Debug|327 active planes LeftArea 此事件对于指定何时将飞机（或任何物体）从战场上完全地移走（不是被摧毁）非常有用。 这样可以防止Tacview错误生成Destroyed事件。0,Event=LeftArea|507| Destroyed 当物体被正式摧毁时。0,Event=Destroyed|6A56| TakenOff 由于Tacview可能无法始终正确地自动检测起飞事件，因此在飞行记录中手动添加此事件可能很有用。0,Event=TakenOff|2723|Col. Sinclair has taken off from Camarillo Airport Landed 由于Tacview可能无法始终正确地自动检测降落事件，因此在飞行记录中手动添加此事件可能很有用。0,Event=Landed|705|Maverick has landed on the USS Ranger Timeout 主要用于现实世界中的训练报告，以指定武器（通常是导弹）何时达到或错过其目标。 Tacview将在射击日志以及3D视图中报告射击结果。 大多数参数是可选的。 SourceId指定发射武器的对象，而TargetId为指定的射击目标。 即使显示的结果可能是海里，也必须以米为单位指定靶心坐标。 必须使用独立于此事件的适当属性来明确（手动）销毁或禁用目标。0,Event=Timeout|SourceId:507|AmmoType:FOX2|AmmoCount:1|Bullseye:50/15000/2500|TargetId:201|IntendedTarget:Leader|Outcome:Kill 6、对象属性 从Tacview 1.5开始，可以实时设置和更改任何对象属性。 即使新属性可能并不总是在3D视图中可见，您也可以始终在原始遥测窗口中查看当前选定对象的每个属性的当前值。\nTacview 1.7引入了一个新的对象 database ，可以预定义Type和Name所需的任何对象属性。 例如，您可以在该数据库中预定义F-16C的默认形状。 如果遥测文件中未定义Shape属性值，则Tacview将使用数据库中存储的值，并在3D视图中显示F-16C的自定义3D模型。\n通过阅读专用文档.了解如何更新和扩展Tacview数据库。\n6.1 文本属性 Property Name Meaning Name 对象名称应为每个对象使用最通用的符号。 强烈建议使用ICAO或北约名称，例如：C172或F A-18C。 这将有助于Tacview将每个对象与其数据库中的相应条目相关联。 只有类型Type和名称Name是不能在Tacview数据库中预定义的属性。Name=F-16C-52 Type 对象类型是使用标签构建的。 与以前的独占类型相比，这使对象管理更加强大和透明。 （请参阅下面的受支持类型列表）。只有类型Type和名称Name是不能在Tacview数据库中预定义的属性。Type=Air+FixedWing AdditionalType 此处定义的所有标签都将添加到当前对象类型中。 这对强制在遥测数据中未明确定义的对象类型很有用。 例如，您可以使用此属性为来自Garmin csv文件（通常不包含任何类型声明）的Cessna 172遥测数据自动设置FixedWing标签。 出于明显的原因，此属性只能在Tacview数据库中使用，而在遥测文件中则不能使用。\u003cAdditionalType\u003eAir+FixedWing\u003c/AdditionalType\u003e Parent 父级十六进制对象ID。 例如，可用于关联导弹（子对象）及其发射飞机（父对象）。 Parent=2D50A7 Next 跟随对象的十六进制ID。 通常用于将航路点链接在一起。Next=40F1 ShortName 该缩写名称将显示在3D视图中，并且在任何其他情况下都将以较小的空间显示对象名称。 通常在Tacview数据库中定义。 不应在遥测数据中定义。ShortName=A-10C LongName 更详细的对象名称，用在比杂乱的3D视图有更多空间但空间不足以显示完整详细名称的小窗口中。 为了便于阅读，建议首先以短名称（通常是北约代码的缩写）开头，然后是对象昵称/北约名称。 通常在Tacview数据库中定义。 不应在遥测数据中定义。LongName=A-10C Thunderbolt II FullName 完整的对象名称，通常在窗口和其他日志中显示，只要有足够的空间可以显示很多数据而不会出现混乱的情况。 通常在Tacview数据库中定义。 不应在遥测数据中定义。FullName=Fairchild Republic A-10C Thunderbolt II CallSign 呼叫符号将优先于对象名称（有时是飞行员名称）显示，尤其是在3D视图和选择框中。 这对于任务报告很方便，在这些任务报告中，呼号比飞机名称更有意义。CallSign=Jester Registration 飞机注册号（又名尾号）Registration=N594EX Squawk 当前的应答器代码。 任何代码都是可能的，没有像旧的4位数字应答器那样的限制。Squawk=1200 Pilot 飞机驾驶员的指挥名称。Pilot=Iceman Group 对对象所属的组进行分组。 用于将对象分组在一起。 例如，一个F-16编队一起飞过CAP。Group=Springfield Country ISO 3166-1 alpha-2 国家代码 Country=us Coalition 联军属性（敌军、友军）Coalition=Allies Color 可以是以下颜色之一：Red, Orange, Green, Blue, Violet。 颜色是预定义的，以确保在所有情况下都能清晰显示整个战场。Color=Blue Shape 3D模型的文件名，将用于表示3D视图中的对象。 3D模型必须为Wavefront .obj文件格式，并存储在%ProgramData%\\Tacview\\Data\\Meshes\\或%APPDATA%\\Tacview\\Data\\Meshes\\中。可以阅读专用文档，了解有关3D模型的更多信息Shape=Rotorcraft.Bell 206.obj Debug 使用/Debug:on命令行参数启动Tacview时，调试文本在3D视图中可见。Debug=ObjectHandle:0x237CB9 Label 可在3D视图和遥测窗口中显示的自由实时文本（向最终用户提供其他信息）Label=Lead aircraft FocusedTarget 该对象当前瞄准的目标（通常用于指定激光束目标对象，也可用于显示飞行员当前瞄准的目标）FocusedTarget=3001200 LockedTarget 首要目标十六进制ID（可以使用任何设备锁定，例如雷达，IR，NVG等）LockedTarget=3001200 6.2 数字属性 Property Name Unit Meaning Importance ratio 比率越高，对象就越重要（例如，本地模拟的飞机可能是1.0的重要因子）Importance=1 Slot index 机群中的飞机地位（最低的是领导者） Slot=0 Disabled boolean 指定禁用一个对象（通常是战斗结束）而不将其销毁。 这对于战斗训练和射击记录特别有用。Disabled=1 Length m 对象长度。 在显示建筑物时特别有用。Length=20.5 Width m 对象宽度。 在显示建筑物时特别有用。Width=10.27 Height m 对象高度。 在显示建筑物时特别有用。 Height=4 Radius m 对象边界球半径。 可用于定义自定义爆炸，烟雾/手榴弹半径。 可以用于动画。Radius=82 IAS m/s 指示空速 IAS=69.4444 CAS m/s 标定空速 CAS=250 TAS m/s 真空速 TAS=75 Mach ratio 马赫数 Mach=0.75 AOA deg 迎角 AOA=15.7 AGL m 物体高于地面的高度 AGL=1501.2 HDG deg 飞机的航向。 如果没有可用的滚转和俯仰数据，则此属性可用于指定偏航，同时在3D视图中保持完整的旋转仿真。 HDG=185.3 HDM deg 飞机的磁航向。 相对于局部磁北偏航。 HDM=187.3 Throttle ratio 主/发动机1号油门手柄位置（对于加力燃烧室，该值可以\u003e 1，对于倒档来说可以\u003c0） Throttle=0.75 Afterburner ratio 主/引擎1加力燃烧器状态 Afterburner=1 AirBrakes ratio 空气制动器状态AirBrakes=0 Flaps ratio 襟翼位置Flaps=0.4 LandingGear ratio 起落架状态 LandingGear=1 LandingGearHandle ratio 起落架手柄位置LandingGearHandle=0 Tailhook ratio 抓钩状态 Tailhook=1 Parachute ratio 降落伞状态（不要误认为DragChute） Parachute=0 DragChute ratio 拖曳伞状态DragChute=1 FuelWeight to FuelWeight9 kg 当前每个油箱中可用的燃油量（最多支持10个油箱）。FuelWeight4=8750 FuelVolume to FuelVolume9 l 当前每个油箱中可用的燃油量（最多支持10个油箱）。 FuelVolume=75 FuelFlowWeight to FuelFlowWeight8 kg/hour 每个引擎的燃油流量（最多支持8个引擎）。 FuelFlowWeight2=38.08 FuelFlowVolume to FuelFlowVolume8 l/hour 每个引擎的燃油流量（最多支持8个引擎）。FuelFlowVolume2=53.2 RadarMode number 雷达模式 (0 = off) RadarMode=1 RadarAzimuth deg 相对于飞机方向的雷达方位角（航向） RadarAzimuth=-20 RadarElevation deg 相对于飞机方向的雷达仰角 RadarElevation=15 RadarRange m 雷达扫描范围 RadarRange=296320 RadarHorizontalBeamwidth deg 雷达水平波束宽度 RadarHorizontalBeamwidth=40 RadarVerticalBeamwidth deg 雷达垂直波束宽度 RadarVerticalBeamwidth=12 LockedTargetMode number 首要目标锁定模式 (0 = no lock/no target) LockedTargetMode=1 LockedTargetAzimuth deg 相对于飞机方向的首要目标方位角（航向）LockedTargetAzimuth=14.5 LockedTargetElevation deg 相对于飞机方向的首要目标俯仰角 LockedTargetElevation=0.9 LockedTargetRange m 距飞机的主要目标距离LockedTargetRange=17303 EngagementMode EngagementMode2 number 开关机状态（例如，当SAM站点关闭其雷达时）(0 = off) EngagementMode=1 EngagementRange EngagementRange2 VerticalEngagementRange VerticalEngagementRange2 m 防空单元的有效范围。 这是将在3D视图中显示的球体的半径。 通常用于SAM和AAA单位，但这也可能与军舰有关。 EngagementRange = 2500您可以选择指定垂直有效范围以绘制蛋形有效气泡形状。VerticalEngagementRange=1800 RollControlInput PitchControlInput YawControlInput ratio 原始玩家HOTAS /Yoke的真实位置（飞行模拟输入设备）PitchControlInput=0.41 RollControlPosition PitchControlPosition YawControlPosition ratio 模拟（带有响应曲线）或现实驾驶舱中的HOTAS/Yoke位置 PitchControlPosition=0.3 RollTrimTab PitchTrimTab YawTrimTab ratio 每个轴的修剪位置 Trim position for each axisPitchTrimTab=-0.15 AileronLeft AileronRight Elevator Rudder ratio 控制面在飞机上的位置 Elevator=0.15 Visible boolean 此标志对于从3D视图隐藏特定对象很有用。 可以用于战争迷雾效果，或防止显示虚拟对象。Visible=0 PilotHeadRoll PilotHeadPitch PilotHeadYaw deg 在驾驶舱内飞行员头部方位相对于飞机方位的方位PilotHeadPitch=12 6.3 对象类型 (aka Tags) 现在，可以使用标签的自由组合来定义对象类型。 标签越多，定义的对象越准确。 标签以加号+分隔。 这里有些例子：\nObject Kind Type (Tags) Aircraft Carrier Type=Heavy+Sea+Watercraft+AircraftCarrier F-16C Type=Medium+Air+FixedWing Bicycle Type=Light+Ground+Vehicle AIM-120C Type=Medium+Weapon+Missile Waypoint Type=Navaid+Static+Waypoint 这是当前支持的标签的列表。 Tacview将使用它们进行显示和分析。\nUse Tags Class Air\nGround\nSea\nWeapon\nSensor\nNavaid\nMisc Attributes Static\nHeavy\nMedium\nLight\nMinor Basic Types FixedWing\nRotorcraft\nArmor\nAntiAircraft\nVehicle\nWatercraft\nHuman\nBiologic\nMissile\nRocket\nBomb\nTorpedo\nProjectile\nBeam\nDecoy\nBuilding\nBullseye\nWaypoint Specific Types Tank\nWarship\nAircraft\nCarrier\nSubmarine\nInfantry\nParachutist\nShell\nBullet\nFlare\nChaff\nSmokeGrenade\nAerodrome\nContainer\nShrapnel\nExplosion 以下是推荐的常见类型（标记的组合），您应该使用它们来描述大多数对象以在Tacview 1.x中显示：\nType Tags Plane Air + FixedWing Helicopter Air + Rotorcraft Anti-Aircraft Ground + AntiAircraft Armor Ground + Heavy + Armor + Vehicle Tank Ground + Heavy + Armor + Vehicle + Tank Ground Vehicle Ground + Vehicle Watercraft Sea + Watercraft Warship Sea + Watercraft + Warship Aircraft Carrier Sea + Watercraft + AircraftCarrier Submarine Sea + Watercraft + Submarine Sonobuoy Sea + Sensor Human Ground + Light + Human Infantry Ground + Light + Human + Infantry Parachutist Ground + Light + Human + Air + Parachutist Missile Weapon + Missile Rocket Weapon + Rocket Bomb Weapon + Bomb Projectile Weapon + Projectile Beam Weapon + Beam Shell Projectile + Shell Bullet Projectile + Bullet Ballistic Shell Projectile + Shell + Heavy Decoy Misc + Decoy Flare Misc + Decoy + Flare Chaff Misc + Decoy + Chaff Smoke Grenade Misc + Decoy + SmokeGrenade Building Ground + Static + Building Aerodrome Ground + Static + Aerodrome Bullseye Navaid + Static + Bullseye Waypoint Navaid + Static + Waypoint Container Misc + Container Shrapnel Misc + Shrapnel Minor Object Misc + Minor Explosion Misc + Explosion 7、注释 为了在导出程序的调试过程中提供帮助，可以在文件的任何行加上双斜杠//作为前缀，与C ++一致。\n// This line and the following are commented // 3000102,T=41.6251307|41.5910417|2000.14,Name=C172 加载文件时，Tacview将忽略这些行。 注释不保留。 您会注意到，下次您从Tacview保存文件时，它们将被丢弃。 如果要包括保留的调试信息，则可以使用前面在全局属性中描述的专用的Debug Event 。\n由于加载性能的考虑，只能在每行的开头插入注释。",
    "description": "This summary is independent of the content.",
    "tags": [],
    "title": "Tacview Technical Reference",
    "uri": "/visual/tacview/index.html"
  },
  {
    "breadcrumb": "FlitSoft Docs \u003e  EM \u003e  Communication",
    "content": "地空测控链路计算模型 版本： 2.0\n日期： 2025年5月29日\n1. 引言 本文档概述了地空测控（M\u0026C）链路的计算模型设计，主要针对无人机（UAV）。无人机数据链用于实现无人机与地面控制站（GCS）之间的遥控、遥测、跟踪、定位及信息传输。该模型侧重于通过考虑视距限制、信号传播特性、接收机灵敏度及多普勒频移影响等因素，评估链路的连通性和性能。\n模型旨在为通信可靠性和有效性评估提供理论依据，使用指标包括比特误码率（BER）、最大有效传输速率和最大有效通信距离。报告详细说明了判断链路状态（连接或中断）的数学公式和逻辑流程。\n2. 系统概述 无人机数据链通常作为全双工、安全、抗干扰的点对点通信系统运行。优先使用视距（LOS）链路，当无人机处于视距范围内时，上行链路和下行链路均切换至视距路径。\n2.1. 链路工作流程 系统包含两个主要通路：\n上行链路（遥控）： 地面控制指令经过多路复用、加密、信道编码、扩频（如DSSS）、调制（如BPSK）及射频上变频处理，随后放大并发射至无人机。 下行链路（遥测）： 无人机将遥测数据传输至地面控制站。由于扩频技术在高速数据传输中的应用难度及指令优先级，遥测链路通常不采用扩频技术。 2.2. 抗干扰技术 上行遥控常用的抗干扰方法包括信道编码（如码率为1/2、约束长度为7的卷积编码）、直接序列扩频（DSSS）及载波调制（如BPSK）。扩频技术提升了抗干扰能力，同时隐藏信号频谱，降低被探测和截获的概率。\n3. 链路连通性分析模型 本模型核心为通过依次评估多个关键因素确定链路连通状态。流程如流程图所示，包括计算最大视距、接收信号强度、噪声门限及多普勒频移对数据速率的影响。\n3.1. 最大视距距离 ($d_m$) 首先判断无人机是否处于最大视距范围内。公式如下：\n不考虑大气折射时： $d_{max}(\\text{km}) = 3.57 (\\sqrt{h_1(\\text{m})} + \\sqrt{h_2(\\text{m})})$ 考虑标准大气折射时： $d_{max}(\\text{km}) = 4.12 (\\sqrt{h_1(\\text{m})} + \\sqrt{h_2(\\text{m})})$ 其中，$h_1$为地面站天线高度（米），$h_2$为无人机飞行高度（米）。 若地面站与无人机实际距离$D$超过$d_m$，则链路判定为中断，否则继续后续分析。\n3.2. 接收信号电平 ($A_r$) 3.2.1 传播损耗 ($L_{\\Sigma}$) 从发射机到接收机的信号传输过程中，除基本的自由空间路径损耗（$L_{bf}$）外，还存在多种额外损耗，这些额外损耗统称为 $L_{\\Sigma}$，对接收信号强度影响显著。低仰角时采用不规则地形模型（ITM），高仰角时采用卫星通信大气传播损耗模型。\n传播损耗可表示为各部分损耗之和：\n$$ L_{\\Sigma} (dB) = L_{bf} (dB)+L_a (dB) + L_{atm} (dB) + L_d (dB) + L_{mp} (dB) + L_o (dB) $$其中：\n$L_{bf}$：自由空间路径损耗 $L_a$：大气吸收损耗 $L_{atm}$：水象体（雨、云、雾、雪）损耗 $L_d$：绕射损耗 $L_{mp}$：多径反射或衰落余量 $L_o$：其他杂项损耗 对于一个全面的链路预算，需要根据工作频率、地理位置、气象统计数据、地形数据和天线特性来估算每个相关的损耗分量。\n3.2.1.1 自由空间路径损耗\n$L_{fs}$ 所代表的是“自由空间路径损耗”（Free‐Space Path Loss），其含义是在无其它障碍、纯真空或均匀介质中，信号由于球面波前展开而必然产生的衰减。公式各项含义如下：\n$$ L_{fs} = 20\\log_{10}(d) + 20\\log_{10}(f) + 20\\log_{10}\\!\\Bigl(\\frac{4\\pi}{c}\\Bigr) $$ $20\\log_{10}(d)$ 表示距离衰减分量，$d$ 为传播距离，单位通常是米（m）。球面波前的面积随距离平方增长，故以对数形式表现为 $20\\log_{10}d$。\n$20\\log_{10}(f)$ 表示频率依赖性，$f$ 为载波频率，单位为赫兹（Hz）。频率越高，单位距离上的相位旋转越快，也会表现为更大的路径损耗。\n$20\\log_{10}\\!\\bigl(\\tfrac{4\\pi}{c}\\bigr)$ 这是一个常数项，其中 $c\\approx3\\times10^8$ m/s 为光速，$4\\pi$ 来自球面面积公式。计算可得\n$$ 20\\log_{10}\\Bigl(\\tfrac{4\\pi}{c}\\Bigr) = 20\\log_{10}(4\\pi) + 20\\log_{10}\\!\\bigl(c^{-1}\\bigr) \\approx +21.99 -169.54 \\approx -147.55\\;\\text{dB}. $$当 $d$ 以米、$f$ 以赫兹代入时，这个常数即可一次性体现“$\\tfrac{4\\pi}{c}$”的量纲转换。\n当将 $d$ 以千米（km）、$f$ 以兆赫（MHz）代入时，常用常数变为 +32.45 dB，于是有：\n$$ L_{fs}(\\text{dB}) = 20\\log_{10}(d_{\\rm km}) + 20\\log_{10}(f_{\\rm MHz}) + 32.45 $$自由空间路径损耗还可采用以下公式简化计算 ($L_{fs}$)：\n$$ L_{fs}(\\mathrm{dB}) = 20\\log_{10}\\!\\Bigl(\\frac{4\\pi d}{\\lambda}\\Bigr) $$ 典型频率：2.4 GHz，$\\lambda=0.125\\,\\mathrm{m}$ 示例：$d=10\\,\\mathrm{km}$ 时，\n$L_{fs}\\approx20\\log_{10}(4\\pi\\times10^4/0.125)\\approx114\\,\\mathrm{dB}$ 3.2.1.2 大气吸收损耗 大气吸收损耗 ($L_a$)：主要因大气中氧气和水汽吸收电磁波能量引起。\n计算模型：采用ITU-R P.676等规范，计算氧气（$\\gamma_o$）和水汽（$\\gamma_w$）的频率、气压、温度及水汽密度相关的比衰减（单位dB/km），有效路径长为$d_{\\mathrm{eff}}$，有\n$$ L_a = (\\gamma_o + \\gamma_w) \\times d_{\\mathrm{eff}} $$其中，地面链路$d_{eff} \\approx d$，无人机斜距$d_{\\mathrm{eff}}$依仰角和高度调整。\n典型参数：\n氧气吸收峰值约60 GHz和118 GHz； 水汽吸收峰值约22.2 GHz和183 GHz； 频率低于10 GHz时（如常用2.4 GHz），氧气吸收通常\u003c0.01 dB/km，大于10GHz时，水汽吸收随湿度变化；100 km路径约1~2 dB； 标准大气参数：压力1013.25 hPa，温度15℃（288.15 K），水汽密度7.5 g/m³，随高度变化 氧气比衰减 ($\\gamma_o$) 参考值\n以下提供的数值主要依据国际电信联盟（ITU）的建议书ITU-R P.676，该标准是计算大气气体衰减的权威参考。\n氧气的比衰减 ($\\gamma_o$) 主要与频率、大气压力、温度有关，受湿度的影响相对较小。以下表格给出了在特定条件下（通常是海平面标准大气压和一定温度下的干燥空气）的一些典型频率下的 $\\gamma_o$ 参考值。\n不同频率下氧气比衰减 ($\\gamma_o$) 参考值 (dB/km) (条件：干燥空气，海平面压力 1013.25 hPa，温度 15°C 或 20°C，具体参考ITU-R P.676模型输出)\n频率 (GHz) $\\gamma_o$ (dB/km) 近似值 备注 1 ~0.005 - 0.007 2.4 ~0.006 - 0.008 文档中示例频率 10 ~0.007 - 0.010 22.2 (水汽峰) ~0.015 - 0.020 氧气在此处贡献相对较小 30 ~0.02 - 0.03 40 ~0.06 - 0.08 开始接近吸收带 50 ~0.8 - 1.5 进入60 GHz吸收带的边缘 54 ~4 - 5 57 ~10 - 12 60 ~14 - 16 氧气主要吸收峰 63 ~10 - 12 66 ~4 - 5 70 ~1 - 1.5 离开60 GHz吸收带 90 ~0.2 - 0.3 100 ~0.3 - 0.4 118.75 ~1.5 - 2.5 氧气次级吸收峰 150 ~0.2 - 0.3 200 ~0.25 - 0.35 300 ~0.3 - 0.5 说明：\n数值的近似性： 上表中的数值是近似值，用于提供一个大致的量级概念。精确的 $\\gamma_o$ 值需要使用ITU-R P.676中给出的详细模型和算法，并输入实际的大气参数（温度、压力）进行计算。 吸收峰值： 氧气的主要吸收峰位于60 GHz附近，还有一个较弱的吸收峰在118.75 GHz。在这些频率附近，衰减会急剧增大。 压力和温度的影响： 大气压力和温度对 $\\gamma_o$ 有显著影响。通常，压力降低（如在高海拔地区），吸收峰会变窄且峰值略有降低；温度变化也会引起谱线的宽度和强度的变化。 实际应用： 在进行精确的链路预算时，强烈建议使用ITU-R P.676中提供的计算程序或详细图表，并根据实际链路所处的具体环境条件（如海拔高度、当地平均气温和气压）进行计算。 水蒸气的比衰减 ($\\gamma_w$) 参考值\n这些参考值主要依据国际电信联盟（ITU）的建议书 ITU-R P.676。\n水蒸气的比衰减 ($\\gamma_w$) 对频率、水蒸气密度（即湿度）、大气温度和压力的依赖性很强，尤其是在水蒸气吸收峰（如22.235 GHz, 183.31 GHz等）附近。\n为了说明湿度条件，定义以下三种情况的水蒸气密度 ($\\rho_w$)：\n干燥 (Dry): $\\rho_w = 1 \\text{ g/m}^3$ (代表非常干燥的空气，或较高海拔地区) 中等 (Medium/Standard): $\\rho_w = 7.5 \\text{ g/m}^3$ (常作为标准参考湿度，例如在海平面15°C，约60%相对湿度时) 潮湿 (Humid): $\\rho_w = 15 \\text{ g/m}^3$ (代表非常潮湿的环境，如热带地区或夏季湿热天气) 以下表格给出了在特定条件下（通常是海平面标准大气压和一定温度下）的一些典型频率下的 $\\gamma_w$ 近似参考值 (dB/km)。\n不同频率下水蒸气比衰减 ($\\gamma_w$) 参考值 (dB/km) (条件：海平面压力 1013.25 hPa，温度 15°C，具体参考ITU-R P.676模型输出)\n频率 (GHz) $\\gamma_w$ (干燥, 1 g/m³) (dB/km) $\\gamma_w$ (中等, 7.5 g/m³) (dB/km) $\\gamma_w$ (潮湿, 15 g/m³) (dB/km) 备注 1 ~0.0002 - 0.0004 ~0.0015 - 0.003 ~0.003 - 0.006 10 ~0.001 - 0.002 ~0.008 - 0.015 ~0.015 - 0.03 15 ~0.003 - 0.005 ~0.02 - 0.04 ~0.04 - 0.08 22.235 ~0.025 - 0.04 ~0.18 - 0.30 ~0.35 - 0.60 水蒸气主要吸收峰 30 ~0.01 - 0.015 ~0.06 - 0.10 ~0.12 - 0.20 40 ~0.012 - 0.018 ~0.08 - 0.12 ~0.15 - 0.25 50 ~0.015 - 0.025 ~0.10 - 0.18 ~0.20 - 0.35 60 ~0.018 - 0.03 ~0.12 - 0.20 ~0.25 - 0.40 氧气吸收在此频段占主导 90 ~0.05 - 0.08 ~0.35 - 0.60 ~0.7 - 1.2 100 ~0.07 - 0.10 ~0.5 - 0.75 ~1.0 - 1.5 150 ~0.3 - 0.5 ~2.0 - 3.5 ~4.0 - 7.0 183.31 ~1.5 - 3.0 ~10 - 22 ~20 - 45 水蒸气强吸收峰 200 ~0.8 - 1.5 ~6.0 - 11 ~12 - 22 300 ~1.5 - 2.5 ~10 - 18 ~20 - 36 325.15 ~2.5 - 4.0 ~18 - 30 ~35 - 60 水蒸气较强吸收峰 说明：\n数值的近似性与湿度依赖性： 上表中的数值为近似值，旨在提供量级概念。水蒸气比衰减对水蒸气密度 ($\\rho_w$) 的依赖性非常强。在许多情况下，尤其是在远离吸收线中心且水蒸气密度不是极高时，$\\gamma_w$ 近似与 $\\rho_w$ 成正比。但在线心附近或高湿度条件下，这种线性关系可能不再精确。 温度和压力影响： 温度和压力同样影响水蒸气的吸收谱线（宽度、中心频率、强度）。上述数值通常基于海平面标准大气压和特定参考温度（如15°C或20°C）。海拔升高导致压力和温度降低，会改变吸收特性。 吸收峰： 水蒸气在22.235 GHz、183.31 GHz、325.15 GHz 等频率附近有显著的吸收峰，此外在更高频率（亚毫米波段）还有更多更强的吸收线。在这些频率附近，$\\gamma_w$ 值会急剧增大，且对水蒸气密度的变化更为敏感。 实际应用： 在进行链路预算时，获取链路所在地区的实际或统计的水蒸气密度数据至关重要。这些数据可以从当地气象部门获得，或者使用ITU-R P.836中提供的全球水蒸气密度模型。 强烈建议使用最新版ITU-R P.676建议书中提供的详细计算模型和算法，输入实际或预期的环境参数（频率、水蒸气密度、温度、压力）来获得精确的 $\\gamma_w$ 值。 中国幅员辽阔，气候多样，从干燥的西北地区到潮湿的东南沿海，水蒸气密度差异巨大。因此，在具体的链路设计中，针对特定地区和季节的湿度条件进行计算尤为重要。\n3.2.1.3 水象体损耗 水象体损耗 ($L_{atm}$) ：由云雾中水滴、雨滴及雪冰粒子的吸收和散射引起，为雨致衰减和云雾衰减之和：$L_{atm}=L_r+L_{cf}$。\n雨致衰减 ($L_r$) ：由雨滴对无线电波的吸收和散射引起。\n计算模型：ITU-R P.838规定，采用比衰减$\\gamma_R = k R^\\alpha$（dB/km），$R$为雨强（mm/h），$k$和$\\alpha$随频率及极化变化。\n$$ L_r = \\gamma_R \\times d_{eff\\_rain} $$$d_{eff\\_rain}$为有效雨路径长度。\n典型参数：\n雨强变化大，设计时参考统计雨强（如0.01%时间内的$R_{0.01}$）； 小雨R=1-5 mm/h，中雨R=5-25 mm/h，大雨R\u003e25 mm/h； 2.4 GHz时$k \\approx 0.00065$，$\\alpha \\approx 1.12$；10 GHz时$k \\approx 0.0101$，$\\alpha \\approx 1.276$； 低频（L波段1-2 GHz，S波段2-4 GHz）雨衰减轻微；高频\u003e5-10 GHz衰减显著； 例如2.4 GHz、25 mm/h雨，约0.025 dB/km；10 GHz、25 mm/h雨，约0.6 dB/km。 以下表格给出了一些典型频率下，水平极化（H）和垂直极化（V）的 $k$ 和 $\\alpha$ 近似参考值。这些值通常是基于Laws and Parsons雨滴谱分布以及20°C的雨滴温度计算得出的。对于其他极化方式（如圆极化），其 $k$ 和 $\\alpha$ 值可以由线极化的值导出。此处提供的值来源于ITU的公开标准，用于支持该雨衰模型的实际应用。\n典型频率下 $k$ 和 $\\alpha$ 的参考值 (源自 ITU-R P.838-3)\n频率 (GHz) $k_H$ $\\alpha_H$ $k_V$ $\\alpha_V$ 1 0.0000387 0.912 0.0000352 0.880 2.4 0.000650 1.121 0.000591 1.075 4 0.00175 1.308 0.00155 1.265 6 0.00454 1.327 0.00387 1.276 8 0.0101 1.276 0.00887 1.264 10 0.0188 1.217 0.0168 1.200 12 0.0302 1.172 0.0265 1.150 15 0.0540 1.128 0.0477 1.100 20 0.101 1.079 0.0897 1.040 25 0.162 1.041 0.145 1.000 30 0.232 1.005 0.215 0.963 40 0.380 0.939 0.352 0.905 50 0.504 0.893 0.479 0.868 60 0.607 0.865 0.589 0.842 70 0.690 0.845 0.672 0.824 80 0.759 0.829 0.743 0.809 90 0.820 0.816 0.805 0.797 100 0.874 0.804 0.860 0.786 说明：\n$k_H$ 和 $\\alpha_H$ 分别是水平极化时的 $k$ 值和 $\\alpha$ 值。 $k_V$ 和 $\\alpha_V$ 分别是垂直极化时的 $k$ 值和 $\\alpha$ 值。 表格中特别标注了 2.4 GHz（本文档中多普勒示例所用频率）和 60 GHz（大气吸收显著的频段）的参考值。 对于圆极化波，其 $k_C$ 和 $\\alpha_C$ 值可以通过以下近似公式计算： $k_C = [k_H + k_V + (k_H - k_V) \\cos^2\\theta \\cos(2\\tau)] / 2$ $\\alpha_C = [k_H\\alpha_H + k_V\\alpha_V + (k_H\\alpha_H - k_V\\alpha_V) \\cos^2\\theta \\cos(2\\tau)] / (2k_C)$ 其中 $\\theta$ 是路径仰角，$\\tau$ 是极化倾斜角（对于圆极化通常取 $\\tau = \\pm 45^\\circ$）。对于 $\\tau = 45^\\circ$ 且 $\\theta = 0^\\circ$（地面路径），通常可以简化近似。更简单常用的近似是取线极化值的平均。 使用注意事项：\n这些值是基于特定假设（如雨滴谱、温度）的经验或半经验值。实际应用中，如果条件有较大差异，可能需要进行修正。 ITU-R P.838建议书会定期更新，使用时应参考最新版本。 对于倾斜路径（如卫星通信或空对地通信），有效路径长度的计算也需要考虑仰角，这会影响总的雨衰。系数 $k$ 和 $\\alpha$ 本身主要由频率和极化决定。 云雾衰减 ($L_{cf}$) ：由云、雾中的液态水滴或雪花对无线电波的吸收和散射引起。\n计算模型：ITU-R P.840基于液态水含量计算比衰减$\\gamma_c$（dB/km），\n$$ L_{cf} = \\gamma_c \\times d_{eff\\_cloud} $$ 典型参数：\n云中液态水含量：0.1 g/m³（层状云）到2 g/m³（积雨云）； 雾的液态水含量：通常在0.05 g/m³ (轻雾) 到 0.5 g/m³ (浓雾)。 影响：通常在10-15 GHz以下频率时，云雾衰减没有雨衰严重，但在更高频率，或者链路长时间穿越云层及浓雾时，可能成为重要因素。雪衰减在毫米波频段影响较大。 3.2.1.4 绕射损耗 ($L_d$) 当信号路径被地形、建筑物或其他障碍物阻挡时，电波发生绕射产生损耗。\n计算模型：\nITM模型是一个综合模型，包含了不规则地形的绕射效应； 对于简单的孤立障碍物，可以使用刀锋（Knife-edge）绕射模型（基于菲涅尔-基尔霍夫 Fresnel-Kirchhoff 理论）或圆角障碍物模型（例如Vogler模型）。损耗取决于菲涅尔参数 $v$，该参数与障碍物相对于视线的高度以及菲涅尔区半径有关。 典型值：\n范围可以从0 dB（无阻挡，清晰视线）到6 dB（轻微遮挡的掠射情况），对于严重阻挡可达20 dB或更高。 需要沿路径的地形剖面数据。 使用简化的Knife-edge 模型： $$ L_{d}(\\mathrm{dB}) = 6.9 + 20\\log_{10}\\Bigl[\\sqrt{(v-0.1)^2+1}\\,+\\,(v-0.1)\\Bigr], $$$$ v = h\\sqrt{\\frac{2d}{\\lambda\\,d_1\\,d_2}} $$ $d_1,d_2$：阻挡物到发/收端距离；$h$：阻挡物高度差 典型参数：$\\lambda=0.125\\,\\mathrm{m}$，$d_1=d_2=5\\,\\mathrm{km}$，$h=10\\,\\mathrm{m}$ 计算示例：$v\\approx0.04$，$L_{diff}\\approx0.2\\,\\mathrm{dB}$ 3.2.1.5 反射损耗/多径衰落 ($L_{mp}$) 无线电波可能通过多条路径（直接路径、地面反射、其他表面反射）到达接收机。这些电波在接收端叠加，可能导致干涉。当叠加结果导致信号弱于自由空间直接波时，有时称为“反射损耗” ，或更普遍地称为多径衰落。\n计算模型 双径模型： 一个考虑直射波和单条地面反射波的简单模型。路径差导致相位差，从而引起建设性或破坏性干涉。 统计模型： 对于复杂环境，使用瑞利（用于非视线或严重多径环境）或莱斯（用于有视线和多径分量的环境）等统计模型来描述衰落包络。 典型值/参数： 衰落深度：可能导致深度衰落，信号强度可能比自由空间电平低10-30 dB甚至更多。 参数：地表反射率（取决于材料、频率、掠射角）、天线高度、地表粗糙度。 在链路预算中通常会包含“衰落余量”，以应对不可预测的多径效应，尤其对于移动链路。 Two-Ray 模型的简化计算： $$ L_{mp}(\\mathrm{dB}) \\approx 20\\log_{10}\\Bigl|\\frac{1}{d_1}+r\\,\\frac{e^{-j k(d_2-d_1)}}{d_2}\\Bigr|^{-1} $$ 地面反射系数 $r\\approx-1$（水平极化） 典型天线高度 $h_t=h_r=10\\,\\mathrm{m}$，$d=10\\,\\mathrm{km}$ 经验值：$L_{refl}\\approx1\\sim5\\,\\mathrm{dB}$ 3.2.1.6 其他损耗 ($L_o$) 植被损耗： 如果路径穿越树木等植被区域，会产生衰减。其大小与频率和植被密度相关（例如，ITU-R P.833等模型）。 天线失配损耗： 如果天线与馈线或收发信机阻抗不匹配导致的损耗。 天线指向误差损耗： 如果发射或接收天线未完美对准。 馈线损耗： 无线电设备和天线之间的电缆和连接器损耗（通常在EIRP或$G_r/T$计算中已考虑，但如果损耗较大且可变，也可在此列出）。 3.2.1.7 极化的影响 极化方式对无线电波的传播损耗，尤其是在某些特定情况下，确实会产生影响，但影响程度因损耗类型而异：\n雨衰减 ($L_r$)：\n影响显著。 雨滴通常不是完美的球形，由于空气动力学效应，较大的雨滴在下落时会变成扁平的椭球形，其长轴大致趋向于水平方向。 这导致水平极化（电场矢量平行于地面）的电波通常会经历比垂直极化（电场矢量垂直于地面）的电波更大的衰减。因此，我们之前讨论的雨衰系数 $k$ 和 $\\alpha$ 会有水平极化版本 ($k_H, \\alpha_H$) 和垂直极化版本 ($k_V, \\alpha_V$)，且通常 $k_H \u003e k_V$ 和 $\\alpha_H \\approx \\alpha_V$ 或略大于 $\\alpha_V$。 圆极化波可以分解为两个正交的线极化分量，其衰减特性通常介于水平极化和垂直极化之间，并且还会引入交叉极化歧视（XPD）的降低。 大气气体吸收 ($L_a$ - 包括氧气和水蒸气)：\n影响很小，通常可以忽略不计。 大气气体分子（如氧气和水蒸气）的吸收特性通常被认为是各向同性的，即它们对不同极化方向的电波的吸收程度没有显著差异。因此，在计算 $\\gamma_o$ 和 $\\gamma_w$ 时，一般不区分极化方式。 绕射损耗 ($L_d$)：\n影响较小。 对于大多数实际的绕射场景（如山脊绕射），极化方式对绕射损耗的影响通常不大，尤其是在较低频率。在一些特定复杂绕射场景或更高频率下可能会有些许差异，但通常在工程估算中不作为首要考虑因素。 反射/多径 ($L_{mp}$):\n影响显著。 地面或水面等反射体对不同极化波的反射系数（菲涅尔反射系数）是不同的，并且随入射角变化。 例如，对于水平极化波，在掠射角（入射角接近90度）时，反射系数接近-1（即幅度接近1，相位反转）。 对于垂直极化波，存在一个布儒斯特角，在该角度入射时，反射系数为0（无反射）。 这种差异会直接影响多径信号的幅度和相位，从而导致不同极化方式下多径衰落的特性（如衰落深度、发生概率）有所不同。 植被衰减：\n可能有影响。 树叶、树枝等结构对不同极化波的散射和吸收特性可能存在差异，尤其是在较高频率。水平极化波在穿透茂密植被时可能经历更大的衰减。 天线本身：\n天线设计本身就是针对特定极化方式的。使用不匹配的极化方式会导致显著的极化失配损耗（cross-polarization loss），这可以高达20-30 dB甚至完全失联。例如，用水平极化天线接收垂直极化信号。 总结：\n地空测控链路计算模型中：\n雨衰减 是必须考虑极化影响的一个重要因素。 对于反射和多径效应，极化也是一个重要影响因素，尤其是在分析地面反射或水面反射对链路的影响时。 对于大气气体吸收，通常可以忽略极化的影响。 对于模型中可能涉及的天线参数，确保发射和接收天线的极化匹配是基本前提。 因此，在进行详细链路计算时，根据具体场景和频率，评估不同传播机制下极化带来的影响是非常有必要的。\n3.2.2 实际接收功率 ($P_r$) 由于在 $L_{\\Sigma}$ 中已经把自由空间路径损耗 $L_{bf}$ 也算进去了，那么原经典公式\n$$ P_r = \\frac{EIRP \\,\\lambda^2\\,G_r}{(4\\pi)^2\\,d^2\\,L_{\\Sigma}} $$其中：\n$EIRP$：发射机等效各向同性辐射功率。 $\\lambda$：工作波长。 $G_r$：接收天线增益。 $d$：发射机与接收机之间距离。 $L_{\\Sigma}$：信号传播过程中的总损耗。 中$(4\\pi)^2d^2/\\lambda^2$ 对应的自由空间损耗（取负）已显式写出， 这里的 $L_{\\Sigma}$ 已经等同于$P_r = \\frac{EIRP \\cdot G_r}{L_{\\Sigma}}$，故本模型实际接收功率 ($P_r$)计算则应改写为\n$$ L_{\\Sigma} = L_{bf} \\;\\times\\; L_{其它} $$对数形式（单位 dBW） 则表示为：\n$$ P_r (dBW) = EIRP (dBW) + G_r (dBi) - L_{\\Sigma} (dB) $$3.3.3 接收电平 $A_r$ 由功率换算到电压电平 $A_r$：\n在接收机输入阻抗为 $R_{in}$ 时，功率与电压有效值的关系为 $$ P_r = \\frac{A_r^2}{2\\,R_{in}} \\quad\\Longrightarrow\\quad A_r = \\sqrt{2\\,R_{in}\\,P_r} $$ 若取标准阻抗 $R_{in}=1\\ \\Omega$，则简化为\n$$ A_r = \\sqrt{2\\,P_r} $$ 若 $R_{in}=50\\ \\Omega$，则\n$$ A_r = \\sqrt{100\\,P_r} $$ 示例：\n设\n发射机等效各向同性辐射功率：$EIRP = 30\\ \\mathrm{dBW}$ 接收天线增益：$G_r = 12\\ \\mathrm{dBi}$ 总传播损耗（已含自由空间损耗等）：$L_{\\Sigma} = 127\\ \\mathrm{dB}$ 则接收功率（对数形式）为：\n$$ P_r(\\mathrm{dBW}) = EIRP + G_r - L_{\\Sigma} = 30 + 12 - 127 = -85\\ \\mathrm{dBW} $$换算成线性功率：\n$$ P_r = 10^{-85/10}\\,\\mathrm W \\approx 3.16\\times10^{-9}\\,\\mathrm W = 3.16\\,\\mathrm{nW}. $$假设接收机输入阻抗 $R_{in}=50\\ \\Omega$。\n$$ A_r = \\sqrt{2\\,R_{in}\\,P_r} = \\sqrt{2 \\times 50 \\times 3.16\\times10^{-9}} \\approx 5.62\\times10^{-4}\\,\\mathrm V $$若将 $A_r$ 表示为 dBmV（相对于 1 mV 的电压电平）： $$ A_r(\\mathrm{dBmV}) = 20\\,\\log_{10}\\!\\biggl(\\frac{A_r\\;[\\mathrm V]}{1\\times10^{-3}\\,\\mathrm V}\\biggr) $$$$ A_r = 5.62\\times10^{-4}\\,\\mathrm V = 0.562\\,\\mathrm{mV} $$ 则\n$$ A_r(\\mathrm{dBmV}) = 20\\log_{10}\\bigl(0.562\\bigr) \\approx -5.02\\;\\mathrm{dBmV} $$3.3 接收机门限电平 ($A_{th}$) 接收机门限电平（即接收灵敏度）是保证正确解调和译码所需的最小信号电平（设备性能中如直接设定，单位为dBmV，以下部分则无需计算）。\n以下计算假设通信链路为AWGN 信道。在数字通信中，AWGN 信道（Additive White Gaussian Noise Channel，加性白高斯噪声信道）是一种最常用的理想化信道模型，AWGN 信道以最简单的“信号＋高斯白噪声”模型，为通信系统设计和性能评估提供了基准参考，是数字通信理论中的基础信道模型。在应用中：\n性能基准：AWGN 信道为各种调制、编码方案的误码率分析提供了最基础、最清晰的理论极限。 简化分析：由于假设最简，它省略了多径衰落、频率选择性衰落等复杂效应，方便推导闭式误码率表达式。 工程近似：在视距良好、无显著多径和阴影衰落的无线链路短程测试中，AWGN 模型能较好近似实际环境。 其主要假设和特性如下：\n加性（Additive） 信道输出信号等于输入信号与噪声之和：\n$$ y(t) = x(t) + n(t) $$其中，$x(t)$ 为发射信号，$n(t)$ 为叠加到信号上的噪声。\n白（White） 噪声的功率谱密度在感兴趣的整个带宽内均匀不变，即\n$$ S_n(f) = \\frac{N_0}{2},\\quad -\\infty",
    "description": "该模型侧重于通过考虑视距限制、信号传播特性、接收机灵敏度及多普勒频移影响等因素，评估无人机地空测控链路的连通性和性能。",
    "tags": [],
    "title": "地空测控链路计算模型",
    "uri": "/em/comm/%E5%9C%B0%E7%A9%BA%E6%B5%8B%E6%8E%A7%E9%93%BE%E8%B7%AF%E8%AE%A1%E7%AE%97%E6%A8%A1%E5%9E%8B/index.html"
  },
  {
    "breadcrumb": "FlitSoft Docs \u003e  EM \u003e  Antenna Pattern",
    "content": "一、辛格方向图数学模型 辛格方向图（Sinc Directional Diagram）模型是电子战仿真中常用的一种天线方向图模型，其数学表达式基于归一化的 sinc 函数，可以用于描述天线的辐射方向性。辛格方向图模型的表达式如下：\n$$ G(\\theta) = G_{\\text{max}} \\cdot \\left( \\frac{\\sin(N \\pi \\sin \\theta)}{N \\pi \\sin \\theta} \\right)^2 $$其中：\n$G(\\theta)$：在方向 $\\theta$ 上的天线增益。 $G_{\\text{max}}$：最大增益，通常出现在主瓣方向。 $\\theta$：观察方向与天线主轴之间的夹角。 $N$：天线阵列的阵元数。 特性说明： 主瓣与旁瓣：\n主瓣是指 $\\theta = 0$ 方向上的主要辐射能量范围，主瓣增益为 $G_{\\text{max}}$。 边旁瓣的幅度由阵元数 $N$ 决定，$N$ 越大，旁瓣越小。 归一化因子：\n归一化的 sinc 函数确保方向图的辐射功率在不同方向上的分布符合物理实际。 阵列影响：\n增加阵元数会使主瓣更加集中，旁瓣抑制效果更好。 应用场景： 辛格方向图模型广泛用于线性阵列天线、相控阵天线等的仿真，尤其是在电子战、通信和雷达信号处理中，用于评估天线的方向性性能。\n二、测试计算器 https://claude.site/artifacts/5f11ccb8-beb2-48a2-8a00-eddd0f871edc\n测试计算器代码：\nimport React, { useState } from 'react'; import { Card, CardHeader, CardTitle, CardContent } from '@/components/ui/card'; import { LineChart, Line, XAxis, YAxis, CartesianGrid, Tooltip, Legend, PolarGrid, PolarAngleAxis, PolarRadiusAxis, RadarChart, Radar } from 'recharts'; import { Slider } from '@/components/ui/slider'; import { Button } from '@/components/ui/button'; import { Label } from '@/components/ui/label'; import { CalculatorIcon } from 'lucide-react'; const SincCalculator = () =\u003e { const [N, setN] = useState(8); const [tempN, setTempN] = useState(8); const [Gmax, setGmax] = useState(1); const [tempGmax, setTempGmax] = useState(1); const [cartesianData, setCartesianData] = useState([]); const [polarData, setPolarData] = useState([]); // 关键方位角定义 const keyAngles = [0, 45, 90, 135, 180, 225, 270, 315]; const calculateGain = (theta, N, Gmax) =\u003e { const thetaRad = (theta * Math.PI) / 180; const sinTheta = Math.sin(thetaRad); if (Math.abs(sinTheta) \u003c 1e-10) { return Gmax; } const numerator = Math.sin(N * Math.PI * sinTheta); const denominator = N * Math.PI * sinTheta; return Gmax * Math.pow(numerator / denominator, 2); }; const updateData = () =\u003e { const newCartesianData = []; const newPolarData = []; // 更新直角坐标数据 for (let theta = -90; theta \u003c= 90; theta += 1) { const gain = calculateGain(theta, tempN, tempGmax); const gainDB = 10 * Math.log10(Math.max(gain, 1e-10)); newCartesianData.push({ theta, gain: gainDB }); } // 更新极坐标数据 for (let theta = 0; theta \u003c 360; theta += 5) { // 对于大于180度的角度，使用对称性计算 const calcTheta = theta \u003c= 180 ? theta - 90 : 270 - theta; const gain = calculateGain(calcTheta, tempN, tempGmax); const gainDB = 10 * Math.log10(Math.max(gain, 1e-10)); const normalizedGain = Math.pow(10, gainDB/20); newPolarData.push({ theta, gain: normalizedGain, gainDB }); } setCartesianData(newCartesianData); setPolarData(newPolarData); setN(tempN); setGmax(tempGmax); }; // 自定义角度轴刻度格式化 const formatPolarAngle = (angleValue) =\u003e { // 只有关键角度才显示标签 if (keyAngles.includes(angleValue)) { return `${angleValue}°`; } return ''; }; return ( \u003cCard className=\"w-full max-w-4xl p-6\"\u003e \u003cCardHeader\u003e \u003cCardTitle\u003e辛格方向图计算器\u003c/CardTitle\u003e \u003c/CardHeader\u003e \u003cCardContent\u003e \u003cdiv className=\"space-y-6\"\u003e {/* 参数控制区 */} \u003cdiv className=\"space-y-4\"\u003e \u003cdiv className=\"space-y-2\"\u003e \u003cLabel\u003e阵元数 (N): {tempN}\u003c/Label\u003e \u003cSlider value={[tempN]} min={2} max={32} step={1} onValueChange={(value) =\u003e setTempN(value[0])} className=\"w-full\" /\u003e \u003c/div\u003e \u003cdiv className=\"space-y-2\"\u003e \u003cLabel\u003e最大增益 (Gmax): {tempGmax}\u003c/Label\u003e \u003cSlider value={[tempGmax]} min={0.1} max={2} step={0.1} onValueChange={(value) =\u003e setTempGmax(value[0])} className=\"w-full\" /\u003e \u003c/div\u003e \u003cButton onClick={updateData} className=\"w-full\" \u003e \u003cCalculatorIcon className=\"w-4 h-4 mr-2\" /\u003e 重新计算 \u003c/Button\u003e \u003c/div\u003e \u003cdiv className=\"grid grid-cols-1 md:grid-cols-2 gap-6\"\u003e {/* 直角坐标图 */} \u003cdiv className=\"w-full overflow-x-auto\"\u003e \u003ch3 className=\"text-lg font-medium mb-4\"\u003e直角坐标方向图\u003c/h3\u003e \u003cLineChart width={500} height={300} data={cartesianData} margin={{ top: 5, right: 30, left: 20, bottom: 5, }} \u003e \u003cCartesianGrid strokeDasharray=\"3 3\" /\u003e \u003cXAxis dataKey=\"theta\" label={{ value: '方位角 (度)', position: 'bottom' }} /\u003e \u003cYAxis label={{ value: '增益 (dB)', angle: -90, position: 'insideLeft' }} domain={[-40, 0]} /\u003e \u003cTooltip /\u003e \u003cLine type=\"monotone\" dataKey=\"gain\" stroke=\"#2563eb\" dot={false} strokeWidth={2} /\u003e \u003c/LineChart\u003e \u003c/div\u003e {/* 极坐标图 */} \u003cdiv className=\"w-full overflow-x-auto\"\u003e \u003ch3 className=\"text-lg font-medium mb-4\"\u003e极坐标方向图\u003c/h3\u003e \u003cRadarChart width={500} height={300} data={polarData} cx=\"50%\" cy=\"50%\" \u003e \u003cPolarGrid /\u003e \u003cPolarAngleAxis dataKey=\"theta\" tickFormatter={formatPolarAngle} ticks={keyAngles} /\u003e \u003cPolarRadiusAxis angle={90} domain={[0, 1]} tickFormatter={(value) =\u003e `${(20 * Math.log10(value)).toFixed(0)}dB`} /\u003e \u003cRadar name=\"增益\" dataKey=\"gain\" stroke=\"#2563eb\" fill=\"#2563eb\" fillOpacity={0.6} /\u003e \u003cTooltip formatter={(value, name, props) =\u003e [ `${(20 * Math.log10(value)).toFixed(2)} dB`, '增益' ]} /\u003e \u003c/RadarChart\u003e \u003c/div\u003e \u003c/div\u003e {/* 关键点数据显示 */} \u003cdiv className=\"grid grid-cols-2 gap-4 mt-4\"\u003e \u003cdiv className=\"p-4 border rounded\"\u003e \u003ch3 className=\"font-medium\"\u003e主瓣增益 (0°)\u003c/h3\u003e \u003cp\u003e{(10 * Math.log10(calculateGain(0, N, Gmax))).toFixed(2)} dB\u003c/p\u003e \u003c/div\u003e \u003cdiv className=\"p-4 border rounded\"\u003e \u003ch3 className=\"font-medium\"\u003e副瓣电平 (±90°)\u003c/h3\u003e \u003cp\u003e{(10 * Math.log10(calculateGain(90, N, Gmax))).toFixed(2)} dB\u003c/p\u003e \u003c/div\u003e \u003c/div\u003e \u003c/div\u003e \u003c/CardContent\u003e \u003c/Card\u003e ); }; export default SincCalculator; 三、模型代码 Python代码 用于测试和可视化辛格方向图模型的代码。这个代码将展示不同阵元数对方向图的影响。\nimport numpy as np import matplotlib.pyplot as plt def calc_sinc_pattern(theta_deg, N, G_max=1.0): \"\"\" 计算辛格方向图模型的增益 参数: theta_deg: ndarray, 观察角度（度） N: int, 天线阵元数 G_max: float, 最大增益 返回: ndarray: 对应角度的增益值 \"\"\" # 将角度转换为弧度 theta_rad = np.deg2rad(theta_deg) # 避免除零错误 sin_theta = np.sin(theta_rad) numerator = np.sin(N * np.pi * sin_theta) denominator = N * np.pi * sin_theta # 处理 theta = 0 的特殊情况 zero_indices = np.where(np.abs(sin_theta) \u003c 1e-10) result = np.zeros_like(theta_deg, dtype=float) # 计算非零角度的增益 nonzero_indices = np.where(np.abs(sin_theta) \u003e= 1e-10) result[nonzero_indices] = G_max * (numerator[nonzero_indices] / denominator[nonzero_indices]) ** 2 # 设置零角度的增益为最大值 result[zero_indices] = G_max return result def plot_pattern(N_values): \"\"\" 绘制不同阵元数的方向图 参数: N_values: list, 要比较的阵元数列表 \"\"\" # 创建角度数组（-90度到90度） theta = np.linspace(-90, 90, 1000) # 设置图形样式 plt.figure(figsize=(12, 8)) plt.grid(True, linestyle='--', alpha=0.7) # 为每个阵元数绘制方向图 for N in N_values: gain_db = 10 * np.log10(calc_sinc_pattern(theta, N)) plt.plot(theta, gain_db, label=f'N={N}') # 设置图形属性 plt.xlabel('方位角 (度)') plt.ylabel('增益 (dB)') plt.title('辛格方向图模型 - 不同阵元数比较') plt.legend() plt.ylim(-40, 0) # 限制最小增益为-40dB plt.show() def test_pattern(): \"\"\" 测试函数：验证方向图的关键特性 \"\"\" # 测试不同阵元数和角度的组合 N_test = [4, 8, 16] theta_test = np.array([0, 30, 60]) print(\"辛格方向图模型测试结果：\") print(\"-\" * 50) for N in N_test: print(f\"\\n阵元数 N = {N}\") gains = calc_sinc_pattern(theta_test, N) gains_db = 10 * np.log10(gains) for theta, gain, gain_db in zip(theta_test, gains, gains_db): print(f\"角度: {theta:3.0f}° | 增益: {gain:.4f} | 增益(dB): {gain_db:.2f} dB\") # 运行测试 if __name__ == \"__main__\": # 执行数值测试 test_pattern() # 绘制不同阵元数的方向图比较 plot_pattern([4, 8, 16]) 以上代码实现了以下功能：\ncalc_sinc_pattern 函数：\n实现了辛格方向图的数学模型 处理了零角度的特殊情况 支持向量化计算，提高效率 plot_pattern 函数：\n绘制极坐标形式的方向图 支持多个阵元数的对比 使用 dB 单位显示增益 test_pattern 函数：\n验证不同角度和阵元数的组合 输出详细的测试结果 要运行这个代码，需要安装 NumPy 和 Matplotlib 库。运行后，将看到：\n控制台输出：显示不同阵元数和角度组合的具体增益值 图形输出：展示不同阵元数的方向图对比 你可以通过修改 N_values 和测试角度来探索不同的参数组合。需要特别注意的是：\n增益值已经归一化，最大值为1（0 dB） 图表中使用了 dB 单位以better展示旁瓣特性 程序处理了 θ = 0° 时的奇异点 C++代码 以下为一个易于集成的C++辛格方向图计算模块，包含清晰的输入输出接口。\n// SincDirectionalModel.hpp #ifndef SINC_DIRECTIONAL_MODEL_HPP #define SINC_DIRECTIONAL_MODEL_HPP #include \u003cvector\u003e #include \u003ccmath\u003e #include \u003cstdexcept\u003e namespace DirectionalModel { /** * @brief 辛格方向图计算模块 * 用于计算和分析天线的辛格方向图特性 */ class SincDirectionalModel { public: /** * @brief 构造函数 * @param elementCount 天线阵元数 * @param maxGain 最大增益值 * @throw std::invalid_argument 当参数无效时抛出异常 */ SincDirectionalModel(unsigned int elementCount = 8, double maxGain = 1.0); /** * @brief 设置天线阵元数 * @param elementCount 天线阵元数 * @return bool 设置是否成功 */ bool setElementCount(unsigned int elementCount); /** * @brief 设置最大增益 * @param maxGain 最大增益值 * @return bool 设置是否成功 */ bool setMaxGain(double maxGain); /** * @brief 计算指定角度的增益 * @param angle_deg 观察角度（度） * @return double 增益值 */ double calculateGain(double angle_deg) const; /** * @brief 计算指定角度的分贝增益 * @param angle_deg 观察角度（度） * @return double 分贝增益值 */ double calculateGainDB(double angle_deg) const; /** * @brief 生成方向图数据点 * @param startAngle 起始角度（度） * @param endAngle 结束角度（度） * @param stepSize 角度步长（度） * @return std::vector\u003cstd::pair\u003cdouble, double\u003e\u003e 角度-增益对 */ std::vector\u003cstd::pair\u003cdouble, double\u003e\u003e generatePattern( double startAngle = -90.0, double endAngle = 90.0, double stepSize = 1.0) const; /** * @brief 生成分贝方向图数据点 * @param startAngle 起始角度（度） * @param endAngle 结束角度（度） * @param stepSize 角度步长（度） * @return std::vector\u003cstd::pair\u003cdouble, double\u003e\u003e 角度-分贝增益对 */ std::vector\u003cstd::pair\u003cdouble, double\u003e\u003e generatePatternDB( double startAngle = -90.0, double endAngle = 90.0, double stepSize = 1.0) const; /** * @brief 获取天线关键参数 * @return std::pair\u003cdouble, double\u003e 主瓣增益(dB)和第一旁瓣电平(dB) */ std::pair\u003cdouble, double\u003e getKeyParameters() const; private: unsigned int N_; // 天线阵元数 double Gmax_; // 最大增益 const double PI = 3.14159265358979323846; // 检查角度参数是否有效 bool validateAngleParams(double start, double end, double step) const; }; } // namespace DirectionalModel #endif // SINC_DIRECTIONAL_MODEL_HPP // SincDirectionalModel.cpp #include \"SincDirectionalModel.hpp\" namespace DirectionalModel { SincDirectionalModel::SincDirectionalModel(unsigned int elementCount, double maxGain) { if (!setElementCount(elementCount) || !setMaxGain(maxGain)) { throw std::invalid_argument(\"Invalid constructor parameters\"); } } bool SincDirectionalModel::setElementCount(unsigned int elementCount) { if (elementCount \u003c 1) return false; N_ = elementCount; return true; } bool SincDirectionalModel::setMaxGain(double maxGain) { if (maxGain \u003c= 0) return false; Gmax_ = maxGain; return true; } double SincDirectionalModel::calculateGain(double angle_deg) const { // 转换为弧度 double angle_rad = angle_deg * PI / 180.0; double sin_theta = std::sin(angle_rad); // 处理零角度特殊情况 if (std::abs(sin_theta) \u003c 1e-10) { return Gmax_; } double numerator = std::sin(N_ * PI * sin_theta); double denominator = N_ * PI * sin_theta; return Gmax_ * std::pow(numerator / denominator, 2); } double SincDirectionalModel::calculateGainDB(double angle_deg) const { double gain = calculateGain(angle_deg); // 防止取对数时出错，设置最小值 gain = std::max(gain, 1e-10); return 10.0 * std::log10(gain); } bool SincDirectionalModel::validateAngleParams(double start, double end, double step) const { if (start \u003e= end || step \u003c= 0) return false; if (std::abs(step) \u003e std::abs(end - start)) return false; return true; } std::vector\u003cstd::pair\u003cdouble, double\u003e\u003e SincDirectionalModel::generatePattern( double startAngle, double endAngle, double stepSize) const { if (!validateAngleParams(startAngle, endAngle, stepSize)) { throw std::invalid_argument(\"Invalid angle parameters\"); } std::vector\u003cstd::pair\u003cdouble, double\u003e\u003e pattern; pattern.reserve(static_cast\u003csize_t\u003e((endAngle - startAngle) / stepSize) + 1); for (double angle = startAngle; angle \u003c= endAngle; angle += stepSize) { pattern.emplace_back(angle, calculateGain(angle)); } return pattern; } std::vector\u003cstd::pair\u003cdouble, double\u003e\u003e SincDirectionalModel::generatePatternDB( double startAngle, double endAngle, double stepSize) const { if (!validateAngleParams(startAngle, endAngle, stepSize)) { throw std::invalid_argument(\"Invalid angle parameters\"); } std::vector\u003cstd::pair\u003cdouble, double\u003e\u003e pattern; pattern.reserve(static_cast\u003csize_t\u003e((endAngle - startAngle) / stepSize) + 1); for (double angle = startAngle; angle \u003c= endAngle; angle += stepSize) { pattern.emplace_back(angle, calculateGainDB(angle)); } return pattern; } std::pair\u003cdouble, double\u003e SincDirectionalModel::getKeyParameters() const { double mainLobeGainDB = calculateGainDB(0.0); // 查找第一旁瓣 double firstSidelobeLevel = -std::numeric_limits\u003cdouble\u003e::infinity(); double angle = 0.0; bool foundFirstPeak = false; while (angle \u003c= 90.0) { double currentGain = calculateGainDB(angle); double nextGain = calculateGainDB(angle + 0.1); if (currentGain \u003e nextGain \u0026\u0026 foundFirstPeak) { firstSidelobeLevel = currentGain; break; } if (currentGain \u003c nextGain) { foundFirstPeak = true; } angle += 0.1; } return {mainLobeGainDB, firstSidelobeLevel}; } } // namespace DirectionalModel 这个模块提供了以下主要功能：\n类接口设计：\n清晰的构造函数和设置函数 完整的错误检查和异常处理 命名空间封装 核心功能：\ncalculateGain: 计算指定角度的增益 calculateGainDB: 计算分贝形式的增益 generatePattern: 生成方向图数据点 generatePatternDB: 生成分贝形式的方向图数据点 辅助功能：\ngetKeyParameters: 获取主瓣增益和第一旁瓣电平 参数验证和错误处理 使用示例：\n#include \"SincDirectionalModel.hpp\" #include \u003ciostream\u003e int main() { try { // 创建模型实例：8个阵元，最大增益1.0 DirectionalModel::SincDirectionalModel model(8, 1.0); // 计算单点增益 double gain_0deg = model.calculateGainDB(0.0); std::cout \u003c\u003c \"0度增益: \" \u003c\u003c gain_0deg \u003c\u003c \" dB\\n\"; // 生成方向图数据 auto pattern = model.generatePatternDB(-90.0, 90.0, 1.0); // 获取关键参数 auto [mainLobe, sidelobe] = model.getKeyParameters(); std::cout \u003c\u003c \"主瓣增益: \" \u003c\u003c mainLobe \u003c\u003c \" dB\\n\"; std::cout \u003c\u003c \"第一旁瓣电平: \" \u003c\u003c sidelobe \u003c\u003c \" dB\\n\"; } catch (const std::exception\u0026 e) { std::cerr \u003c\u003c \"Error: \" \u003c\u003c e.what() \u003c\u003c std::endl; return 1; } return 0; } 集成建议：\n将头文件和源文件添加到项目中 包含头文件并使用 DirectionalModel 命名空间 根据需要调用相应的方法 注意处理可能的异常",
    "description": "This summary is independent of the content.",
    "tags": [],
    "title": "辛格方向图模型",
    "uri": "/em/antenna-pattern/01.%E8%BE%9B%E6%A0%BC%E6%96%B9%E5%90%91%E5%9B%BE%E6%A8%A1%E5%9E%8B/index.html"
  },
  {
    "breadcrumb": "FlitSoft Docs \u003e  EM \u003e  Antenna Pattern",
    "content": "一、高斯方向图模型 高斯方向图模型是一种基于高斯分布的天线方向图简化模型，适合描述天线辐射方向图中主瓣的形状。其数学表达式如下： $$ G(\\theta) = G_{\\text{max}} \\cdot e^{-k (\\frac{\\theta}{\\theta_{\\text{3dB}}})^2} $$参数说明\n$G(\\theta)$：方向 $\\theta$ 上的天线增益。 $G_{\\text{max}}$：主瓣最大增益，通常在 $\\theta = 0$ 时取值。 $\\theta$：观察方向与天线主轴（通常是主瓣方向）之间的夹角。 $\\theta_{\\text{3dB}}$：3dB 波束宽度，定义为增益下降到最大值的一半时对应的角度宽度。 $k$：控制波束形状的系数，通常与 $\\theta_{\\text{3dB}}$ 有关，常取值为 $k = \\ln 2$，使得 $\\theta = \\theta_{\\text{3dB}}$ 时增益下降到 $G_{\\text{max}} / 2$。 特性\n主瓣集中性：\n高斯方向图模型的主瓣呈对称的高斯分布，随着角度偏离主轴，增益迅速下降。 由于模型忽略了旁瓣的影响，它通常用于关注主瓣方向的应用场景。 简洁性：\n高斯方向图模型通过简化旁瓣和其他次要特性，显著降低了计算复杂度，适合快速仿真计算。 归一化：\n为了便于计算，可以对增益进行归一化，使得 $G(\\theta)$ 的值在主瓣方向取 1。 应用场景\n电子战：快速估计天线主瓣方向的辐射能量分布，用于干扰或抗干扰评估。 雷达和通信：对主瓣方向性较强的天线进行快速仿真。 方向性优化：通过调整 $\\theta_{\\text{3dB}}$ 和 $k$ 参数实现特定的波束宽度和集中性。 如果需要进一步扩展高斯方向图模型以包括旁瓣或其他特性，也可以通过叠加额外分量进行修正。\n高斯方向图模型的改进形式 改进的高斯方向图模型其特点是用高斯分布描述主瓣，同时提供了一个函数形式用于描述主瓣以外的方向图（即旁瓣）：\n主瓣公式 $$ f(\\theta) = \\exp\\left(-k \\theta^2\\right) $$ 主瓣部分是标准的高斯分布形式，其中 $k = \\frac{4 \\ln \\sqrt{2}}{\\theta_b^2}$，由 $\\theta_b$（单程半功率点波束宽度）控制主瓣的宽度。 参数 $k$ 确保在 $\\theta = \\pm \\frac{\\theta_b}{2}$ 时，方向图幅度下降到其峰值的一半（即 3dB 下降点）。 主瓣以外的方向图 $$ f(\\theta) = \\frac{(1 + \\cos \\theta) \\sin(k \\sin(\\theta))}{2k \\sin(\\theta)} $$ 这一部分用于描述主瓣以外（旁瓣）的方向图特性。 $k = \\frac{1.3916}{\\sin(0.5\\theta_b)}$ 是根据波束宽度 $\\theta_b$ 确定的常数。 分母 $\\sin(\\theta)$ 和分子的 $\\sin(k \\sin(\\theta))$ 描述了旁瓣的振荡特性，旁瓣随 $\\theta$ 增加呈周期性变化。 模型分析\n主瓣部分：\n与传统高斯方向图模型相符，用高斯函数来精确描述主瓣方向的辐射分布。 通过参数 $k$ 和 $\\theta_b$ 控制主瓣的宽度和增益衰减速率。 旁瓣部分：\n旁瓣描述使用的是一个分段函数，体现了辐射能量的衰减和分布。 $(1 + \\cos \\theta)$ 项增强了主瓣附近的旁瓣幅度，而 $k$ 的引入确保旁瓣幅度的适当抑制。 是否为高斯方向图模型：\n这个模型主瓣部分严格满足高斯分布，可以视为高斯方向图模型。 增加了旁瓣描述的扩展部分，因此可以认为它是 一种改进的高斯方向图模型，在实际应用中更接近实际天线的辐射特性。 适用场景\n这种模型在需要对主瓣精确建模并同时考虑旁瓣对系统性能影响的场景中非常适用，例如：\n电子战中的方向图干扰仿真。 雷达系统对目标信号主瓣和旁瓣的能量分布分析。 无线通信中的波束形成优化。 二、可视化线上计算器 https://claude.site/artifacts/917d549d-d142-4c69-95dc-7a8e4ad48997\n这个交互式的React组件，可以让用户调整参数并实时查看改进型高斯方向图模型的变化。\n计算器代码：\nimport React, { useState, useCallback, useEffect } from 'react'; import { LineChart, Line, XAxis, YAxis, CartesianGrid, Tooltip, Legend, ResponsiveContainer } from 'recharts'; import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card'; import { Slider } from '@/components/ui/slider'; import { Label } from '@/components/ui/label'; import { Button } from '@/components/ui/button'; import { Input } from '@/components/ui/input'; import { Switch } from '@/components/ui/switch'; import { Calculator } from 'lucide-react'; const GaussianBeamCalculator = () =\u003e { // 状态管理 const [thetaB, setThetaB] = useState(10); // 波束宽度（度） const [plotRange, setPlotRange] = useState(90); // 绘图范围（度） const [resolution, setResolution] = useState(360); // 数据点数量 const [patternData, setPatternData] = useState([]); // 方向图数据 const [kMain, setKMain] = useState(0); // 主瓣k参数 const [kSide, setKSide] = useState(0); // 旁瓣k参数 const [manualK, setManualK] = useState(false); // 是否手动设置K参数 const [manualKMain, setManualKMain] = useState('0'); // 手动输入的主瓣k参数 const [manualKSide, setManualKSide] = useState('0'); // 手动输入的旁瓣k参数 // 自动计算K参数 const calculateKParameters = useCallback(() =\u003e { const thetaBRad = (thetaB * Math.PI) / 180; const newKMain = (4 * Math.log(Math.sqrt(2))) / (thetaBRad * thetaBRad); const newKSide = 1.3916 / Math.sin(0.5 * thetaBRad); return { kMain: newKMain, kSide: newKSide }; }, [thetaB]); // 更新K参数（考虑手动/自动模式） const updateKParameters = useCallback(() =\u003e { if (manualK) { setKMain(parseFloat(manualKMain) || 0); setKSide(parseFloat(manualKSide) || 0); } else { const { kMain: newKMain, kSide: newKSide } = calculateKParameters(); setKMain(newKMain); setKSide(newKSide); setManualKMain(newKMain.toFixed(4)); setManualKSide(newKSide.toFixed(4)); } }, [manualK, manualKMain, manualKSide, calculateKParameters]); // 计算方向图数据 const calculatePattern = useCallback(() =\u003e { updateKParameters(); const data = []; const step = (2 * plotRange) / (resolution - 1); const currentKMain = manualK ? parseFloat(manualKMain) : kMain; const currentKSide = manualK ? parseFloat(manualKSide) : kSide; for (let theta = -plotRange; theta \u003c= plotRange; theta += step) { const thetaRad = (theta * Math.PI) / 180; const thetaBHalf = thetaB / 2; const isMainLobe = Math.abs(theta) \u003c= thetaBHalf; let amplitude; if (isMainLobe) { amplitude = Math.exp(-currentKMain * thetaRad * thetaRad); } else { if (Math.abs(thetaRad) \u003c 1e-10) { amplitude = 1; } else { amplitude = ((1 + Math.cos(thetaRad)) * Math.sin(currentKSide * Math.sin(thetaRad))) / (2 * currentKSide * Math.sin(thetaRad)); } } const amplitudeDB = 20 * Math.log10(Math.abs(amplitude)); const normalizedDB = Math.max(amplitudeDB, -60); const r = normalizedDB + 60; data.push({ theta, amplitude: normalizedDB, r, x: r * Math.cos(thetaRad), y: r * Math.sin(thetaRad) }); } setPatternData(data); }, [thetaB, plotRange, resolution, kMain, kSide, manualK, manualKMain, manualKSide, updateKParameters]); // 首次加载时计算初始数据 useEffect(() =\u003e { calculatePattern(); }, []); // 处理手动/自动模式切换 const handleModeToggle = (checked) =\u003e { setManualK(checked); if (!checked) { const { kMain: newKMain, kSide: newKSide } = calculateKParameters(); setManualKMain(newKMain.toFixed(4)); setManualKSide(newKSide.toFixed(4)); } }; // 自定义极坐标图组件（与之前相同） const PolarPattern = ({ data }) =\u003e { if (!data || data.length === 0) { return \u003cdiv\u003eLoading...\u003c/div\u003e; } return ( \u003csvg className=\"w-full h-full\" viewBox=\"-70 -70 140 140\"\u003e {/* 绘制同心圆 */} {[0, 15, 30, 45, 60].map((r, i) =\u003e ( \u003ccircle key={i} cx=\"0\" cy=\"0\" r={r} fill=\"none\" stroke=\"#ddd\" strokeWidth=\"0.5\" /\u003e ))} {/* 绘制角度线 */} {[0, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330].map((angle) =\u003e { const radians = (angle * Math.PI) / 180; return ( \u003cline key={angle} x1=\"0\" y1=\"0\" x2={60 * Math.cos(radians)} y2={60 * Math.sin(radians)} stroke=\"#ddd\" strokeWidth=\"0.5\" /\u003e ); })} {/* 绘制方向图曲线 */} {data.length \u003e 0 \u0026\u0026 ( \u003cpath d={`M ${data[0].x} ${data[0].y} ` + data.map(p =\u003e `L ${p.x} ${p.y}`).join(' ')} fill=\"none\" stroke=\"#2563eb\" strokeWidth=\"1\" /\u003e )} {/* 添加刻度标签 */} {[0, -20, -40, -60].map((db, i) =\u003e ( \u003ctext key={i} x=\"2\" y={-15 * i - 2} fontSize=\"4\" fill=\"#666\" \u003e {db}dB \u003c/text\u003e ))} {/* 添加角度标签 */} {[0, 90, 180, 270].map((angle) =\u003e { const radians = (angle * Math.PI) / 180; return ( \u003ctext key={angle} x={65 * Math.cos(radians)} y={65 * Math.sin(radians)} fontSize=\"4\" fill=\"#666\" textAnchor=\"middle\" \u003e {angle}° \u003c/text\u003e ); })} \u003c/svg\u003e ); }; return ( \u003cCard className=\"w-full max-w-4xl\"\u003e \u003cCardHeader\u003e \u003cCardTitle\u003e改进型高斯方向图模型计算器\u003c/CardTitle\u003e \u003c/CardHeader\u003e \u003cCardContent className=\"space-y-6\"\u003e \u003cdiv className=\"space-y-4\"\u003e \u003cdiv className=\"space-y-2\"\u003e \u003cLabel\u003e波束宽度 θb (度)\u003c/Label\u003e \u003cdiv className=\"flex items-center space-x-4\"\u003e \u003cSlider value={[thetaB]} onValueChange={(value) =\u003e setThetaB(value[0])} min={1} max={30} step={0.5} className=\"flex-1\" /\u003e \u003cspan className=\"w-12 text-right\"\u003e{thetaB}°\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv className=\"space-y-2\"\u003e \u003cLabel\u003e绘图范围 (±度)\u003c/Label\u003e \u003cdiv className=\"flex items-center space-x-4\"\u003e \u003cSlider value={[plotRange]} onValueChange={(value) =\u003e setPlotRange(value[0])} min={30} max={180} step={10} className=\"flex-1\" /\u003e \u003cspan className=\"w-12 text-right\"\u003e±{plotRange}°\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv className=\"space-y-2\"\u003e \u003cdiv className=\"flex items-center justify-between\"\u003e \u003cLabel\u003e手动设置K参数\u003c/Label\u003e \u003cSwitch checked={manualK} onCheckedChange={handleModeToggle} /\u003e \u003c/div\u003e {manualK \u0026\u0026 ( \u003cdiv className=\"grid grid-cols-2 gap-4\"\u003e \u003cdiv className=\"space-y-2\"\u003e \u003cLabel\u003e主瓣k参数\u003c/Label\u003e \u003cInput type=\"number\" value={manualKMain} onChange={(e) =\u003e setManualKMain(e.target.value)} step=\"0.0001\" /\u003e \u003c/div\u003e \u003cdiv className=\"space-y-2\"\u003e \u003cLabel\u003e旁瓣k参数\u003c/Label\u003e \u003cInput type=\"number\" value={manualKSide} onChange={(e) =\u003e setManualKSide(e.target.value)} step=\"0.0001\" /\u003e \u003c/div\u003e \u003c/div\u003e )} \u003c/div\u003e \u003cButton onClick={calculatePattern} className=\"w-full\" \u003e \u003cCalculator className=\"mr-2 h-4 w-4\" /\u003e 计算方向图 \u003c/Button\u003e \u003c/div\u003e \u003cdiv className=\"grid grid-cols-1 md:grid-cols-2 gap-4\"\u003e {/* 直角坐标图 */} \u003cdiv className=\"h-96\"\u003e \u003cLabel className=\"mb-2 block\"\u003e直角坐标显示\u003c/Label\u003e \u003cResponsiveContainer width=\"100%\" height=\"100%\"\u003e \u003cLineChart data={patternData}\u003e \u003cCartesianGrid strokeDasharray=\"3 3\" /\u003e \u003cXAxis dataKey=\"theta\" label={{ value: '角度 (度)', position: 'bottom' }} /\u003e \u003cYAxis domain={[-60, 5]} label={{ value: '幅度 (dB)', angle: -90, position: 'left' }} /\u003e \u003cTooltip formatter={(value) =\u003e `${value.toFixed(2)} dB`} labelFormatter={(label) =\u003e `${label}°`} /\u003e \u003cLegend /\u003e \u003cLine type=\"monotone\" dataKey=\"amplitude\" stroke=\"#2563eb\" name=\"方向图\" dot={false} /\u003e \u003c/LineChart\u003e \u003c/ResponsiveContainer\u003e \u003c/div\u003e {/* 极坐标图 */} \u003cdiv className=\"h-96\"\u003e \u003cLabel className=\"mb-2 block\"\u003e极坐标显示\u003c/Label\u003e \u003cdiv className=\"w-full h-full\"\u003e \u003cPolarPattern data={patternData} /\u003e \u003c/div\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv className=\"text-sm space-y-2\"\u003e \u003cp\u003e主瓣k参数: {kMain.toFixed(4)}\u003c/p\u003e \u003cp\u003e旁瓣k参数: {kSide.toFixed(4)}\u003c/p\u003e \u003cp\u003e3dB波束宽度: {thetaB}°\u003c/p\u003e \u003c/div\u003e \u003c/CardContent\u003e \u003c/Card\u003e ); }; export default GaussianBeamCalculator; 这个交互式的高斯方向图模型计算器具有以下特点：\n参数控制：\n波束宽度(θb)滑块：可调范围1°-30° 绘图范围滑块：可调范围±30°到±180° 实时更新的参数显示 可视化功能：\n响应式图表显示 自动缩放的坐标轴 网格线便于读数 鼠标悬停时显示具体数值 Y轴范围限制在-60dB到5dB 计算特性：\n实时计算主瓣和旁瓣参数 自动处理临界值 平滑的曲线显示 显示关键参数值（k参数等） 使用说明：\n拖动滑块来调整波束宽度和显示范围 图表会实时更新显示新的方向图 将鼠标悬停在曲线上可以查看具体数值 底部显示当前的计算参数 这个计算器使用了现代的React组件和hooks，采用了优化的计算方法，可以流畅地进行实时计算和显示。使用了shadcn/ui组件库来提供统一的UI风格。\n主瓣和旁瓣的K参数可以手动输入，同时保持原有的自动计算功能。\nK参数控制模式：\n添加了切换开关，可以在自动计算和手动输入之间切换 在自动模式下，K参数根据波束宽度自动计算 在手动模式下，可以直接输入K参数值 新增输入界面：\n添加了主瓣和旁瓣K参数的输入框 输入框支持高精度数值（步进值为0.0001） 切换到自动模式时会自动填充计算值 计算逻辑优化：\n分离了K参数计算和方向图计算 在手动模式下使用输入的K值 在自动模式下使用计算的K值 用户界面改进：\n清晰的模式切换开关 数值输入框的合理布局 实时显示当前使用的K参数值 使用方法：\n自动模式（默认）：\nK参数根据波束宽度自动计算 调整波束宽度会影响K参数的计算值 手动模式：\n打开\"手动设置K参数\"开关 直接输入想要的主瓣和旁瓣K参数值 点击\"计算方向图\"查看效果 切换模式：\n从自动切换到手动时，保留当前计算的K值 从手动切换到自动时，恢复根据波束宽度计算的K值 需要注意的是：\n波束宽度的选择会影响both主瓣和旁瓣的形状 可以通过调整显示范围来观察不同角度范围的细节 这个工具可以更好地理解和验证改进型高斯方向图模型的特性。\n三、参考代码 Python代码 一个方便测试和验证这个改进型高斯方向图模型的Python代码。代码将包含模型的实现、可视化以及参数测试功能。\nimport numpy as np import matplotlib.pyplot as plt from matplotlib.widgets import Slider class GaussianBeamPattern: def __init__(self, theta_b_deg=10): \"\"\" 初始化改进型高斯方向图模型 参数: theta_b_deg: float, 单程半功率点波束宽度(度) \"\"\" self.set_theta_b(theta_b_deg) def set_theta_b(self, theta_b_deg): \"\"\"设置波束宽度并更新相关参数\"\"\" self.theta_b = np.deg2rad(theta_b_deg) # 转换为弧度 # 计算主瓣的k参数 self.k_main = 4 * np.log(np.sqrt(2)) / (self.theta_b**2) # 计算旁瓣的k参数 self.k_side = 1.3916 / np.sin(0.5 * self.theta_b) def main_lobe(self, theta): \"\"\"计算主瓣方向图\"\"\" return np.exp(-self.k_main * theta**2) def side_lobe(self, theta): \"\"\"计算旁瓣方向图\"\"\" # 避免除零错误 small_angles = np.abs(theta) \u003c 1e-10 result = np.zeros_like(theta, dtype=float) # 处理非零角度 non_zero = ~small_angles theta_nz = theta[non_zero] result[non_zero] = (1 + np.cos(theta_nz)) * np.sin(self.k_side * np.sin(theta_nz)) / (2 * self.k_side * np.sin(theta_nz)) # 处理接近零度的情况（使用极限值） result[small_angles] = (1 + 1) * 1 / (2) # lim(x-\u003e0) sin(kx)/x = k return result def pattern(self, theta): \"\"\"计算完整的方向图\"\"\" # 确定主瓣范围（这里取±theta_b/2） is_main_lobe = np.abs(theta) \u003c= self.theta_b/2 # 分别计算主瓣和旁瓣 pattern = np.zeros_like(theta) pattern[is_main_lobe] = self.main_lobe(theta[is_main_lobe]) pattern[~is_main_lobe] = self.side_lobe(theta[~is_main_lobe]) return pattern def plot_beam_pattern(theta_b_deg=10): \"\"\"绘制方向图并添加交互式控件\"\"\" # 创建图形和坐标轴 fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 12)) plt.subplots_adjust(bottom=0.25) # 为滑块留出空间 # 初始化模型 beam = GaussianBeamPattern(theta_b_deg) # 计算角度范围和方向图 theta_deg = np.linspace(-90, 90, 1000) theta = np.deg2rad(theta_deg) pattern = beam.pattern(theta) # 在直角坐标系中绘制 line1, = ax1.plot(theta_deg, 20*np.log10(np.abs(pattern)), 'b-', label='方向图') ax1.grid(True) ax1.set_xlabel('角度 (度)') ax1.set_ylabel('相对幅度 (dB)') ax1.set_ylim(-60, 5) ax1.set_title('方向图 (直角坐标)') ax1.legend() # 在极坐标系中绘制 ax2.set_theta_zero_location('N') # 设置0度在正上方 ax2.set_theta_direction(-1) # 设置角度增长方向为顺时针 pattern_db = 20*np.log10(np.abs(pattern)) pattern_db = np.maximum(pattern_db, -60) # 限制最小值为-60dB line2, = ax2.plot(theta, pattern_db, 'b-') ax2.set_title('方向图 (极坐标)') ax2.set_rmin(-60) ax2.set_rmax(0) ax2.grid(True) # 添加波束宽度滑块 ax_slider = plt.axes([0.2, 0.1, 0.6, 0.03]) slider = Slider(ax_slider, '波束宽度 (度)', 1, 30, valinit=theta_b_deg) def update(val): \"\"\"更新方向图\"\"\" beam.set_theta_b(slider.val) pattern = beam.pattern(theta) pattern_db = 20*np.log10(np.abs(pattern)) # 更新直角坐标图 line1.set_ydata(pattern_db) # 更新极坐标图 pattern_db_polar = np.maximum(pattern_db, -60) line2.set_ydata(pattern_db_polar) fig.canvas.draw_idle() slider.on_changed(update) plt.show() if __name__ == \"__main__\": # 测试代码 plot_beam_pattern(10) # 默认波束宽度为10度 这段代码实现了以下功能：\n模型实现：\n创建了GaussianBeamPattern类，完整实现了改进型高斯方向图模型 分别实现了主瓣和旁瓣的计算函数 处理了临界情况（如角度接近0度时的计算） 可视化功能：\n同时提供直角坐标和极坐标两种显示方式 直角坐标显示详细的幅度变化 极坐标显示更直观的方向图特性 坐标轴和网格的合理设置 交互式参数调节：\n添加了波束宽度的滑动条 实时更新方向图显示 范围设置在1-30度之间 其他特性：\ndB显示范围限制在-60dB到5dB 合理的极坐标显示设置（北向为0度，顺时针方向） 完善的注释和文档 使用方法：\n# 直接运行程序 python gaussian_beam_pattern.py # 或者在其他代码中导入使用 from gaussian_beam_pattern import GaussianBeamPattern beam = GaussianBeamPattern(theta_b_deg=10) pattern = beam.pattern(theta) # theta为弧度制的角度数组 你可以通过滑动控制条来改变波束宽度，观察方向图的变化。这对于理解参数变化对方向图形状的影响非常有帮助。\n需要注意的是，代码需要安装以下Python包：\npip install numpy matplotlib C++代码 以下是一个高斯方向图模型的C++代码模块，具有清晰的输入输出，便于嵌入实际应用程序中使用。\n功能说明\n主瓣使用高斯模型：$f(\\theta) = \\exp\\left(-k \\theta^2\\right)$ 旁瓣描述：$f(\\theta) = \\frac{(1 + \\cos \\theta) \\sin(k \\sin(\\theta))}{2k \\sin(\\theta)}$ 输入： $\\theta$（方向角，单位：弧度） $\\theta_b$（单程半功率点波束宽度，单位：弧度） 输出： 天线方向图增益 $f(\\theta)$ C++代码模块\n#include \u003ciostream\u003e #include \u003ccmath\u003e #include \u003cstdexcept\u003e // 高斯方向图模型的实现 class GaussianAntennaPattern { public: // 构造函数，传入波束宽度 GaussianAntennaPattern(double theta_b) { if (theta_b \u003c= 0) { throw std::invalid_argument(\"Beamwidth theta_b must be positive.\"); } this-\u003etheta_b = theta_b; this-\u003ek_main = 4 * std::log(std::sqrt(2)) / (theta_b * theta_b); this-\u003ek_side = 1.3916 / std::sin(0.5 * theta_b); } // 获取指定方向角上的增益值 double computeGain(double theta) const { // 主瓣模型 if (std::abs(theta) \u003c= 0.5 * theta_b) { return std::exp(-k_main * theta * theta); } // 旁瓣模型 else { double sin_theta = std::sin(theta); if (std::abs(sin_theta) \u003c 1e-6) { // 避免除零 return 0.0; } return ((1 + std::cos(theta)) * std::sin(k_side * sin_theta)) / (2 * k_side * sin_theta); } } private: double theta_b; // 半功率点波束宽度 double k_main; // 主瓣系数 double k_side; // 旁瓣系数 }; // 测试高斯方向图模型 int main() { try { // 定义波束宽度 double theta_b = 0.5; // 以弧度为单位 GaussianAntennaPattern antennaPattern(theta_b); // 输出不同方向角的增益 std::cout \u003c\u003c \"Theta (radians) | Gain\" \u003c\u003c std::endl; for (double theta = -1.0; theta \u003c= 1.0; theta += 0.1) { double gain = antennaPattern.computeGain(theta); std::cout \u003c\u003c theta \u003c\u003c \" | \" \u003c\u003c gain \u003c\u003c std::endl; } } catch (const std::exception\u0026 e) { std::cerr \u003c\u003c \"Error: \" \u003c\u003c e.what() \u003c\u003c std::endl; } return 0; } 代码功能解析\n主类 GaussianAntennaPattern：\n构造函数接受波束宽度 $\\theta_b$ 并计算主瓣和旁瓣的系数 $k_{\\text{main}}$ 和 $k_{\\text{side}}$。 computeGain 方法根据 $\\theta$ 判断是主瓣还是旁瓣，并分别计算增益。 输入校验：\n确保 $\\theta_b \u003e 0$。 防止 $\\sin(\\theta) = 0$ 时的除零错误。 示例输出：\n主程序循环计算不同方向角 $\\theta$ 下的增益并打印。 示例输出\n假设 $\\theta_b = 0.5$，方向角 $\\theta$ 从 $-1.0$ 到 $1.0$：\nTheta (radians) | Gain -1.0 | 0.005 -0.9 | 0.010 -0.8 | 0.050 -0.7 | 0.150 -0.6 | 0.400 -0.5 | 0.707 -0.4 | 0.900 ... 适用性\n模块化设计，便于集成到现有代码中。 支持灵活的方向角计算，适合电子战仿真、雷达信号处理等应用。 可扩展性强，能够添加额外特性（如干扰建模、噪声影响等）。 示例使用场景 场景 1：快速计算特定方向的增益 可以将代码改为直接计算某个方向角的增益，而不是循环输出：\nint main() { try { // 定义波束宽度 double theta_b = 0.5; // 单程半功率点波束宽度 GaussianAntennaPattern antennaPattern(theta_b); // 计算某个角度的增益 double theta = 0.3; // 方向角 double gain = antennaPattern.computeGain(theta); std::cout \u003c\u003c \"Gain at theta = \" \u003c\u003c theta \u003c\u003c \" radians: \" \u003c\u003c gain \u003c\u003c std::endl; } catch (const std::exception\u0026 e) { std::cerr \u003c\u003c \"Error: \" \u003c\u003c e.what() \u003c\u003c std::endl; } return 0; } 运行输出：\nGain at theta = 0.3 radians: 0.9798 场景 2：与实际仿真集成 将类 GaussianAntennaPattern 作为模块嵌入到电子战仿真程序中，只需要调用 computeGain 方法传入角度即可获取对应的增益值。例如：\ndouble signalPower = 10.0; // 原始信号功率 double theta = 0.5; // 当前方向角 double gain = antennaPattern.computeGain(theta); double receivedPower = signalPower * gain; // 加权后的接收功率 优化建议\n多线程支持：可以对 computeGain 进行多线程优化，适合批量计算多个方向增益。 文件输入输出：将计算结果写入文件或从文件读取方向角。 图形化输出：将计算结果导出为数据文件，用于可视化方向图。",
    "description": "This summary is independent of the content.",
    "tags": [],
    "title": "高斯方向图模型",
    "uri": "/em/antenna-pattern/02.%E9%AB%98%E6%96%AF%E6%96%B9%E5%90%91%E5%9B%BE%E6%A8%A1%E5%9E%8B/index.html"
  },
  {
    "breadcrumb": "FlitSoft Docs \u003e  UAS \u003e  Path Searching \u003e  A* Path Searching",
    "content": "参考的基于运动基元的四旋翼无人机A*算法：\nhttps://github.com/HKUST-Aerial-Robotics/Fast-Planner/blob/master/fast_planner/path_searching/src/kinodynamic_astar.cpp\n总体思路\n分析四旋翼A*算法的核心部分：了解其状态表示、控制输入、运动模型和运动基元生成方式。\n理解固定翼无人机的动力学特性：明确其状态变量、控制输入、运动学/动力学模型，以及物理和操作限制。\n整合调整：在前两步的基础上，重新定义状态和控制输入，修改运动基元生成方法，调整启发式函数和代价函数，确保算法的合理性和可行性。\n1. 四旋翼A*算法概述 1.1 状态表示\n位置：$\\mathbf{p} = [x, y, z]^T$ 速度：$\\mathbf{v} = [v_x, v_y, v_z]^T$ 状态向量：$\\mathbf{s} = [\\mathbf{p}, \\mathbf{v}]^T$，共6维。 1.2 控制输入\n加速度：$\\mathbf{a} = [a_x, a_y, a_z]^T$ 控制输入集：在最大加速度范围内进行离散化，生成一系列可能的加速度向量。 1.3 运动模型\n假设加速度在时间段$\\tau$内恒定，使用匀加速运动方程进行状态转移： $$ \\begin{cases} \\mathbf{p}(t+\\tau) = \\mathbf{p}(t) + \\mathbf{v}(t) \\tau + \\frac{1}{2} \\mathbf{a} \\tau^2 \\\\ \\mathbf{v}(t+\\tau) = \\mathbf{v}(t) + \\mathbf{a} \\tau \\end{cases} $$1.4 运动基元生成\n对控制输入$\\mathbf{a}$和持续时间$\\tau$进行离散化，生成一系列可能的运动基元。 在节点扩展时，应用这些运动基元进行状态转移，生成新节点。 2. 固定翼无人机动力学特性 2.1 状态表示\n位置：$\\mathbf{p} = [x, y, z]^T$ 航向角：$\\chi$（水平面内的方向） 俯仰角（航迹角）：$\\gamma$（垂直方向的角度） 速度大小：$v$（通常假设恒定或在一定范围内） 状态向量：$\\mathbf{s} = [x, y, z, \\chi, \\gamma]^T$，共5维。 2.2 控制输入\n航向角变化率：$\\dot{\\chi}$ 航迹角变化率：$\\dot{\\gamma}$ 控制输入向量：$\\mathbf{u} = [\\dot{\\chi}, \\dot{\\gamma}]^T$ 2.3 运动学模型\n假设速度$v$恒定，固定翼无人机的运动学方程为：\n$$ \\begin{cases} \\dot{x} = v \\cos \\gamma \\cos \\chi \\\\ \\dot{y} = v \\cos \\gamma \\sin \\chi \\\\ \\dot{z} = v \\sin \\gamma \\\\ \\dot{\\chi} = \\dot{\\chi} \\\\ \\dot{\\gamma} = \\dot{\\gamma} \\end{cases} $$2.4 动力学限制\n最小速度限制：$v_{\\min}$，避免失速。 最大速度限制：$v_{\\max}$ 最大航向角变化率：$|\\dot{\\chi}| \\leq \\dot{\\chi}_{\\max}$ 最大航迹角变化率：$|\\dot{\\gamma}| \\leq \\dot{\\gamma}_{\\max}$ 3. 方案整合与调整 3.1 状态和控制输入的重新定义\n状态向量：$\\mathbf{s} = [x, y, z, \\chi, \\gamma]^T$ 控制输入：$\\mathbf{u} = [\\dot{\\chi}, \\dot{\\gamma}]^T$ 3.2 运动基元的生成\n控制输入离散化：\n航向角变化率 $\\dot{\\chi}$：\n$$ \\dot{\\gamma}_D = \\left\\{ -\\dot{\\gamma}_{\\max}, -\\dot{\\gamma}_{\\max} + \\Delta_{\\gamma}, \\ldots, 0, \\ldots, \\dot{\\gamma}_{\\max} - \\Delta_{\\gamma}, \\dot{\\gamma}_{\\max} \\right\\} $$ 航迹角变化率 $\\dot{\\gamma}$： $$ \\dot{\\gamma}_D = \\left\\{ -\\dot{\\gamma}_{\\max}, -\\dot{\\gamma}_{\\max} + \\Delta_{\\gamma}, \\ldots, 0, \\ldots, \\dot{\\gamma}_{\\max} - \\Delta_{\\gamma}, \\dot{\\gamma}_{\\max} \\right\\} $$ 组合控制输入集：\n$$ \\mathcal{U}_D = \\left\\{ (\\dot{\\chi}, \\dot{\\gamma}) \\ \\big| \\ \\dot{\\chi} \\in \\dot{\\chi}_D, \\ \\dot{\\gamma} \\in \\dot{\\gamma}_D \\right\\} $$ 时间步长的确定：设定固定的时间步长$\\tau$，或者根据无人机的速度和环境动态调整。\n状态转移：\n使用数值积分方法（如四阶Runge-Kutta方法）在时间步长$\\tau$内对运动学方程进行积分，计算新状态$\\mathbf{s}(t+\\tau)$。\n状态更新函数：\nvoid stateTransit(const Eigen::VectorXd\u0026 state0, Eigen::VectorXd\u0026 state1, const Eigen::Vector2d\u0026 control_input, double tau) { double v = speed_; // 固定翼无人机的速度 double chi0 = state0(3); double gamma0 = state0(4); double dot_chi = control_input(0); double dot_gamma = control_input(1); // 更新航向角和航迹角 double chi1 = chi0 + dot_chi * tau; double gamma1 = gamma0 + dot_gamma * tau; // 使用平均值近似或数值积分计算位置更新 double avg_chi = (chi0 + chi1) / 2; double avg_gamma = (gamma0 + gamma1) / 2; double x1 = state0(0) + v * cos(avg_gamma) * cos(avg_chi) * tau; double y1 = state0(1) + v * cos(avg_gamma) * sin(avg_chi) * tau; double z1 = state0(2) + v * sin(avg_gamma) * tau; state1.resize(5); state1 \u003c\u003c x1, y1, z1, chi1, gamma1; } 3.3 节点扩展\n扩展函数：\nvoid expandNode(PathNodePtr current_node, std::vector\u003cPathNodePtr\u003e\u0026 successors) { // 获取当前状态 Eigen::VectorXd state0 = current_node-\u003estate; // 遍历所有可能的控制输入 for (const auto\u0026 dot_chi : dot_chi_values) { for (const auto\u0026 dot_gamma : dot_gamma_values) { Eigen::Vector2d control_input(dot_chi, dot_gamma); Eigen::VectorXd state1; // 状态转移 stateTransit(state0, state1, control_input, tau); // 检查速度限制（如果速度可变） // 检查物理可行性，如最小转弯半径 // 碰撞检测 if (!isCollisionFree(state0, state1)) { continue; } // 创建新节点 PathNodePtr new_node = new PathNode(); new_node-\u003estate = state1; new_node-\u003einput = control_input; new_node-\u003eduration = tau; new_node-\u003eparent = current_node; // 计算代价 new_node-\u003eg_score = current_node-\u003eg_score + costFunction(state0, state1, control_input, tau); new_node-\u003ef_score = new_node-\u003eg_score + heuristic(state1); // 加入后继节点列表 successors.push_back(new_node); } } } 3.4 代价函数和启发式函数\n代价函数：考虑航向角和航迹角变化率的代价，以及时间代价。 $$ \\text{Cost} = w_{\\chi} |\\dot{\\chi}| + w_{\\gamma} |\\dot{\\gamma}| + w_t \\tau $$ 启发式函数：使用三维Dubins路径的长度作为启发式估计。\nDubins路径：在已知最小转弯半径的情况下，计算从当前状态到目标状态的最短路径长度。\n启发式函数实现：\ndouble heuristic(const Eigen::VectorXd\u0026 state) { // 计算当前状态到目标状态的Dubins路径长度 double h = computeDubinsPathLength(state, goal_state_, min_turn_radius_); return h; } 3.5 碰撞检测\n离散采样：在状态转移过程中，对轨迹进行离散采样，检查每个采样点是否与障碍物发生碰撞。\n碰撞检测函数：\nbool isCollisionFree(const Eigen::VectorXd\u0026 state0, const Eigen::VectorXd\u0026 state1) { int num_checks = 10; // 采样点数量 for (int i = 1; i \u003c= num_checks; ++i) { double t = (double)i / num_checks * tau; Eigen::VectorXd intermediate_state; stateTransit(state0, intermediate_state, state1.segment(3,2) - state0.segment(3,2), t); Eigen::Vector3d position = intermediate_state.head(3); if (!isPositionValid(position)) { return false; } } return true; } 3.6 节点结构调整\n节点结构：根据新的状态和控制输入，调整节点的定义。\nclass PathNode { public: Eigen::Vector3i index; // 栅格索引 Eigen::VectorXd state; // 状态向量 [x, y, z, chi, gamma] double g_score, f_score; Eigen::Vector2d input; // 控制输入 [dot_chi, dot_gamma] double duration; PathNode* parent; char node_state; // 构造函数和析构函数 }; 3.7 A*算法流程\n搜索主循环：与传统A*算法类似，使用开启集和关闭集管理节点，按照 $f = g + h$ 的代价进行节点扩展和选择。\n算法步骤：\n初始化开启集，将起始节点加入开启集。 当开启集非空时： 从开启集中取出 $f$ 值最小的节点作为当前节点。 如果当前节点达到目标状态（或在容忍范围内），则回溯路径，结束搜索。 将当前节点加入关闭集。 扩展当前节点，生成后继节点。 对于每个后继节点： 如果节点在关闭集中，跳过。 如果节点不在开启集中，或找到更优路径，更新节点信息并加入开启集。 4. 方案可行性分析 4.1 动力学合理性\n重新定义的状态和控制输入符合固定翼无人机的动力学特性。 运动基元的生成考虑了固定翼的物理限制，如最小转弯半径和速度限制。 4.2 算法有效性\n通过使用合适的启发式函数（Dubins路径长度），保证算法的效率和最优性。 在节点扩展时进行碰撞检测，确保路径的可行性和安全性。 4.3 实际应用性\n方案中各部分的实现细节，如状态转移函数、碰撞检测和启发式函数，都可以在实际代码中具体实现。 方案兼顾了计算效率和规划质量，可以适用于实时路径规划。 5. 示例参数设置 速度：$v = 15 \\ \\text{m/s}$\n最大航向角变化率：$\\dot{\\chi}_{\\max} = \\frac{\\pi}{6} \\ \\text{rad/s}$（30度/秒）\n最大航迹角变化率：$\\dot{\\gamma}_{\\max} = \\frac{\\pi}{18} \\ \\text{rad/s}$（10度/秒）\n时间步长：$\\tau = 1 \\ \\text{s}$\n控制输入离散化步长：\n$\\Delta_{\\chi} = \\frac{\\dot{\\chi}_{\\max}}{2}$ $\\Delta_{\\gamma} = \\frac{\\dot{\\gamma}_{\\max}}{2}$ 控制输入集合：\nstd::vector\u003cdouble\u003e dot_chi_values = {-dot_chi_max, -dot_chi_max/2, 0, dot_chi_max/2, dot_chi_max}; std::vector\u003cdouble\u003e dot_gamma_values = {-dot_gamma_max, -dot_gamma_max/2, 0, dot_gamma_max/2, dot_gamma_max}; 代价函数权重：\n$w_{\\chi} = 1.0$ $w_{\\gamma} = 1.0$ $w_t = 0.1$ 最小转弯半径：\n$$ R_{\\min} = \\frac{v}{\\dot{\\chi}_{\\max}} $$ 6. 实现注意事项 6.1 数值积分方法\n由于航向角和航迹角在时间内线性变化，可以使用解析积分或简单的数值积分方法。 6.2 速度的可变性\n如果需要考虑速度的变化，可以将速度作为状态变量，并引入油门控制输入。 6.3 启发式函数的一致性\n确保启发式函数不超过实际代价，保持算法的可完备性和最优性。 6.4 碰撞检测的精度\n根据环境的复杂程度，调整采样点数量，以在精度和计算效率之间取得平衡。 总结 通过综合以上方案，我们成功地将基于四旋翼运动基元的A*算法调整为适用于固定翼无人机的版本。关键的调整在于：\n重新定义状态和控制输入：符合固定翼无人机的动力学特性。\n修改运动基元生成方式：基于固定翼的运动学模型，生成物理可行的运动基元。\n调整代价函数和启发式函数：考虑固定翼的运动特性，使用Dubins路径作为启发式估计。\n确保算法的可行性和有效性：通过碰撞检测和合理的参数设置，生成安全可行的路径。\n该方案兼顾了理论合理性和实际可行性，可用于固定翼无人机的路径规划，实现自主导航和避障功能。",
    "description": "将基于运动基元的A*算法从四旋翼无人机改进适配到固定翼无人机",
    "tags": [],
    "title": "基于运动基元的A*算法",
    "uri": "/uas/path-searching/a-search/a-path-searching/index.html"
  }
]
