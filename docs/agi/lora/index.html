<!doctype html><html lang=zh-cn dir=ltr itemscope itemtype=http://schema.org/Article data-r-output-format=html><head><meta charset=utf-8><meta name=viewport content="height=device-height,width=device-width,initial-scale=1,minimum-scale=1"><meta name=generator content="Hugo 0.147.3"><meta name=generator content="Relearn 7.6.1+4407b4364ab6f7477f7671fbd20c0494bade40ee"><meta name=description content="对论文《LoRA: Low-Rank Adaptation of Large Language Models》的研究动机、方法设计、实验验证及深入分析等方面进行了详细剖析"><meta name=author content="你的名字"><meta name=twitter:card content="summary"><meta name=twitter:title content="LoRA :: FlitSoft Docs"><meta name=twitter:description content="对论文《LoRA: Low-Rank Adaptation of Large Language Models》的研究动机、方法设计、实验验证及深入分析等方面进行了详细剖析"><meta property="og:url" content="https://hill68.github.io/agi/lora/index.html"><meta property="og:site_name" content="FlitSoft Docs"><meta property="og:title" content="LoRA :: FlitSoft Docs"><meta property="og:description" content="对论文《LoRA: Low-Rank Adaptation of Large Language Models》的研究动机、方法设计、实验验证及深入分析等方面进行了详细剖析"><meta property="og:locale" content="zh_cn"><meta property="og:type" content="article"><meta property="article:section" content="AI"><meta property="article:published_time" content="2025-06-01T17:07:50+08:00"><meta property="article:modified_time" content="2025-06-01T17:07:50+08:00"><meta itemprop=name content="LoRA :: FlitSoft Docs"><meta itemprop=description content="对论文《LoRA: Low-Rank Adaptation of Large Language Models》的研究动机、方法设计、实验验证及深入分析等方面进行了详细剖析"><meta itemprop=datePublished content="2025-06-01T17:07:50+08:00"><meta itemprop=dateModified content="2025-06-01T17:07:50+08:00"><meta itemprop=wordCount content="1352"><title>LoRA :: FlitSoft Docs</title>
<link href=/images/logo.png?1749791745 rel=icon type=image/png><link href=/fonts/fontawesome/css/fontawesome-all.min.css?1749791745 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/fonts/fontawesome/css/fontawesome-all.min.css?1749791745 rel=stylesheet></noscript><link href=/css/perfect-scrollbar/perfect-scrollbar.min.css?1749791745 rel=stylesheet><link href=/css/theme.min.css?1749791745 rel=stylesheet><link href=/css/format-html.min.css?1749791745 rel=stylesheet id=R-format-style><link href=/css/auto-complete/auto-complete.min.css?1749791745 rel=stylesheet><script src=/js/auto-complete/auto-complete.min.js?1749791745 defer></script><script src=/js/lunr/lunr.min.js?1749791745 defer></script><script src=/js/lunr/lunr.stemmer.support.min.js?1749791745 defer></script><script src=/js/lunr/lunr.multi.min.js?1749791745 defer></script><script src=/js/lunr/lunr.zh.min.js?1749791745 defer></script><script src=/js/search.min.js?1749791745 defer></script><script>window.relearn=window.relearn||{},window.relearn.min=`.min`,window.relearn.path="/agi/lora/index.html",window.relearn.relBasePath="../..",window.relearn.relBaseUri="../..",window.relearn.absBaseUri="https://hill68.github.io",window.relearn.contentLangs=["zh"],window.relearn.index_js_url="/searchindex.en.js?1749791745",window.relearn.disableAnchorCopy=!1,window.relearn.disableAnchorScrolling=!1,window.relearn.disableInlineCopyToClipboard=!1,window.relearn.enableBlockCodeWrap=!0,window.relearn.getItem=(e,t)=>e.getItem(t),window.relearn.setItem=(e,t,n)=>e.setItem(t,n),window.relearn.removeItem=(e,t)=>e.removeItem(t),window.relearn.themevariants=["zen-light","zen-dark"],window.relearn.customvariantname="my-custom-variant",window.relearn.changeVariant=function(e){var t=document.documentElement.dataset.rThemeVariant;window.relearn.setItem(window.localStorage,window.relearn.absBaseUri+"/variant",e),document.documentElement.dataset.rThemeVariant=e,t!=e&&(document.dispatchEvent(new CustomEvent("themeVariantLoaded",{detail:{variant:e,oldVariant:t}})),window.relearn.markVariant())},window.relearn.markVariant=function(){var e=window.relearn.getItem(window.localStorage,window.relearn.absBaseUri+"/variant");document.querySelectorAll(".R-variantswitcher select").forEach(t=>{t.value=e})},window.relearn.initVariant=function(){var e=window.relearn.getItem(window.localStorage,window.relearn.absBaseUri+"/variant")??"";e==window.relearn.customvariantname||(!e||!window.relearn.themevariants.includes(e))&&(e=window.relearn.themevariants[0],window.relearn.setItem(window.localStorage,window.relearn.absBaseUri+"/variant",e)),document.documentElement.dataset.rThemeVariant=e},window.relearn.initVariant(),window.relearn.markVariant(),window.T_Copy_to_clipboard=`Copy to clipboard`,window.T_Copied_to_clipboard=`Copied to clipboard!`,window.T_Copy_link_to_clipboard=`Copy link to clipboard`,window.T_Link_copied_to_clipboard=`Copied link to clipboard!`,window.T_Reset_view=`Reset view`,window.T_View_reset=`View reset!`,window.T_No_results_found=`No results found for "{0}"`,window.T_N_results_found=`{1} results found for "{0}"`</script><link href=/css/custom.css?1749791745 rel=stylesheet></head><body class="mobile-support html" data-url=/agi/lora/index.html><div id=R-body class=default-animation><div id=R-body-overlay></div><nav id=R-topbar><div class=topbar-wrapper><div class=topbar-sidebar-divider></div><div class="topbar-area topbar-area-start" data-area=start><div class="topbar-button topbar-button-sidebar" data-content-empty=disable data-width-s=show data-width-m=hide data-width-l=hide><button class=topbar-control onclick=toggleNav() type=button title="Menu (CTRL+ALT+n)"><i class="fa-fw fas fa-bars"></i></button></div><div class="topbar-button topbar-button-toc" data-content-empty=hide data-width-s=show data-width-m=show data-width-l=show><button class=topbar-control onclick=toggleTopbarFlyout(this) type=button title="Table of Contents (CTRL+ALT+t)"><i class="fa-fw fas fa-list-alt"></i></button><div class=topbar-content><div class=topbar-content-wrapper><nav class=TableOfContents><ul><li><a href=#1-研究背景与动机>1. 研究背景与动机</a></li><li><a href=#2-问题定义>2. 问题定义</a></li><li><a href=#3-lora-方法>3. LoRA 方法</a><ul><li><a href=#31-核心思想低秩分解更新>3.1 核心思想：低秩分解更新</a></li><li><a href=#32-在-transformer-中的应用>3.2 在 Transformer 中的应用</a></li></ul></li><li><a href=#4-lora-的实用优势与局限>4. LoRA 的实用优势与局限</a><ul><li><a href=#41-优势>4.1 优势</a></li><li><a href=#42-局限>4.2 局限</a></li></ul></li><li><a href=#5-实验验证>5. 实验验证</a><ul><li><a href=#51-基线方法>5.1 基线方法</a></li><li><a href=#52-roberta-baselarge-上的-glue-基准>5.2 RoBERTa Base/Large 上的 GLUE 基准</a></li><li><a href=#53-deberta-xxl-上的-glue-基准>5.3 DeBERTa XXL 上的 GLUE 基准</a></li><li><a href=#54-gpt-2-mediumlarge-上的-nlg-任务>5.4 GPT-2 Medium/Large 上的 NLG 任务</a></li><li><a href=#55-gpt-3-175b-上的规模化实验>5.5 GPT-3 175B 上的规模化实验</a></li></ul></li><li><a href=#6-对-lora-更新矩阵的深入分析>6. 对 LoRA 更新矩阵的深入分析</a><ul><li><a href=#61-选取哪些权重进行-lora-更优>6.1 选取哪些权重进行 LoRA 更优</a></li><li><a href=#62-更新矩阵是否真低秩最佳秩--的选择>6.2 更新矩阵是否真低秩？最佳秩 的选择</a></li><li><a href=#63-更新矩阵--与原权重--之间的关联>6.3 更新矩阵 与原权重 之间的关联</a></li></ul></li><li><a href=#7-结论与展望>7. 结论与展望</a><ul><li><a href=#71-主要贡献>7.1 主要贡献</a></li><li><a href=#72-未来研究方向>7.2 未来研究方向</a></li></ul></li></ul></nav></div></div></div></div><ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype=http://schema.org/BreadcrumbList><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=/index.html><span itemprop=name>FlitSoft Docs</span></a><meta itemprop=position content="1">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=/agi/index.html><span itemprop=name>AI</span></a><meta itemprop=position content="2">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><span itemprop=name>LoRA</span><meta itemprop=position content="3"></li></ol><div class="topbar-area topbar-area-end" data-area=end><div class="topbar-button topbar-button-prev" data-content-empty=disable data-width-s=show data-width-m=show data-width-l=show><a class=topbar-control href=/agi/index.html title="AI (🡐)"><i class="fa-fw fas fa-chevron-left"></i></a></div><div class="topbar-button topbar-button-next" data-content-empty=disable data-width-s=show data-width-m=show data-width-l=show><a class=topbar-control href=/agi/why-we-think-ch/index.html title="Why We Think (🡒)"><i class="fa-fw fas fa-chevron-right"></i></a></div><div class="topbar-button topbar-button-more" data-content-empty=hide data-width-s=show data-width-m=show data-width-l=show><button class=topbar-control onclick=toggleTopbarFlyout(this) type=button title=More><i class="fa-fw fas fa-ellipsis-v"></i></button><div class=topbar-content><div class=topbar-content-wrapper><div class="topbar-area topbar-area-more" data-area=more></div></div></div></div></div></div></nav><div id=R-main-overlay></div><main id=R-body-inner class="highlightable agi" tabindex=-1><div class=flex-block-wrapper><article class=default><header class=headline></header><h1 id=lora>LoRA</h1><hr><h2 id=1-研究背景与动机>1. 研究背景与动机</h2><p>当下，自然语言处理领域普遍采取“大规模预训练＋下游微调”的范式。然而，随着模型规模不断增大，<strong>全量微调(fine-tuning)</strong> 面临以下两大挑战：</p><ol><li><strong>存储与部署成本高昂</strong>：例如在 GPT-3 175B（约1750亿参数）上进行全量微调时，每个任务都需要保存一套完整的 175B 参数，若同时支持多个任务，则需要占用数 TB 级别的存储空间，且加载模型实例时开销巨大。</li><li><strong>训练资源门槛升高</strong>：对于 Adam 这样的自适应优化器，需要为所有参数维护梯度和优化器状态，GPT-3 175B 全量微调时，显存占用高达约 1.2TB，这对大多数团队和硬件环境几乎无法承受。</li></ol><p>为缓解上述问题，既往研究尝试<strong>冻结部分权重</strong>或通过引入外部适配器（adapter）/前缀（prompt/prefix）等模块来降低可训练参数规模。但这些方法往往会带来以下弊端：</p><ul><li><strong>Adapter 方法增加推理时延</strong>：在 Transformer 层间插入一个小规模的瓶颈层（Adapter），虽参数量少，但必须在正向推理时进行额外计算，在线推理时（尤其 Batch Size=1 情况下）延迟不容忽视。</li><li><strong>Prompt/Prefix 方法难以优化且占用输入长度</strong>：这类方法通过在输入序列中插入特殊标记，使模型在前向时多处理一段“可训练”激活；但随着特殊标记数目增多，性能提升并不稳定，而且会减少可用于下游任务的实际 Token 数。</li></ul><p>鉴于此，论文提出一种新的 <strong>低秩适配(LoRA, Low-Rank Adaptation)</strong> 策略：在保持预训练权重不变的前提下，通过向每层注入低秩分解矩阵来进行微调，从而在不增加推理时延、不缩减序列长度的情况下，大幅降低可训练参数量和显存占用。</p><hr><h2 id=2-问题定义>2. 问题定义</h2><p>假设已得到一个预训练的自回归语言模型 $P_\Phi(y\mid x)$，其参数为 $\Phi_0$。在下游任务中，往往通过最大化条件语言建模目标进行全量微调：</p>$$
\max_{\Phi}\sum_{(x,y)\in \mathcal{Z}}\sum_{t=1}^{|y|} \log P_{\Phi}(y_t)(y_t \mid x, y_{< t}) \quad,\quad \Phi = \Phi_0 + \Delta \Phi
$$<p>此时需为每个下游任务保存一份 $\Delta \Phi$，且 $|\Delta \Phi| = |\Phi_0|$。当 $\Phi_0$ 较大（如 GPT-3 175B）时，无论是<strong>存储</strong>还是<strong>训练显存</strong>都几近或超出可承受范围。</p><p>论文改写该问题为：寻找一个仅依赖于少量参数 $\Theta$ 的更新映射 $\Delta \Phi(\Theta)$ 使得</p>$$
\max_{\Theta}\sum_{(x,y)\in \mathcal{Z}}\sum_{t=1}^{|y|} \log P_{\Phi_0 + \Delta \Phi(\Theta)}(y_t \mid x, y_{< t}) \quad,\quad |\Theta| \ll |\Phi_0|.
$$<p>最终目标是在<strong>显存占用</strong>与<strong>可训练参数量</strong>大幅下降的同时，仍保持或超越全量微调的模型性能。</p><hr><h2 id=3-lora-方法>3. LoRA 方法</h2><h3 id=31-核心思想低秩分解更新>3.1 核心思想：低秩分解更新</h3><p>LoRA 的核心假设是：在大规模预训练模型的下游微调过程中，<strong>权重变化 $\Delta W$ 具有“低秩”特性</strong>，即若原始权重矩阵 $W_0\in \mathbb{R}^{d\times k}$ 进行更新因子 $\Delta W$，则可以近似为低秩分解</p>$$
W_0 + \Delta W = W_0 + B A,
\quad
B \in \mathbb{R}^{d \times r},\;
A \in \mathbb{R}^{r \times k},\;
r \ll \min(d, k).
$$<p>其中，$W_0$ 冻结不更新，仅对矩阵 $A, B$ 进行梯度更新。这样就将原来需要更新的 $d\times k$ 参数量，压缩为 $d\times r + r\times k\approx 2dr$ 个参数。</p><p>在前向计算时，对于某一层输入向量 $x\in \mathbb{R}^k$，原本输出为 $h = W_0 x$。采用 LoRA 后，输出变为</p>$$
h = W_0 x + \Delta W\,x = W_0 x + B (A x).
\tag{3}
$$<p>因此在实现上，只需在每次前向时多做一个 $A x$ 然后左乘 $B$，并与原始输出相加即可。论文实施时将 $B$ 初始化为零矩阵，$A$ 初始化为服从高斯分布的小随机值，保证微调初期 $\Delta W = BA$ 为零；训练过程中，会对 $A,B$ 应用缩放系数 $\alpha/r$（对相同的学习率而言相当于缩放初始值），以方便在不同秩 $r$ 下无需大幅调参而保持收敛稳定。</p><h4 id=311-与全量微调的关系>3.1.1 与全量微调的关系</h4><ul><li>当 $r = \min(d,k)$ 时，等价于对原始权重矩阵 $W_0$ 进行全秩微调，相当于完整的 $\Delta W$；</li><li>当采用更小的 $r$ 时，只训练低秩子空间中的更新，从而实现<strong>与全量微调相似的表达力</strong>，但参数量和计算开销大幅减少。</li></ul><hr><h3 id=32-在-transformer-中的应用>3.2 在 Transformer 中的应用</h3><p>论文将 LoRA 主要应用于 Transformer 结构中**自注意力模块（self-attention）**的投影矩阵：查询矩阵 $W_q$、键矩阵 $W_k$、值矩阵 $W_v$、输出矩阵 $W_o$ 以及前馈网络（MLP）部分的全连接权重矩阵。具体做法如下：</p><ol><li><strong>仅对注意力投影矩阵应用 LoRA</strong>：论文在大多数实验中只在 $W_q$ 和 $W_v$ 上引入低秩更新矩阵 $\Delta W_q = B_q A_q$，$\Delta W_v = B_v A_v$，并冻结其它权重（包括 MLP 层和层归一化层等）。实验证明，这样已经能够获得与全量微调相当或更优的性能。</li><li><strong>保持正向推理时延不变</strong>：在部署推理时，只需将训练好的 $\Delta W$ 与 $W_0$ 合并为 $W_0 + BA$，正向计算流程与微调后模型完全一致，没有新增任何顺序化计算，因此<strong>不会增加推理时延</strong>。</li><li><strong>灵活切换任务</strong>：将 $\Delta W$ 合并后对应于某个任务的权重写入硬盘，多个任务只需维护一份基础预训练权重与若干份低秩适配参数（大小通常为几 MB），切换任务时仅载入对应的 $\Delta W$，显存和存储占用极小。</li></ol><table><thead><tr><th>应用位置</th><th>维度</th><th>低秩参数量 $\displaystyle 2\times d\times r$</th><th>说明</th></tr></thead><tbody><tr><td>$W_q$</td><td>$d\times d$</td><td>$2dr$</td><td>查询投影，只改前两项</td></tr><tr><td>$W_v$</td><td>$d\times d$</td><td>$2dr$</td><td>值投影</td></tr><tr><td>…</td><td>…</td><td>…</td><td>…</td></tr></tbody></table><p>实践中，仅在 $W_q, W_v$ 上应用 $r=4$ 时（共计适配参数约数 MB 级别），即可满足 GPT-3 175B各种下游任务的性能需求。</p><hr><h2 id=4-lora-的实用优势与局限>4. LoRA 的实用优势与局限</h2><h3 id=41-优势>4.1 优势</h3><ol><li><p><strong>显存占用降低</strong></p><ul><li>由于大部分权重冻结，不需为其维护梯度或优化器状态，仅对低秩矩阵 $A,B$ 更新。以 GPT-3 175B 为例，LoRA 微调时显存从约 1.2 TB 降至约 350 GB，节省约 3 倍显存。</li></ul></li><li><p><strong>可训练参数量大幅减少</strong></p><ul><li>对 GPT-3 175B，仅在 $W_q,W_v$ 部分以 $r=4$ 方式注入，则低秩参数量约为 4.7 M，相比全量微调（175 B）减少约 10 000 ×。</li></ul></li><li><p><strong>推理时延不增加</strong></p><ul><li>预先合并 $\Delta W = B A$ 到权重后，推理流程与全量微调相同，不会引入顺序化计算。与 Adapter 方法相比，Adapter 在每层插入瓶颈层会造成推理时间因顺序运算大幅增长，而 LoRA 不存在此缺陷。</li></ul></li><li><p><strong>任务切换便捷</strong></p><ul><li>共享同一份预训练权重，在不同任务间只需加载不同的几 MB 级别的低秩适配参数，存储和部署成本极低。</li></ul></li><li><p><strong>训练吞吐量提升</strong></p><ul><li>由于冻结大部分权重，反向传播计算量下降，在相同硬件下可获得约 25% 的训练速度提升。</li></ul></li></ol><h3 id=42-局限>4.2 局限</h3><ol><li><p><strong>批量多任务训练不便</strong></p><ul><li>若想在一个 Batch 中同时对不同任务样本使用不同的 $\Delta W$（即 A,B 不同），需在正向时动态切换权重，或者不合并权重，此时推理/训练流程复杂。论文指出若对延迟敏感，可以选择动态加载 LoRA 模块，否则需将不同 $\Delta W$ 合并到原权重，从而无法混合多任务一起正向。</li></ul></li><li><p><strong>低秩假设或不适用所有任务</strong></p><ul><li>当下游任务与预训练任务域差异极大（例如全新语言、跨模态任务）时，所需更新可能并不低秩，此时 LoRA 的表达能力可能受限。论文在 GPT-3 上实验发现对于大部分 NLP 任务，仅需 $r=1$ 即可；但也提示并非所有任务都适用，需要适度调节秩 $r$。</li></ul></li></ol><hr><h2 id=5-实验验证>5. 实验验证</h2><p>论文在四种主流 Transformer 结构上进行了大规模实验：RoBERTa、DeBERTa、GPT-2 以及 GPT-3 175B。下文中，对照各项结果进行说明。</p><h3 id=51-基线方法>5.1 基线方法</h3><table><thead><tr><th>基线名称</th><th>说明</th></tr></thead><tbody><tr><td><strong>Full Fine-Tuning（FT）</strong></td><td>对所有权重和偏置进行微调。</td></tr><tr><td><strong>BitFit</strong></td><td>仅训练偏置向量（bias），其它权重冻结。</td></tr><tr><td><strong>Adapter (Houlsby 等)</strong></td><td>在自注意力和 MLP 后插入瓶颈 Adapter 层。AdapterL/AdapterH 两种变体，分别对应单适配器或双适配器结构，参数量约为原模型的 1% 左右。</td></tr><tr><td><strong>Prefix-Tuning/Embedding (PE)</strong></td><td>在输入/层激活前加入 lp + li 个可训练 Token 激活，等同于动态插入额外可训练参数，无法并行优化且会占用下游任务的序列长度。</td></tr><tr><td><strong>Prefix-Layer (PL)</strong></td><td>类似于 PrefixEmbed，但对各层插入可训练的激活向量，同样占用计算和序列长度。</td></tr></tbody></table><h3 id=52-roberta-baselarge-上的-glue-基准>5.2 RoBERTa Base/Large 上的 GLUE 基准</h3><p>论文在 GLUE 数据集（包含 MNLI、SST-2、MRPC、CoLA、QNLI、QQP、RTE、STS-B）上对 RoBERTa base (125M 参数) 和 RoBERTa large (355M 参数) 进行了多种方法对比。部分结果汇总如下（指标为各任务对应分数，整体为平均得分；越高越好）：</p><table><thead><tr><th>模型 (RoBERTa Base)</th><th>可训练参数</th><th>MNLI</th><th>SST-2</th><th>MRPC</th><th>CoLA</th><th>QNLI</th><th>QQP</th><th>RTE</th><th>STS-B</th><th>Avg.</th><th></th></tr></thead><tbody><tr><td>FT (125M)</td><td>125 M</td><td>87.6</td><td>94.8</td><td>90.2</td><td>63.6</td><td>92.8</td><td>91.9</td><td>78.7</td><td>91.2</td><td>86.4</td><td></td></tr><tr><td>BitFit (0.1 M)</td><td>0.1 M</td><td>84.7</td><td>93.7</td><td>92.7</td><td>62.0</td><td>91.8</td><td>84.0</td><td>81.5</td><td>90.8</td><td>85.2</td><td></td></tr><tr><td>AdapterD (0.3 M)</td><td>0.3 M</td><td>87.1</td><td>94.2</td><td>88.5</td><td>60.8</td><td>93.1</td><td>90.2</td><td>71.5</td><td>89.7</td><td>84.4</td><td></td></tr><tr><td>AdapterD (0.9 M)</td><td>0.9 M</td><td>87.3</td><td>94.7</td><td>88.4</td><td>62.6</td><td>93.0</td><td>90.6</td><td>75.9</td><td>90.3</td><td>85.4</td><td></td></tr><tr><td><strong>LoRA (r=4, 0.3 M)</strong></td><td>0.3 M</td><td>87.5</td><td>95.1</td><td>89.7</td><td>63.4</td><td>93.3</td><td>90.8</td><td>86.6</td><td>91.5</td><td>87.2</td><td></td></tr></tbody></table><table><thead><tr><th>模型 (RoBERTa Large)</th><th>可训练参数</th><th>MNLI</th><th>SST-2</th><th>MRPC</th><th>CoLA</th><th>QNLI</th><th>QQP</th><th>RTE</th><th>STS-B</th><th>Avg.</th><th></th></tr></thead><tbody><tr><td>FT (355 M)</td><td>355 M</td><td>90.2</td><td>96.4</td><td>90.9</td><td>68.0</td><td>94.7</td><td>92.2</td><td>86.6</td><td>92.4</td><td>88.9</td><td></td></tr><tr><td><strong>LoRA (r=8, 0.8 M)</strong></td><td>0.8 M</td><td>90.6</td><td>96.2</td><td>90.9</td><td>68.2</td><td>94.9</td><td>91.6</td><td>87.4</td><td>92.6</td><td>89.0</td><td></td></tr><tr><td>AdptP (3.0 M)</td><td>3.0 M</td><td>90.2</td><td>96.1</td><td>90.2</td><td>68.3</td><td>94.8</td><td>91.9</td><td>83.8</td><td>92.1</td><td>88.4</td><td></td></tr><tr><td>AdptP (0.8 M)</td><td>0.8 M</td><td>90.5</td><td>96.6</td><td>89.7</td><td>67.8</td><td>94.8</td><td>91.7</td><td>80.1</td><td>91.9</td><td>87.9</td><td></td></tr><tr><td>AdptH (6.0 M)</td><td>6.0 M</td><td>89.9</td><td>96.2</td><td>88.7</td><td>66.5</td><td>94.7</td><td>92.1</td><td>83.4</td><td>91.0</td><td>87.8</td><td></td></tr><tr><td>AdptH (0.8 M)</td><td>0.8 M</td><td>90.3</td><td>96.3</td><td>87.7</td><td>66.3</td><td>94.7</td><td>91.5</td><td>72.9</td><td>91.5</td><td>86.4</td><td></td></tr><tr><td><strong>LoRA (0.8 M)</strong></td><td>0.8 M</td><td>90.6</td><td>96.2</td><td>90.2</td><td>68.2</td><td>94.8</td><td>91.6</td><td>85.2</td><td>92.3</td><td>88.6</td><td></td></tr></tbody></table><p>从上表可以看出，<strong>LoRA 在仅用 0.3 M—0.8 M 可训练参数的情况下，几乎匹配甚至略超全量微调</strong>，且优于其他几种参数高效微调方法（如 Adapter、BitFit 等）。</p><hr><h3 id=53-deberta-xxl-上的-glue-基准>5.3 DeBERTa XXL 上的 GLUE 基准</h3><p>DeBERTa XXL（约 1.5B 参数）也是较大规模可用模型。论文在 GLUE 任务上对比了下列设置：</p><table><thead><tr><th>模型 (DeBERTa XXL)</th><th>可训练参数</th><th>MNLI</th><th>SST-2</th><th>MRPC</th><th>CoLA</th><th>QNLI</th><th>QQP</th><th>RTE</th><th>STS-B</th><th>Avg.</th><th></th></tr></thead><tbody><tr><td>FT (1.5 B)</td><td>1500 M</td><td>91.8</td><td>97.2</td><td>92.0</td><td>72.0</td><td>96.0</td><td>92.7</td><td>93.9</td><td>92.9</td><td>91.1</td><td></td></tr><tr><td><strong>LoRA (r=8, 4.7 M)</strong></td><td>4.7 M</td><td>91.9</td><td>96.9</td><td>92.6</td><td>72.4</td><td>96.0</td><td>92.9</td><td>94.9</td><td>93.0</td><td>91.3</td><td></td></tr></tbody></table><p>结果显示，LoRA 仅用 4.7 M 可训练参数，就能略微超过全量微调的 DeBERTa XXL，且比 Adapter 等方法表现更稳定。</p><hr><h3 id=54-gpt-2-mediumlarge-上的-nlg-任务>5.4 GPT-2 Medium/Large 上的 NLG 任务</h3><p>针对生成任务，论文在 E2E NLG Challenge、WebNLG、DART 等数据集上对比了以下方法。以 E2E NLG Challenge（指标包括 BLEU、NIST、METEOR、ROUGE-L、CIDEr；越高越好）为例：</p><table><thead><tr><th>模型 & 方法</th><th>可训练参数</th><th>BLEU</th><th>NIST</th><th>METEOR</th><th>ROUGE-L</th><th>CIDEr</th><th></th></tr></thead><tbody><tr><td>GPT-2 Medium (FT, 354.9 M)</td><td>354.9 M</td><td>68.2</td><td>8.62</td><td>0.4565</td><td>0.710</td><td>2.47</td><td></td></tr><tr><td>GPT-2 Medium (AdapterL, 0.37 M)</td><td>0.37 M</td><td>66.3</td><td>8.41</td><td>0.450</td><td>0.698</td><td>2.40</td><td></td></tr><tr><td>GPT-2 Medium (AdapterL, 11.09 M)</td><td>11.09 M</td><td>68.9</td><td>8.71</td><td>0.461</td><td>0.713</td><td>2.47</td><td></td></tr><tr><td>GPT-2 Medium (AdapterH, 11.09 M)</td><td>11.09 M</td><td>67.3</td><td>8.50</td><td>0.460</td><td>0.707</td><td>2.44</td><td></td></tr><tr><td>GPT-2 Medium (FTTop2, 25.19 M)</td><td>25.19 M</td><td>68.1</td><td>8.59</td><td>0.460</td><td>0.708</td><td>2.41</td><td></td></tr><tr><td>GPT-2 Medium (PreLayer, 0.35 M)</td><td>0.35 M</td><td>69.7</td><td>8.81</td><td>0.461</td><td>0.714</td><td>2.49</td><td></td></tr><tr><td><strong>GPT-2 Medium (LoRA, 0.35 M)</strong></td><td>0.35 M</td><td><strong>70.4</strong></td><td><strong>8.85</strong></td><td><strong>0.4689</strong></td><td><strong>0.7186</strong></td><td><strong>2.5349</strong></td><td></td></tr></tbody></table><table><thead><tr><th>模型 & 方法</th><th>可训练参数</th><th>BLEU</th><th>NIST</th><th>METEOR</th><th>ROUGE-L</th><th>CIDEr</th><th></th></tr></thead><tbody><tr><td>GPT-2 Large (FT, 774.0 M)</td><td>774.0 M</td><td>68.5</td><td>8.78</td><td>0.460</td><td>0.699</td><td>2.45</td><td></td></tr><tr><td>GPT-2 Large (AdapterL, 0.88 M)</td><td>0.88 M</td><td>69.1</td><td>8.68</td><td>0.463</td><td>0.714</td><td>2.49</td><td></td></tr><tr><td>GPT-2 Large (AdapterL, 23.00 M)</td><td>23.00 M</td><td>68.9</td><td>8.70</td><td>0.461</td><td>0.713</td><td>2.45</td><td></td></tr><tr><td>GPT-2 Large (PreLayer, 0.77 M)</td><td>0.77 M</td><td>70.3</td><td>8.85</td><td>0.462</td><td>0.717</td><td>2.47</td><td></td></tr><tr><td><strong>GPT-2 Large (LoRA, 0.77 M)</strong></td><td>0.77 M</td><td><strong>70.4</strong></td><td><strong>8.89</strong></td><td><strong>0.4689</strong></td><td><strong>0.720</strong></td><td><strong>2.47</strong></td><td></td></tr></tbody></table><p>由此可见，<strong>LoRA 在仅 0.3 M—0.8 M 可训练参数的情况下，取得了与全量微调相当甚至略优的生成质量</strong>。</p><hr><h3 id=55-gpt-3-175b-上的规模化实验>5.5 GPT-3 175B 上的规模化实验</h3><p>最后，论文将 LoRA 扩展至 GPT-3 175B，重点验证其在大模型下的可行性及性能。实验包括 WikiSQL（NL→SQL）、MultiNLI (MNLI-matched) 和 SAMSum（三元组对话摘要）三种任务，结果如下：</p><table><thead><tr><th>方法</th><th>可训练参数</th><th>WikiSQL (Acc. %)</th><th>MultiNLI-m (Acc. %)</th><th>SAMSum (Rouge-1/2/L)</th><th></th></tr></thead><tbody><tr><td>GPT-3 (FT)</td><td>175 255.8 M</td><td>73.8</td><td>89.5</td><td>52.0/28.0/44.5</td><td></td></tr><tr><td>GPT-3 (BitFit, 14.2 M)</td><td>14.2 M</td><td>71.3</td><td>91.0</td><td>51.3/27.4/43.5</td><td></td></tr><tr><td>GPT-3 (PreEmbed, 3.2 M)</td><td>3.2 M</td><td>63.1</td><td>88.6</td><td>48.3/24.2/40.5</td><td></td></tr><tr><td>GPT-3 (PreLayer, 20.2 M)</td><td>20.2 M</td><td>70.1</td><td>89.5</td><td>50.8/27.3/43.5</td><td></td></tr><tr><td>GPT-3 (AdapterH, 7.1 M)</td><td>7.1 M</td><td>71.9</td><td>89.8</td><td>53.0/28.9/44.8</td><td></td></tr><tr><td>GPT-3 (AdapterH, 40.1 M)</td><td>40.1 M</td><td>73.2</td><td>91.5</td><td>53.2/29.0/45.1</td><td></td></tr><tr><td><strong>GPT-3 (LoRA, 4.7 M)</strong></td><td>4.7 M</td><td>73.4</td><td>91.7</td><td>53.8/29.8/45.9</td><td></td></tr><tr><td><strong>GPT-3 (LoRA, 37.7 M)</strong></td><td>37.7 M</td><td>74.0</td><td>91.6</td><td>53.4/29.2/45.1</td><td></td></tr></tbody></table><p>可以看出，<strong>LoRA 在极少参数（4.7 M）情况下，已经逼近或超越了全量微调（175 B）的性能</strong>，并且随着可训练参数量增加（37.7 M），任务性能略有提升但基本趋于稳定。实验还给出了不同方法在可训练参数数目上的性能曲线（图 2），LoRA 的表现明显更为平滑和可扩展。</p><hr><h2 id=6-对-lora-更新矩阵的深入分析>6. 对 LoRA 更新矩阵的深入分析</h2><p>针对为何低秩更新能取得上述效果，论文进行了多项实证研究，探讨更新矩阵 $\Delta W$ 的秩及与原权重 $W$ 之间的关系。以下是关键结论：</p><h3 id=61-选取哪些权重进行-lora-更优>6.1 选取哪些权重进行 LoRA 更优</h3><p>在 GPT-3 175B 上设定约 18 M 参数预算，实验对比了在不同注意力矩阵上分别应用 LoRA 的效果（秩 $r$ 根据权重数目反算，适配 $W_q, W_v$ 时取 $r=4$，仅适配单矩阵时取 $r=8$）。结果（表 5）显示：</p><table><thead><tr><th>适配位置</th><th>可训练参数约 18 M</th><th>WikiSQL (Acc. %)</th><th>MNLI(m) (Acc. %)</th><th></th></tr></thead><tbody><tr><td>仅 $W_q$ (r=8)</td><td>18 M</td><td>68.8—70.4</td><td>90.7—90.9</td><td></td></tr><tr><td>仅 $W_k$ (r=8)</td><td>18 M</td><td>70.0</td><td>90.8</td><td></td></tr><tr><td>仅 $W_v$ (r=8)</td><td>18 M</td><td>73.0</td><td>91.0</td><td></td></tr><tr><td>仅 $W_o$ (r=8)</td><td>18 M</td><td>73.2</td><td>91.3</td><td></td></tr><tr><td>$W_q,W_k$ (各 r=4)</td><td>18 M</td><td>71.4</td><td>91.3</td><td></td></tr><tr><td><strong>$W_q,W_v$ (各 r=4)</strong></td><td>18 M</td><td><strong>73.7</strong></td><td><strong>91.3</strong></td><td></td></tr><tr><td>$W_q,W_k,W_v,W_o$ (r=2)</td><td>18 M</td><td>73.7</td><td>91.7</td><td></td></tr></tbody></table><p>可见，在预算固定时，<strong>同时适配 $W_q$ 与 $W_v$（各 $r=4$）能够获得最佳整体表现</strong>。单独适配某一矩阵往往次优，比如仅适配 $W_q$ 需要更高 $r$ 才能接近效果。</p><hr><h3 id=62-更新矩阵是否真低秩最佳秩--的选择>6.2 更新矩阵是否真低秩？最佳秩 $r$ 的选择</h3><p>实验进一步在 GPT-3 上考察了不同秩 $r$ 对下游任务性能的影响。以同时适配 $\{W_q,W_v\}$ 为例，在 WikiSQL 和 MNLI 上，当 $r$ 取 1、2、4、8、64 时，性能如表 6 所示：</p><table><thead><tr><th>适配位置</th><th>r</th><th>WikiSQL (±0.5 %)</th><th>MNLI (±0.1 %)</th></tr></thead><tbody><tr><td>仅 $W_q$</td><td>1</td><td>68.8</td><td>90.7</td></tr><tr><td>仅 $W_q$</td><td>2</td><td>69.6</td><td>90.9</td></tr><tr><td>仅 $W_q$</td><td>4</td><td>70.5</td><td>91.1</td></tr><tr><td>仅 $W_q$</td><td>8</td><td>70.4</td><td>90.7</td></tr><tr><td>仅 $W_q$</td><td>64</td><td>70.0</td><td>90.7</td></tr><tr><td><strong>$W_q,W_v$</strong></td><td>1</td><td>73.4</td><td>91.3</td></tr><tr><td>$W_q,W_v$</td><td>2</td><td>73.3</td><td>91.4</td></tr><tr><td>$W_q,W_v$</td><td>4</td><td>73.7</td><td>91.3</td></tr><tr><td>$W_q,W_v$</td><td>8</td><td>73.8</td><td>91.6</td></tr><tr><td>$W_q,W_v$</td><td>64</td><td>73.5</td><td>91.4</td></tr><tr><td>$W_q,W_k,W_v,W_o$</td><td>1</td><td>74.1</td><td>91.2</td></tr><tr><td>…</td><td>…</td><td>…</td><td>…</td></tr></tbody></table><p>可见，仅用 $r=1$ 即可让 $\{W_q,W_v\}$ 在这两项任务上达到接近最优性能，进一步说明了更新 $\Delta W$ 的“<strong>内在秩（intrinsic rank）</strong>”极低。反之，仅适配单个矩阵 $W_q$ 时则需要稍大 $r$ 才能逼近。</p><hr><h3 id=63-更新矩阵--与原权重--之间的关联>6.3 更新矩阵 $\Delta W$ 与原权重 $W$ 之间的关联</h3><p>论文借助**奇异值分解（SVD）<strong>和</strong>子空间相似度（Grassmann 距离投影）**来探究 $\Delta W$ 与 $W$ 的关联程度。</p><ol><li><p><strong>$\Delta W$ 是否与 $W$ 的主要奇异向量方向对齐？</strong>
定义对于矩阵 $W$ 的前 $r$ 个左右奇异向量分别为 $U_W \in \mathbb{R}^{d\times r}, V_W \in \mathbb{R}^{k\times r}$；对于 $\Delta W$ 的对应前 $r$ 个奇异向量为 $U_{\Delta}, V_{\Delta}$。论文计算了</p>$$
\lVert U_{\Delta}^\top\,W\,V_{\Delta} \rVert_F
\quad\text{与}\quad
\lVert W \rVert_F,\;\lVert \Delta W \rVert_F
$$<p>的对比，发现 <strong>$\Delta W$ 与 $W$ 之间存在明显相关性</strong>，即 $\lVert U_{\Delta}^\top\,W\,V_{\Delta} \rVert_F$ 远大于对随机矩阵情形，说明 $\Delta W$ 更倾向于放大 $W$ 中尚未充分强调但对下游任务重要的特征模式。举例：在 GPT-3 第 48 层 $W_q$ 上，当 $r=4$ 时，有</p>$$
\frac{\|\Delta W_q\|_F}{\|U_{\Delta}^\top\,W_q\,V_{\Delta}\|_F} \approx 21.5,
\quad
\lVert W_q\rVert_F \approx 61.95,\;\lVert \Delta W_q\rVert_F \approx 6.91,\;\lVert U^\top W_q V\rVert_F \approx 0.32,
$$<p>而随机矩阵投影仅约 0.02，可见 $\Delta W$ 在特征放大方面的力度远超随机噪声。</p></li><li><p><strong>不同秩 $r$ 学得的子空间是否一致？</strong>
论文考察了在相同层（如 GPT-3 第 48 层）下，$\Delta W$ 当 $r=8$ 与 $r=64$ 时得到的奇异值向量子空间之间的重叠程度，计算归一化子空间相似度 $\phi(\Delta W_{r=8}, \Delta W_{r=64})$，发现<strong>最重要的前几维方向（尤其第 1 奇异向量）高度重合</strong>，而后续方向多为噪声。由此进一步佐证：$\Delta W$ 的“有效秩”非常低。</p></li><li><p><strong>不同随机种子学得的 $\Delta W$ 子空间是否稳定？</strong>
当 $r=64$ 时，论文对两次随机初始化训练得到的 $\Delta W$ 做同样的子空间相似度分析，发现<strong>前数个奇异方向在不同种子之间具有一定重叠</strong>，而随机高秩矩阵之间却无此现象。说明 LoRA 的优化结果并非完全随机，而是在低秩子空间里学得了较稳定的模式。</p></li></ol><hr><h2 id=7-结论与展望>7. 结论与展望</h2><h3 id=71-主要贡献>7.1 主要贡献</h3><ol><li>提出 <strong>LoRA</strong>，利用低秩分解技术，仅对部分权重层注入 $B\in \mathbb{R}^{d \times r}$、$A\in \mathbb{R}^{r \times d}$ 两个低秩矩阵进行微调，而冻结大部分预训练权重，从而显著降低可训练参数量（如 GPT-3 175B 仅需 $\sim4.7$ M），同时在推理阶段不引入额外时延。</li><li>在多种模型（RoBERTa、DeBERTa、GPT-2、GPT-3）和任务（NLU、NLG）上全面实验，证明 LoRA 在仅用数百万参数的情况下，能够<strong>获得或超过全量微调的性能</strong>，并优于其他高效微调方法（Adapter、Prefix 等）。</li><li>通过实证分析，揭示了<strong>微调更新矩阵 $\Delta W$ 的“内在秩”极低</strong>，并与原权重 $W$ 具有显著相关性，从而从<strong>理论和经验</strong>两方面说明 LoRA 原理的合理性。</li></ol><h3 id=72-未来研究方向>7.2 未来研究方向</h3><p>论文指出若干可拓展方向：</p><ol><li><strong>与其他高效微调方法结合</strong>：如将 LoRA 与 Prefix-Tuning、Adapter、Tensor-Product 结构等组合，或利用不同张量分解方法进一步压缩参数空间。</li><li><strong>微调机理研究</strong>：深入探索为何低秩更新能够捕获下游任务所需特征，以及 $\Delta W$ 如何重塑预训练特征空间。LoRA 的低秩约束使得此类分析更易开展。</li><li><strong>自动化权重选取</strong>：目前论文主要通过经验或少量验证选取在哪些权重矩阵上应用 LoRA；未来可研究更<strong>有理论依据</strong>或通过自动搜索的方式来决定最优注入位置。</li><li><strong>进一步压缩与加速</strong>：针对不同任务的秩需求进行动态调节，或探索更稀疏/结构化的低秩分解形式，以在更严格资源约束下保持性能。</li></ol><p>总之，LoRA 在保持推理效率的前提下，实现了对大规模预训练模型微调的<strong>极大参数压缩</strong>，为大模型在资源受限环境下的下游部署提供了可行方案，并为进一步研究微调机理提供了启发。</p><p><a href=/pdf/28.LoRA-2106.09685v2.ch.pdf>论文中文译文</a></p><iframe src=/pdf/Advanced_Battle_Management_System.pdf width=100% height=600 style="border:1px solid #ccc">此浏览器不支持 iframe，请
<a href=/pdf/28.LoRA-2106.09685v2.ch.pdf>点击下载 PDF</a></iframe><footer class=footline><i class='fa-fw fas fa-calendar'></i> 2025-06-01</footer></article></div></main></div><aside id=R-sidebar class=default-animation><div id=R-header-topbar class=default-animation></div><div id=R-header-wrapper class=default-animation><div id=R-header class=default-animation><a id=R-logo href=/index.html><img src=/images/logo.png alt="FlitSoft Docs" style=width:80px;height:auto></a></div><search><form action=/search/index.html method=get><div class="searchbox default-animation"><button class=search-detail type=submit title="Search (CTRL+ALT+f)"><i class="fas fa-search"></i></button>
<label class=a11y-only for=R-search-by>Search</label>
<input data-search-input id=R-search-by name=search-by class=search-by type=search placeholder=Search...>
<button class=search-clear type=button data-search-clear title="Clear search"><i class="fas fa-times" title="Clear search"></i></button></div></form></search></div><div id=R-homelinks class=default-animation><div class="R-menu-divider default-animation"><hr class=padding></div><div class="R-sidebarmenu R-shortcutmenu-homelinks"><ul class="space collapsible-menu"></ul></div><div class="R-menu-divider default-animation"><hr class=padding></div><div class="R-sidebarmenu R-shortcutmenu-headercontrols"><ul></ul></div><div class="R-menu-divider default-animation"><hr class=padding></div></div><div id=R-content-wrapper class=highlightable><div class="R-sidebarmenu R-shortcutmenu-main"><ul class="enlarge morespace collapsible-menu"><li data-nav-id=/uas/index.html><a class=padding href=/uas/index.html>UAS</a><ul id=R-subsections-50d6e18f3c774adcdf96c62beb3fb9ae class=collapsible-menu></ul></li><li data-nav-id=/em/index.html><a class=padding href=/em/index.html>EM</a><ul id=R-subsections-5221d921411ef33ede36c0310590339e class=collapsible-menu></ul></li><li class=parent data-nav-id=/agi/index.html><a class=padding href=/agi/index.html>AI</a><ul id=R-subsections-b697951847df19851ae8635cac95c15a class=collapsible-menu><li class=active data-nav-id=/agi/lora/index.html><a class=padding href=/agi/lora/index.html>LoRA</a></li><li data-nav-id=/agi/why-we-think-ch/index.html><a class=padding href=/agi/why-we-think-ch/index.html>Why We Think</a></li><li data-nav-id=/agi/foundation-models-and-intelligent-decision-making.ch/index.html><a class=padding href=/agi/foundation-models-and-intelligent-decision-making.ch/index.html>基础模型与智能决策</a></li></ul></li><li data-nav-id=/gaming/index.html><a class=padding href=/gaming/index.html>Gaming</a></li><li data-nav-id=/c2/index.html><a class=padding href=/c2/index.html>C2</a><ul id=R-subsections-e0126222f5f1b52fd67c95ccf5ad1c18 class=collapsible-menu></ul></li><li data-nav-id=/simu/index.html><a class=padding href=/simu/index.html>Simulation</a><ul id=R-subsections-80cfed847676c641fa01f11f3f2904bf class=collapsible-menu></ul></li><li data-nav-id=/visual/index.html><a class=padding href=/visual/index.html>Visualization</a><ul id=R-subsections-080a96fba97ea97926a463e36c9cb108 class=collapsible-menu></ul></li><li data-nav-id=/log/index.html><a class=padding href=/log/index.html>Log</a></li></ul></div><div class="R-sidebarmenu R-shortcutmenu-shortcuts"><ul class="space collapsible-menu"></ul></div><div id=R-footer-margin></div><div class="R-menu-divider default-animation"><hr class=padding></div><div class="R-sidebarmenu R-shortcutmenu-footercontrols"><ul><li class=R-variantswitcher><div class="padding menu-control"><i class="fa-fw fas fa-paint-brush"></i>
<span>&nbsp;</span><div class=control-style><label class=a11y-only for=R-select-variant>Theme</label>
<select id=R-select-variant><option id=R-select-variant-zen-light value=zen-light selected>Zen Light</option><option id=R-select-variant-zen-dark value=zen-dark>Zen Dark</option></select></div><div class=clear></div></div><script>window.relearn.markVariant()</script></li></ul></div><div id=R-footer><p>Built By FiltSoft</p></div></div></aside><script src=/js/clipboard/clipboard.min.js?1749791745 defer></script><script src=/js/perfect-scrollbar/perfect-scrollbar.min.js?1749791745 defer></script><script>window.MathJax=Object.assign(window.MathJax||{},{tex:{inlineMath:[["\\(","\\)"],["$","$"]],displayMath:[["\\[","\\]"],["$$","$$"]]},options:{enableMenu:!1}},JSON.parse("{}"))</script><script id=MathJax-script async src=/js/mathjax/tex-mml-chtml.js?1749791745></script><script src=/js/theme.min.js?1749791745 defer></script></body></html>